[
    {
        "timestamp": "2025-06-10 16:12:00",
        "task_name": "research_task",
        "task": "阅读论文《HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization》，论文内容如下：# HeuriGym: An Agentic Benchmark for LLM-Crafted Heuristics in Combinatorial Optimization\n\nHongzheng Chen1<sup>∗</sup> Yingheng Wang1<sup>∗</sup> Yaohui Cai1<sup>∗</sup> Hins Hu1<sup>∗</sup> Jiajie Li1<sup>∗</sup> Shirley Huang<sup>2</sup> Chenhui Deng<sup>3</sup> Rongjian Liang<sup>3</sup> Shufeng Kong<sup>1</sup> Haoxing Ren<sup>3</sup> Samitha Samaranayake<sup>1</sup> Carla P. Gomes<sup>1</sup> Zhiru Zhang<sup>1</sup> <sup>1</sup> Cornell University <sup>2</sup> Harvard University <sup>3</sup> NVIDIA Corporation {hzchen,yingheng}@cs.cornell.edu, {yc2632,zh223,jl4257}@cornell.edu\n\n# Abstract\n\nWhile Large Language Models (LLMs) have demonstrated significant advancements in reasoning and agent-based problem-solving, current evaluation methodologies fail to adequately assess their capabilities: existing benchmarks either rely on closed-ended questions prone to saturation and memorization, or subjective comparisons that lack consistency and rigor. In this work, we introduce HeuriGym, an agentic framework designed for evaluating heuristic algorithms generated by LLMs for combinatorial optimization problems, characterized by clearly defined objectives and expansive solution spaces. HeuriGym empowers LLMs to propose heuristics, receive evaluative feedback via code execution, and iteratively refine their solutions. We evaluate nine state-of-the-art models on nine problems across domains such as computer systems, logistics, and biology, exposing persistent limitations in tool use, planning, and adaptive reasoning. To quantify performance, we propose the Quality-Yield Index (QYI), a metric that captures both solution pass rate and quality. Even top models like GPT-o4-mini-high and Gemini-2.5-Pro attain QYI scores of only 0.6, well below the expert baseline of 1. Our open-source benchmark aims to guide the development of LLMs toward more effective and realistic problem-solving in scientific and engineering domains.\n\n# <span id=\"page-0-0\"></span>1 Introduction\n\nRecent advancements in Large Language Models (LLMs) have significantly expanded their capabilities in complex reasoning and agent-based problem-solving, enabling applications ranging from automated code generation [\\[25,](#page-10-0) [79,](#page-13-0) [177\\]](#page-18-0) to dynamic decision-making systems [\\[126,](#page-15-0) [165\\]](#page-17-0). Despite these breakthroughs, existing evaluation frameworks struggle to rigorously assess the full spectrum of LLMs' emergent abilities. Traditional benchmarks increasingly fail to capture the nuanced demands of real-world tasks that require iterative reasoning, creative algorithm design, and adaptive tool use. This limitation creates a critical gap in understanding whether LLMs can transcend pattern recognition and demonstrate genuine problem-solving ingenuity in real-world scenarios.\n\nCurrent evaluation paradigms fall into two categories with distinct limitations. (1) Ground-truthbased objective benchmarks rely on closed-form questions (e.g., multiple-choice mathematics problems) that have become susceptible to rapid performance saturation. Widely used benchmarks such as AIME [\\[102\\]](#page-14-0), HumanEval [\\[25\\]](#page-10-0), and GPQA Diamond [\\[115\\]](#page-14-1) now exhibit ceiling effects, with state-of-the-art models achieving over 80% accuracy [\\[103,](#page-14-2) [141,](#page-16-0) [38\\]](#page-10-1). Even emerging evaluations like Humanity's Last Exam (HLE) [\\[111\\]](#page-14-3), initially proposed as a rigorous PhD-level test, saw performance leap from 3% to 25% within months of release [\\[103\\]](#page-14-2). These benchmarks face a dual crisis: their static question banks risk data contamination as models ingest newer training data, while their\n\n<sup>∗</sup>Core Contributor\n\nclosed-ended nature fails to reflect real-world problem-solving where solutions are neither unique nor predefined. (2) Judge-preference-based subjective evaluations, such as Chatbot Arena [\\[27\\]](#page-10-2), take a different approach by assessing model quality through pairwise comparisons by humans or LLM-based proxies [\\[174\\]](#page-17-1). These benchmarks support a wide range of plausible outputs, making them better suited for open-ended tasks. However, this flexibility introduces high variance: everyday communication tasks are inherently subjective, and judgments often prioritize superficial factors like response structure or emoji usage over substantive reasoning quality [\\[132,](#page-15-1) [169\\]](#page-17-2). While recent efforts to automate evaluation with LLM-as-a-judge systems show promise, their reliability remains inconsistent across domains [\\[71\\]](#page-12-0), particularly for technical tasks requiring specialized expertise.\n\nTo address these limitations, we introduce HeuriGym[1](#page-1-0) , a new evaluation paradigm with an agentic framework centered on combinatorial optimization problems, which naturally combine *well-defined objectives* with *large solution spaces*. Such problems are foundational across domains including computer systems [\\[15,](#page-9-0) [97,](#page-14-4) [88\\]](#page-13-1), scientific reasoning [\\[20,](#page-10-3) [21\\]](#page-10-4), computational biology [\\[153,](#page-16-1) [139,](#page-16-2) [28\\]](#page-10-5), logistics [\\[77,](#page-12-1) [51\\]](#page-11-0), and electronic design automation [\\[19,](#page-9-1) [33\\]](#page-10-6). They are well-suited for benchmarking LLMs because they resist memorization due to their computational hardness, offer clear metrics for quantitative evaluation, and reflect real-world use cases where optimal solutions are tractable only for small instances. Importantly, no single heuristic or optimization algorithm dominates across all problems or instances [\\[155\\]](#page-16-3), resulting in a rich and diverse search space. Tackling these challenges requires not only algorithmic knowledge but also heuristic reasoning, tradeoff navigation, and creative problem-solving — skills that are still underexplored in current LLM evaluations. Our framework extends beyond conventional static evaluations by implementing an interactive agentic loop: LLMs generate heuristic algorithms, receive execution feedback from a code environment, and iteratively refine their solutions. This process mirrors practical engineering workflows and enables deeper evaluation of multi-step reasoning, tool use, and instruction following.\n\nOur benchmark systematically evaluates LLMs across four dimensions: (1) *tool-augmented reasoning* through integration with external libraries, (2) *multi-step planning* in decomposing complex problems into executable sub-tasks, (3) *instruction fidelity* in adhering to problem constraints, and (4) *iterative refinement* based on runtime feedback. The framework uniquely probes practical creativity – the ability to adapt textbook algorithms or invent novel strategies for large-scale instances where exact methods like integer linear programming (ILP) may fail.\n\nTo capture both the number of feasible solutions and their quality relative to expert performance, we introduce a unified metric – the Quality-Yield Index (QYI) – which ranges from 0 (all outputs are incorrect or low-quality) to 1 (expert-level performance). Empirical results reveal substantial performance gap: across nine diverse optimization problems, even state-of-the-art LLMs such as GPT-o4-mini-high [\\[103\\]](#page-14-2) and Gemini-2.5-Pro [\\[38\\]](#page-10-1) achieve QYI scores around 0.6, underscoring their limited effectiveness in realistic problem-solving settings. These findings highlight the limitations of current benchmarks, which fail to capture the complex, real-world demands of computational problem-solving—where success requires integrating theoretical understanding, tool proficiency, and adaptive reasoning. The contributions of this work are threefold:\n\n- An open-source benchmark suite of nine combinatorial optimization problems that evaluates LLMs' multi-step reasoning capabilities through realistic programming tasks.\n- An end-to-end agentic framework supporting LLM solution generation, automated verification, quantitative evaluation with well-defined metrics, and iterative refinement.\n- A comprehensive empirical study of cutting-edge LLMs, uncovering their current limitations and offering actionable insights for the development of next-generation models and agents.\n\n# 2 Related Work\n\nLLMs for Combinatorial Optimization. Recent LLM-based combinatorial optimization (CO) methods follow two main paradigms. The first emphasizes formalization – translating natural language into structured optimization problems. This direction was initiated by the NL4Opt Competition [\\[114\\]](#page-14-5), with follow-up work improving domain-specific model training [\\[157,](#page-17-3) [65,](#page-12-2) [78\\]](#page-13-2) and prompting strategies [\\[161,](#page-17-4) [3,](#page-9-2) [62\\]](#page-12-3). While effective on benchmarks, these methods struggle to scale due to their reliance on exact solvers [\\[53\\]](#page-11-1). The second paradigm focuses on heuristic discovery. FunSearch [\\[117\\]](#page-15-2) and\n\n<span id=\"page-1-0\"></span><sup>1</sup> <https://github.com/cornell-zhang/heurigym>\n\n<span id=\"page-2-0\"></span>\n\n| Subjects                      | Benchmark                           | Well-Defined<br>Objective | Large<br>Solution Space | Agentic<br>Setting | Evaluation<br>Metrics |\n|-------------------------------|-------------------------------------|---------------------------|-------------------------|--------------------|-----------------------|\n| Frontier<br>Knowledge         | Humanity's Last Exam<br>(HLE) [111] | ✓                         | ✗                       | ✗                  | Accuracy              |\n|                               | HumanEval(+) [25, 86]               | ✓                         | ✗                       | ✗                  | pass@k                |\n| Software<br>Engineering       | BigCodeBench [177]                  | ✓                         | ✗                       | ✗                  | pass@k                |\n|                               | LiveCodeBench [63]                  | ✓                         | ✗                       | ✗                  | pass@1                |\n|                               | SWE-Bench [66]                      | ✓                         | ✗                       | ✗                  | pass@1                |\n|                               | Commit0 [171]                       | ✓                         | ✗                       | ✓                  | Pass rate             |\n| Performance<br>Engineering    | KernelBench [106]                   | ✗                         | ✓                       | ✗                  | fastp                 |\n| Daily-Life Tasks              | Chatbot Arena [27]                  | ✗                         | ✓                       | ✗                  | ELO                   |\n|                               | τ -Bench [164]                      | ✓                         | ✓                       | ✓                  | pass∧k                |\n|                               | NPHardEval [49]                     | ✓                         | ✗                       | ✗                  | Accuracy              |\n| Combinatorial<br>Optimization | GraphArena [140]                    | ✓                         | ✗                       | ✗                  | Accuracy              |\n|                               | HeuriGym (This work)                | ✓                         | ✓                       | ✓                  | solves@i, QYI         |\n\nTable 1: Comparison with other recent benchmarks.\n\nAlphaEvolve [\\[100\\]](#page-14-7) use LLMs with evolutionary search to generate novel heuristics, but require evaluating thousands of candidates. Recent approaches [\\[166,](#page-17-7) [84,](#page-13-4) [36,](#page-10-7) [176\\]](#page-18-1) improve efficiency via metaheuristic templates, but still limit LLMs to filling in scoring functions rather than designing full algorithms. In contrast, HeuriGym removes reliance on templates or scaffolds. It tasks LLMs with generating complete, self-contained optimization programs, including custom data structures and end-to-end pipelines – better reflecting real-world CO challenges, where success hinges on uncovering problem-specific structure and designing bespoke algorithms [\\[155\\]](#page-16-3).\n\nEvaluation on LLMs. As shown in Table [1,](#page-2-0) existing LLM benchmarks expose key limitations. Many focus on closed-ended tasks in domains like mathematics [\\[102\\]](#page-14-0), programming [\\[25,](#page-10-0) [177,](#page-18-0) [86\\]](#page-13-3), and specialized knowledge [\\[115,](#page-14-1) [111,](#page-14-3) [57\\]](#page-11-3), with fixed ground-truths that are prone to data contamination (see Section [1\\)](#page-0-0). In contrast, open-ended benchmarks such as Chatbot Arena [\\[27\\]](#page-10-2) and KernelBench [\\[106\\]](#page-14-6) encourage diverse outputs but often lack clear objectives, resulting in inconsistent evaluations. Benchmarks like NPHardEval [\\[49\\]](#page-11-2) and GraphArena [\\[140\\]](#page-16-4) assess exact solutions to small NP-hard instances, limiting real-world relevance where heuristic solutions are often preferred for scalability. Our benchmark instead accepts any *feasible* solution that satisfies constraints, enabling broader evaluation of algorithmic reasoning. It tasks LLMs with synthesizing executable code, using external libraries, and refining solutions through execution feedback, mimicking realistic workflows. We also propose new evaluation metrics to quantify multi-round reasoning, as detailed in Section [3.2.](#page-3-0)\n\n# 3 HeuriGym: An Agentic Framework for Heuristic Generation\n\nIn this section, we introduce our agentic framework for evaluating LLM reasoning via iterative heuristic generation, along with benchmark metrics for quantitative assessment.\n\n## 3.1 Overview\n\nAs illustrated in Fig. [1,](#page-3-1) our framework begins by presenting a formal problem description to the LLM, which is then prompted to generate a complete heuristic algorithm. The generated program conforms to a standardized function signature and is subsequently compiled (for C++) or interpreted (for Python). Upon execution, the solution is verified for yield and evaluated for performance. Crucially, the framework incorporates a feedback loop: execution logs, verification outcomes, and evaluation costs from a small demonstration set are appended back to the prompt, enabling iterative refinement of the LLM-generated solution.\n\n### 3.1.1 Problem Description\n\nAs shown on the left of Fig. [1,](#page-3-1) we use operator scheduling [\\[33,](#page-10-6) [87\\]](#page-13-5), a classic optimization problem in electronic design automation, as an example. Each benchmark task is accompanied by a structured problem description with three main parts: (1) Background: Introduces the optimization context and key terminology to help the LLM understand the problem setting. (2) Formalization: Defines the optimization objective and constraints using mathematical notation (e.g., minimizing latency under\n\n<span id=\"page-3-1\"></span>![](_page_3_Figure_0.jpeg)\n\nFigure 1: Overview of the HeuriGym agentic framework for heuristic program generation, execution, and verification. We use operator scheduling [\\[33\\]](#page-10-6) as an example for the problem description.\n\nhardware resource constraints), guiding the LLM toward objective-oriented algorithm design. (3) Input/Output Format: Specifies the structure of input and output files, providing clear expectations for parsing and execution. More detailed information on the problem set can be found in Section [4.](#page-4-0)\n\n### 3.1.2 Prompt Design\n\nEffective prompt engineering is crucial for leveraging LLMs' capabilities [\\[152,](#page-16-5) [122\\]](#page-15-3). We construct both system- and user-level prompts, tailored to each problem instance. A complete prompt example is provided in Appendix [A.](#page-20-0)\n\nSystem prompt. The system prompt includes machine configuration details (e.g., CPU cores, memory limits), available libraries with version numbers, and task-specific constraints such as execution timeouts. This environment specification instructs the LLM to avoid relying on unrealistic assumptions or producing inefficient solutions that violate runtime limits.\n\nUser prompt. In the initial iteration, the user prompt includes the problem description and a code skeleton with a predefined function signature. As shown in Fig. [1,](#page-3-1) the LLM is only provided the interface – function name, input path, and output path – without hints on data structures or algorithmic approache, contrasting with prior work [\\[117,](#page-15-2) [84,](#page-13-4) [166\\]](#page-17-7) that often handcrafts partial implementations or restricts the design space. Here, LLMs must reason about the problem holistically: parsing inputs, constructing internal representations, and designing and implementing heuristics from scratch.\n\n### <span id=\"page-3-2\"></span>3.1.3 Feedback Loop\n\nTo emulate a few-shot in-context learning setup [\\[42,](#page-11-4) [85,](#page-13-6) [156\\]](#page-17-8), we partition the dataset into a small *demonstration set* (around five instances) and a larger *evaluation set*. Demonstration data is used during the refinement loop to provide timely, example-based feedback to the LLM; the evaluation set is withheld until the model stabilizes its performance.\n\nEach problem includes a domain-specific verifier and evaluator. The verifier ensures constraint satisfaction (e.g., dependency preservation in operator scheduling), while the evaluator calculates the cost based on the given problem objective. If the verifier fails, diagnostic messages are recorded.\n\nAfter each iteration, we log the LLM-generated solution, execution trace, verification result, and evaluation score. These logs are appended to the prompt with the demonstration data in the next iteration, enabling the LLM to learn from past attempts and incrementally improve its output.\n\n### <span id=\"page-3-0\"></span>3.2 Metric Design\n\nTraditional LLM benchmarks predominantly rely on the pass@k metric [\\[25,](#page-10-0) [177,](#page-18-0) [66\\]](#page-12-5), which measures the probability of generating a ground-truth solution within the top-k samples. While pass@k is effective for single-turn tasks with deterministic ground truths, it falls short in capturing the iterative reasoning and problem-solving abilities required in our multi-round agentic setting. Specifically, it does not reflect whether the LLM can understand problem constraints, debug based on feedback, or iteratively refine its solutions over multiple attempts.\n\nTo better evaluate LLMs in this complex setting, we introduce a new metric, denoted as solves@i, which tracks the LLM's ability to solve constrained problems within i iterations:\n\n$$\n\\mathtt{solve}_s @ i := \\frac{1}{N} \\sum_{n=1}^{N} \\mathbb{1}(\\text{pass stage } s \\text{ in the } \\text{first } i\\text{-th iteration}),\n$$\n\nwhere N is the total number of test instances, and s ∈ {I, II, III} indicates the specific stage of the pipeline that the solution must pass. Each stage reflects a key milestone in agentic reasoning:\n\n- Stage I: Execution. The generated program must compile or interpret correctly with all necessary libraries included, and successfully perform basic I/O operations (e.g., reading and writing files).\n- Stage II: Solution Generation. The program must produce a non-empty output within the predefined timeout and adhere to the expected output format.\n- Stage III: Verification. The solution must satisfy all problem-specific constraints, as checked by a problem-specific verifier.\n\nHowever, solves@i only indicates whether a *feasible* solution is eventually produced through the iterative process – it does not account for solution quality. To address this, we additionally define separate metrics for quality and yield as follows:\n\n$$\n\\text{Quality} = \\frac{1}{\\hat{N}} \\sum_{n=1}^{\\hat{N}} \\min \\left( 1, \\frac{c_n^\\star}{c_n} \\right) \\qquad \\text{Yield} = \\frac{\\hat{N}}{N} \\, ,\n$$\n\nwhere c<sup>n</sup> and c ⋆ n represent the cost of the LLM-generated and expert-provided solutions, respectively, and Nˆ is the number of instances that pass verification (Stage III) in the *current* iteration. In this paper, we adopt the capped version of quality, which checks whether the LLM matches expert performance (up to a maximum of 1), though an uncapped version can also be used to measure cases where the LLM outperforms the expert. We define a unified metric, the *Quality-Yield Index (QYI)*, as the harmonic mean of quality and yield. This formulation, analogous to the F-score [\\[144\\]](#page-16-6), penalizes imbalanced values more strongly than the arithmetic mean:\n\n$$\n\\texttt{QYI} = \\frac{2 \\cdot \\texttt{Quality} \\cdot \\texttt{Yield}}{\\texttt{Quality} + \\texttt{Yield}}\\,.\n$$\n\nQYI captures both success rate and the relative quality of solutions, enabling holistic evaluation of an LLM's agentic reasoning capabilities, including its capacity for long-horizon planning and iterative refinement. Additionally, we can define a weighted QYI by averaging QYI scores across different problems, weighted by the number of instances in each, as an overall performance metric.\n\n# <span id=\"page-4-0\"></span>4 Benchmark Construction\n\nThis section outlines the construction of our combinatorial optimization benchmark, detailing the principles behind problem selection and providing an overview of the resulting problem set.\n\n### 4.1 Problem Selection Criteria\n\nOur primary goal is to evaluate an LLM's capacity for reasoning rather than its ability to regurgitate well-known algorithms. To this end, we intentionally exclude ubiquitous problems such as the Traveling Salesman Problem [\\[116\\]](#page-15-4) and canonical satisfiability (SAT) formulations [\\[125\\]](#page-15-5) – problems that are so widely studied and frequently included in public datasets that they are likely memorized during pretraining. Instead, we focus on problems that meet the following criteria:\n\nLimited exposure in the literature. For each candidate problem, we perform a Google Scholar search and retain it only if the most-cited paper has fewer than 1,000 citations (as of April 2025). This\n\n<span id=\"page-5-0\"></span>\n\n| Domain            | Problem                             | References      | Difficulty |\n|-------------------|-------------------------------------|-----------------|------------|\n|                   | Operator scheduling                 | [33, 129, 87]   | ⋆          |\n| Electronic Design | Technology mapping                  | [19, 95]        | ⋆⋆         |\n| Automation (EDA)  | Global routing                      | [80, 81]        | ⋆⋆⋆        |\n|                   | E-graph extraction                  | [15, 50, 154]   | ⋆          |\n| Compilers         | Intra-operator parallelism          | [97, 175, 44]   | ⋆⋆         |\n| Computational     | Protein sequence design             | [139, 56, 70]   | ⋆          |\n| Biology           | Mendelian error detection           | [153, 123, 101] | ⋆⋆         |\n|                   | Airline crew pairing                | [51, 2, 90]     | ⋆⋆         |\n| Logistics         | Pickup and delivery w/ time windows | [77, 46]        | ⋆⋆⋆        |\n\nTable 2: Existing combinatorial optimization problems in our HeuriGym benchmark.\n\nempirical threshold ensures that the problem is well-defined and supported by peer-reviewed work, yet not so well-known that an LLM could solve it through rote memorization or pattern matching.\n\nClear natural-language specification with well-defined objectives. Each problem must be clearly expressible using plain language without the need for visual aids. We encode mathematical objectives in LATEX to eliminate ambiguity, ensuring the LLM receives well-specified instructions.\n\nLarge solution spaces. We focus on problems that admit vast solution spaces with many feasible outputs, encouraging creative exploration and reasoning rather than narrow pattern recognition [\\[60\\]](#page-12-7).\n\nScalable data instances. Each problem includes two disjoint sets of instances: a small-scale demonstration set and a large-scale evaluation set, differing by at least an order of magnitude. The demonstration set supports few-shot prompting and iterative refinement, while the evaluation set is reserved for final performance testing, as discussed in Section [3.1.3.](#page-3-2)\n\nReproducible expert baselines. Reference implementations are bundled in the benchmark repository to ensure fair comparison across future studies. Where possible, we include both exact solvers (e.g., ILP) and high-quality heuristics to illuminate the performance gap.\n\nWe prioritize domains with real-world impact, where even small gains yield significant societal or industrial benefits. Many selected problems remain open, with heuristics far from theoretical bounds – offering a compelling testbed for LLMs.\n\n### 4.2 Dataset Statistics\n\nThe initial release of the HeuriGym benchmark includes nine distinct optimization problems spanning four scientific and engineering domains, as summarized in Table [2.](#page-5-0) For each problem, we provide around five demonstration instances and 20 large-scale evaluation instances, totaling 218 data instances. All datasets are derived from realistic sources and real-world applications, enhancing the benchmark's practical relevance. In addition, we reserve hundreds of instances as private test sets for future release and evaluation.\n\nA detailed description of each problem is provided in Appendix [C.](#page-23-0) Notably, most problems in the benchmark are NP-hard and feature complex constraints, resulting in a compact yet highly challenging problem suite. Despite its modest size, the benchmark still presents substantial difficulty for current state-of-the-art LLMs, as shown in Section [5.](#page-6-0)\n\nTo ensure clarity and correctness, we adopt a human-in-the-loop process for problem specification. After drafting the initial natural-language description, an annotator prompts a weaker LLM [\\[83\\]](#page-13-11) to identify any unclear or ambiguous statements. Discrepancies are iteratively resolved until the description is unambiguous and fully aligned with the intended semantics. The full prompt template used for refining problem descriptions is provided in Appendix [A.](#page-20-0)\n\nEach problem includes a task-specific verifier and evaluator to assess solution pass rate and quality. A separate reviewer ensures the expert solver reproduces published results and passes both checks.\n\nLooking forward, we plan to extend HeuriGym along two axes: (1) *breadth*, by incorporating additional combinatorial optimization problems from underexplored scientific domains; and (2) *depth*, by scaling existing problems to larger instance sizes and tighter constraint settings. Community contributions are welcome, provided new problems satisfy the selection criteria articulated above.\n\n<span id=\"page-6-1\"></span>\n\n|                   |       | solveIII |       |        | solveII |       | solveI |        |        |\n|-------------------|-------|----------|-------|--------|---------|-------|--------|--------|--------|\n| Model             | @10   | @5       | @1    | @10    | @5      | @1    | @10    | @5     | @1     |\n| DeepSeek-V3       | 46.8% | 42.7%    | 14.2% | 87.6%  | 83.0%   | 66.1% | 100.0% | 100.0% | 90.8%  |\n| DeepSeek-R1       | 73.4% | 72.9%    | 44.0% | 88.1%  | 88.1%   | 60.6% | 100.0% | 100.0% | 71.6%  |\n| Gemini-2.5-Flash  | 67.4% | 58.3%    | 25.2% | 83.9%  | 79.4%   | 56.4% | 100.0% | 100.0% | 72.9%  |\n| Gemini-2.5-Pro    | 65.1% | 64.2%    | 20.2% | 89.4%  | 89.0%   | 42.7% | 100.0% | 100.0% | 51.4%  |\n| LLaMA-4-Maverick  | 35.8% | 33.5%    | 6.0%  | 84.9%  | 74.3%   | 8.3%  | 85.3%  | 85.3%  | 13.3%  |\n| LLaMA-3.3-70B     | 33.9% | 33.9%    | 20.6% | 78.4%  | 78.4%   | 40.4% | 99.5%  | 99.5%  | 61.9%  |\n| Qwen3-235B        | 45.9% | 45.4%    | 38.5% | 86.2%  | 83.0%   | 56.0% | 100.0% | 100.0% | 70.6%  |\n| Claude-3.7-Sonnet | 60.1% | 58.7%    | 9.2%  | 97.7%  | 97.7%   | 41.3% | 100.0% | 100.0% | 60.1%  |\n| GPT-o4-mini       | 74.8% | 69.7%    | 53.2% | 100.0% | 100.0%  | 93.1% | 100.0% | 100.0% | 100.0% |\n\nTable 3: Overall solves@i metric of models on the whole HeuriGym benchmark.\n\n<span id=\"page-6-2\"></span>![](_page_6_Figure_2.jpeg)\n\nFigure 2: Quality-Yield Index and estimated API cost of different models.\n\n# <span id=\"page-6-0\"></span>5 Evaluation\n\nTo evaluate the reasoning capabilities of LLMs on combinatorial optimization problems, we benchmark nine prominent models released in late 2024 and early 2025. These include OpenAI GPT-o4-mini-high [\\[103\\]](#page-14-2), Anthropic Claude-3.7-Sonnet [\\[9\\]](#page-9-4), DeepSeek-V3 [\\[83\\]](#page-13-11) and DeepSeek-R1 [\\[52\\]](#page-11-9), Google Gemini-2.5-Flash and Pro [\\[38\\]](#page-10-1), Meta LLaMA-3.3 [\\[91\\]](#page-13-12) and LLaMA-4-Maverick [\\[92\\]](#page-13-13), and Alibaba Qwen3-235B [\\[141\\]](#page-16-0). These models represent the current state-of-the-art in general-purpose LLMs and rank among the top entries on OpenRouter [\\[104\\]](#page-14-9) and Chatbot Arena leaderboards [\\[27\\]](#page-10-2). We exclude smaller models due to the complexity of the benchmark tasks. Detailed model specifications are provided in Appendix [B.](#page-23-1)\n\nAll evaluations are conducted via official APIs to ensure reproducibility. We adopt the agentic workflow in Fig. [1,](#page-3-1) constraining each model to generate Python programs that solve the given problems under fixed resource limits: a maximum of 8 CPU cores and problem-specific timeouts. We also allow the models to access external libraries like numpy and pandas for simple tool use. We then assess model performance through both quantitative metrics and qualitative case analysis. Full details of the experimental settings and results can be found in Appendix [D.](#page-27-0)\n\n### 5.1 Overall Performance\n\nFor the overall evaluation, we fix the generation temperature at 0, following standard practice in recent LLM benchmarks [\\[106,](#page-14-6) [164,](#page-17-6) [111\\]](#page-14-3). This ensures deterministic outputs and eliminates randomness across runs. Notably, OpenAI's o-series models only support a fixed temperature of 1.0 [\\[103\\]](#page-14-2). We measure the multi-round performance using the solves@i metric, where i indicates the number of iterations allowed (we use i = 1, 5, and 10).\n\nAs shown in Table [3,](#page-6-1) most LLMs fail to solve a large fraction of test cases within a single attempt, as reflected in the solveIII@1 score. Increasing the number of iterations generally improves performance across all models. For instance, the solveIII success rate rises from 53.2% to 74.8% for GPT-o4-mini as i increases, underscoring the importance of iterative refinement in improving LLM-generated solutions. Among all models, GPT-o4-mini and DeepSeek-R1 demonstrate high success rates across multiple iterations, highlighting their stronger program repair capabilities.\n\nTo assess solution quality, we compare the final LLM-generated programs to expert-designed solutions using the weighted QYI metric defined in Section [3.2.](#page-3-0) As illustrated in Fig. [2,](#page-6-2) a substantial\n\n<span id=\"page-7-0\"></span>![](_page_7_Figure_0.jpeg)\n\nFigure 3: Error classifications.\n\nFigure 4: Quality-Yield tradeoff.\n\nperformance gap remains: even the best-performing model, Gemini-2.5-Pro, achieves a QYI of only 0.62, indicating that its solutions are, on average, just 60% as effective as expert-crafted ones. Several models, such as LLaMA-3.3 and LLaMA-4, produce results with QYI scores below 30%, highlighting their limited effectiveness on these tasks. We also estimate the API cost for each model and find that Gemini-2.5-Flash offers the best cost-efficiency relative to its achieved QYI.\n\nTo identify common failure modes, we analyze and categorize the most common error types produced by the evaluated models, as shown in Fig. [3.](#page-7-0) These include: (1) Hallucinated APIs: using nonexistent or outdated library calls. (2) Incorrect algorithmic logic: flawed implementation even when the general approach is reasonable. (3) Constraint misunderstanding: ignoring or misinterpreting problem constraints. (4) Timeouts: no output or the execution time exceeds the given constraints. Additional error cases and examples are listed in Appendix [D.](#page-27-0)\n\n### 5.2 Ablation Study\n\nTo assess the robustness and sensitivity of LLM performance under different settings, we conduct a set of ablation experiments with full details in Appendix [D.](#page-27-0)\n\nTemperature. We evaluate three representative models across the QYI spectrum using decoding temperatures T ∈ {0.0, 0.5, 1.0}. As shown in Fig. [4,](#page-7-0) higher T increases diversity and quality but lowers yield due to more invalid outputs. Greedy decoding (T = 0) has maximum yield with suboptimal quality, while stochastic sampling (T = 1) achieves better quality at the cost of solving fewer problems. Our benchmark reveals a fundamental trade-off between quality and yield that future LLMs must address.\n\n| # of Demos / # of Feedback Rounds | 5/10   | 3/10   | 0/10   | 5/5    | 5/1    |  |  |  |  |\n|-----------------------------------|--------|--------|--------|--------|--------|--|--|--|--|\n| QYI Score                         | 0.4196 | 0.2829 | 0.2351 | 0.3330 | 0.2350 |  |  |  |  |\n\n<span id=\"page-7-1\"></span>Table 4: Ablation study on the pickup and delivery with time windows problem [\\[77,](#page-12-1) [46\\]](#page-11-8).\n\nFew-shot demonstrations. We assess the impact of in-context examples by comparing zero-shot, half-shot, and full-shot prompts. Due to budget constraints, these experiments are conducted on a few representative models. Specifically, we evaluate Gemini-2.5-Pro on the pickup and delivery problem – one of the most challenging tasks in our benchmark. As shown in Table [4,](#page-7-1) providing more informative demonstrations significantly boosts the overall performance, especially for tasks involving unfamiliar domains or requiring long-horizon reasoning.\n\nFeedback rounds. To evaluate the role of iterative refinement, we vary the number of feedback rounds given to LLMs (1, 5, and 10), keeping the temperature fixed at 0. The results in Table [4](#page-7-1) show that later iterations frequently fix logic errors or constraint violations from earlier attempts, underscoring the value of multi-round reasoning. We provide further analysis in Section [5.3.](#page-7-2)\n\n### <span id=\"page-7-2\"></span>5.3 Case Study\n\nWe present a case study on technology mapping [\\[95\\]](#page-13-7) to highlight both the promise and current limitations of LLMs. The goal is to cover a logic network with K-input subgraphs – corresponding to lookup tables (LUTs) – that minimize the total number of LUTs. We fix K = 6 in our setting.\n\n<span id=\"page-8-0\"></span>![](_page_8_Figure_0.jpeg)\n\nFigure 5: One iterative example of GPT-o4-mini on the technology mapping problem.\n\nAs an expert baseline, we use ABC [\\[14\\]](#page-9-5), a state-of-the-art logic synthesis tool that leverages optimized cut enumeration and dynamic programming (DP)-based covering. We find that top-performing LLMs, such as GPT-o4-mini and Gemini-2.5-Pro, can mimic similar heuristic strategies and iteratively refine them through feedback. As illustrated in Fig. [5,](#page-8-0) GPT-o4-mini explores a range of approaches over multiple iterations, evolving from naive mappings to increasingly sophisticated DP-based heuristics with pruning. By the fifth iteration, it converges on a strategy that effectively balances yield and solution quality, which achieves the highest QYI score.\n\nNonetheless, a substantial gap remains between LLMs and expert tools, due to the latter's extensive use of domain-specific optimizations and efficient implementations. This suggests that while LLMs can learn and refine heuristic algorithms, they are not yet capable of generating solutions with expert-level performance in real-world complex optimization tasks.\n\n# 6 Discussion and Limitation\n\nWhile our benchmark and framework offer a promising foundation for evaluating LLMs on combinatorial optimization problems, several limitations remain that suggest directions for future work.\n\nFirst, all experiments are conducted in Python, which, while accessible, introduces execution overhead at scale. Although we include preliminary results with C++ in Appendix [D,](#page-27-0) integrating C++ remains challenging due to dependencies on domain-specific libraries and the difficulty LLMs face in generating efficient, functionally correct, and parallel C++ code.\n\nSecond, the iterative self-refinement process in our agentic workflow can be interpreted as a form of test-time scaling (TTS), analogous to compute-optimal scaling strategies [\\[134\\]](#page-15-8). This perspective creates opportunities to incorporate techniques such as Best-of-N sampling [\\[138\\]](#page-16-8), beam search [\\[158\\]](#page-17-9), and evolutionary algorithms [\\[100,](#page-14-7) [166\\]](#page-17-7), especially with increased iteration budgets. Furthermore, with a robust verifier in place, our framework provides a natural platform to investigate self-verification capabilities [\\[72,](#page-12-8) [168,](#page-17-10) [173\\]](#page-17-11), a promising avenue toward greater LLM autonomy.\n\n⚠️ **TimeoutError** Third, our evaluation pipeline currently relies on proxy metrics that are formally defined and computationally efficient. While these metrics are useful for initial benchmarking, they often fall short in reflecting real-world performance – particularly in (1) scientific domains, where solution quality must ultimately be validated through physical experiments, and (2) engineering domains like EDA, where quality must be confirmed through time-consuming backend synthesis. Bridging the gap between proxy evaluation and real-world deployment – while managing the latency introduced by longer feedback loops – remains a key challenge and an important direction for future work.\n\nCurrently HeuriGym includes only nine problems. Although these have been carefully curated to test reasoning and generalization, they may eventually become saturated as LLM capabilities improve. To maintain long-term relevance, we envision the benchmark as an evolving resource and actively encourage community contributions. Future iterations will expand both the breadth and depth of the benchmark by introducing new problems from underrepresented scientific domains and scaling existing ones to more complex regimes.\n\nBy formalizing combinatorial problems with standardized formats with reproducible agentic workflows, we believe HeuriGym can serve as a shared testbed and foster interdisciplinary collaboration.\n\n# References\n\n- <span id=\"page-9-14\"></span>[1] Luca Aceto, Jens A Hansen, Anna Ingólfsdóttir, Jacob Johnsen, and John Knudsen. The complexity of checking consistency of pedigree information and related problems. *Journal of Computer Science and Technology*, 19:42–59, 2004.\n- <span id=\"page-9-3\"></span>[2] Divyam Aggarwal, Dhish Kumar Saxena, Thomas Bäck, and Michael Emmerich. Real-world airline crew pairing optimization: Customized genetic algorithm versus column generation method. In *International Conference on Evolutionary Multi-Criterion Optimization*, pages 518–531. Springer, 2023.\n- <span id=\"page-9-2\"></span>[3] Ali AhmadiTeshnizi, Wenzhi Gao, and Madeleine Udell. Optimus: scalable optimization modeling with (mi)lp solvers and large language models. In *Proceedings of the 41st International Conference on Machine Learning (ICML)*, 2024.\n- <span id=\"page-9-8\"></span>[4] Christoph Albrecht. Global routing by new approximation algorithms for multicommodity flow. *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, 20(5):622–632, 2001.\n- <span id=\"page-9-12\"></span>[5] Benjamin D Allen and Stephen L Mayo. An efficient algorithm for multistate protein design based on faster. *Journal of computational chemistry*, 31(5):904–916, 2010.\n- <span id=\"page-9-18\"></span>[6] Luca Amarú, Pierre-Emmanuel Gaillardon, and Giovanni De Micheli. The epfl combinational benchmark suite. In *Proceedings of the 24th International Workshop on Logic & Synthesis (IWLS)*, 2015.\n- <span id=\"page-9-11\"></span>[7] Xavier I Ambroggio and Brian Kuhlman. Computational design of a single amino acid sequence that can switch between two distinct protein folds. *Journal of the American Chemical Society*, 128(4):1154–1161, 2006.\n- <span id=\"page-9-15\"></span>[8] Ranga Anbil, Rajan Tanga, and Ellis L. Johnson. A global approach to crew-pairing optimization. *IBM Systems Journal*, 31(1):71–78, 1992.\n- <span id=\"page-9-4\"></span>[9] Anthropic. Claude 3.7 sonnet and claude code, 2025. [https://www.anthropic.com/news/](https://www.anthropic.com/news/claude-3-7-sonnet) [claude-3-7-sonnet](https://www.anthropic.com/news/claude-3-7-sonnet).\n- <span id=\"page-9-17\"></span>[10] Roberto Baldacci, Enrico Bartolini, and Aristide Mingozzi. An exact algorithm for the pickup and delivery problem with time windows. *Operations research*, 59(2):414–426, 2011.\n- <span id=\"page-9-13\"></span>[11] Jayanth R Banavar, Marek Cieplak, Amos Maritan, Gautham Nadig, Flavio Seno, and Saraswathi Vishveshwara. Structure-based design of model proteins. *Proteins: Structure, Function, and Bioinformatics*, 31(1):10–20, 1998.\n- <span id=\"page-9-9\"></span>[12] Laleh Behjat, Anthony Vannelli, and William Rosehart. Integer linear programming models for global routing. *INFORMS Journal on Computing*, 18(2):137–150, 2006.\n- <span id=\"page-9-16\"></span>[13] Russell Bent and Pascal Van Hentenryck. A two-stage hybrid algorithm for pickup and delivery vehicle routing problems with time windows. *Computers & Operations Research*, 33(4):875–893, 2006.\n- <span id=\"page-9-5\"></span>[14] Berkeley Logic Synthesis and Verification Group. ABC: A System for Sequential Synthesis and Verification, 2005. <http://www.eecs.berkeley.edu/~alanmi/abc/>.\n- <span id=\"page-9-0\"></span>[15] Yaohui Cai, Kaixin Yang, Chenhui Deng, Cunxi Yu, and Zhiru Zhang. Smoothe: Differentiable e-graph extraction. In *Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS), Volume 1*, 2025.\n- <span id=\"page-9-6\"></span>[16] Andrew Canis, Jongsok Choi, Mark Aldham, Victor Zhang, Ahmed Kammoona, Jason H Anderson, Stephen Brown, and Tomasz Czajkowski. Legup: high-level synthesis for fpga-based processor/accelerator systems. In *Proceedings of the 19th ACM/SIGDA international symposium on Field programmable gate arrays*, pages 33–36, 2011.\n- <span id=\"page-9-7\"></span>[17] RC Carden, Jianmin Li, and Chung-Kuan Cheng. A global router with a theoretical bound on the optimal solution. *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, 15(2):208–216, 1996.\n- <span id=\"page-9-10\"></span>[18] Chong-Yun Chao and Earl Glen Whitehead. On chromatic equivalence of graphs. *Theory and Applications of Graphs*, pages 121–131, 1978.\n- <span id=\"page-9-1\"></span>[19] Deming Chen and Jason Cong. Daomap: A depth-optimal area optimization mapping algorithm for fpga designs. In *IEEE/ACM International Conference on Computer Aided Design, 2004. ICCAD-2004.*, pages 752–759. IEEE, 2004.\n- <span id=\"page-10-3\"></span>[20] Di Chen, Yiwei Bai, Sebastian Ament, Wenting Zhao, Dan Guevarra, Lan Zhou, Bart Selman, R Bruce van Dover, John M Gregoire, and Carla P Gomes. Automating crystal-structure phase mapping by combining deep learning with constraint reasoning. *Nature Machine Intelligence*, 3(9):812–822, 2021.\n- <span id=\"page-10-4\"></span>[21] Di Chen, Yexiang Xue, Shuo Chen, Daniel Fink, and Carla Gomes. Deep multi-species embedding. *arXiv preprint arXiv:1609.09353*, 2016.\n- <span id=\"page-10-10\"></span>[22] Hongzheng Chen and Minghua Shen. A deep-reinforcement-learning-based scheduler for fpga hls. In *2019 IEEE/ACM International Conference on Computer-Aided Design (ICCAD)*, pages 1–8. IEEE, 2019.\n- <span id=\"page-10-15\"></span>[23] Hongzheng Chen, Cody Hao Yu, Shuai Zheng, Zhen Zhang, Zhiru Zhang, and Yida Wang. Slapo: A schedule language for progressive optimization of large deep learning model training. In *Proceedings of the 29th ACM International Conference on Architectural Support for Programming Languages and Operating Systems, Volume 2*, pages 1095–1111, 2024.\n- <span id=\"page-10-13\"></span>[24] Hongzheng Chen, Niansong Zhang, Shaojie Xiang, Zhichen Zeng, Mengjia Dai, and Zhiru Zhang. Allo: A programming model for composable accelerator design. *Proceedings of the ACM on Programming Languages*, 8(PLDI):593–620, 2024.\n- <span id=\"page-10-0\"></span>[25] Mark Chen, Jerry Tworek, Heewoo Jun, Qiming Yuan, Henrique Ponde De Oliveira Pinto, Jared Kaplan, Harri Edwards, Yuri Burda, Nicholas Joseph, Greg Brockman, et al. Evaluating large language models trained on code. *arXiv preprint arXiv:2107.03374*, 2021.\n- <span id=\"page-10-14\"></span>[26] Jianyi Cheng, Samuel Coward, Lorenzo Chelini, Rafael Barbalho, and Theo Drane. Seer: Superoptimization explorer for high-level synthesis using e-graph rewriting. *Int'l Conf. on Architectural Support for Programming Languages and Operating Systems (ASPLOS)*, pages 1029–1044, 2024.\n- <span id=\"page-10-2\"></span>[27] Wei-Lin Chiang, Lianmin Zheng, Ying Sheng, Anastasios N. Angelopoulos, Tianle Li, Dacheng Li, Banghua Zhu, Hao Zhang, Michael I. Jordan, Joseph E. Gonzalez, and Ion Stoica. Chatbot arena: an open platform for evaluating llms by human preference. In *Proceedings of the 41st International Conference on Machine Learning (ICML)*, 2024.\n- <span id=\"page-10-5\"></span>[28] Michael Codish, Michael Frank, and Vitaly Lagoon. The dna word design problem: A new constraint model and new results. In *IJCAI*, pages 585–591, 2017.\n- <span id=\"page-10-18\"></span>[29] China Graduate Mathematical Modeling Competition. Problem f, 2021.\n- <span id=\"page-10-11\"></span>[30] Jason Cong and Yuzheng Ding. Flowmap: An optimal technology mapping algorithm for delay optimization in lookup-table based fpga designs. *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, 13(1):1–12, 1994.\n- <span id=\"page-10-8\"></span>[31] Jason Cong, Bin Liu, Stephen Neuendorffer, Juanjo Noguera, Kees Vissers, and Zhiru Zhang. High-level synthesis for fpgas: From prototyping to deployment. *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, 30(4):473–491, 2011.\n- <span id=\"page-10-12\"></span>[32] Jason Cong and Patrick Madden. Performance-driven global routing for standard cell design. In *Proceedings of the 1998 International Symposium on Physical Design*, pages 73–78, 1998.\n- <span id=\"page-10-6\"></span>[33] Jason Cong and Zhiru Zhang. An efficient and versatile scheduling algorithm based on sdc formulation. In *Proceedings of the 43rd annual Design Automation Conference (DAC)*, pages 433–438, 2006.\n- <span id=\"page-10-16\"></span>[34] Timothy Curtois, Dario Landa-Silva, Yi Qu, and Wasakorn Laesanklang. Large neighbourhood search with adaptive guided ejection search for the pickup and delivery problem with time windows. *EURO Journal on Transportation and Logistics*, 7(2):151–192, 2018.\n- <span id=\"page-10-9\"></span>[35] Steve Dai, Gai Liu, and Zhiru Zhang. A scalable approach to exact resource-constrained scheduling based on a joint sdc and sat formulation. In *Proceedings of the 2018 ACM/SIGDA International Symposium on Field-Programmable Gate Arrays*, pages 137–146, 2018.\n- <span id=\"page-10-7\"></span>[36] Pham Vu Tuan Dat, Long Doan, and Huynh Thi Thanh Binh. Hsevo: Elevating automatic heuristic design with diversity-driven harmony search and genetic algorithm using llms. In *The 39th Annual AAAI Conference on Artificial Intelligence*, 2025. <https://github.com/datphamvn/HSEvo>.\n- <span id=\"page-10-17\"></span>[37] Protein Database. Rcsb protein data bank (rcsb pdb), 2024.\n- <span id=\"page-10-1\"></span>[38] Google DeepMind. Gemini 2.5: Our most intelligent ai model, 2025. [https://blog.google/](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025) [technology/google-deepmind/gemini-model-thinking-updates-march-2025](https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025).\n- <span id=\"page-11-15\"></span>[39] Guy Desaulniers, Jacques Desrosiers, and Marius M Solomon. *Column generation*, volume 5. Springer Science & Business Media, 2006.\n- <span id=\"page-11-12\"></span>[40] JM Deutsch and Tanya Kurosky. New algorithm for protein design. *Physical review letters*, 76(2):323, 1996.\n- <span id=\"page-11-14\"></span>[41] Ken A Dill, Sarina Bromberg, Kaizhi Yue, Hue Sun Chan, Klaus M Ftebig, David P Yee, and Paul D Thomas. Principles of protein folding—a perspective from simple exact models. *Protein science*, 4(4):561–602, 1995.\n- <span id=\"page-11-4\"></span>[42] Qingxiu Dong, Lei Li, Damai Dai, Ce Zheng, Jingyuan Ma, Rui Li, Heming Xia, Jingjing Xu, Zhiyong Wu, Baobao Chang, Xu Sun, Lei Li, and Zhifang Sui. A survey on in-context learning. In *Proceedings of the 2024 Conference on Empirical Methods in Natural Language Processing*, 2024.\n- <span id=\"page-11-11\"></span>[43] K Eric Drexler. Molecular engineering: An approach to the development of general capabilities for molecular manipulation. *Proceedings of the National Academy of Sciences*, 78(9):5275–5278, 1981.\n- <span id=\"page-11-6\"></span>[44] Jiangsu Du, Jinhui Wei, Jiazhi Jiang, Shenggan Cheng, Dan Huang, Zhiguang Chen, and Yutong Lu. Liger: Interleaving intra-and inter-operator parallelism for distributed large model inference. In *Proceedings of the 29th ACM SIGPLAN Annual Symposium on Principles and Practice of Parallel Programming*, pages 42–54, 2024.\n- <span id=\"page-11-10\"></span>[45] Yuanqi Du, Arian R Jamasb, Jeff Guo, Tianfan Fu, Charles Harris, Yingheng Wang, Chenru Duan, Pietro Liò, Philippe Schwaller, and Tom L Blundell. Machine learning-aided generative molecular design. *Nature Machine Intelligence*, 6(6):589–604, 2024.\n- <span id=\"page-11-8\"></span>[46] Yvan Dumas, Jacques Desrosiers, and Francois Soumis. The pickup and delivery problem with time windows. *European journal of operational research*, 54(1):7–22, 1991.\n- <span id=\"page-11-17\"></span>[47] Yvan Dumas, Jacques Desrosiers, and Francois Soumis. The pickup and delivery problem with time windows. *European journal of operational research*, 54(1):7–22, 1991.\n- <span id=\"page-11-16\"></span>[48] Issmail Elhallaoui, Daniel Villeneuve, François Soumis, and Guy Desaulniers. Dynamic aggregation of set-partitioning constraints in column generation. *Operations Research*, 53(4):632–645, 2005.\n- <span id=\"page-11-2\"></span>[49] Lizhou Fan, Wenyue Hua, Lingyao Li, Haoyang Ling, and Yongfeng Zhang. NPHardEval: Dynamic benchmark on reasoning ability of large language models via complexity classes. In Lun-Wei Ku, Andre Martins, and Vivek Srikumar, editors, *Proceedings of the 62nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, 2024.\n- <span id=\"page-11-5\"></span>[50] Amir Kafshdar Goharshady, Chun Kit Lam, and Lionel Parreaux. Fast and optimal extraction for sparse equality graphs. *Proceedings of the ACM on Programming Languages*, 8(OOPSLA2):2551–2577, 2024.\n- <span id=\"page-11-0\"></span>[51] Glenn W Graves, Richard D McBride, Ira Gershkoff, Diane Anderson, and Deepa Mahidhara. Flight crew scheduling. *Management science*, 39(6):736–745, 1993.\n- <span id=\"page-11-9\"></span>[52] Daya Guo, Dejian Yang, Haowei Zhang, Junxiao Song, Ruoyu Zhang, Runxin Xu, Qihao Zhu, Shirong Ma, Peiyi Wang, Xiao Bi, et al. Deepseek-r1: Incentivizing reasoning capability in llms via reinforcement learning. *arXiv preprint arXiv:2501.12948*, 2025.\n- <span id=\"page-11-1\"></span>[53] Gurobi. Gurobi optimizer, 2025. <https://www.gurobi.com/solutions/gurobi-optimizer/>.\n- <span id=\"page-11-13\"></span>[54] Mark A Hallen and Bruce R Donald. Comets (constrained optimization of multistate energies by tree search): A provable and efficient protein design algorithm to optimize binding affinity and specificity with respect to sequence. *Journal of Computational Biology*, 23(5):311–321, 2016.\n- <span id=\"page-11-19\"></span>[55] Mark C Hansen, Hakan Yalcin, and John P Hayes. Unveiling the iscas-85 benchmarks: A case study in reverse engineering. *IEEE Design & Test of Computers*, 1999.\n- <span id=\"page-11-7\"></span>[56] William E Hart. On the computational complexity of sequence design problems. In *Proceedings of the first annual international conference on Computational molecular biology*, pages 128–136, 1997.\n- <span id=\"page-11-3\"></span>[57] Dan Hendrycks, Collin Burns, Saurav Kadavath, Akul Arora, Steven Basart, Eric Tang, Dawn Song, and Jacob Steinhardt. Measuring mathematical problem solving with the MATH dataset. In *Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)*, 2021.\n- <span id=\"page-11-18\"></span>[58] Sin C Ho, Wai Yuen Szeto, Yong-Hong Kuo, Janny MY Leung, Matthew Petering, and Terence WH Tou. A survey of dial-a-ride problems: Literature review and recent developments. *Transportation Research Part B: Methodological*, 111:395–421, 2018.\n- <span id=\"page-12-11\"></span>[59] Jiang Hu and Sachin S Sapatnekar. A survey on multi-net global routing for integrated circuits. *Integration*, 31(1):1–49, 2001.\n- <span id=\"page-12-7\"></span>[60] Edward Hughes, Michael D Dennis, Jack Parker-Holder, Feryal Behbahani, Aditi Mavalankar, Yuge Shi, Tom Schaul, and Tim Rocktäschel. Position: Open-endedness is essential for artificial superhuman intelligence. In *Proceedings of the 41st International Conference on Machine Learning*, 2024.\n- <span id=\"page-12-9\"></span>[61] C-T Hwang, J-H Lee, and Y-C Hsu. A formal approach to the scheduling problem in high level synthesis. *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, 10(4):464–475, 1991.\n- <span id=\"page-12-3\"></span>[62] Zangir Iklassov, Yali Du, Farkhad Akimov, and Martin Takác. Self-guiding exploration for combinatorial ˇ problems. In *The Thirty-eighth Annual Conference on Neural Information Processing Systems (NeurIPS)*, 2024.\n- <span id=\"page-12-4\"></span>[63] Naman Jain, King Han, Alex Gu, Wen-Ding Li, Fanjia Yan, Tianjun Zhang, Sida Wang, Armando Solar-Lezama, Koushik Sen, and Ion Stoica. Livecodebench: Holistic and contamination free evaluation of large language models for code. In *The Thirteenth International Conference on Learning Representations (ICLR)*, 2025.\n- <span id=\"page-12-18\"></span>[64] Jeppesen. Jeppesen crew pairing solution. [https://ww2.jeppesen.com/](https://ww2.jeppesen.com/airline-crew-optimization-solutions/airline-crew-pairing/) [airline-crew-optimization-solutions/airline-crew-pairing/](https://ww2.jeppesen.com/airline-crew-optimization-solutions/airline-crew-pairing/), 2021.\n- <span id=\"page-12-2\"></span>[65] Caigao JIANG, Xiang Shu, Hong Qian, Xingyu Lu, JUN ZHOU, Aimin Zhou, and Yang Yu. LLMOPT: Learning to define and solve general optimization problems from scratch. In *The Thirteenth International Conference on Learning Representations (ICLR)*, 2025.\n- <span id=\"page-12-5\"></span>[66] Carlos E Jimenez, John Yang, Alexander Wettig, Shunyu Yao, Kexin Pei, Ofir Press, and Karthik R Narasimhan. SWE-bench: Can language models resolve real-world github issues? In *The Twelfth International Conference on Learning Representations*, 2024.\n- <span id=\"page-12-14\"></span>[67] John Jumper, Richard Evans, Alexander Pritzel, Tim Green, Michael Figurnov, Olaf Ronneberger, Kathryn Tunyasuvunakool, Russ Bates, Augustin Žídek, Anna Potapenko, et al. Highly accurate protein structure prediction with alphafold. *nature*, 596(7873):583–589, 2021.\n- <span id=\"page-12-16\"></span>[68] Satwik Kamtekar, Jarad M Schiffer, Huayu Xiong, Jennifer M Babik, and Michael H Hecht. Protein design by binary patterning of polar and nonpolar amino acids. *Science*, 262(5140):1680–1685, 1993.\n- <span id=\"page-12-17\"></span>[69] Atoosa Kasirzadeh, Mohammed Saddoune, and François Soumis. Airline crew scheduling: models, algorithms, and data sets. *EURO Journal on Transportation and Logistics*, 6(2):111–137, 2017.\n- <span id=\"page-12-6\"></span>[70] Jon M Kleinberg. Efficient algorithms for protein sequence design and the analysis of certain evolutionary fitness landscapes. In *Proceedings of the third annual international conference on Computational molecular biology*, pages 226–237, 1999.\n- <span id=\"page-12-0\"></span>[71] Michael Krumdick, Charles Lovering, Varshini Reddy, Seth Ebner, and Chris Tanner. No free labels: Limitations of llm-as-a-judge without human grounding. *arXiv preprint arXiv:2503.05061*, 2025.\n- <span id=\"page-12-8\"></span>[72] Aviral Kumar, Vincent Zhuang, Rishabh Agarwal, Yi Su, John D Co-Reyes, Avi Singh, Kate Baumli, Shariq Iqbal, Colton Bishop, Rebecca Roelofs, et al. Training language models to self-correct via reinforcement learning. *arXiv preprint arXiv:2409.12917*, 2024.\n- <span id=\"page-12-12\"></span>[73] Avery Laird, Bangtian Liu, NIKOLAJ BJØRNER, and Maryam Mehri Dehnavi. Speq: Translation of sparse codes using equivalences. *ACM SIGPLAN Conf. on Programming Language Design and Implementation (PLDI)*, 2024.\n- <span id=\"page-12-15\"></span>[74] Kit Fun Lau and Ken A Dill. Theory for protein mutability and biogenesis. *Proceedings of the National Academy of Sciences*, 87(2):638–642, 1990.\n- <span id=\"page-12-10\"></span>[75] Chin Yang Lee. An algorithm for path connections and its applications. *IRE transactions on electronic computers*, EC-10(3):346–365, 2009.\n- <span id=\"page-12-13\"></span>[76] Dmitry Lepikhin, HyoukJoong Lee, Yuanzhong Xu, Dehao Chen, Orhan Firat, Yanping Huang, Maxim Krikun, Noam Shazeer, and Zhifeng Chen. Gshard: Scaling giant models with conditional computation and automatic sharding. *arXiv preprint arXiv:2006.16668*, 2020.\n- <span id=\"page-12-1\"></span>[77] Haibing Li and Andrew Lim. A metaheuristic for the pickup and delivery problem with time windows. In *Proceedings 13th IEEE international conference on tools with artificial intelligence*, pages 160–167. IEEE, 2001.\n- <span id=\"page-13-2\"></span>[78] Sirui Li, Janardhan Kulkarni, Ishai Menache, Cathy Wu, and Beibin Li. Towards foundation models for mixed integer linear programming. In *The Thirteenth International Conference on Learning Representations (ICLR)*, 2025.\n- <span id=\"page-13-0\"></span>[79] Yujia Li, David Choi, Junyoung Chung, Nate Kushman, Julian Schrittwieser, Rémi Leblond, Tom Eccles, James Keeling, Felix Gimeno, Agustin Dal Lago, et al. Competition-level code generation with alphacode. *Science*, 378(6624):1092–1097, 2022.\n- <span id=\"page-13-8\"></span>[80] Rongjian Liang, Anthony Agnesina, Wen-Hao Liu, and Haoxing Ren. Gpu/ml-enhanced large scale global routing contest. In *Proceedings of the 2024 International Symposium on Physical Design (ISPD)*, 2024.\n- <span id=\"page-13-9\"></span>[81] Haiguang Liao, Wentai Zhang, Xuliang Dong, Barnabas Poczos, Kenji Shimada, and Levent Burak Kara. A deep reinforcement learning approach for global routing. *Journal of Mechanical Design*, 142(6):061701, 2020.\n- <span id=\"page-13-16\"></span>[82] Zeming Lin, Halil Akin, Roshan Rao, Brian Hie, Zhongkai Zhu, Wenting Lu, Nikita Smetanin, Robert Verkuil, Ori Kabeli, Yaniv Shmueli, et al. Evolutionary-scale prediction of atomic-level protein structure with a language model. *Science*, 379(6637):1123–1130, 2023.\n- <span id=\"page-13-11\"></span>[83] Aixin Liu, Bei Feng, Bing Xue, Bingxuan Wang, Bochao Wu, Chengda Lu, Chenggang Zhao, Chengqi Deng, Chenyu Zhang, Chong Ruan, et al. Deepseek-v3 technical report. *arXiv preprint arXiv:2412.19437*, 2024.\n- <span id=\"page-13-4\"></span>[84] Fei Liu, Xialiang Tong, Mingxuan Yuan, Xi Lin, Fu Luo, Zhenkun Wang, Zhichao Lu, and Qingfu Zhang. Evolution of heuristics: towards efficient automatic algorithm design using large language model. In *Proceedings of the 41st International Conference on Machine Learning (ICML)*, 2024.\n- <span id=\"page-13-6\"></span>[85] Jiachang Liu, Dinghan Shen, Yizhe Zhang, Bill Dolan, Lawrence Carin, and Weizhu Chen. What makes good in-context examples for GPT-3? In *Proceedings of Deep Learning Inside Out (DeeLIO 2022): The 3rd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures*, 2022.\n- <span id=\"page-13-3\"></span>[86] Jiawei Liu, Chunqiu Steven Xia, Yuyao Wang, and Lingming Zhang. Is your code generated by chatGPT really correct? rigorous evaluation of large language models for code generation. In *Thirty-seventh Conference on Neural Information Processing Systems*, 2023.\n- <span id=\"page-13-5\"></span>[87] Mingju Liu, Yingjie Li, Jiaqi Yin, Zhiru Zhang, and Cunxi Yu. Differentiable combinatorial scheduling at scale. In *Proceedings of the 41st International Conference on Machine Learning (ICML)*, 2024.\n- <span id=\"page-13-1\"></span>[88] Tianfeng Liu, Yangrui Chen, Dan Li, Chuan Wu, Yibo Zhu, Jun He, Yanghua Peng, Hongzheng Chen, Hongzhi Chen, and Chuanxiong Guo. BGL:GPU-efficient GNN training by optimizing graph data I/O and preprocessing. In *20th USENIX Symposium on Networked Systems Design and Implementation (NSDI 23)*, pages 103–118, 2023.\n- <span id=\"page-13-18\"></span>[89] Panta Luciˇ c and Dušan Teodorovi ´ c. Metaheuristics approach to the aircrew rostering problem. ´ *Annals of Operations Research*, 155:311–338, 2007.\n- <span id=\"page-13-10\"></span>[90] Xiaodong Luo, Yogesh Dashora, and Tina Shaw. Airline crew augmentation: decades of improvements from sabre. *Interfaces*, 45(5):409–424, 2015.\n- <span id=\"page-13-12\"></span>[91] Meta. The llama 3 herd of models, 2024. [https://ai.meta.com/research/publications/](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/) [the-llama-3-herd-of-models/](https://ai.meta.com/research/publications/the-llama-3-herd-of-models/).\n- <span id=\"page-13-13\"></span>[92] Meta. The llama 4 herd: The beginning of a new era of natively multimodal ai innovation, 2025. <https://ai.meta.com/blog/llama-4-multimodal-intelligence/>.\n- <span id=\"page-13-17\"></span>[93] Cristian Micheletti, Jayanth R Banavar, Amos Maritan, and Flavio Seno. Protein structures and optimal folding from a geometrical variational principle. *Physical Review Letters*, 82(16):3372, 1999.\n- <span id=\"page-13-15\"></span>[94] Yaosen Min, Ye Wei, Peizhuo Wang, Xiaoting Wang, Han Li, Nian Wu, Stefan Bauer, Shuxin Zheng, Yu Shi, Yingheng Wang, et al. From static to dynamic structures: Improving binding affinity prediction with a graph-based deep learning model. *arXiv e-prints*, pages arXiv–2208, 2022.\n- <span id=\"page-13-7\"></span>[95] Alan Mishchenko, Satrajit Chatterjee, and Robert Brayton. Improvements to technology mapping for lut-based fpgas. In *Proceedings of the 2006 ACM/SIGDA 14th International Symposium on Field Programmable Gate Arrays (FPGA)*, 2006.\n- <span id=\"page-13-14\"></span>[96] Michael D Moffitt. Global routing revisited. In *Proceedings of the 2009 International Conference on Computer-Aided Design*, pages 805–808, 2009.\n- <span id=\"page-14-4\"></span>[97] Michael D. Moffitt and Pratik Fegade. The asplos 2025 / eurosys 2025 contest on intra-operator parallelism for distributed deep learning. In *Proceedings of the 30th ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)*, volume 3 of *ASPLOS 2025*, 2025.\n- <span id=\"page-14-18\"></span>[98] Christopher Negron and Amy E Keating. Multistate protein design using clever and classy. In *Methods in enzymology*, volume 523, pages 171–190. Elsevier, 2013.\n- <span id=\"page-14-14\"></span>[99] Greg Nelson and Derek C Oppen. Simplification by cooperating decision procedures. *ACM Transactions on Programming Languages and Systems*, 1(2):245–257, 1979.\n- <span id=\"page-14-7\"></span>[100] Alexander Novikov, Ngân Vu, Marvin Eisenberger, Emilien Dupont, Po-Sen Huang, Adam Zsolt Wagner, Sergey Shirobokov, Borislav Kozlovskii, Francisco JR Ruiz, Abbas Mehrabian, et al. Alphaevolve: A coding agent for scientific and algorithmic discovery. Technical report, Technical report, Google DeepMind, 05 2025. URL https://storage. googleapis . . . , 2025.\n- <span id=\"page-14-8\"></span>[101] Jeffrey R O'Connell and Daniel E Weeks. An optimal algorithm for automatic genotype elimination. *The American Journal of Human Genetics*, 65(6):1733–1740, 1999.\n- <span id=\"page-14-0\"></span>[102] AoPS Online. American invitational mathematics examination (aime), 2025. [https:](https://artofproblemsolving.com/wiki/index.php/American_Invitational_Mathematics_Examination) [//artofproblemsolving.com/wiki/index.php/American\\\\_Invitational\\\\_Mathematics\\\\_](https://artofproblemsolving.com/wiki/index.php/American_Invitational_Mathematics_Examination) [Examination](https://artofproblemsolving.com/wiki/index.php/American_Invitational_Mathematics_Examination).\n- <span id=\"page-14-2\"></span>[103] OpenAI. Introducing openai o3 and o4-mini, 2025. [https://openai.com/index/](https://openai.com/index/introducing-o3-and-o4-mini/) [introducing-o3-and-o4-mini/](https://openai.com/index/introducing-o3-and-o4-mini/).\n- <span id=\"page-14-9\"></span>[104] OpenRouter. Llm rankings, 2025. <https://openrouter.ai/rankings>.\n- <span id=\"page-14-11\"></span>[105] Julian Oppermann, Andreas Koch, Melanie Reuter-Oppermann, and Oliver Sinnen. Ilp-based modulo scheduling for high-level synthesis. In *Proceedings of the International Conference on Compilers, Architectures and Synthesis for Embedded Systems*, pages 1–10, 2016.\n- <span id=\"page-14-6\"></span>[106] Anne Ouyang, Simon Guo, Simran Arora, Alex L. Zhang, William Hu, Christopher Ré, and Azalia Mirhoseini. Kernelbench: Can llms write efficient gpu kernels?, 2025.\n- <span id=\"page-14-10\"></span>[107] Debjit Pal, Yi-Hsiang Lai, Shaojie Xiang, Niansong Zhang, Hongzheng Chen, Jeremy Casas, Pasquale Cocchini, Zhenkun Yang, Jin Yang, Louis-Noël Pouchet, et al. Accelerator design with decoupled hardware customizations: benefits and challenges. In *Proceedings of the 59th ACM/IEEE Design Automation Conference*, pages 1351–1354, 2022.\n- <span id=\"page-14-15\"></span>[108] Pavel Panchekha, Alex Sanchez-Stern, James R Wilcox, and Zachary Tatlock. Automatically improving accuracy for floating point expressions. *ACM SIGPLAN Conf. on Programming Language Design and Implementation (PLDI)*, 50(6):1–11, 2015.\n- <span id=\"page-14-12\"></span>[109] Alice C Parker, Jorge Pizarro, and Mitch Mlinar. Maha: A program for datapath synthesis. In *23rd ACM/IEEE Design Automation Conference*, pages 461–466. IEEE, 1986.\n- <span id=\"page-14-13\"></span>[110] Pierre G Paulin and John P Knight. Force-directed scheduling for the behavioral synthesis of asics. *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, 8(6):661–679, 2002.\n- <span id=\"page-14-3\"></span>[111] Long Phan, Alice Gatti, Ziwen Han, Nathaniel Li, Josephina Hu, Hugh Zhang, Chen Bo Calvin Zhang, Mohamed Shaaban, John Ling, Sean Shi, et al. Humanity's last exam. *arXiv preprint arXiv:2501.14249*, 2025.\n- <span id=\"page-14-17\"></span>[112] Navin Pokala and Tracy M Handel. Energy functions for protein design: adjustment with protein–protein complex affinities, models for the unfolded state, and negative design of solubility and specificity. *Journal of molecular biology*, 347(1):203–227, 2005.\n- <span id=\"page-14-16\"></span>[113] Samyam Rajbhandari, Jeff Rasley, Olatunji Ruwase, and Yuxiong He. Zero: Memory optimizations toward training trillion parameter models. In *SC20: International Conference for High Performance Computing, Networking, Storage and Analysis*, pages 1–16. IEEE, 2020.\n- <span id=\"page-14-5\"></span>[114] Rindranirina Ramamonjison, Timothy Yu, Raymond Li, Haley Li, Giuseppe Carenini, Bissan Ghaddar, Shiqi He, Mahdi Mostajabdaveh, Amin Banitalebi-Dehkordi, Zirui Zhou, et al. Nl4opt competition: Formulating optimization problems based on their natural language descriptions. In *NeurIPS 2022 Competition Track*, pages 189–203. PMLR, 2023.\n- <span id=\"page-14-1\"></span>[115] David Rein, Betty Li Hou, Asa Cooper Stickland, Jackson Petty, Richard Yuanzhe Pang, Julien Dirani, Julian Michael, and Samuel R. Bowman. GPQA: A graduate-level google-proof q&a benchmark. In *First Conference on Language Modeling*, 2024.\n- <span id=\"page-15-4\"></span>[116] Julia Robinson. *On the Hamiltonian game (a traveling salesman problem)*. Rand Corporation, 1949.\n- <span id=\"page-15-2\"></span>[117] Bernardino Romera-Paredes, Mohammadamin Barekatain, Alexander Novikov, Matej Balog, M Pawan Kumar, Emilien Dupont, Francisco JR Ruiz, Jordan S Ellenberg, Pengming Wang, Omar Fawzi, et al. Mathematical discoveries from program search with large language models. *Nature*, 625(7995):468–475, 2024.\n- <span id=\"page-15-17\"></span>[118] Stefan Ropke and Jean-François Cordeau. Branch and cut and price for the pickup and delivery problem with time windows. *Transportation science*, 43(3):267–286, 2009.\n- <span id=\"page-15-18\"></span>[119] Stefan Ropke, Jean-François Cordeau, and Gilbert Laporte. Models and branch-and-cut algorithms for pickup and delivery problems with time windows. *Networks: An International Journal*, 49(4):258–272, 2007.\n- <span id=\"page-15-15\"></span>[120] Stefan Ropke and David Pisinger. An adaptive large neighborhood search heuristic for the pickup and delivery problem with time windows. *Transportation science*, 40(4):455–472, 2006.\n- <span id=\"page-15-13\"></span>[121] Sabre. Sabre crew pairing. [https://your.sabre.com/inthistogether/restart\\\\_efficient\\\\_](https://your.sabre.com/inthistogether/restart_efficient_ops) [ops](https://your.sabre.com/inthistogether/restart_efficient_ops), 2020.\n- <span id=\"page-15-3\"></span>[122] Pranab Sahoo, Ayush Kumar Singh, Sriparna Saha, Vinija Jain, Samrat Mondal, and Aman Chadha. A systematic survey of prompt engineering in large language models: Techniques and applications. *arXiv preprint arXiv:2402.07927*, 2024.\n- <span id=\"page-15-7\"></span>[123] Marti Sanchez, Simon de Givry, and Thomas Schiex. Mendelian error detection in complex pedigrees using weighted constraint satisfaction techniques. *Constraints*, 13(1):130–154, 2008.\n- <span id=\"page-15-16\"></span>[124] Carlo S Sartori and Luciana S Buriol. A study on the pickup and delivery problem with time windows: Matheuristics and new instances. *Computers & Operations Research*, 124:105065, 2020.\n- <span id=\"page-15-5\"></span>[125] Thomas J Schaefer. The complexity of satisfiability problems. In *Proceedings of the tenth annual ACM symposium on Theory of computing*, pages 216–226, 1978.\n- <span id=\"page-15-0\"></span>[126] Timo Schick, Jane Dwivedi-Yu, Roberto Dessí, Roberta Raileanu, Maria Lomeli, Eric Hambro, Luke Zettlemoyer, Nicola Cancedda, and Thomas Scialom. Toolformer: language models can teach themselves to use tools. In *Proceedings of the 37th International Conference on Neural Information Processing Systems (NeurIPS)*, 2023.\n- <span id=\"page-15-19\"></span>[127] Thomas Schiex. Cost function library. [https://forgemia.inra.fr/thomas.schiex/](https://forgemia.inra.fr/thomas.schiex/cost-function-library) [cost-function-library](https://forgemia.inra.fr/thomas.schiex/cost-function-library), 2018.\n- <span id=\"page-15-12\"></span>[128] Eugene I Shakhnovich and AM Gutin. A new approach to the design of stable proteins. *Protein Engineering, Design and Selection*, 6(8):793–800, 1993.\n- <span id=\"page-15-6\"></span>[129] Minghua Shen, Hongzheng Chen, and Nong Xiao. Entropy-directed scheduling for fpga high-level synthesis. *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, 39(10):2588– 2601, 2019.\n- <span id=\"page-15-11\"></span>[130] Ziji Shi, Le Jiang, Ang Wang, Jie Zhang, Xianyan Jia, Yong Li, Chencan Wu, Jialin Li, and Wei Lin. Tap: Efficient derivation of tensor parallel plans for large neural networks. In *Architecture and System Support for Transformer Models (ASSYST@ ISCA)*, 2023.\n- <span id=\"page-15-9\"></span>[131] Eugene Shragowitz and Lynn Keel. A multicommodity flow approach to concurrent global routing. In *Proceedings of the 24th ACM/IEEE Design Automation Conference*, pages 414–419, 1987.\n- <span id=\"page-15-1\"></span>[132] Shivalika Singh, Yiyang Nan, Alex Wang, Daniel D'Souza, Sayash Kapoor, Ahmet Üstün, Sanmi Koyejo, Yuntian Deng, Shayne Longpre, Noah Smith, et al. The leaderboard illusion. *arXiv preprint arXiv:2504.20879*, 2025.\n- <span id=\"page-15-10\"></span>[133] Gus Henry Smith, Zachary D Sisco, Thanawat Techaumnuaiwit, Jingtao Xia, Vishal Canumalla, Andrew Cheung, Zachary Tatlock, Chandrakana Nandi, and Jonathan Balkind. There and back again: A netlist's tale with much egraphin'. *arXiv preprint arXiv:2404.00786*, 2024.\n- <span id=\"page-15-8\"></span>[134] Charlie Snell, Jaehoon Lee, Kelvin Xu, and Aviral Kumar. Scaling llm test-time compute optimally can be more effective than scaling model parameters. *arXiv preprint arXiv:2408.03314*, 2024.\n- <span id=\"page-15-14\"></span>[135] Nadia Souai and Jacques Teghem. Genetic algorithm based approach for the integrated airline crew-pairing and rostering problem. *European Journal of Operational Research*, 199(3):674–683, 2009.\n- <span id=\"page-16-9\"></span>[136] JIRI Soukup. Fast maze router. In *Design Automation Conference*, pages 100–101. IEEE Computer Society, 1978.\n- <span id=\"page-16-15\"></span>[137] Michael B. Stepp. *Equality Saturation: Engineering Challenges and Applications*. PhD thesis, University of California San Diego, 2011.\n- <span id=\"page-16-8\"></span>[138] Nisan Stiennon, Long Ouyang, Jeffrey Wu, Daniel Ziegler, Ryan Lowe, Chelsea Voss, Alec Radford, Dario Amodei, and Paul F Christiano. Learning to summarize with human feedback. *Advances in neural information processing systems*, 33:3008–3021, 2020.\n- <span id=\"page-16-2\"></span>[139] Shaojian Sun, Rachel Brem, Hue Sun Chan, and Ken A Dill. Designing amino acid sequences to fold with good hydrophobic cores. *Protein Engineering, Design and Selection*, 8(12):1205–1213, 1995.\n- <span id=\"page-16-4\"></span>[140] Jianheng Tang, Qifan Zhang, Yuhan Li, Nuo Chen, and Jia Li. Grapharena: Evaluating and exploring large language models on graph computation. In *The Thirteenth International Conference on Learning Representations (ICLR)*, 2025.\n- <span id=\"page-16-0\"></span>[141] Qwen Team. Qwen3: Think deeper, act faster, 2025. <https://qwenlm.github.io/blog/qwen3/>.\n- <span id=\"page-16-13\"></span>[142] Samuel Thomas and James Bornholt. Automatic generation of vectorizing compilers for customizable digital signal processors. *Int'l Conf. on Architectural Support for Programming Languages and Operating Systems (ASPLOS)*, pages 19–34, 2024.\n- <span id=\"page-16-14\"></span>[143] Ecenur Ustun, Ismail San, Jiaqi Yin, Cunxi Yu, and Zhiru Zhang. Impress: Large integer multiplication expression rewriting for fpga hls. *IEEE Symp. on Field Programmable Custom Computing Machines (FCCM)*, pages 1–10, 2022.\n- <span id=\"page-16-6\"></span>[144] C Van Rijsbergen. Information retrieval: theory and practice. In *Proceedings of the joint IBM/University of Newcastle upon tyne seminar on data base systems*, volume 79, pages 1–14, 1979.\n- <span id=\"page-16-12\"></span>[145] Alexa VanHattum, Rachit Nigam, Vincent T Lee, James Bornholt, and Adrian Sampson. Vectorization for digital signal processors via equality saturation. *Int'l Conf. on Architectural Support for Programming Languages and Operating Systems (ASPLOS)*, pages 874–886, 2021.\n- <span id=\"page-16-10\"></span>[146] Anthony Vannelli. An adaptation of the interior point method for solving the global routing problem. *IEEE transactions on computer-aided design of integrated circuits and systems*, 10(2):193–203, 2002.\n- <span id=\"page-16-18\"></span>[147] Jelena Vucinic, David Simoncini, Manon Ruffini, Sophie Barbe, and Thomas Schiex. Positive multistate protein design. *Bioinformatics*, 36(1):122–130, 2020.\n- <span id=\"page-16-19\"></span>[148] Gang Wang, Wenrui Gong, Brian DeRenzi, and Ryan Kastner. Ant colony optimizations for resource- and timing-constrained operation scheduling. *IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems*, 2007.\n- <span id=\"page-16-17\"></span>[149] Yingheng Wang, Zichen Wang, Gil Sadeh, Luca Zancato, Alessandro Achille, George Karypis, and Huzefa Rangwala. Long-context protein language model. *bioRxiv*, pages 2024–10, 2024.\n- <span id=\"page-16-11\"></span>[150] Yisu Remy Wang, Shana Hutchison, Jonathan Leang, Bill Howe, and Dan Suciu. Spores: Sum-product optimization via relational equality saturation for large scale linear algebra. *Int'l Conf. on Very Large Data Bases (VLDB)*, 13(11), 2020.\n- <span id=\"page-16-16\"></span>[151] Joseph L Watson, David Juergens, Nathaniel R Bennett, Brian L Trippe, Jason Yim, Helen E Eisenach, Woody Ahern, Andrew J Borst, Robert J Ragotte, Lukas F Milles, et al. De novo design of protein structure and function with rfdiffusion. *Nature*, 620(7976):1089–1100, 2023.\n- <span id=\"page-16-5\"></span>[152] Jason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Fei Xia, Ed Chi, Quoc V Le, Denny Zhou, et al. Chain-of-thought prompting elicits reasoning in large language models. *Advances in neural information processing systems*, 35:24824–24837, 2022.\n- <span id=\"page-16-1\"></span>[153] Ellen M Wijsman. The role of large pedigrees in an era of high-throughput sequencing. *Human genetics*, 131:1555–1563, 2012.\n- <span id=\"page-16-7\"></span>[154] Max Willsey, Chandrakana Nandi, Yisu Remy Wang, Oliver Flatt, Zachary Tatlock, and Pavel Panchekha. egg: Fast and extensible equality saturation. *Proc. ACM Program. Lang.*, 2021.\n- <span id=\"page-16-3\"></span>[155] David H Wolpert and William G Macready. No free lunch theorems for optimization. *IEEE transactions on evolutionary computation*, 1(1):67–82, 1997.\n- <span id=\"page-17-8\"></span>[156] Zhiyong Wu, Yaoxiang Wang, Jiacheng Ye, and Lingpeng Kong. Self-adaptive in-context learning: An information compression perspective for in-context example selection and ordering. In *Proceedings of the 61st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)*, 2023.\n- <span id=\"page-17-3\"></span>[157] Ziyang Xiao, Dongxiang Zhang, Yangjun Wu, Lilin Xu, Yuan Jessica Wang, Xiongwei Han, Xiaojin Fu, Tao Zhong, Jia Zeng, Mingli Song, et al. Chain-of-experts: When llms meet complex operations research problems. In *The twelfth international conference on learning representations (ICLR)*, 2023.\n- <span id=\"page-17-9\"></span>[158] Yuxi Xie, Kenji Kawaguchi, Yiran Zhao, James Xu Zhao, Min-Yen Kan, Junxian He, and Michael Xie. Self-evaluation guided beam search for reasoning. *Advances in Neural Information Processing Systems*, 36:41618–41650, 2023.\n- <span id=\"page-17-12\"></span>[159] AMD Xilinx. Vitis high-level synthesis (hls), 2025. [https://www.amd.com/de/products/](https://www.amd.com/de/products/software/adaptive-socs-and-fpgas/vitis/vitis-hls.html) [software/adaptive-socs-and-fpgas/vitis/vitis-hls.html](https://www.amd.com/de/products/software/adaptive-socs-and-fpgas/vitis/vitis-hls.html).\n- <span id=\"page-17-18\"></span>[160] Yassine Yaakoubi, François Soumis, and Simon Lacoste-Julien. Machine learning in airline crew pairing to construct initial clusters for dynamic constraint aggregation. *EURO Journal on Transportation and Logistics*, 9(4):100020, 2020.\n- <span id=\"page-17-4\"></span>[161] Chengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun Chen. Large language models as optimizers. In *The Twelfth International Conference on Learning Representations (ICLR)*, 2024.\n- <span id=\"page-17-13\"></span>[162] Yichen Yang, Phitchaya Phothilimthana, Yisu Wang, Max Willsey, Sudip Roy, and Jacques Pienaar. Equality saturation for tensor graph superoptimization. *Conf. on Machine Learning and Systems (MLSys)*, 3:255–268, 2021.\n- <span id=\"page-17-17\"></span>[163] Chen Yanover, Menachem Fromer, and Julia M Shifman. Dead-end elimination for multistate protein design. *Journal of Computational Chemistry*, 28(13):2122–2129, 2007.\n- <span id=\"page-17-6\"></span>[164] Shunyu Yao, Noah Shinn, Pedram Razavi, and Karthik R Narasimhan. {\\$\\tau\\$}-bench: A benchmark for \\underline{T}ool-\\underline{A}gent-\\underline{U}ser interaction in real-world domains. In *The Thirteenth International Conference on Learning Representations (ICLR)*, 2025.\n- <span id=\"page-17-0\"></span>[165] Shunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik R Narasimhan, and Yuan Cao. React: Synergizing reasoning and acting in language models. In *The Eleventh International Conference on Learning Representations*, 2023.\n- <span id=\"page-17-7\"></span>[166] Haoran Ye, Jiarui Wang, Zhiguang Cao, Federico Berto, Chuanbo Hua, Haeyeon Kim, Jinkyoo Park, and Guojie Song. Reevo: Large language models as hyper-heuristics with reflective evolution. In *Advances in Neural Information Processing Systems (NeurIPS)*, 2024.\n- <span id=\"page-17-16\"></span>[167] Kaizhi Yue and Ken A Dill. Forces of tertiary structural organization in globular proteins. *Proceedings of the National Academy of Sciences*, 92(1):146–150, 1995.\n- <span id=\"page-17-10\"></span>[168] Qiyuan Zhang, Fuyuan Lyu, Zexu Sun, Lei Wang, Weixu Zhang, Zhihan Guo, Yufei Wang, Irwin King, Xue Liu, and Chen Ma. What, how, where, and how well? a survey on test-time scaling in large language models. *arXiv preprint arXiv:2503.24235*, 2025.\n- <span id=\"page-17-2\"></span>[169] Xuanchang Zhang, Wei Xiong, Lichang Chen, Tianyi Zhou, Heng Huang, and Tong Zhang. From lists to emojis: How format bias affects model alignment. *arXiv preprint arXiv:2409.11704*, 2024.\n- <span id=\"page-17-14\"></span>[170] Yihong Zhang. The e-graph extraction problem is np-complete. https://effect.systems/blog/egraphextraction.html.\n- <span id=\"page-17-5\"></span>[171] Wenting Zhao, Nan Jiang, Celine Lee, Justin T Chiu, Claire Cardie, Matthias Gallé, and Alexander M Rush. Commit0: Library generation from scratch. In *The Thirteenth International Conference on Learning Representations (ICLR)*, 2025.\n- <span id=\"page-17-15\"></span>[172] Yanli Zhao, Andrew Gu, Rohan Varma, Liang Luo, Chien-Chin Huang, Min Xu, Less Wright, Hamid Shojanazeri, Myle Ott, Sam Shleifer, et al. Pytorch fsdp: experiences on scaling fully sharded data parallel. *arXiv preprint arXiv:2304.11277*, 2023.\n- <span id=\"page-17-11\"></span>[173] Chujie Zheng, Zhenru Zhang, Beichen Zhang, Runji Lin, Keming Lu, Bowen Yu, Dayiheng Liu, Jingren Zhou, and Junyang Lin. Processbench: Identifying process errors in mathematical reasoning. *arXiv preprint arXiv:2412.06559*, 2024.\n- <span id=\"page-17-1\"></span>[174] Lianmin Zheng, Wei-Lin Chiang, Ying Sheng, Siyuan Zhuang, Zhanghao Wu, Yonghao Zhuang, Zi Lin, Zhuohan Li, Dacheng Li, Eric Xing, et al. Judging llm-as-a-judge with mt-bench and chatbot arena. *Advances in Neural Information Processing Systems (NeurIPS)*, 2023.\n- <span id=\"page-18-2\"></span>[175] Lianmin Zheng, Zhuohan Li, Hao Zhang, Yonghao Zhuang, Zhifeng Chen, Yanping Huang, Yida Wang, Yuanzhong Xu, Danyang Zhuo, Eric P Xing, et al. Alpa: Automating inter-and {Intra-Operator} parallelism for distributed deep learning. In *16th USENIX Symposium on Operating Systems Design and Implementation (OSDI 22)*, pages 559–578, 2022.\n- <span id=\"page-18-1\"></span>[176] Zhi Zheng, Zhuoliang Xie, Zhenkun Wang, and Bryan Hooi. Monte carlo tree search for comprehensive exploration in llm-based automatic heuristic design. In *Proceedings of the 42nd International Conference on Machine Learning (ICML)*, 2025.\n- <span id=\"page-18-0\"></span>[177] Terry Yue Zhuo, Vu Minh Chien, Jenny Chim, Han Hu, Wenhao Yu, Ratnadira Widyasari, Imam Nur Bani Yusuf, Haolan Zhan, Junda He, Indraneil Paul, Simon Brunner, Chen GONG, James Hoang, Armel Randy Zebaze, Xiaoheng Hong, Wen-Ding Li, Jean Kaddour, Ming Xu, Zhihan Zhang, Prateek Yadav, Naman Jain, Alex Gu, Zhoujun Cheng, Jiawei Liu, Qian Liu, Zijian Wang, David Lo, Binyuan Hui, Niklas Muennighoff, Daniel Fried, Xiaoning Du, Harm de Vries, and Leandro Von Werra. Bigcodebench: Benchmarking code generation with diverse function calls and complex instructions. In *The Thirteenth International Conference on Learning Representations (ICLR)*, 2025.\n\n| A |          | Prompt Design                                   | 21 |\n|---|----------|-------------------------------------------------|----|\n|   | A.1      | System Prompt<br>.                              | 21 |\n|   | A.2      | User Prompt                                     | 21 |\n|   | A.3      | Prompts for Improvement Guidance<br>.           | 22 |\n|   | A.4      | Refinement Prompt for Problem Descriptions<br>. | 23 |\n|   | A.5      | Example Program Description<br>.                | 23 |\n| B | Models   |                                                 | 24 |\n| C |          | Problem Set                                     | 24 |\n|   | C.1      | Operator Scheduling<br>.                        | 25 |\n|   | C.2      | Technology Mapping<br>.                         | 25 |\n|   | C.3      | Global Routing<br>.                             | 25 |\n|   | C.4      | E-Graph Extraction                              | 26 |\n|   | C.5      | Intra-Operator Parallelism<br>.                 | 26 |\n|   | C.6      | Protein Sequence Design<br>.                    | 26 |\n|   | C.7      | Mendelian Error Detection<br>.                  | 27 |\n|   | C.8      | Airline Crew Pairing<br>.                       | 27 |\n|   | C.9      | Pickup and Delivery Problem with Time Windows   | 28 |\n| D |          | Additional Experiments                          | 28 |\n|   | D.1      | Experimental Settings                           | 28 |\n|   | D.2      | Detailed Results on Each Problem<br>.           | 28 |\n|   | D.3      | Ablation on Temperature<br>.                    | 31 |\n|   | D.4      | Few-Shot Demonstration<br>.                     | 31 |\n|   | D.5      | Feedback Rounds                                 | 32 |\n|   | D.6      | Iterative Best-of-N Sampling                    | 32 |\n|   | D.7      | Error Analysis                                  | 32 |\n|   | D.8      | C++ Example                                     | 33 |\n| E |          | Detailed Analysis of Case Study                 | 34 |\n| F | Datasets |                                                 | 49 |\n\n# <span id=\"page-20-0\"></span>A Prompt Design\n\nIn this section, we detail the system and user prompts used by the LLM agent, as well as the auxiliary prompt employed to enhance our problem descriptions.\n\n### <span id=\"page-20-1\"></span>A.1 System Prompt\n\nEach iteration of our benchmark begins with a task-agnostic system prompt that instructs the LLM to generate and iteratively refine executable heuristics for combinatorial optimization problems. This system prompt is followed by a task-specific problem statement and an input/output specification. The prompt includes placeholders – highlighted in red – that are dynamically instantiated at runtime for each task. For instance, {NUM\\_CPU\\_CORES} represents the CPU core limit for the task (default: 8), and {TIMEOUT} specifies the wall-clock time limit (default: 10 seconds).\n\n### System Prompt\n\nYou are a world-class optimization expert and algorithmic problem solver. Your task is to develop a highly efficient solution to the following optimization problem. Please analyze the problem background, mathematical formulation, and I/O specifications with extreme rigor and attention to detail.\n\nYour mission is to devise and implement the most performant algorithm possible, optimizing for both computational efficiency and solution quality. You should leverage your deep knowledge of algorithms, data structures, and optimization techniques to craft a powerful solution. You have complete freedom in your algorithmic approach. Think systematically and creatively. Your goal is to push the boundaries of what's possible within the computational constraints. Please strictly follow the instructions below.\n\n- 1. A problem template is provided below. You only need to implement the solve function. Do NOT modify the function signature including the data types of the input arguments. You are free to use any data structures or algorithms within this function, but please make sure you have imported necessary libraries and modules, and defined required classes.\n- 2. The evaluation machine has {NUM\\_CPU\\_CORES} CPU cores and sufficient memory to run your program. The time limit for this question is {TIMEOUT} seconds. You are free to implement parallel algorithms where appropriate to maximize performance.\n- 3. The Python version is 3.12. You may use any standard Python libraries and only the following third-party libraries:\n\t- numpy==2.2.5\n\t- networkx==3.4.2\n\t- pandas==2.2.3\n- 4. Your response should consist of a complete implementation of the 'solve' function. Do NOT include any explanations, comments, additional text, or Markdown formatting.\n- 5. You will receive execution feedback after the user runs your program, including runtime metrics and correctness evaluation.\n\n### <span id=\"page-20-2\"></span>A.2 User Prompt\n\nFor each problem, the first iteration begins with the following user prompt, which introduces the task and its objective to the LLM, along with a program template that the model is expected to complete.\n\nUser Prompt # Problem Information {PROBLEM DESCRIPTION} # Program Template def solve(input\\_file: str, solution\\_file: str): \"\"\" Solve the optimization problem. Please do NOT change the function name and arguments. Inputs should be read from input\\_file and outputs should be written to solution\\_file. Input and output formats have been specified in the problem statement. \"\"\" raise NotImplementedError( \"This is a placeholder implementation you need to fill in.\" )\n\n## <span id=\"page-21-0\"></span>A.3 Prompts for Improvement Guidance\n\nBased on the feasibility of the final outputs, we issue one of two improvement prompts in subsequent iterations. If any test cases fail, we provide the following prompt:\n\n![](_page_21_Figure_3.jpeg)\n\nOtherwise, if all test cases pass verification, we issue the following prompt:\n\nImprovement Guidance Case 2\n\n# Feedback from Previous Iteration (Iteration {iteration-1})\n\n# Improvement Guidance\n\n...\n\nPlease carefully observe the problem structure and improve upon this program by:\n\n1. Addressing any weaknesses in the previous approach.\n\n- 2. Introducing more advanced or efficient algorithms.\n- 3. Focusing on improving performance for test cases.\n\nYour goal is to improve the solution for as many test cases as possible, with special attention to those where the previous solution performed poorly.\n\n### <span id=\"page-22-0\"></span>A.4 Refinement Prompt for Problem Descriptions\n\nTo ensure clarity and correctness in problem specification, we employ a human-in-the-loop process. Specifically, we prompt a weaker LLM to flag any unclear or ambiguous statements in the task description. The following prompt is used for this purpose:\n\n### Refinement Prompt for Problem Descriptions\n\nIf you were to solve the programming task below, do you have any questions? Is there anything I should clarify before you begin writing code?\n\n# Problem Description {PROBLEM DESCRIPTION}\n\n### <span id=\"page-22-1\"></span>A.5 Example Program Description\n\nThe following provides an example problem description for operator scheduling. For other problems, please refer to our GitHub repository.\n\n#### ## Background High-level synthesis (HLS) is an important stage in electronic design automation (EDA), aimed at translating a high-level program specification (e.g., written in C/C++ or SystemC) into a cycle-accurate hardware implementation. After the program is parsed and analyzed, it is typically transformed into an intermediate representation known as a Control Data Flow Graph (CDFG). This graph captures the operations (e.g., arithmetic, memory accesses) and their control/data dependencies. The CDFG can further be processed into a Directed Acyclic Graph (DAG) to facilitate scheduling and optimization. ,→ ,→ ,→ ,→ ,→ ,→ One of the core challenges in HLS is operator scheduling, which determines the exact control step (or cycle) at which each operation is executed, while satisfying data dependencies and resource constraints. Efficient scheduling plays a critical role in optimizing design quality in terms of performance, area, and power. ,→ ,→ ,→ ## Formalization Consider a CDFG with \\$n\\$ operation nodes \\$o\\_i\\$, where \\$i \\in O = \\{1, 2, \\ldots, n\\}\\$, and a precedence relation \\$\\prec\\$ on \\$O\\$ that captures operation dependencies. Each operation \\$o\\_i\\$ is associated with a cycle delay \\$d\\_i \\in \\mathbb{Z}^+\\$ and a resource type \\$r\\_i \\in R = \\{1, 2, \\ldots, k\\}\\$. Let \\$T = \\{0, 1, 2, \\ldots, L\\}\\$ represent the set of control steps (c-steps), and define a schedule as an \\$n\\$-tuple \\$s = (t\\_1, t\\_2, \\ldots, t\\_n)\\$, where \\$t\\_i \\in T\\$ denotes the start time (c-step) of operation \\$o\\_i\\$. ,→ ,→ ,→ ,→ ,→ A schedule \\$s\\$ is feasible if it satisfies all data dependencies: \\$\\forall i, j \\in O: i \\prec j \\Rightarrow t\\_i + d\\_i \\leq t\\_j\\$. Let \\$S\\$ denote the set of all feasible schedules. For a given schedule \\$s\\$, let \\$N\\_r(t)\\$ be the number of operations that use resource \\$r\\$ in control step \\$t\\$, and define the total usage of resource \\$r\\$ as \\$N\\_r = \\sum\\_{t \\in T} N\\_r(t)\\$. ,→ ,→ Given a bound \\$G\\_r\\$ on the number of available instances for each resource type \\$r \\in R\\$, the operator scheduling problem is to find a feasible schedule \\$s \\in S\\$ that minimizes the overall latency \\$L\\$, defined as ,→ ,→\n\n```\n$\\min_{s \\in S} \\max_{i \\in O} (t_i + d_i)$,\nsubject to the resource constraints\n$\\forall r \\in R, t \\in T: N_r(t) \\leq G_r$.\n## Input Format\nThe input is provided in JSON format with the following structure:\n```json\n{\n  \"name\": \"input\",\n  \"delay\": {\n    \"mul\": 3,\n    \"sub\": 1\n  },\n  \"resource\": {\n    \"mul\": 2,\n    \"sub\": 1\n  },\n  \"nodes\": [\n    [\"n1\", \"mul\"],\n    [\"n2\", \"mul\"],\n    [\"n3\", \"sub\"]\n  ],\n  \"edges\": [\n    [\"n1\", \"n3\", \"lhs\"],\n    [\"n2\", \"n3\", \"rhs\"]\n  ]\n}\n```\nWhere:\n- `name`: Name of the input graph\n- `delay`: Maps each resource type to its execution delay in cycles\n- `resource`: Maps each resource type to the number of available functional units\n- `nodes`: List of nodes, where each node is represented as `[node_id, resource_type]`\n- `edges`: List of edges, where each edge is represented as `[source_node, target_node, edge_name]`\n## Output Format\nThe output should provide the execution schedule of the program, indicating the start cycle of each\n    operation. For example, the following output means that `n1` and `n2` start at cycle 0, while `n3`\n    starts at cycle 3:\n,→\n,→\n```\nn1:0\nn2:0\nn3:3\n```\n```\n# <span id=\"page-23-1\"></span>B Models\n\nThe LLMs used in our experiments are listed in Table [4.](#page-7-1) All models were accessed via official APIs provided by their respective organizations, except for the Meta models, which are accessed through the OpenRouter [\\[104\\]](#page-14-9) API.\n\nTable 5: Model specifications with API names and official pricing\n\n| Organization | Model             | API Name                                      | Price (\\$In/\\$Out) | Type      |\n|--------------|-------------------|-----------------------------------------------|--------------------|-----------|\n| OpenAI       | GPT-o4-mini       | o4-mini:high                                  | 1.1/4.4            | Reasoning |\n| Anthropic    | Claude-3.7-Sonnet | claude-3-7-sonnet-20250219                    | 3/15               | Reasoning |\n| DeepSeek     | DeepSeek-V3       | deepseek-chat(0324)                           | 0.27/1.10          | Base      |\n| DeepSeek     | DeepSeek-R1       | deepseek-reasoner                             | 0.55/2.19          | Reasoning |\n| Google       | Gemini-2.5-Flash  | gemini-2.5-flash-preview-04-17                | 0.15/3.5           | Reasoning |\n| Google       | Gemini-2.5-Pro    | gemini-2.5-pro-preview-05-06                  | 1.25/10.0          | Reasoning |\n| Meta         | LLaMA-3.3-70B     | meta-llama/Llama-3.3-70B-Instruct             | 0.07/0.33          | Base      |\n| Meta         | LLaMA-4-Maverick  | meta-llama/Llama-4-Maverick-17B-128E-Instruct | 0.27/0.85          | Base      |\n| Alibaba      | Qwen3-235B        | qwen3-235b-a22b                               | 0.29/2.86          | Reasoning |\n\n# <span id=\"page-23-0\"></span>C Problem Set\n\nIn this section, we provide more details on the problems included in Table [2.](#page-5-0) For a representative problem description used in the prompts, please consult our GitHub repository for additional details.\n\n### <span id=\"page-24-0\"></span>C.1 Operator Scheduling\n\nOperator scheduling is a critical stage in high-level synthesis (HLS) [\\[31,](#page-10-8) [107\\]](#page-14-10), the process of converting behavioral hardware descriptions into register-transfer level (RTL) implementations. This task involves carefully assigning each operation to a specific clock cycle while managing a variety of constraints such as data dependencies, resource availability, and performance targets. The effectiveness of the scheduling process is vital, as it directly influences key design metrics including area, power consumption, and execution time, making it an important focus in the field of electronic design automation (EDA).\n\nOver the years, researchers have developed a wide range of techniques to tackle the inherent challenges of operator scheduling in HLS. Exact methods, such as those based on integer linear programming (ILP) [\\[61,](#page-12-9) [105\\]](#page-14-11), can provide optimal solutions but often suffer from scalability issues. As a result, many commercial and academic HLS tools [\\[159,](#page-17-12) [16\\]](#page-9-6) rely on heuristics to achieve practical, nearoptimal results. Traditional heuristic approaches, including priority-function-based methods [\\[129,](#page-15-6) [109,](#page-14-12) [110\\]](#page-14-13), focus on balancing resource utilization with performance requirements. Notably, methods leveraging systems of difference constraints (SDC) enable an efficient formulation that captures a rich set of scheduling restrictions and casts the optimization objective into a linear programming (LP) framework [\\[33,](#page-10-6) [35\\]](#page-10-9). More recently, the incorporation of machine learning techniques [\\[22,](#page-10-10) [87\\]](#page-13-5) has further advanced the state-of-the-art, enhancing both scheduling efficiency and solution quality in the face of increasingly complex hardware designs.\n\n### <span id=\"page-24-1\"></span>C.2 Technology Mapping\n\nTechnology mapping, in the context of logic synthesis for integrated circuits and field-programmable gate arrays (FPGAs), is the process of converting a logic network into an equivalent network of standard cells or logic resources from a specific technology library. The objective is to optimize key design metrics such as area, delay, and power consumption. It is a crucial step in the VLSI design flow and FPGA design flow, determining the actual physical implementation of a design.\n\nHere in our problem setting, we focus on area-optimal technology mapping for lookup table (LUT) based FPGAs. Given an input logic network, the goal is to cover the network with K-input subgraphs, each of which can be implemented by a K-LUT, while minimizing the number of LUTs representing the circuit area.\n\nThe most widely adopted approaches are cut-based methods, which operate in two stages: cut enumeration and cut selection. In this approach, all feasible K-input cuts – i.e., subgraphs with at most K inputs – are enumerated for each node in the boolean network. Then, a dynamic programmingbased selection process chooses one cut per node to construct a full LUT cover of the circuit, optimizing for metrics such as area or delay [\\[19,](#page-9-1) [30,](#page-10-11) [95\\]](#page-13-7). A refinement of this approach is known as priority cut pruning, which retains only a limited set of the most promising cuts per node rather than considering all possible cuts. This significantly improves scalability for large circuits and is widely implemented in tools such as ABC [\\[14\\]](#page-9-5).\n\n### <span id=\"page-24-2\"></span>C.3 Global Routing\n\nThe global routing problem addresses the challenge of planning signal paths across a chip after logic placement, determining how a set of nets should traverse the layout to ensure connectivity while reserving space for detailed routing. Rather than producing exact wire geometries, global routing generates abstract paths through routing regions. This step must account for routing congestion, layer limitations, and timing criticality, while managing a growing number of nets in modern designs like Very-Large-Scale Integration (VLSI). The quality of the global routing solution plays a critical role in determining the feasibility and effectiveness of downstream routing stages and can ultimately dictate the success or failure of physical design closure.\n\nThe problem has been studied extensively via sequential and ILP-based methods. Maze routing, introduced by Lee et al. [\\[75\\]](#page-12-10), laid the groundwork for sequential approaches, with subsequent improvements such as the work by Soukup [\\[136\\]](#page-16-9). For multi-terminal nets, rectilinear Steiner tree methods were developed [\\[32\\]](#page-10-12). However, sequential routing lacks global coordination and often leads to congestion. ILP-based methods formulate routing as a 0-1 programming, concurrently optimizing over all nets with objectives like wire length and capacity constraints. While exact ILP\n\nsolvers are computationally intensive, relaxation techniques such as randomized rounding [\\[17\\]](#page-9-7) and multi-commodity network flow models [\\[131,](#page-15-9) [4\\]](#page-9-8) have been employed. Interior-point methods for solving the LP relaxation [\\[146,](#page-16-10) [12\\]](#page-9-9) have also proven effective for scalable and near-optimal routing.\n\nSapatnekar et al. [\\[59\\]](#page-12-11) conducted a comprehensive survey on global routing for integrated circuits. Moffitt et al. [\\[96\\]](#page-13-14) revisited the problem by briefing the history and emphasizing open challenges that remain unsolved.\n\n# <span id=\"page-25-0\"></span>C.4 E-Graph Extraction\n\nE-graph [\\[18,](#page-9-10) [99\\]](#page-14-14) is a data structure that compactly represents a set of expressions. Given an input program and a set of rewrite rules, an e-graph is constructed by applying the rules to the program, generating new expressions, and merging equivalent expressions. It has been widely used to represent and explore the huge number of equivalent program space in tensor graph transformation [\\[162,](#page-17-13) [24\\]](#page-10-13), sparse linear algebra optimization [\\[150\\]](#page-16-11), code optimization [\\[73,](#page-12-12) [133\\]](#page-15-10), digital signal processor (DSP) compilation [\\[145,](#page-16-12) [142\\]](#page-16-13), circuit datapath synthesis [\\[143,](#page-16-14) [26\\]](#page-10-14), and floating-point arithmetic [\\[108\\]](#page-14-15).\n\nIn an e-graph, all functionally equivalent terms are organized in the same equivalent classes, known as e-classes. Nodes within each e-class that represent values or operators are called e-nodes. E-classes are a partition of e-nodes, where each e-node belongs to exactly one e-class. Dependencies in e-graphs are directed, which point from e-nodes to their children e-classes, indicating the operator (e-node) requires the values (e-nodes) from the child e-classes to compute its value.\n\nIn e-graph extraction, an optimized term from an e-graph is extracted after rewrites, based on a userdefined cost model. The goal is to produce a functionally equivalent but improved implementation of the original input program. The e-graph extraction problem is proven to be NP-hard when common sub-expressions are considered [\\[137,](#page-16-15) [170\\]](#page-17-14).\n\nExisting e-graph extraction methods include exact methods employing ILP [\\[26,](#page-10-14) [133\\]](#page-15-10). Recently, there has been significant progress in employing heuristics for e-graph extraction. These include a simple working-list method [\\[108\\]](#page-14-15), a relaxation method utilizing gradient descent [\\[15\\]](#page-9-0), and a specialized method tailored for sparse e-graphs [\\[50\\]](#page-11-5). The dataset used in evaluation for this work primarily comes from SmoothE [\\[15\\]](#page-9-0).\n\n## <span id=\"page-25-1\"></span>C.5 Intra-Operator Parallelism\n\nIntra-Operator Parallelism (IOPDDL), an emerging challenge introduced in the ASPLOS'25 contest track [\\[97\\]](#page-14-4), addresses the complexities of distributed deep learning. Leading teams in this competition have predominantly employed meta-heuristic approaches, distinguished by their unique pre-processing and optimization strategies.\n\nThe effective distribution of large machine learning models across multiple hardware accelerators is paramount for achieving desired performance in both training and serving applications [\\[175,](#page-18-2) [172,](#page-17-15) [130,](#page-15-11) [113,](#page-14-16) [76,](#page-12-13) [44,](#page-11-6) [23\\]](#page-10-15). This task necessitates sharding the computation graph to minimize communication overhead, a process made intricate by the vast number of operations and tensors involved. Specifically, for a given graph where nodes represent operations with distinct execution strategies (each possessing associated cost and memory usage), an optimal strategy must be chosen for every node. The objective is to minimize the aggregate sum of node and edge costs, without exceeding a strict memory usage constraint across all devices at any point. The inherent diversity in topological and memory characteristics of ML models across varied tasks and modalities renders this problem especially demanding.\n\n## <span id=\"page-25-2\"></span>C.6 Protein Sequence Design\n\nUnderstanding how proteins fold into their native three-dimensional structures [\\[67,](#page-12-14) [151\\]](#page-16-16) is a central problem in structural biology [\\[94,](#page-13-15) [45\\]](#page-11-10), traditionally framed as a forward problem: predicting the structure a given amino acid sequence will adopt [\\[82,](#page-13-16) [149\\]](#page-16-17). In contrast, the protein sequence design or inverse folding problem starts from a fixed target structure and seeks sequences that are likely to fold into it. Many works have shown that this inverse formulation not only offers practical applications in protein engineering but also deepens our understanding of sequence–structure relationships [\\[43,](#page-11-11) [167,](#page-17-16) [128,](#page-15-12) [40,](#page-11-12) [139,](#page-16-2) [74\\]](#page-12-15).\n\nA common modeling approach treats sequence design as a global optimization problem over the space of amino acid sequences. Methods developed by Sun et al. [\\[139\\]](#page-16-2), Shakhnovich and Gutin [\\[128\\]](#page-15-12), and others define a fitness function to select sequences with favorable folding properties. These functions are designed to balance positive design (low free energy in the target structure) with negative design (high energy in competing folds), promoting both thermodynamic stability and structural specificity. More recently, people have been working on multi-state design with more or less general fitness functions [\\[112,](#page-14-17) [7,](#page-9-11) [5,](#page-9-12) [98,](#page-14-18) [163,](#page-17-17) [54,](#page-11-13) [147\\]](#page-16-18)\n\nIn our benchmark, we focus on the Grand Canonical (GC) model [\\[139\\]](#page-16-2) of protein sequence design. The GC model operates on (i) a detailed three-dimensional geometric representation of a target structure with n residues, (ii) a simplified binary alphabet distinguishing only hydrophobic (H) and polar (P) residues, and (iii) a fitness function Φ that favors sequences with densely packed hydrophobic cores while penalizing solvent-exposed hydrophobic residues. Despite its simplicity, the H/P model has been shown to capture key qualitative features of real protein structures [\\[41,](#page-11-14) [68\\]](#page-12-16). Several studies [\\[93,](#page-13-17) [11\\]](#page-9-13) have explored the correspondence between sequences optimized under the GC model and those observed in natural proteins. However, a key obstacle has remained: computing an optimal sequence for a given structure is computationally challenging. The brute-force enumeration over all 2 <sup>n</sup> H/P sequences is infeasible for realistic protein sizes, and the algorithmic complexity of the problem was explicitly raised as an open question by Hart et al. [\\[56\\]](#page-11-7). An efficient algorithm that constructs an optimal sequence in polynomial runtime was introduced later [\\[70\\]](#page-12-6) using network flow.\n\n### <span id=\"page-26-0\"></span>C.7 Mendelian Error Detection\n\nChromosomes encode an individual's genetic information, with each gene occupying a specific position known as a locus. At each locus, a diploid organism carries two alleles – one inherited from each parent – forming its genotype. When direct genotyping is not available, researchers rely on the observable traits or phenotypes, which represent sets of compatible genotypes. A group of related individuals, along with their phenotypes at a locus, is organized into a pedigree, where each individual is either a founder or has parents defined within the structure.\n\nDue to experimental and human errors, pedigree data may contain inaccuracies. These errors are classified as either parental errors (incorrect parentage, which we assume do not occur here) or phenotype errors, which can lead to Mendelian errors. A Mendelian error arises when all genotype combinations compatible with observed phenotypes violate Mendel's law that each individual inherits one allele from each parent. Detecting such inconsistencies is computationally challenging; the number of possible genotype combinations grows exponentially with pedigree size, making full enumeration impractical. In fact, verifying consistency has been shown to be NP-complete [\\[1\\]](#page-9-14).\n\nError detection and correction are crucial for downstream tasks like genetic mapping or disease gene localization. However, existing tools are often limited by scalability issues, strong assumptions, or incomplete analysis. To address these limitations, a soft constraint network framework for detecting Mendelian inconsistencies was proposed [\\[123\\]](#page-15-7), estimating the minimum number of required corrections, and suggesting optimal modifications. These problems naturally align with weighted constraint satisfaction and provide a rich testbed for scalable and flexible inference in large, complex pedigrees.\n\n# <span id=\"page-26-1\"></span>C.8 Airline Crew Pairing\n\nThe airline crew pairing problem is a well-established topic in operations research. It involves constructing sequences of flight legs – known as pairings – that begin and end at a crew base, cover all scheduled flights, and satisfy a variety of regulatory and contractual constraints. The primary goal is to minimize total crew-related costs, such as wages, hotel accommodations, and deadhead travel, while ensuring legality and operational feasibility. This problem is typically formulated as a set partitioning model and addressed using column generation and branch-and-price techniques [\\[39,](#page-11-15) [69\\]](#page-12-17). Foundational systems developed for carriers like American Airlines demonstrated the effectiveness of these methods at scale [\\[8\\]](#page-9-15). More recent innovations include dynamic constraint aggregation [\\[48\\]](#page-11-16) and machine learning-based pairing generation [\\[160\\]](#page-17-18), which are now integral to commercial solvers such as Jeppesen [\\[64\\]](#page-12-18) and Sabre [\\[121\\]](#page-15-13), capable of processing monthly schedules with tens of thousands of flights.\n\nIn addition to exact methods, heuristic and metaheuristic techniques – such as genetic algorithms, simulated annealing, and local search – have been explored to improve scalability and reduce computation time, particularly for medium-sized instances or disruption recovery [\\[89,](#page-13-18) [135\\]](#page-15-14). These hybrid approaches aim to complement exact optimization methods by leveraging historical data and incorporating planner preferences, offering more flexible and adaptive solutions in practice.\n\n### <span id=\"page-27-1\"></span>C.9 Pickup and Delivery Problem with Time Windows\n\nThe Pick-up and Delivery Problem with Time Windows (PDPTW), originally proposed by Dumas, Desrosiers, and Soumis [\\[47\\]](#page-11-17), is generalized from a classical NP-hard combinatorial optimization problem – the Capacitated Vehicle Routing Problem (CVRP). It introduces additional complexity through precedence constraints, requiring pick-up locations to precede corresponding drop-off locations, and service time windows at each location. The problem can be seen in many logistic and public transportation systems, with the primary objective of minimizing the total travel cost.\n\nOver the past three decades, a wide range of models and algorithms have been proposed to address the PDPTW, with most falling into the category of heuristic or metaheuristic approaches. Prominent works include simulated annealing [\\[77,](#page-12-1) [13\\]](#page-9-16), large neighborhood search [\\[34,](#page-10-16) [120\\]](#page-15-15), and iterated local search [\\[124\\]](#page-15-16). In contrast, research into exact solution methods has been relatively limited, with the most effective approaches relying on the set partitioning formulation combined with the branchcut-and-price algorithm [\\[118,](#page-15-17) [10\\]](#page-9-17). Ropke et al. [\\[119\\]](#page-15-18) provided a comprehensive survey of PDPTW solvers developed up to 2007. Ho et al. [\\[58\\]](#page-11-18) later reviewed more recent advancements up to 2018, with a particular emphasis on PDPTW variants for people transportation, referred to as the Dial-a-Ride problem.\n\nTo support algorithm development, several benchmark datasets have been created and maintained. The Li and Lim dataset [\\[77\\]](#page-12-1) is widely used and includes instances ranging from 100 to 1000 locations. More recently, Sartori and Buriol [\\[124\\]](#page-15-16) released a larger-scale dataset generated from real-world spatial-temporal distributions.\n\n# <span id=\"page-27-0\"></span>D Additional Experiments\n\nIn this section, we provide more experimental results and analysis on our benchmark.\n\n### <span id=\"page-27-2\"></span>D.1 Experimental Settings\n\n<span id=\"page-27-4\"></span>By default, we constrain LLMs to generate Python code for each problem and execute the code on a CPU server, with each instance allocated 8 CPU cores. The timeout for each problem is specified in Table [6.](#page-27-4)\n\n| Problem                             | Timeout (sec) |  |  |  |  |  |  |  |  |\n|-------------------------------------|---------------|--|--|--|--|--|--|--|--|\n| Operator scheduling                 | 10            |  |  |  |  |  |  |  |  |\n| Technology mapping                  | 10            |  |  |  |  |  |  |  |  |\n| Global routing                      | 300           |  |  |  |  |  |  |  |  |\n| E-graph extraction                  | 10            |  |  |  |  |  |  |  |  |\n| Intra-op parallelism                | 60            |  |  |  |  |  |  |  |  |\n| Protein sequence design             | 10            |  |  |  |  |  |  |  |  |\n| Mendelian error detection           | 10            |  |  |  |  |  |  |  |  |\n| Airline crew pairing                | 10            |  |  |  |  |  |  |  |  |\n| Pickup and delivery w/ time windows | 60            |  |  |  |  |  |  |  |  |\n\nTable 6: Timeout for each problem.\n\n### <span id=\"page-27-3\"></span>D.2 Detailed Results on Each Problem\n\nWe provide the detailed solves@i values for each problem in Tables [7](#page-28-0) through [15.](#page-29-0) The variation in solves@i across different problems highlights the diverse levels of difficulty, as summarized in Table [2.](#page-5-0) For instance, the global routing problem remains unsolved by all evaluated LLMs – even for generating a single feasible solution. In the case of the pickup and delivery problem, the low\n\n<span id=\"page-28-0\"></span>solveIII@10 ratio also indicates that current LLMs struggle to consistently satisfy the problem's constraints.\n\nTable 7: solves@i results on operator scheduling problem.\n\n|                   |        | solveIII |        |        | solveII |        |        | solveI |        |  |\n|-------------------|--------|----------|--------|--------|---------|--------|--------|--------|--------|--|\n| Model             | @10    | @5       | @1     | @10    | @5      | @1     | @10    | @5     | @1     |  |\n| DeepSeek-V3       | 100.0% | 100.0%   | 4.2%   | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |  |\n| DeepSeek-R1       | 100.0% | 100.0%   | 100.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |  |\n| Gemini-2.5-Flash  | 100.0% | 100.0%   | 0.0%   | 100.0% | 100.0%  | 0.0%   | 100.0% | 100.0% | 0.0%   |  |\n| Gemini-2.5-Pro    | 100.0% | 100.0%   | 100.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |  |\n| LLaMA-4-Maverick  | 20.8%  | 0.0%     | 0.0%   | 100.0% | 4.2%    | 0.0%   | 100.0% | 100.0% | 4.2%   |  |\n| LLaMA-3.3-70B     | 100.0% | 100.0%   | 100.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |  |\n| Qwen3-235B        | 100.0% | 100.0%   | 100.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |  |\n| Claude-3.7-Sonnet | 100.0% | 100.0%   | 0.0%   | 100.0% | 100.0%  | 0.0%   | 100.0% | 100.0% | 0.0%   |  |\n| GPT-o4-mini       | 100.0% | 100.0%   | 100.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |  |\n\nTable 8: solves@i results on technology mapping problem.\n\n|                   |        | solveIII |       | solveII |        |        | solveI |        |        |\n|-------------------|--------|----------|-------|---------|--------|--------|--------|--------|--------|\n| Model             | @10    | @5       | @1    | @10     | @5     | @1     | @10    | @5     | @1     |\n| DeepSeek-V3       | 0.0%   | 0.0%     | 0.0%  | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n| DeepSeek-R1       | 87.1%  | 87.1%    | 77.4% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Flash  | 0.0%   | 0.0%     | 0.0%  | 93.5%   | 77.4%  | 67.7%  | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Pro    | 74.2%  | 74.2%    | 0.0%  | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| LLaMA-4-Maverick  | 0.0%   | 0.0%     | 0.0%  | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| LLaMA-3.3-70B     | 0.0%   | 0.0%     | 0.0%  | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0% | 6.5%   |\n| Qwen3-235B        | 0.0%   | 0.0%     | 0.0%  | 100.0%  | 87.1%  | 0.0%   | 100.0% | 100.0% | 3.2%   |\n| Claude-3.7-Sonnet | 87.1%  | 87.1%    | 0.0%  | 100.0%  | 100.0% | 64.5%  | 100.0% | 100.0% | 100.0% |\n| GPT-o4-mini       | 100.0% | 100.0%   | 45.2% | 100.0%  | 100.0% | 51.6%  | 100.0% | 100.0% | 100.0% |\n\nTable 9: solves@i results on global routing problem.\n\n|                   |      | solveIII |      |        | solveII |        |        | solveI |        |\n|-------------------|------|----------|------|--------|---------|--------|--------|--------|--------|\n| Model             | @10  | @5       | @1   | @10    | @5      | @1     | @10    | @5     | @1     |\n| DeepSeek-V3       | 0.0% | 0.0%     | 0.0% | 33.3%  | 33.3%   | 0.0%   | 100.0% | 100.0% | 100.0% |\n| DeepSeek-R1       | 0.0% | 0.0%     | 0.0% | 0.0%   | 0.0%    | 0.0%   | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Flash  | 0.0% | 0.0%     | 0.0% | 20.8%  | 0.0%    | 0.0%   | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Pro    | 0.0% | 0.0%     | 0.0% | 100.0% | 100.0%  | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| LLaMA-4-Maverick  | 0.0% | 0.0%     | 0.0% | 0.0%   | 0.0%    | 0.0%   | 0.0%   | 0.0%   | 0.0%   |\n| LLaMA-3.3-70B     | 0.0% | 0.0%     | 0.0% | 0.0%   | 0.0%    | 0.0%   | 100.0% | 100.0% | 4.2%   |\n| Qwen3-235B        | 0.0% | 0.0%     | 0.0% | 0.0%   | 0.0%    | 0.0%   | 100.0% | 100.0% | 100.0% |\n| Claude-3.7-Sonnet | 0.0% | 0.0%     | 0.0% | 100.0% | 100.0%  | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| GPT-o4-mini       | 0.0% | 0.0%     | 0.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n\nTable 10: solves@i results on e-graph extraction problem.\n\n|                   |        | solveIII |        | solveII |        |        |        |              |        |\n|-------------------|--------|----------|--------|---------|--------|--------|--------|--------------|--------|\n| Model             | @10    | @5       | @1     | @10     | @5     | @1     | @10    | solveI<br>@5 | @1     |\n| DeepSeek-V3       | 4.3%   | 0.0%     | 0.0%   | 100.0%  | 100.0% | 82.6%  | 100.0% | 100.0%       | 100.0% |\n| DeepSeek-R1       | 100.0% | 100.0%   | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0%       | 100.0% |\n| Gemini-2.5-Flash  | 100.0% | 100.0%   | 0.0%   | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0%       | 0.0%   |\n| Gemini-2.5-Pro    | 100.0% | 100.0%   | 0.0%   | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0%       | 100.0% |\n| LLaMA-4-Maverick  | 0.0%   | 0.0%     | 0.0%   | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0%       | 0.0%   |\n| LLaMA-3.3-70B     | 39.1%  | 39.1%    | 0.0%   | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0%       | 100.0% |\n| Qwen3-235B        | 87.0%  | 87.0%    | 87.0%  | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0%       | 100.0% |\n| Claude-3.7-Sonnet | 39.1%  | 39.1%    | 0.0%   | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0%       | 100.0% |\n| GPT-o4-mini       | 100.0% | 100.0%   | 39.1%  | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0%       | 100.0% |\n\nTable 11: solves@i results on intra-op parallelism problem.\n\n|                   |        | solveIII |        |        | solveII |        | solveI |        |        |\n|-------------------|--------|----------|--------|--------|---------|--------|--------|--------|--------|\n| Model             | @10    | @5       | @1     | @10    | @5      | @1     | @10    | @5     | @1     |\n| DeepSeek-V3       | 82.1%  | 53.6%    | 35.7%  | 82.1%  | 53.6%   | 35.7%  | 100.0% | 100.0% | 100.0% |\n| DeepSeek-R1       | 92.9%  | 92.9%    | 35.7%  | 92.9%  | 92.9%   | 35.7%  | 100.0% | 100.0% | 35.7%  |\n| Gemini-2.5-Flash  | 100.0% | 100.0%   | 100.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Pro    | 82.1%  | 82.1%    | 0.0%   | 82.1%  | 82.1%   | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| LLaMA-4-Maverick  | 96.4%  | 96.4%    | 3.6%   | 100.0% | 100.0%  | 3.6%   | 100.0% | 100.0% | 3.6%   |\n| LLaMA-3.3-70B     | 75.0%  | 75.0%    | 3.6%   | 82.1%  | 82.1%   | 3.6%   | 100.0% | 100.0% | 100.0% |\n| Qwen3-235B        | 75.0%  | 71.4%    | 67.9%  | 78.6%  | 75.0%   | 75.0%  | 100.0% | 100.0% | 100.0% |\n| Claude-3.7-Sonnet | 82.1%  | 82.1%    | 71.4%  | 82.1%  | 82.1%   | 78.6%  | 100.0% | 100.0% | 96.4%  |\n| GPT-o4-mini       | 100.0% | 100.0%   | 92.9%  | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n\nTable 12: solves@i results on protein sequence design problem.\n\n|                   |        | solveIII |       | solveII |        |        | solveI |        |        |\n|-------------------|--------|----------|-------|---------|--------|--------|--------|--------|--------|\n| Model             | @10    | @5       | @1    | @10     | @5     | @1     | @10    | @5     | @1     |\n| DeepSeek-V3       | 83.3%  | 83.3%    | 83.3% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n| DeepSeek-R1       | 87.5%  | 87.5%    | 0.0%  | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| Gemini-2.5-Flash  | 95.8%  | 95.8%    | 95.8% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Pro    | 100.0% | 95.8%    | 0.0%  | 100.0%  | 95.8%  | 0.0%   | 100.0% | 100.0% | 4.2%   |\n| LLaMA-4-Maverick  | 83.3%  | 83.3%    | 0.0%  | 95.8%   | 95.8%  | 0.0%   | 100.0% | 100.0% | 4.2%   |\n| LLaMA-3.3-70B     | 12.5%  | 12.5%    | 12.5% | 95.8%   | 95.8%  | 95.8%  | 95.8%  | 95.8%  | 95.8%  |\n| Qwen3-235B        | 87.5%  | 87.5%    | 87.5% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n| Claude-3.7-Sonnet | 58.3%  | 45.8%    | 0.0%  | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| GPT-o4-mini       | 91.7%  | 91.7%    | 91.7% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n\nTable 13: solves@i results on mendelian error detection problem.\n\n|                   |        | solveIII |       | solveII |        |        | solveI |        |        |\n|-------------------|--------|----------|-------|---------|--------|--------|--------|--------|--------|\n| Model             | @10    | @5       | @1    | @10     | @5     | @1     | @10    | @5     | @1     |\n| DeepSeek-V3       | 100.0% | 100.0%   | 0.0%  | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| DeepSeek-R1       | 100.0% | 100.0%   | 0.0%  | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| Gemini-2.5-Flash  | 100.0% | 10.0%    | 10.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Pro    | 80.0%  | 80.0%    | 80.0% | 80.0%   | 80.0%  | 80.0%  | 100.0% | 100.0% | 100.0% |\n| LLaMA-4-Maverick  | 60.0%  | 60.0%    | 60.0% | 60.0%   | 60.0%  | 60.0%  | 60.0%  | 60.0%  | 60.0%  |\n| LLaMA-3.3-70B     | 55.0%  | 55.0%    | 55.0% | 55.0%   | 55.0%  | 55.0%  | 100.0% | 100.0% | 100.0% |\n| Qwen3-235B        | 55.0%  | 55.0%    | 0.0%  | 100.0%  | 100.0% | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| Claude-3.7-Sonnet | 100.0% | 100.0%   | 0.0%  | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n| GPT-o4-mini       | 100.0% | 50.0%    | 35.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% | 100.0% |\n\nTable 14: solves@i results on airline crew pairing problem.\n\n|                   |        | solveIII |        |        | solveII |        |        | solveI |        |\n|-------------------|--------|----------|--------|--------|---------|--------|--------|--------|--------|\n| Model             | @10    | @5       | @1     | @10    | @5      | @1     | @10    | @5     | @1     |\n| DeepSeek-V3       | 100.0% | 100.0%   | 0.0%   | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n| DeepSeek-R1       | 100.0% | 100.0%   | 100.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Flash  | 0.0%   | 0.0%     | 0.0%   | 0.0%   | 0.0%    | 0.0%   | 100.0% | 100.0% | 14.3%  |\n| Gemini-2.5-Pro    | 0.0%   | 0.0%     | 0.0%   | 0.0%   | 0.0%    | 0.0%   | 100.0% | 100.0% | 100.0% |\n| LLaMA-4-Maverick  | 100.0% | 100.0%   | 0.0%   | 100.0% | 100.0%  | 35.7%  | 100.0% | 100.0% | 100.0% |\n| LLaMA-3.3-70B     | 42.9%  | 42.9%    | 42.9%  | 42.9%  | 42.9%   | 42.9%  | 100.0% | 100.0% | 100.0% |\n| Qwen3-235B        | 21.4%  | 21.4%    | 0.0%   | 100.0% | 85.7%   | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| Claude-3.7-Sonnet | 100.0% | 100.0%   | 0.0%   | 100.0% | 100.0%  | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| GPT-o4-mini       | 100.0% | 100.0%   | 100.0% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n\nTable 15: solves@i results on pickup and delivery with time windows problem.\n\n<span id=\"page-29-0\"></span>\n\n|                   |       | solveIII |       |        | solveII |        |        | solveI |        |\n|-------------------|-------|----------|-------|--------|---------|--------|--------|--------|--------|\n| Model             | @10   | @5       | @1    | @10    | @5      | @1     | @10    | @5     | @1     |\n| DeepSeek-V3       | 0.0%  | 0.0%     | 0.0%  | 80.0%  | 73.3%   | 73.3%  | 100.0% | 100.0% | 100.0% |\n| DeepSeek-R1       | 16.7% | 13.3%    | 3.3%  | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Flash  | 96.7% | 90.0%    | 6.7%  | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n| Gemini-2.5-Pro    | 30.0% | 26.7%    | 13.3% | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n| LLaMA-4-Maverick  | 0.0%  | 0.0%     | 0.0%  | 100.0% | 100.0%  | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| LLaMA-3.3-70B     | 0.0%  | 0.0%     | 0.0%  | 100.0% | 100.0%  | 0.0%   | 100.0% | 100.0% | 0.0%   |\n| Qwen3-235B        | 0.0%  | 0.0%     | 0.0%  | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n| Claude-3.7-Sonnet | 0.0%  | 0.0%     | 0.0%  | 100.0% | 100.0%  | 16.7%  | 100.0% | 100.0% | 100.0% |\n| GPT-o4-mini       | 3.3%  | 0.0%     | 0.0%  | 100.0% | 100.0%  | 100.0% | 100.0% | 100.0% | 100.0% |\n\n### <span id=\"page-30-0\"></span>D.3 Ablation on Temperature\n\nWe evaluate various models across different temperature settings, T ∈ {0.0, 0.5, 1.0}. For each model, we run 10 iterations per problem and report the highest QYI achieved across these iterations as the final QYI score for that problem. The overall benchmark score is then computed as the arithmetic mean of QYI across all problems. Detailed results are shown in Tables [16](#page-30-2) to [18.](#page-31-3)\n\nIn general, improving the temperature can be beneficial to quality as the model becomes more creative, but may harm yield as it may not follow the constraints strictly. Note that yield emphasizes the best iteration that achieves the highest QYI, whereas solveIII reflects the cumulative success rate across iterations; therefore, their values may differ. Additionally, the weighted QYI is not the harmonic mean of weighted yield and weighted quality, as it is computed by aggregating metrics across different problems using a weighted approach.\n\nWe also report an uncapped version of the weighted QYI metric[2](#page-30-3) , which better reflects cases where LLM-generated programs outperform expert solutions on certain test instances. Improvements are underlined in the tables. While this variant achieves slightly higher scores for most models – indicating occasional superior performance – it also confirms that, in the majority of cases, LLMs still lag significantly behind expert solutions.\n\nTable 16: Performance of different models on Temperature = 0.\n\n<span id=\"page-30-2\"></span>\n\n| Model             | Weighted Yield | Weighted Quality | Weighted QYI<br>(Capped) | Weighted QYI<br>(Uncapped) |\n|-------------------|----------------|------------------|--------------------------|----------------------------|\n| Claude-3.7-Sonnet | 0.5963         | 0.4686           | 0.5034                   | 0.5034                     |\n| DeepSeek-R1       | 0.6972         | 0.5775           | 0.5498                   | 0.5553                     |\n| DeepSeek-V3       | 0.4587         | 0.3890           | 0.3707                   | 0.3707                     |\n| Gemini-2.5-Flash  | 0.6606         | 0.5281           | 0.5682                   | 0.5753                     |\n| Gemini-2.5-Pro    | 0.6468         | 0.6700           | 0.6170                   | 0.6228                     |\n| LLaMA-3.3-70B     | 0.3394         | 0.3521           | 0.2951                   | 0.2953                     |\n| LLaMA-4-Maverick  | 0.3211         | 0.3383           | 0.2955                   | 0.2955                     |\n| Qwen3-235B        | 0.4450         | 0.4513           | 0.4355                   | 0.4423                     |\n\nTable 17: Performance of different models on Temperature = 0.5.\n\n| Model             | Weighted Yield | Weighted Quality | Weighted QYI<br>(Capped) | Weighted QYI<br>(Uncapped) |\n|-------------------|----------------|------------------|--------------------------|----------------------------|\n| Claude-3.7-Sonnet | 0.6147         | 0.6468           | 0.5437                   | 0.5451                     |\n| DeepSeek-R1       | 0.5138         | 0.5751           | 0.4743                   | 0.4812                     |\n| DeepSeek-V3       | 0.3716         | 0.4645           | 0.3322                   | 0.3322                     |\n| Gemini-2.5-Flash  | 0.4817         | 0.5700           | 0.4760                   | 0.4828                     |\n| Gemini-2.5-Pro    | 0.4817         | 0.5609           | 0.4767                   | 0.4789                     |\n| LLaMA-3.3-70B     | 0.3991         | 0.4407           | 0.4108                   | 0.4108                     |\n| LLaMA-4-Maverick  | 0.3349         | 0.3712           | 0.3050                   | 0.3646                     |\n| Qwen3-235B        | 0.4128         | 0.4798           | 0.4269                   | 0.4327                     |\n\n### <span id=\"page-30-1\"></span>D.4 Few-Shot Demonstration\n\nTable [19](#page-31-4) highlights the impact of few-shot demonstrations on LLM performance across the entire HeuriGym benchmark. Introducing only a small number of demonstrations (e.g., three) can negatively affect solution quality and success rate, as these examples may not be representative of the overall dataset, leading the model to overfit to them. However, providing a larger set of demonstrations can potentially improve QYI, as the model benefits from greater diversity and can learn more generalizable patterns.\n\n<span id=\"page-30-3\"></span><sup>2</sup>The uncapped version of quality is computed as 1/Nˆ P<sup>N</sup><sup>ˆ</sup> <sup>n</sup>=1 c ⋆ <sup>n</sup>/cn, and the uncapped QYI is derived by substituting the original quality metric with this uncapped variant.\n\n<span id=\"page-31-3\"></span>\n\n| Weighted Yield | Weighted Quality                                                             | Weighted QYI<br>(Capped)                                                     | Weighted QYI<br>(Uncapped)                                                   |  |\n|----------------|------------------------------------------------------------------------------|------------------------------------------------------------------------------|------------------------------------------------------------------------------|--|\n|                |                                                                              |                                                                              | 0.4841                                                                       |  |\n|                |                                                                              |                                                                              | 0.5383                                                                       |  |\n|                |                                                                              |                                                                              | 0.3841                                                                       |  |\n|                |                                                                              |                                                                              | 0.6158                                                                       |  |\n|                |                                                                              |                                                                              | 0.5047                                                                       |  |\n|                |                                                                              |                                                                              | 0.4981                                                                       |  |\n|                |                                                                              |                                                                              | 0.2916                                                                       |  |\n|                |                                                                              |                                                                              | 0.2672                                                                       |  |\n| 0.5459         | 0.5228                                                                       | 0.5294                                                                       | 0.5364                                                                       |  |\n|                | 0.5138<br>0.5688<br>0.4128<br>0.6927<br>0.4771<br>0.5229<br>0.3028<br>0.2982 | 0.5924<br>0.5625<br>0.4188<br>0.6440<br>0.7688<br>0.4893<br>0.3627<br>0.3271 | 0.4828<br>0.5313<br>0.3839<br>0.6089<br>0.5030<br>0.4921<br>0.2868<br>0.2667 |  |\n\nTable 18: Performance of different models on Temperature = 1.\n\n<span id=\"page-31-4\"></span>Table 19: Impact of few-shot demonstrations on performance (Model: Gemini-2.5-pro).\n\n| # of Demos | Weighted Yield | Weighted Quality | Weighted QYI |\n|------------|----------------|------------------|--------------|\n| Zero-shot  | 0.5872         | 0.7159           | 0.5999       |\n| Half-shot  | 0.5092         | 0.6526           | 0.5361       |\n| Full-shot  | 0.6468         | 0.6700           | 0.6170       |\n\n### <span id=\"page-31-0\"></span>D.5 Feedback Rounds\n\nTable [20](#page-31-5) shows that increasing the number of feedback rounds has a nuanced impact on performance. While a moderate number of rounds (e.g., five) can enhance overall quality by guiding the model to refine its solutions, excessive feedback may lead to diminishing returns or even degrade performance. This suggests that too many rounds can overwhelm the model, making it harder to identify and prioritize the most critical information from the feedback.\n\n<span id=\"page-31-5\"></span>Table 20: Impact of feedback rounds on performance (Model: Gemini-2.5-pro).\n\n| # of Feedback Rounds | Weighted Yield | Weighted Quality | Weighted QYI |\n|----------------------|----------------|------------------|--------------|\n| 1                    | 0.6193         | 0.7290           | 0.6253       |\n| 5                    | 0.6055         | 0.7313           | 0.6259       |\n| 10                   | 0.6468         | 0.6700           | 0.6170       |\n|                      |                |                  |              |\n\n### <span id=\"page-31-1\"></span>D.6 Iterative Best-of-N Sampling\n\nTo investigate the benefits of test-time search strategies, we sample k candidate programs in each iteration, evaluate them, and return feedback for all k programs to the LLM. After a fixed number of iterations, we select the best-performing program from the entire pool – a process we refer to as *iterative best-of-N sampling*. The total number of sampled programs is held constant across different values of k. This strategy allows the model to explore diverse candidate solutions in parallel and evolve the program based on evaluative feedback.\n\nAs shown in Table [21,](#page-31-6) increasing k leads to better quality of results, indicating that aggregating feedback across multiple candidates allows the LLM to better explore the solution space and improve sampling efficiency by allocating computational budget toward more informative evaluations.\n\n<span id=\"page-31-6\"></span>Table 21: Impact of best-of-N sampling on performance (Model: Gemini-2.5-pro).\n\n| # of Samples @ Iteration | Weighted Yield | Weighted Quality | Weighted QYI |\n|--------------------------|----------------|------------------|--------------|\n| 2@5                      | 0.5688         | 0.7698           | 0.6160       |\n| 1@10                     | 0.6468         | 0.6700           | 0.6170       |\n\n### <span id=\"page-31-2\"></span>D.7 Error Analysis\n\nIn the following, we present representative examples of common errors made by LLMs during heuristic generation. These errors highlight current limitations in code reliability and execution:\n\n• Import error: This type of error occurs when the generated code relies on external libraries that are not available in the environment. In the example below, the model attempts to import the ortools library, which results in a ModuleNotFoundError. Such errors suggest that the model does not strictly follow the instructions given in the prompt.\n\n```\nFile \"operator_scheduling/gemini-2.5-flash-preview-04-17/iteration4/sol ⌋\n      ver.py\", line 2, in\n      <module>\n  ,→\n  ,→\n    from ortools.sat.python import cp_model\nModuleNotFoundError: No module named 'ortools'\n```\n• API misuse error: LLMs often misuse APIs due to a misunderstanding of library interfaces. In the following case, the model tries to call random() directly from the random module, which is not callable.\n\n```\nFile \"intra_op_parallel/o4-mini/iteration3/solver.py\", line 64, in\n  ,→ init_jitter\n    if len(ci) > 1 and random() < 0.1:\n                       ^^^^^^^^\nTypeError: 'module' object is not callable\n```\n• Syntax error: Syntax errors are common when the model fails to adhere to basic language rules. In this example, there is an unmatched parenthesis in a while loop condition, leading to a SyntaxError. Such mistakes typically indicate a lack of code completion validation in the generation process.\n\n```\nFile \"crew_pairing/deepseek-chat/iteration7/solver.py\", line 60\n    while len(used_legs) < len(df)):\n                                   ^\nSyntaxError: unmatched ')'\n```\n• Runtime error: Even syntactically and semantically correct code can fail at runtime. In this case, the model modifies a dictionary while iterating over it, which raises a RuntimeError. This highlights the model's difficulty in reasoning about the actual executable code in a long context.\n\n```\nFile \"technology_mapping/llama-4-maverick/iteration2/solver.py\", line\n  ,→ 104, in technology_mapping\n    for successor in G.successors(node):\nRuntimeError: dictionary changed size during iteration\n```\n### <span id=\"page-32-0\"></span>D.8 C++ Example\n\nWe conduct preliminary experiments on the technology mapping problem by modifying the prompt to instruct the LLM to generate a C++ solution, using the provided function template: void solve(const std::string& input\\_file, const std::string& output\\_file).\n\nIntegrating C++ into our agentic feedback loop remains challenging due to dependencies on domainspecific libraries and the complexity of parallel execution. As a result, our preliminary experiment with C++ involves only a single iteration of prompting.\n\nTable [22](#page-33-1) presents a performance comparison between the Python solution with 10 iterations and the C++ solution with just one iteration. Although the C++ solution does not produce high-quality output in its initial attempt, it already achieves a better yield than the Python solution after 10 iterations – an unexpectedly strong outcome. Notably, the Python solution fails to generate any valid result in its first iteration. This is attributed to the significantly faster execution speed of C++ code, which enables it to avoid the timeout errors frequently encountered by Python in this task.\n\nWe expect to see further performance improvement with C++ after we integrate it into the feedback loop in our framework.\n\n<span id=\"page-33-1\"></span>Table 22: Impact of C++ code on technology mapping performance (Model: Gemini-2.5-pro).\n\n| Language | # of Iterations | Yield  | Quality | QYI    |\n|----------|-----------------|--------|---------|--------|\n| Python   | 10              | 0.7419 | 0.6423  | 0.6885 |\n| C++      | 1               | 0.7742 | 0.3493  | 0.4814 |\n\n# <span id=\"page-33-0\"></span>E Detailed Analysis of Case Study\n\nHere we include a detailed analysis of the case study in Section [5.3.](#page-7-2) We append the entire code of each iteration and analyze the generated solution.\n\nIn the first iteration, the GPT-o4-mini model generates an algorithm based on cut enumeration and dynamic programming (DP)-based cut selection, which is the common approach used in technology mapping tools. The core logic is highlighted in the following code snippet. However, it does not prune the cut enumeration space and computes all possible K-feasible cuts for each node, which leads to an exponential explosion in computation time. While this achieves high quality, it frequently triggers TimeoutError for larger datasets, resulting in low yield.\n\n```\n1 # iteration 1: base algorithm without pruning the search space\n2\n3 def solve(input_file: str, solution_file: str):\n4 from collections import deque\n5 class Node:\n6 __slots__ = ('name','fanin_names','fanins','fanouts','patterns_one','patterns_zero','const_val')\n7 def __init__(self,name):\n8 self.name = name\n9 self.fanin_names = []\n10 self.fanins = []\n11 self.fanouts = []\n12 self.patterns_one = []\n13 self.patterns_zero = []\n14 self.const_val = None\n15 raw_lines = open(input_file).read().splitlines()\n16 lines = []\n17 i = 0\n18 while i < len(raw_lines):\n19 line = raw_lines[i].rstrip()\n20 if not line or line.lstrip().startswith('#'):\n21 i += 1\n22 continue\n23 if line.endswith('\\\\'):\n24 merged = line[:-1].rstrip()\n25 i += 1\n26 while i < len(raw_lines):\n27 nxt = raw_lines[i].rstrip()\n28 if nxt.endswith('\\\\'):\n29 merged += ' ' + nxt[:-1].rstrip()\n30 i += 1\n31 else:\n32 merged += ' ' + nxt\n33 i += 1\n34 break\n35 lines.append(merged)\n36 else:\n37 lines.append(line)\n38 i += 1\n39 model_name = ''\n40 input_list = []\n41 output_list = []\n42 nodes = {}\n43 idx = 0\n44 while idx < len(lines):\n45 l = lines[idx].strip()\n46 if not l or l.startswith('#'):\n47 idx += 1\n48 continue\n49 if l.startswith('.model'):\n50 parts = l.split()\n51 if len(parts) > 1:\n52 model_name = parts[1]\n53 idx += 1\n54 elif l.startswith('.inputs'):\n55 parts = l.split()\n56 for name in parts[1:]:\n```\n\n```\n57 input_list.append(name)\n58 if name not in nodes:\n59 nodes[name] = Node(name)\n60 idx += 1\n61 elif l.startswith('.outputs'):\n62 parts = l.split()\n63 for name in parts[1:]:\n64 output_list.append(name)\n65 idx += 1\n66 elif l.startswith('.names'):\n67 parts = l.split()\n68 in_names = parts[1:-1]\n69 out_name = parts[-1]\n70 if out_name not in nodes:\n71 nodes[out_name] = Node(out_name)\n72 node = nodes[out_name]\n73 node.fanin_names = in_names[:]\n74 patterns = []\n75 j = idx + 1\n76 while j < len(lines):\n77 lj = lines[j].strip()\n78 if not lj or lj.startswith('.') or lj.startswith('#'):\n79 break\n80 patterns.append(lj)\n81 j += 1\n82 if len(in_names) == 0:\n83 if patterns and patterns[0].strip() == '1':\n84 node.const_val = 1\n85 else:\n86 node.const_val = 0\n87 else:\n88 for pline in patterns:\n89 parts2 = pline.split()\n90 if len(parts2) == 1:\n91 mask = parts2[0]; bit = '1'\n92 else:\n93 mask = parts2[0]; bit = parts2[1]\n94 if bit == '1':\n95 node.patterns_one.append(mask)\n96 else:\n97 node.patterns_zero.append(mask)\n98 idx = j\n99 elif l.startswith('.end'):\n100 break\n101 else:\n102 idx += 1\n103 for node in nodes.values():\n104 node.fanins = []\n105 for fn in node.fanin_names:\n106 if fn in nodes:\n107 node.fanins.append(nodes[fn])\n108 node.fanouts = []\n109 for node in nodes.values():\n110 for f in node.fanins:\n111 f.fanouts.append(node)\n112 reachable = set()\n113 dq = deque()\n114 for out in output_list:\n115 if out in nodes:\n116 dq.append(out)\n117 while dq:\n118 u = dq.pop()\n119 if u in reachable:\n120 continue\n121 reachable.add(u)\n122 for f in nodes[u].fanins:\n123 if f.name not in reachable:\n124 dq.append(f.name)\n125 nodes = {name:node for name,node in nodes.items() if name in reachable}\n126 for node in nodes.values():\n127 node.fanins = [f for f in node.fanins if f.name in nodes]\n128 node.fanouts = [f for f in node.fanouts if f.name in nodes]\n129 indeg = {name: len(node.fanins) for name,node in nodes.items()}\n130 dq = deque([name for name,d in indeg.items() if d == 0])\n131 topo_names = []\n132 while dq:\n133 u = dq.popleft()\n134 topo_names.append(u)\n135 for w in nodes[u].fanouts:\n136 indeg[w.name] -= 1\n137 if indeg[w.name] == 0:\n```\n\n```\n138 dq.append(w.name)\n139 topo_list = [nodes[name] for name in topo_names]\n140 K = 6\n141 def prune_cuts(cset):\n142 cuts = list(cset)\n143 res = []\n144 for c in cuts:\n145 skip = False\n146 for d in cuts:\n147 if d is not c and d.issubset(c):\n148 skip = True\n149 break\n150 if not skip:\n151 res.append(c)\n152 return res\n153 cuts = {} # Cut Enumeration\n154 for n in topo_list:\n155 if not n.fanins:\n156 cuts[n.name] = [frozenset([n.name])]\n157 else:\n158 cuts_n = None\n159 for f in n.fanins:\n160 cf = cuts[f.name]\n161 if cuts_n is None:\n162 cuts_n = cf[:]\n163 else:\n164 newset = set()\n165 for c1 in cuts_n:\n166 for c2 in cf:\n167 u = c1 | c2\n168 if len(u) <= K:\n169 newset.add(u)\n170 cuts_n = prune_cuts(newset)\n171 if cuts_n is None:\n172 cuts_n = []\n173 cuts_set = set(cuts_n)\n174 cuts_set.add(frozenset([n.name]))\n175 cuts[n.name] = prune_cuts(cuts_set)\n176 cost = {}\n177 best_cut = {}\n178 INF = 10**18\n179 for n in topo_list: # DP-based Cut Selection\n180 if not n.fanins:\n181 cost[n.name] = 0\n182 best_cut[n.name] = None\n183 else:\n184 bcut = None\n185 bval = INF\n186 for c in cuts[n.name]:\n187 if c == frozenset([n.name]):\n188 continue\n189 s = 0\n190 for m in c:\n191 s += cost.get(m,0)\n192 cval = s + 1\n193 if cval < bval:\n194 bval = cval; bcut = c\n195 if bcut is None:\n196 fl = frozenset([f.name for f in n.fanins])\n197 bcut = fl\n198 s = 0\n199 for m in bcut:\n200 s += cost.get(m,0)\n201 bval = s + 1\n202 cost[n.name] = bval\n203 best_cut[n.name] = bcut\n204 mapping_nodes = set()\n205 dq = deque()\n206 for out in output_list:\n207 if out in best_cut and best_cut[out] is not None:\n208 dq.append(out)\n209 while dq:\n210 u = dq.pop()\n211 if u in mapping_nodes:\n212 continue\n213 mapping_nodes.add(u)\n214 c = best_cut[u]\n215 if c:\n216 for m in c:\n217 if m in nodes:\n218 nm = nodes[m]\n```\n\n```\n219 if m not in input_list and nm.const_val is None:\n220 dq.append(m)\n221 mapping_topo = [n for n in topo_list if n.name in mapping_nodes]\n222 f = open(solution_file,'w')\n223 f.write('.model '+model_name+'\\n')\n224 f.write('.inputs '+' '.join(input_list)+'\\n')\n225 f.write('.outputs '+' '.join(output_list)+'\\n')\n226 for n in mapping_topo:\n227 leaves = best_cut[n.name]\n228 inputs = sorted(leaves)\n229 k = len(inputs)\n230 N = 1<<k\n231 full_mask = (1<<N) - 1\n232 masks = []\n233 for i in range(k):\n234 m = 0\n235 for j in range(N):\n236 if (j>>i)&1:\n237 m |= (1<<j)\n238 masks.append(m)\n239 vis = set()\n240 queue2 = [n.name]\n241 while queue2:\n242 u = queue2.pop()\n243 if u in vis or u in inputs:\n244 continue\n245 vis.add(u)\n246 for fn in nodes[u].fanins:\n247 if fn.name not in vis:\n248 queue2.append(fn.name)\n249 cone_nodes = [nodes[name] for name in topo_names if name in vis]\n250 val = {}\n251 for i,name in enumerate(inputs):\n252 val[name] = masks[i]\n253 for v in cone_nodes:\n254 if v.const_val is not None:\n255 val[v.name] = full_mask if v.const_val==1 else 0\n256 else:\n257 if v.patterns_zero:\n258 zero_mask = 0\n259 for p in v.patterns_zero:\n260 m = full_mask\n261 for idx,ch in enumerate(p):\n262 vm = val[v.fanin_names[idx]]\n263 if ch=='1':\n264 m &= vm\n265 elif ch=='0':\n266 m &= (~vm)&full_mask\n267 zero_mask |= m\n268 val[v.name] = (~zero_mask)&full_mask\n269 else:\n270 one_mask = 0\n271 for p in v.patterns_one:\n272 m = full_mask\n273 for idx,ch in enumerate(p):\n274 vm = val[v.fanin_names[idx]]\n275 if ch=='1':\n276 m &= vm\n277 elif ch=='0':\n278 m &= (~vm)&full_mask\n279 one_mask |= m\n280 val[v.name] = one_mask\n281 root_mask = val[n.name]\n282 f.write('.names '+' '.join(inputs)+' '+n.name+'\\n')\n283 for j in range(N):\n284 if (root_mask>>j)&1:\n285 line = ''.join('1' if (j>>i)&1 else '0' for i in range(k))\n286 f.write(line+' 1\\n')\n287 f.write('.end\\n')\n288 f.close()\n289\n```\nIn the second iteration, the model overcorrects by adopting a naive 6-LUT mapping strategy that trivially assigns each node to a separate LUT. While this approach passes all test cases within the timeout, it produces poor solution quality. Specifically, it redundantly maps each non-primary-input node as an individual LUT by directly copying inputs to outputs, resulting in excessive and inefficient resource usage.\n\n```\n1 # iteration 2: a very naive mapping strategy. Simply copy the input to the output.\n2\n3 def solve(input_file: str, solution_file: str):\n4 raw = open(input_file).read().splitlines()\n5 merged = []\n6 i = 0\n7 while i < len(raw):\n8 line = raw[i].rstrip()\n9 if not line or line.lstrip().startswith('#'):\n10 i += 1\n11 continue\n12 if line.endswith('\\\\'):\n13 accum = line[:-1].rstrip()\n14 i += 1\n15 while i < len(raw):\n16 nxt = raw[i].rstrip()\n17 if nxt.endswith('\\\\'):\n18 accum += ' ' + nxt[:-1].rstrip()\n19 i += 1\n20 else:\n21 accum += ' ' + nxt\n22 i += 1\n23 break\n24 merged.append(accum)\n25 else:\n26 merged.append(line)\n27 i += 1\n28 with open(solution_file, 'w') as f:\n29 for l in merged:\n30 f.write(l + '\\n')\n```\nIn the third iteration, the model proposes a more sophisticated strategy that first applies static pruning to the cut enumeration space – limiting the number of cuts per node to 20 – followed by a dynamic programming-based cut selection. This approach improves solution quality, though full yield is still not achieved. Additionally, truth table computation is optimized using bitwise operations.\n\n```\n1 # iteration 3: static pruning by capping the number of cuts per node to M = 20; efficient bitwise\n   ,→ operations\n2\n3 def solve(input_file: str, solution_file: str):\n4 from collections import deque\n5 raw_lines = open(input_file).read().splitlines()\n6 lines = []\n7 i = 0\n8 while i < len(raw_lines):\n9 line = raw_lines[i].rstrip()\n10 if not line or line.lstrip().startswith('#'):\n11 i += 1\n12 continue\n13 if line.endswith('\\\\'):\n14 accum = line[:-1].rstrip()\n15 i += 1\n16 while i < len(raw_lines):\n17 nxt = raw_lines[i].rstrip()\n18 if nxt.endswith('\\\\'):\n19 accum += ' ' + nxt[:-1].rstrip()\n20 i += 1\n21 else:\n22 accum += ' ' + nxt\n23 i += 1\n24 break\n25 lines.append(accum)\n26 else:\n27 lines.append(line)\n28 i += 1\n29 class Node:\n30 def __init__(self, name):\n31 self.name = name\n32 self.fanin_names = []\n33 self.patterns_one = []\n34 self.patterns_zero = []\n35 self.const_val = None\n36 self.fanins = []\n37 self.fanouts = []\n38 model_name = ''\n39 input_list = []\n40 output_list = []\n```\n\n```\n41 nodes = {}\n42 idx = 0\n43 while idx < len(lines):\n44 l = lines[idx].strip()\n45 if not l:\n46 idx += 1\n47 continue\n48 if l.startswith('.model'):\n49 parts = l.split()\n50 if len(parts) > 1:\n51 model_name = parts[1]\n52 idx += 1\n53 elif l.startswith('.inputs'):\n54 parts = l.split()\n55 for name in parts[1:]:\n56 input_list.append(name)\n57 if name not in nodes:\n58 nodes[name] = Node(name)\n59 idx += 1\n60 elif l.startswith('.outputs'):\n61 parts = l.split()\n62 for name in parts[1:]:\n63 output_list.append(name)\n64 idx += 1\n65 elif l.startswith('.names'):\n66 parts = l.split()\n67 in_names = parts[1:-1]\n68 out_name = parts[-1]\n69 if out_name not in nodes:\n70 nodes[out_name] = Node(out_name)\n71 node = nodes[out_name]\n72 node.fanin_names = in_names[:]\n73 patterns = []\n74 j = idx + 1\n75 while j < len(lines) and not lines[j].startswith('.'):\n76 s = lines[j].strip()\n77 if s:\n78 patterns.append(s)\n79 j += 1\n80 if len(in_names) == 0:\n81 if patterns and patterns[0] == '1':\n82 node.const_val = 1\n83 else:\n84 node.const_val = 0\n85 else:\n86 for pline in patterns:\n87 parts2 = pline.split()\n88 if len(parts2) == 1:\n89 mask = parts2[0]; bit = '1'\n90 else:\n91 mask = parts2[0]; bit = parts2[1]\n92 if bit == '1':\n93 node.patterns_one.append(mask)\n94 else:\n95 node.patterns_zero.append(mask)\n96 idx = j\n97 elif l.startswith('.end'):\n98 break\n99 else:\n100 idx += 1\n101 for node in nodes.values():\n102 node.fanins = [nodes[nm] for nm in node.fanin_names if nm in nodes]\n103 node.fanouts = []\n104 for node in nodes.values():\n105 for f in node.fanins:\n106 f.fanouts.append(node)\n107 reachable = set()\n108 stack = [nm for nm in output_list if nm in nodes]\n109 while stack:\n110 u = stack.pop()\n111 if u in reachable: continue\n112 reachable.add(u)\n113 for p in nodes[u].fanin_names:\n114 if p in nodes and p not in reachable:\n115 stack.append(p)\n116 nodes = {nm:nd for nm,nd in nodes.items() if nm in reachable}\n117 for nd in nodes.values():\n118 nd.fanins = [f for f in nd.fanins if f.name in nodes]\n119 nd.fanouts = [f for f in nd.fanouts if f.name in nodes]\n120 indeg = {nm: len(nd.fanins) for nm,nd in nodes.items()}\n121 dq = deque([nm for nm,d in indeg.items() if d == 0])\n```\n\n```\n122 topo = []\n123 while dq:\n124 u = dq.popleft()\n125 topo.append(u)\n126 for w in nodes[u].fanouts:\n127 indeg[w.name] -= 1\n128 if indeg[w.name] == 0:\n129 dq.append(w.name)\n130 topo_nodes = [nodes[nm] for nm in topo]\n131 name_to_idx = {nd.name:i for i,nd in enumerate(topo_nodes)}\n132 idx_to_node = topo_nodes\n133 idx_to_name = [nd.name for nd in topo_nodes]\n134 N = len(topo_nodes)\n135 PI_idx = set(name_to_idx[nm] for nm in input_list if nm in name_to_idx)\n136 self_mask = [1 << i for i in range(N)]\n137 K = 6\n138 M = 20\n139 cuts = [[] for _ in range(N)]\n140 for i, nd in enumerate(topo_nodes):\n141 if i in PI_idx or nd.const_val is not None:\n142 cuts[i] = [self_mask[i]]\n143 continue\n144 fan_idxs = [name_to_idx[x] for x in nd.fanin_names if x in name_to_idx]\n145 c_list = None\n146 for f in fan_idxs:\n147 fcuts = cuts[f]\n148 if c_list is None:\n149 c_list = fcuts[:M]\n150 else:\n151 newset = set()\n152 for a in c_list[:M]:\n153 for b in fcuts[:M]:\n154 u = a | b\n155 if u.bit_count() <= K:\n156 newset.add(u)\n157 if newset:\n158 lst = sorted(newset, key=lambda x: x.bit_count())\n159 c_list = lst[:M]\n160 else:\n161 c_list = []\n162 if not c_list:\n163 break\n164 if c_list is None:\n165 c_list = []\n166 s = set(c_list)\n167 s.add(self_mask[i])\n168 lst2 = sorted(s, key=lambda x: x.bit_count())\n169 cuts[i] = lst2[:M]\n170 INF = 10**18\n171 cost = [0]*N\n172 bestM = [None]*N\n173 for i, nd in enumerate(topo_nodes):\n174 if i in PI_idx or nd.const_val is not None:\n175 cost[i] = 0\n176 bestM[i] = None\n177 continue\n178 bestc = INF\n179 bm = None\n180 for cm in cuts[i]:\n181 if cm == self_mask[i]:\n182 continue\n183 s = 0\n184 m = cm\n185 while m:\n186 lsb = m & -m\n187 j = lsb.bit_length() - 1\n188 s += cost[j]\n189 m ^= lsb\n190 cval = s + 1\n191 if cval < bestc:\n192 bestc = cval\n193 bm = cm\n194 if bm is None:\n195 s = 0\n196 mask = 0\n197 for f in nd.fanin_names:\n198 if f in name_to_idx:\n199 j = name_to_idx[f]\n200 mask |= self_mask[j]\n201 s += cost[j]\n202 bm = mask\n```\n\n| 203 | bestc = s + 1                                                                |\n|-----|------------------------------------------------------------------------------|\n|     |                                                                              |\n| 204 | cost[i] = bestc                                                              |\n| 205 | bestM[i] = bm                                                                |\n| 206 | mapping = set()                                                              |\n| 207 | stack = [name_to_idx[nm] for nm in output_list if nm in name_to_idx]         |\n| 208 | visited = set()                                                              |\n|     |                                                                              |\n| 209 | while stack:                                                                 |\n| 210 | u = stack.pop()                                                              |\n| 211 | if u in visited:                                                             |\n| 212 | continue                                                                     |\n| 213 | visited.add(u)                                                               |\n|     |                                                                              |\n| 214 | bm = bestM[u]                                                                |\n| 215 | if bm is None or bm == self_mask[u]:                                         |\n| 216 | continue                                                                     |\n| 217 | mapping.add(u)                                                               |\n| 218 | m = bm                                                                       |\n|     | while m:                                                                     |\n| 219 |                                                                              |\n| 220 | lsb = m & -m                                                                 |\n| 221 | j = lsb.bit_length() - 1                                                     |\n| 222 | m ^= lsb                                                                     |\n| 223 | if j not in visited and j not in PI_idx and topo_nodes[j].const_val is None: |\n| 224 | stack.append(j)                                                              |\n|     |                                                                              |\n| 225 | mapped = [i for i in range(N) if i in mapping]                               |\n| 226 | with open(solution_file, 'w') as f:                                          |\n| 227 | f.write('.model ' + model_name + '\\n')                                       |\n| 228 | f.write('.inputs ' + ' '.join(input_list) + '\\n')                            |\n| 229 | f.write('.outputs ' + ' '.join(output_list) + '\\n')                          |\n| 230 | for i in mapped:                                                             |\n|     |                                                                              |\n| 231 | nd = topo_nodes[i]                                                           |\n| 232 | bm = bestM[i]                                                                |\n| 233 | leaves = [j for j in range(N) if (bm >> j) & 1]                              |\n| 234 | inputs = [idx_to_name[j] for j in leaves]                                    |\n| 235 | k = len(inputs)                                                              |\n| 236 | Np = 1 << k                                                                  |\n| 237 | full = (1 << Np) - 1                                                         |\n|     |                                                                              |\n| 238 | masks = []                                                                   |\n| 239 | for t in range(k):                                                           |\n| 240 | mm = 0                                                                       |\n| 241 | for j in range(Np):                                                          |\n| 242 | if (j >> t) & 1:                                                             |\n| 243 | mm  = 1 << j                                                                 |\n|     |                                                                              |\n| 244 | masks.append(mm)                                                             |\n| 245 | val = {}                                                                     |\n| 246 | for t,j in enumerate(leaves):                                                |\n| 247 | val[j] = masks[t]                                                            |\n| 248 | vis = set(leaves)                                                            |\n| 249 | stack2 = [i]                                                                 |\n| 250 | while stack2:                                                                |\n|     |                                                                              |\n| 251 | u = stack2.pop()                                                             |\n| 252 | if u in vis:                                                                 |\n| 253 | continue                                                                     |\n| 254 | vis.add(u)                                                                   |\n| 255 | for p in topo_nodes[u].fanins:                                               |\n| 256 | pi = name_to_idx.get(p.name)                                                 |\n| 257 | if pi is not None and pi not in vis:                                         |\n|     |                                                                              |\n| 258 | stack2.append(pi)                                                            |\n| 259 | cone = [j for j in range(N) if j in vis and j not in leaves]                 |\n| 260 | for j in sorted(cone, key=lambda x: name_to_idx[topo_nodes[x].name]):        |\n| 261 | v = topo_nodes[j]                                                            |\n| 262 | if v.const_val is not None:                                                  |\n| 263 | val[j] = full if v.const_val == 1 else 0                                     |\n|     |                                                                              |\n| 264 | else:                                                                        |\n| 265 | if v.patterns_zero:                                                          |\n| 266 | zm = 0                                                                       |\n| 267 | for p in v.patterns_zero:                                                    |\n| 268 | mm = full                                                                    |\n| 269 | for t,ch in enumerate(p):                                                    |\n| 270 | fn = v.fanin_names[t]                                                        |\n|     |                                                                              |\n| 271 | pj = name_to_idx.get(fn)                                                     |\n| 272 | if pj is None:                                                               |\n| 273 | mm = 0                                                                       |\n| 274 | break                                                                        |\n| 275 | vm = val[pj]                                                                 |\n| 276 | if ch == '1':                                                                |\n|     |                                                                              |\n| 277 | mm &= vm                                                                     |\n| 278 | elif ch == '0':                                                              |\n| 279 | mm &= (~vm) & full                                                           |\n| 280 | zm  = mm                                                                     |\n| 281 | val[j] = (~zm) & full                                                        |\n| 282 | else:                                                                        |\n| 283 | om = 0                                                                       |\n|     |                                                                              |\n\n```\n284 for p in v.patterns_one:\n285 mm = full\n286 for t,ch in enumerate(p):\n287 fn = v.fanin_names[t]\n288 pj = name_to_idx.get(fn)\n289 if pj is None:\n290 mm = 0\n291 break\n292 vm = val[pj]\n293 if ch == '1':\n294 mm &= vm\n295 elif ch == '0':\n296 mm &= (~vm) & full\n297 om |= mm\n298 val[j] = om\n299 root = val[i]\n300 f.write('.names ' + ' '.join(inputs) + ' ' + nd.name + '\\n')\n301 for j in range(Np):\n302 if (root >> j) & 1:\n303 bits = ''.join('1' if (j >> t) & 1 else '0' for t in range(k))\n304 f.write(bits + ' 1\\n')\n305 f.write('.end\\n')\n306\n```\nIn the fourth iteration, the cut limit per node is increased from 20 to 30, enabling broader solution exploration and potentially improving quality. Additionally, the algorithm reduces redundant computations by caching precomputed scores for each cut.\n\n```\n1 # iteration 4: explore larger solution space; reduce redundant computations\n2\n3 def solve(input_file: str, solution_file: str):\n4 from collections import deque\n5 raw = open(input_file).read().splitlines()\n6 lines = []\n7 i = 0\n8 while i < len(raw):\n9 l = raw[i].rstrip()\n10 if not l or l.lstrip().startswith('#'):\n11 i += 1\n12 continue\n13 if l.endswith('\\\\'):\n14 acc = l[:-1].rstrip()\n15 i += 1\n16 while i < len(raw):\n17 nl = raw[i].rstrip()\n18 if nl.endswith('\\\\'):\n19 acc += ' ' + nl[:-1].rstrip()\n20 i += 1\n21 else:\n22 acc += ' ' + nl\n23 i += 1\n24 break\n25 lines.append(acc)\n26 else:\n27 lines.append(l)\n28 i += 1\n29 class Node:\n30 __slots__ = ('name','fanin_names','patterns_one','patterns_zero','const_val','fanins','fanouts')\n31 def __init__(self,n):\n32 self.name = n\n33 self.fanin_names = []\n34 self.patterns_one = []\n35 self.patterns_zero = []\n36 self.const_val = None\n37 self.fanins = []\n38 self.fanouts = []\n39 model = ''\n40 inputs = []\n41 outputs = []\n42 nodes = {}\n43 idx = 0\n44 while idx < len(lines):\n45 l = lines[idx].strip()\n46 if not l:\n47 idx += 1; continue\n48 if l.startswith('.model'):\n49 parts = l.split()\n50 if len(parts)>1: model = parts[1]\n```\n\n```\n51 idx += 1\n52 elif l.startswith('.inputs'):\n53 parts = l.split()\n54 for nm in parts[1:]:\n55 inputs.append(nm)\n56 if nm not in nodes: nodes[nm] = Node(nm)\n57 idx += 1\n58 elif l.startswith('.outputs'):\n59 parts = l.split()\n60 for nm in parts[1:]:\n61 outputs.append(nm)\n62 idx += 1\n63 elif l.startswith('.names'):\n64 parts = l.split()\n65 inps = parts[1:-1]; outp = parts[-1]\n66 if outp not in nodes: nodes[outp] = Node(outp)\n67 nd = nodes[outp]\n68 nd.fanin_names = inps[:]\n69 pats = []\n70 j = idx+1\n71 while j < len(lines) and not lines[j].startswith('.'):\n72 s = lines[j].strip()\n73 if s: pats.append(s)\n74 j += 1\n75 if not inps:\n76 if pats and pats[0]=='1': nd.const_val = 1\n77 else: nd.const_val = 0\n78 else:\n79 for pt in pats:\n80 sp = pt.split()\n81 if len(sp)==1:\n82 mask = sp[0]; bit = '1'\n83 else:\n84 mask,bit = sp[0],sp[1]\n85 if bit=='1': nd.patterns_one.append(mask)\n86 else: nd.patterns_zero.append(mask)\n87 idx = j\n88 elif l.startswith('.end'):\n89 break\n90 else:\n91 idx += 1\n92 for nd in nodes.values():\n93 nd.fanins = [nodes[nm] for nm in nd.fanin_names if nm in nodes]\n94 for nd in nodes.values():\n95 for f in nd.fanins:\n96 f.fanouts.append(nd)\n97 reachable = set()\n98 st = [nm for nm in outputs if nm in nodes]\n99 while st:\n100 u = st.pop()\n101 if u in reachable: continue\n102 reachable.add(u)\n103 for p in nodes[u].fanin_names:\n104 if p in nodes and p not in reachable:\n105 st.append(p)\n106 nodes = {nm:nd for nm,nd in nodes.items() if nm in reachable}\n107 for nd in nodes.values():\n108 nd.fanins = [f for f in nd.fanins if f.name in nodes]\n109 nd.fanouts = [f for f in nd.fanouts if f.name in nodes]\n110 indeg = {nm: len(nd.fanins) for nm,nd in nodes.items()}\n111 dq = deque([nm for nm,d in indeg.items() if d==0])\n112 topo = []\n113 while dq:\n114 u = dq.popleft(); topo.append(u)\n115 for w in nodes[u].fanouts:\n116 indeg[w.name] -= 1\n117 if indeg[w.name]==0: dq.append(w.name)\n118 topo_nodes = [nodes[nm] for nm in topo]\n119 N = len(topo_nodes)\n120 name_to_idx = {nd.name:i for i,nd in enumerate(topo_nodes)}\n121 idx_to_name = [nd.name for nd in topo_nodes]\n122 PI = set(name_to_idx[nm] for nm in inputs if nm in name_to_idx)\n123 cost = [0]*N\n124 bestM = [None]*N\n125 K = 6\n126 M = 30\n127 cuts = [[] for _ in range(N)]\n128 for i,nd in enumerate(topo_nodes):\n129 if i in PI or nd.const_val is not None:\n130 cost[i] = 0\n131 bestM[i] = None\n```\n\n```\n132 cuts[i] = [(1<<i, 0)]\n133 continue\n134 fans = [name_to_idx[nm] for nm in nd.fanin_names if nm in name_to_idx]\n135 c_list = None\n136 for f in fans:\n137 fcuts = cuts[f]\n138 if len(fcuts) > M: fcuts = fcuts[:M]\n139 if c_list is None:\n140 c_list = fcuts.copy()\n141 else:\n142 newm = {}\n143 for m1,sc1 in c_list:\n144 for m2,sc2 in fcuts:\n145 m = m1 | m2\n146 if m.bit_count() <= K:\n147 if m in newm: continue\n148 t = m; sc = 0\n149 while t:\n150 lsb = t & -t; j = lsb.bit_length()-1\n151 sc += cost[j]; t ^= lsb\n152 newm[m] = sc\n153 if not newm:\n154 c_list = []\n155 break\n156 items = sorted(newm.items(), key=lambda x: x[1])\n157 c_list = items[:M]\n158 if c_list is None: c_list = []\n159 fb = 0\n160 scf = 0\n161 for f in fans:\n162 fb |= (1<<f)\n163 scf += cost[f]\n164 if fb.bit_count() <= K:\n165 if not any(m==fb for m,_ in c_list):\n166 c_list.append((fb, scf))\n167 bestc = 10**18; bm = None\n168 for m,sc in c_list:\n169 v = sc + 1\n170 if v < bestc:\n171 bestc = v; bm = m\n172 if bm is None:\n173 bm = fb; bestc = scf + 1\n174 cost[i] = bestc; bestM[i] = bm\n175 cuts[i] = sorted(c_list, key=lambda x: x[1])[:M]\n176 mapping = set()\n177 st = [name_to_idx[nm] for nm in outputs if nm in name_to_idx]\n178 vis = set()\n179 while st:\n180 u = st.pop()\n181 if u in vis: continue\n182 vis.add(u)\n183 bm = bestM[u]\n184 if bm is None: continue\n185 mapping.add(u)\n186 t = bm\n187 while t:\n188 lsb = t & -t; j = lsb.bit_length()-1; t ^= lsb\n189 if j in PI or topo_nodes[j].const_val is not None: continue\n190 if j not in vis: st.append(j)\n191 mapped = sorted(mapping)\n192 with open(solution_file, 'w') as f:\n193 f.write('.model ' + model + '\\n')\n194 f.write('.inputs ' + ' '.join(inputs) + '\\n')\n195 f.write('.outputs ' + ' '.join(outputs) + '\\n')\n196 for i in mapped:\n197 nd = topo_nodes[i]\n198 bm = bestM[i]\n199 leaves = [j for j in range(N) if (bm>>j)&1]\n200 inputs_l = [idx_to_name[j] for j in leaves]\n201 k = len(inputs_l)\n202 Np = 1<<k\n203 full = (1<<Np) - 1\n204 masks = []\n205 for t in range(k):\n206 mm = 0\n207 for j in range(Np):\n208 if (j>>t)&1: mm |= 1<<j\n209 masks.append(mm)\n210 val = {}\n211 for t,j in enumerate(leaves):\n212 val[j] = masks[t]\n```\n\n| 213 | vis2 = set(leaves)                                             |\n|-----|----------------------------------------------------------------|\n| 214 | stk = [i]                                                      |\n| 215 | while stk:                                                     |\n| 216 | u = stk.pop()                                                  |\n| 217 | if u in vis2: continue                                         |\n| 218 | vis2.add(u)                                                    |\n| 219 | for p in topo_nodes[u].fanins:                                 |\n| 220 | pj = name_to_idx.get(p.name)                                   |\n| 221 | if pj is not None and pj not in vis2:                          |\n| 222 | stk.append(pj)                                                 |\n| 223 | cone = [j for j in topo if False]                              |\n| 224 | cone = [j for j in range(N) if j in vis2 and j not in leaves]  |\n| 225 | for j in sorted(cone):                                         |\n| 226 | v = topo_nodes[j]                                              |\n| 227 | if v.const_val is not None:                                    |\n| 228 | val[j] = full if v.const_val==1 else 0                         |\n| 229 | else:                                                          |\n| 230 | if v.patterns_zero:                                            |\n| 231 | zm = 0                                                         |\n| 232 | for p in v.patterns_zero:                                      |\n| 233 | mm = full                                                      |\n| 234 | for t,ch in enumerate(p):                                      |\n| 235 | fn = v.fanin_names[t]                                          |\n| 236 | pj = name_to_idx.get(fn)                                       |\n| 237 | if pj is None:                                                 |\n| 238 | mm = 0; break                                                  |\n| 239 | vm = val[pj]                                                   |\n| 240 | if ch=='1': mm &= vm                                           |\n| 241 | elif ch=='0': mm &= (~vm)&full                                 |\n| 242 | zm  = mm                                                       |\n| 243 | val[j] = (~zm)&full                                            |\n| 244 | else:                                                          |\n| 245 | om = 0                                                         |\n| 246 | for p in v.patterns_one:                                       |\n| 247 | mm = full                                                      |\n| 248 | for t,ch in enumerate(p):                                      |\n| 249 | fn = v.fanin_names[t]                                          |\n| 250 | pj = name_to_idx.get(fn)                                       |\n| 251 | if pj is None:                                                 |\n| 252 | mm = 0; break                                                  |\n| 253 | vm = val[pj]                                                   |\n| 254 | if ch=='1': mm &= vm                                           |\n| 255 | elif ch=='0': mm &= (~vm)&full                                 |\n| 256 | om  = mm                                                       |\n| 257 | val[j] = om                                                    |\n| 258 | root = val[i]                                                  |\n| 259 | f.write('.names ' + ' '.join(inputs_l) + ' ' + nd.name + '\\n') |\n| 260 | for j in range(Np):                                            |\n| 261 | if (root>>j)&1:                                                |\n| 262 | pat = ''.join('1' if (j>>t)&1 else '0' for t in range(k))      |\n| 263 | f.write(pat + ' 1\\n')                                          |\n| 264 | f.write('.end\\n')                                              |\n| 265 |                                                                |\n\nIn the fifth iteration, it introduces a dynamic pruning method by adapting the cut limit based on circuit size – more cuts for smaller circuits (higher quality), and fewer for large circuits (better yield).\n\n```\n1 # iteration 5: dynamic pruning of cut enumeration space\n2\n3 def solve(input_file: str, solution_file: str):\n4 from collections import deque\n5 raw = open(input_file).read().splitlines()\n6 lines = []\n7 i = 0\n8 while i < len(raw):\n9 l = raw[i].rstrip()\n10 if not l or l.lstrip().startswith('#'):\n11 i += 1\n12 continue\n13 if l.endswith('\\\\'):\n14 acc = l[:-1].rstrip()\n15 i += 1\n16 while i < len(raw):\n17 nl = raw[i].rstrip()\n18 if nl.endswith('\\\\'):\n19 acc += ' ' + nl[:-1].rstrip()\n20 i += 1\n21 else:\n22 acc += ' ' + nl\n```\n\n```\n23 i += 1\n24 break\n25 lines.append(acc)\n26 else:\n27 lines.append(l)\n28 i += 1\n29 class Node:\n30 __slots__ = ('name','fanin_names','patterns_one','patterns_zero','const_val','fanins','fanouts')\n31 def __init__(self,n):\n32 self.name = n\n33 self.fanin_names = []\n34 self.patterns_one = []\n35 self.patterns_zero = []\n36 self.const_val = None\n37 self.fanins = []\n38 self.fanouts = []\n39 model = ''\n40 inputs = []\n41 outputs = []\n42 nodes = {}\n43 idx = 0\n44 while idx < len(lines):\n45 l = lines[idx].strip()\n46 if not l:\n47 idx += 1; continue\n48 if l.startswith('.model'):\n49 parts = l.split()\n50 if len(parts) > 1: model = parts[1]\n51 idx += 1\n52 elif l.startswith('.inputs'):\n53 parts = l.split()\n54 for nm in parts[1:]:\n55 inputs.append(nm)\n56 if nm not in nodes: nodes[nm] = Node(nm)\n57 idx += 1\n58 elif l.startswith('.outputs'):\n59 parts = l.split()\n60 for nm in parts[1:]:\n61 outputs.append(nm)\n62 idx += 1\n63 elif l.startswith('.names'):\n64 parts = l.split()\n65 inps = parts[1:-1]; outp = parts[-1]\n66 if outp not in nodes: nodes[outp] = Node(outp)\n67 nd = nodes[outp]\n68 nd.fanin_names = inps[:]\n69 pats = []\n70 j = idx + 1\n71 while j < len(lines) and not lines[j].startswith('.'):\n72 s = lines[j].strip()\n73 if s: pats.append(s)\n74 j += 1\n75 if not inps:\n76 nd.const_val = 1 if pats and pats[0] == '1' else 0\n77 else:\n78 for pt in pats:\n79 sp = pt.split()\n80 if len(sp) == 1:\n81 mask, bit = sp[0], '1'\n82 else:\n83 mask, bit = sp[0], sp[1]\n84 if bit == '1': nd.patterns_one.append(mask)\n85 else: nd.patterns_zero.append(mask)\n86 idx = j\n87 elif l.startswith('.end'):\n88 break\n89 else:\n90 idx += 1\n91 for nd in nodes.values():\n92 nd.fanins = [nodes[nm] for nm in nd.fanin_names if nm in nodes]\n93 for nd in nodes.values():\n94 for f in nd.fanins:\n95 f.fanouts.append(nd)\n96 reachable = set()\n97 st = [nm for nm in outputs if nm in nodes]\n98 while st:\n99 u = st.pop()\n100 if u in reachable: continue\n101 reachable.add(u)\n102 for p in nodes[u].fanin_names:\n103 if p in nodes and p not in reachable:\n```\n\n```\n104 st.append(p)\n105 nodes = {nm:nd for nm,nd in nodes.items() if nm in reachable}\n106 for nd in nodes.values():\n107 nd.fanins = [f for f in nd.fanins if f.name in nodes]\n108 nd.fanouts = [f for f in nd.fanouts if f.name in nodes]\n109 indeg = {nm: len(nd.fanins) for nm,nd in nodes.items()}\n110 dq = deque([nm for nm,d in indeg.items() if d == 0])\n111 topo = []\n112 while dq:\n113 u = dq.popleft(); topo.append(u)\n114 for w in nodes[u].fanouts:\n115 indeg[w.name] -= 1\n116 if indeg[w.name] == 0: dq.append(w.name)\n117 topo_nodes = [nodes[nm] for nm in topo]\n118 N = len(topo_nodes)\n119 name_to_idx = {nd.name: i for i, nd in enumerate(topo_nodes)}\n120 idx_to_name = [nd.name for nd in topo_nodes]\n121 PI = set(name_to_idx[nm] for nm in inputs if nm in name_to_idx)\n122 cost = [0] * N\n123 bestM = [None] * N\n124 K = 6\n125 if N <= 1500:\n126 M = 64\n127 elif N <= 3000:\n128 M = 48\n129 elif N <= 5000:\n130 M = 32\n131 else:\n132 M = 20\n133 cuts = [[] for _ in range(N)]\n134 def prune_cuts(items, limit):\n135 items_sorted = sorted(items, key=lambda x: (x[1], x[0].bit_count()))\n136 pr = []\n137 for m, sc in items_sorted:\n138 dom = False\n139 for pm, psc in pr:\n140 if psc <= sc and (pm & m) == pm:\n141 dom = True\n142 break\n143 if not dom:\n144 pr.append((m, sc))\n145 if len(pr) >= limit:\n146 break\n147 return pr\n148 for i, nd in enumerate(topo_nodes):\n149 if i in PI or nd.const_val is not None:\n150 cost[i] = 0\n151 bestM[i] = None\n152 cuts[i] = [(1 << i, 0)]\n153 continue\n154 fans = [name_to_idx[nm] for nm in nd.fanin_names if nm in name_to_idx]\n155 fans.sort(key=lambda x: len(cuts[x]))\n156 c_list = None\n157 for f in fans:\n158 fcuts = cuts[f]\n159 if not fcuts:\n160 c_list = []\n161 break\n162 fcuts = fcuts[:M]\n163 if c_list is None:\n164 c_list = fcuts.copy()\n165 else:\n166 newm = {}\n167 for m1, sc1 in c_list:\n168 for m2, sc2 in fcuts:\n169 m = m1 | m2\n170 if m.bit_count() <= K:\n171 s2 = sc1 + sc2\n172 prev = newm.get(m)\n173 if prev is None or s2 < prev:\n174 newm[m] = s2\n175 if not newm:\n176 c_list = []\n177 break\n178 c_list = prune_cuts(list(newm.items()), M)\n179 if not c_list:\n180 um = 0; usc = 0\n181 for f in fans:\n182 um |= (1 << f)\n183 usc += cost[f]\n184 c_list = [(um, usc)]\n```\n\n| 185        | um = 0; usc = 0                                               |\n|------------|---------------------------------------------------------------|\n| 186        | for f in fans:                                                |\n|            |                                                               |\n| 187        | um  = (1 << f)                                                |\n| 188        | usc += cost[f]                                                |\n| 189        | if um.bit_count() <= K and all(m != um for m, _ in c_list):   |\n| 190        | c_list.append((um, usc))                                      |\n| 191        | c_list = prune_cuts(c_list, M)                                |\n|            |                                                               |\n| 192        | bestc = 10**18; bm = None                                     |\n| 193        | selfm = (1 << i)                                              |\n| 194        | for m, sc in c_list:                                          |\n| 195        | if m == selfm:                                                |\n|            |                                                               |\n| 196        | continue                                                      |\n| 197        | v = sc + 1                                                    |\n| 198        | if v < bestc:                                                 |\n| 199        | bestc = v; bm = m                                             |\n| 200        | if bm is None:                                                |\n|            | bm = um                                                       |\n| 201        |                                                               |\n| 202        | bestc = usc + 1                                               |\n| 203        | cost[i] = bestc                                               |\n| 204        | bestM[i] = bm                                                 |\n| 205        | cuts[i] = c_list                                              |\n| 206        | mapping = set()                                               |\n|            |                                                               |\n| 207        | st = [name_to_idx[nm] for nm in outputs if nm in name_to_idx] |\n| 208        | vis = set()                                                   |\n| 209        | while st:                                                     |\n| 210        | u = st.pop()                                                  |\n| 211        | if u in vis: continue                                         |\n|            |                                                               |\n| 212        | vis.add(u)                                                    |\n| 213        | bm = bestM[u]                                                 |\n| 214        | if bm is None: continue                                       |\n| 215        | mapping.add(u)                                                |\n| 216        | t = bm                                                        |\n|            |                                                               |\n| 217        | while t:                                                      |\n| 218        | lsb = t & -t                                                  |\n| 219        | j = lsb.bit_length() - 1                                      |\n| 220        | t ^= lsb                                                      |\n| 221        | if j in PI or topo_nodes[j].const_val is not None: continue   |\n| 222        | if j not in vis:                                              |\n|            |                                                               |\n| 223        | st.append(j)                                                  |\n| 224        | mapped = sorted(mapping)                                      |\n| 225        | with open(solution_file, 'w') as f:                           |\n| 226        | f.write('.model ' + model + '\\n')                             |\n| 227        | f.write('.inputs ' + ' '.join(inputs) + '\\n')                 |\n|            |                                                               |\n| 228        | f.write('.outputs ' + ' '.join(outputs) + '\\n')               |\n| 229        | for i in mapped:                                              |\n| 230        | nd = topo_nodes[i]                                            |\n| 231        | bm = bestM[i]                                                 |\n| 232        | leaves = [j for j in range(N) if (bm >> j) & 1]               |\n| 233        | inputs_l = [idx_to_name[j] for j in leaves]                   |\n|            |                                                               |\n| 234        | k = len(inputs_l)                                             |\n| 235        | Np = 1 << k                                                   |\n| 236        | full = (1 << Np) - 1                                          |\n| 237        | masks = []                                                    |\n| 238        |                                                               |\n|            |                                                               |\n|            | for t in range(k):                                            |\n| 239        | mm = 0                                                        |\n| 240        | for j in range(Np):                                           |\n| 241        | if (j >> t) & 1:                                              |\n| 242        | mm  = 1 << j                                                  |\n|            |                                                               |\n| 243        | masks.append(mm)                                              |\n| 244        | val = {}                                                      |\n| 245        | for t, j in enumerate(leaves):                                |\n| 246        | val[j] = masks[t]                                             |\n| 247        | seen = set(leaves)                                            |\n| 248        | stk = [i]                                                     |\n|            |                                                               |\n| 249        | cone = []                                                     |\n| 250        | while stk:                                                    |\n| 251        | u = stk.pop()                                                 |\n| 252        | if u in seen: continue                                        |\n| 253        | seen.add(u)                                                   |\n| 254        |                                                               |\n|            | cone.append(u)                                                |\n| 255        | for p in topo_nodes[u].fanins:                                |\n| 256        | pj = name_to_idx.get(p.name)                                  |\n| 257        | if pj is not None and pj not in seen:                         |\n| 258        | stk.append(pj)                                                |\n| 259        | cone.sort()                                                   |\n|            |                                                               |\n| 260        | for j in cone:                                                |\n| 261        | v = topo_nodes[j]                                             |\n| 262        | if v.const_val is not None:                                   |\n| 263        | val[j] = full if v.const_val == 1 else 0                      |\n| 264<br>265 | else:<br>if v.patterns_zero:                                  |\n\n![](_page_48_Figure_0.jpeg)\n\n# <span id=\"page-48-0\"></span>F Datasets\n\nWe summarize the original data sources for each problem in Table [23.](#page-48-1) All datasets are derived from real-world applications. We further partition or transform them into standardized input formats, ensuring the inclusion of both small-scale instances for demonstration purposes and large-scale instances for evaluation. For detailed data organization, please refer to our GitHub repository.\n\n<span id=\"page-48-1\"></span>\n\n| Table 23: Datasets used in our benchmark. |                                                            |  |  |  |\n|-------------------------------------------|------------------------------------------------------------|--|--|--|\n| Problem                                   | Original Data Source                                       |  |  |  |\n| Operator scheduling                       | EXPRESS [148]                                              |  |  |  |\n| Technology mapping                        | EPFL [6] and ISCAS85 [55]                                  |  |  |  |\n| Global routing                            | ISPD'24 Contest [80]                                       |  |  |  |\n| E-graph extraction                        | SmoothE [15]                                               |  |  |  |\n| Intra-op parallelism                      | ASPLOS'24 Contest [97]                                     |  |  |  |\n| Protein sequence design                   | Protein Data Bank (PDB) [37]                               |  |  |  |\n| Mendelian error detection                 | Cost Function Library [123, 127]                           |  |  |  |\n| Airline crew pairing                      | China Graduate Mathematical Modeling Competition'21 F [29] |  |  |  |\n| Pickup and delivery w/ time windows       | MetaPDPTW [77]                                             |  |  |  |，分析其研究动机、核心方法与公式推导细节。请结合摘要与正文信息，提取论文背景、问题定义、方法核心流程与理论基础。\n",
        "agent": "论文解读专家\n",
        "status": "started"
    }
]
