{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "1d32fbfba0d85489f924bed5c6a41fdc28d08914", "publication_date": "2020-07-22", "title": "Multi-Task Curriculum Framework for Open-Set Semi-Supervised Learning", "authors": "Qing Yu, Daiki Ikami, Go Irie, K. Aizawa", "venue": "European Conference on Computer Vision", "citation_count": 130, "influential_citation_count": 31, "abstract": "Semi-supervised learning (SSL) has been proposed to leverage unlabeled data for training powerful models when only limited labeled data is available. While existing SSL methods assume that samples in the labeled and unlabeled data share the classes of their samples, we address a more complex novel scenario named open-set SSL, where out-of-distribution (OOD) samples are contained in unlabeled data. Instead of training an OOD detector and SSL separately, we propose a multi-task curriculum learning framework. First, to detect the OOD samples in unlabeled data, we estimate the probability of the sample belonging to OOD. We use a joint optimization framework, which updates the network parameters and the OOD score alternately. Simultaneously, to achieve high performance on the classification of in-distribution (ID) data, we select ID samples in unlabeled data having small OOD scores, and use these data with labeled data for training the deep neural networks to classify ID samples in a semi-supervised manner. We conduct several experiments, and our method achieves state-of-the-art results by successfully eliminating the effect of OOD samples.", "pdf_url": "https://arxiv.org/pdf/2007.11330.pdf", "pdf_filepath": "data/semantic/pdf_files/2020-07-22_Multi-Task_Curriculum_Framework_for_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2020-07-22_Multi-Task_Curriculum_Framework_for_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "85de3579e2142fafecb04b88452ee1c53d4faf3f", "publication_date": "2021-08-12", "title": "Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning", "authors": "Junkai Huang, Chaowei Fang, Weikai Chen, Z. Chai, Xiaolin Wei, Pengxu Wei, Liang Lin, Guanbin Li", "venue": "IEEE International Conference on Computer Vision", "citation_count": 64, "influential_citation_count": 16, "abstract": "Open-set semi-supervised learning (open-set SSL) investigates a challenging but practical scenario where out-of-distribution (OOD) samples are contained in the unlabeled data. While the mainstream technique seeks to completely filter out the OOD samples for semi-supervised learning (SSL), we propose a novel training mechanism that could effectively exploit the presence of OOD data for enhanced feature learning while avoiding its adverse impact on the SSL. We achieve this goal by first introducing a warm-up training that leverages all the unlabeled data, including both the in-distribution (ID) and OOD samples. Specifically, we perform a pretext task that enforces our feature extractor to obtain a high-level semantic understanding of the training images, leading to more discriminative features that can benefit the downstream tasks. Since the OOD samples are inevitably detrimental to SSL, we propose a novel cross-modal matching strategy to detect OOD samples. Instead of directly applying binary classification [39], we train the network to predict whether the data sample is matched to an assigned one-hot class label. The appeal of the proposed cross-modal matching over binary classification is the ability to generate a compatible feature space that aligns with the core classification task. Extensive experiments show that our approach substantially lifts the performance on open-set SSL and outperforms the state-of-the-art by a large margin.", "pdf_url": "https://arxiv.org/pdf/2108.05617.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-08-12_Trash_to_Treasure__Harvesting_OOD_Data_with_Cross-Modal_Matching_for_Open-Set_Semi-Supervised_Learni.pdf", "markdown_path": "data/semantic/markdown_files/2021-08-12_Trash_to_Treasure__Harvesting_OOD_Data_with_Cross-Modal_Matching_for_Open-Set_Semi-Supervised_Learni.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "a968cea0f72242662bcf8b1d24f3491135907ead", "publication_date": "2023-08-25", "title": "IOMatch: Simplifying Open-Set Semi-Supervised Learning with Joint Inliers and Outliers Utilization", "authors": "Zekun Li, Lei Qi, Yinghuan Shi, Yang Gao", "venue": "IEEE International Conference on Computer Vision", "citation_count": 31, "influential_citation_count": 6, "abstract": "Semi-supervised learning (SSL) aims to leverage massive unlabeled data when labels are expensive to obtain. Unfortunately, in many real-world applications, the collected unlabeled data will inevitably contain unseen-class outliers not belonging to any of the labeled classes. To deal with the challenging open-set SSL task, the mainstream methods tend to first detect outliers and then filter them out. However, we observe a surprising fact that such approach could result in more severe performance degradation when labels are extremely scarce, as the unreliable outlier detector may wrongly exclude a considerable portion of valuable inliers. To tackle with this issue, we introduce a novel open-set SSL framework, IOMatch, which can jointly utilize inliers and outliers, even when it is difficult to distinguish exactly between them. Specifically, we propose to employ a multi-binary classifier in combination with the standard closed-set classifier for producing unified open-set classification targets, which regard all outliers as a single new class. By adopting these targets as open-set pseudo-labels, we optimize an open-set classifier with all unlabeled samples including both inliers and outliers. Extensive experiments have shown that IOMatch significantly outperforms the baseline methods across different benchmark datasets and different settings despite its remarkable simplicity. Our code and models are available at https://github.com/nukezil/IOMatch.", "pdf_url": "https://arxiv.org/pdf/2308.13168.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-08-25_IOMatch__Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_Utilization.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-25_IOMatch__Simplifying_Open-Set_Semi-Supervised_Learning_with_Joint_Inliers_and_Outliers_Utilization.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "3beb4d0a73f7fc905b64f4db802fb08645d12003", "publication_date": "2024-09-26", "title": "SCOMatch: Alleviating Overtrusting in Open-set Semi-supervised Learning", "authors": "Zerun Wang, Liuyu Xiang, Lang Huang, Jiafeng Mao, Ling Xiao, Toshihiko Yamasaki", "venue": "European Conference on Computer Vision", "citation_count": 2, "influential_citation_count": 0, "abstract": "Open-set semi-supervised learning (OSSL) leverages practical open-set unlabeled data, comprising both in-distribution (ID) samples from seen classes and out-of-distribution (OOD) samples from unseen classes, for semi-supervised learning (SSL). Prior OSSL methods initially learned the decision boundary between ID and OOD with labeled ID data, subsequently employing self-training to refine this boundary. These methods, however, suffer from the tendency to overtrust the labeled ID data: the scarcity of labeled data caused the distribution bias between the labeled samples and the entire ID data, which misleads the decision boundary to overfit. The subsequent self-training process, based on the overfitted result, fails to rectify this problem. In this paper, we address the overtrusting issue by treating OOD samples as an additional class, forming a new SSL process. Specifically, we propose SCOMatch, a novel OSSL method that 1) selects reliable OOD samples as new labeled data with an OOD memory queue and a corresponding update strategy and 2) integrates the new SSL process into the original task through our Simultaneous Close-set and Open-set self-training. SCOMatch refines the decision boundary of ID and OOD classes across the entire dataset, thereby leading to improved results. Extensive experimental results show that SCOMatch significantly outperforms the state-of-the-art methods on various benchmarks. The effectiveness is further verified through ablation studies and visualization.", "pdf_url": "https://arxiv.org/pdf/2409.17512.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-09-26_SCOMatch__Alleviating_Overtrusting_in_Open-set_Semi-supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-26_SCOMatch__Alleviating_Overtrusting_in_Open-set_Semi-supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ce7396b78c3ac52160dce71380e8fff2fee480c1", "publication_date": "2024-07-16", "title": "ProSub: Probabilistic Open-Set Semi-Supervised Learning with Subspace-Based Out-of-Distribution Detection", "authors": "Erik Wallin, Lennart Svensson, Fredrik Kahl, Lars Hammarstrand", "venue": "European Conference on Computer Vision", "citation_count": 2, "influential_citation_count": 0, "abstract": "In open-set semi-supervised learning (OSSL), we consider unlabeled datasets that may contain unknown classes. Existing OSSL methods often use the softmax confidence for classifying data as in-distribution (ID) or out-of-distribution (OOD). Additionally, many works for OSSL rely on ad-hoc thresholds for ID/OOD classification, without considering the statistics of the problem. We propose a new score for ID/OOD classification based on angles in feature space between data and an ID subspace. Moreover, we propose an approach to estimate the conditional distributions of scores given ID or OOD data, enabling probabilistic predictions of data being ID or OOD. These components are put together in a framework for OSSL, termed \\emph{ProSub}, that is experimentally shown to reach SOTA performance on several benchmark problems. Our code is available at https://github.com/walline/prosub.", "pdf_url": "https://arxiv.org/pdf/2407.11735.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-07-16_ProSub__Probabilistic_Open-Set_Semi-Supervised_Learning_with_Subspace-Based_Out-of-Distribution_Dete.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-16_ProSub__Probabilistic_Open-Set_Semi-Supervised_Learning_with_Subspace-Based_Out-of-Distribution_Dete.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "efb9cb7a0576a36c16297fe0992ddcb91e520ce9", "publication_date": "2023-01-24", "title": "Improving Open-Set Semi-Supervised Learning with Self-Supervision", "authors": "Erik Wallin, Lennart Svensson, Fredrik Kahl, Lars Hammarstrand", "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision", "citation_count": 9, "influential_citation_count": 1, "abstract": "Open-set semi-supervised learning (OSSL) embodies a practical scenario within semi-supervised learning, wherein the unlabeled training set encompasses classes absent from the labeled set. Many existing OSSL methods assume that these out-of-distribution data are harmful and put effort into excluding data belonging to unknown classes from the training objective. In contrast, we propose an OSSL framework that facilitates learning from all unlabeled data through self-supervision. Additionally, we utilize an energy-based score to accurately recognize data belonging to the known classes, making our method well-suited for handling uncurated data in deployment. We show through extensive experimental evaluations that our method yields state-of-the-art results on many of the evaluated benchmark problems in terms of closed-set accuracy and open-set recognition when compared with existing methods for OSSL. Our code is available at https://github.com/walline/ssl-tf2-sefoss.", "pdf_url": "https://arxiv.org/pdf/2301.10127.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-01-24_Improving_Open-Set_Semi-Supervised_Learning_with_Self-Supervision.pdf", "markdown_path": "data/semantic/markdown_files/2023-01-24_Improving_Open-Set_Semi-Supervised_Learning_with_Self-Supervision.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "1c952a381a5175f9dd936435b8f1a2bd706c8ffb", "publication_date": "2024-08-01", "title": "Partial Optimal Transport Based Out-of-Distribution Detection for Open-Set Semi-Supervised Learning", "authors": "Yilong Ren, Chuanwen Feng, Xike Xie, S. K. Zhou", "venue": "International Joint Conference on Artificial Intelligence", "citation_count": 1, "influential_citation_count": 0, "abstract": "Semi-supervised learning (SSL) is a machine learning paradigm that utilizes both labeled and unlabeled data to enhance the performance of learning tasks. However, SSL methods operate under the assumption that the label spaces of labeled and unlabeled data are identical, which may not hold in open-world applications. In such scenarios, the unlabeled data may contain novel categories that were not presented in the labeled training data, essentially outliers. This specific challenge is referred to as the Open-set Semi-supervised Learning (OSSL) problem. In OSSL, a pivotal concern is the detection of out-of-distribution (OOD) samples within unlabeled data. Existing methods often struggle to provide effective OOD detection strategies, especially when dealing with datasets comprising a large number of training categories. In response to this challenge, we model the OOD detection problem in OSSL as a partial optimal transport (POT) problem. With POT theory, we devise a mass score function to measure the likelihood of a sample being an outlier, which enables a binary classifier for OOD detection. Further, we put forward an OOD loss, enabling the seamless integration of the binary classifier and off-the-shelf SSL methods under OSSL settings, all within an end-to-end training framework. We extensively evaluate our proposal under various datasets and OSSL configurations, consistently demonstrating the superior performance of our proposal. Codes are available at https://github.com/ryl0427/Code_for_POT_OSSL.", "pdf_url": "https://www.ijcai.org/proceedings/2024/0536.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-08-01_Partial_Optimal_Transport_Based_Out-of-Distribution_Detection_for_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2024-08-01_Partial_Optimal_Transport_Based_Out-of-Distribution_Detection_for_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "0f8f693be24517e8b055d24cc3dcc970119826cf", "publication_date": "2024", "title": "Mutual Filter Teaching for Open-Set Semi-Supervised Learning", "authors": "Xiaokun Li, Rumeng Yi, Y. Huang", "venue": "IEEE transactions on multimedia", "citation_count": 1, "influential_citation_count": 0, "abstract": "Open-set semi-supervised learning (OSSL) provides a practical solution by filtering out-of-distribution (OOD) samples from unlabeled data to guarantee the reliance on large unlabeled data in semi-supervised setting. However, existing OSSL methods mainly focus on identifying in-distribution (ID) samples and discarding OOD samples, while ignoring to make full use of samples that could not be exactly identified as ID or OOD samples. Those samples are more likely to be hard samples, which should be carefully explored to boost the performance in OSSL task. Hence, in this paper, we propose a novel framework, named Mutual Filter Teaching (MFT), where two networks are trained simultaneously to divide the unlabeled data into three parts: ID samples, OOD samples and hard samples. The samples are regarded as ID or OOD samples only if two networks give consistent decisions according to Mahalanobis distance between the unlabeled samples and their closest class prototypes. For those samples with inconsistent decisions, we treat them as hard samples and design an efficient mutual teaching scheme where the samples detected by only one network as positive samples are fed to its peer network for training. Furthermore, we propose to employ the prediction variance of two networks to dynamically rectify the learning from hard samples. Experiments on multiple benchmark datasets demonstrate that our approach achieves the state-of-the-art performance.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "7c146bf72b942a721fce8acd66f3e33ef0284d04", "publication_date": "2023-10-01", "title": "SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning", "authors": "Yue Fan, Anna Kukleva, Dengxin Dai, B. Schiele", "venue": "IEEE International Conference on Computer Vision", "citation_count": 9, "influential_citation_count": 2, "abstract": "Semi-supervised learning (SSL) methods effectively leverage unlabeled data to improve model generalization. However, SSL models often underperform in open-set scenarios, where unlabeled data contain outliers from novel categories that do not appear in the labeled set. In this paper, we study the challenging and realistic open-set SSL setting, where the goal is to both correctly classify inliers and to detect outliers. Intuitively, the inlier classifier should be trained on inlier data only. However, we find that inlier classification performance can be largely improved by incorporating high-confidence pseudo-labeled data, regardless of whether they are inliers or outliers. Also, we propose to utilize non-linear transformations to separate the features used for inlier classification and outlier detection in the multi-task learning framework, preventing adverse effects between them. Additionally, we introduce pseudo-negative mining, which further boosts outlier detection performance. The three ingredients lead to what we call Simple but Strong Baseline (SSB) for open-set SSL. In experiments, SSB greatly improves both inlier classification and outlier detection performance, outperforming existing methods by a large margin. Our code will be released at https://github.com/YUE-FAN/SSB.", "pdf_url": "https://arxiv.org/pdf/2311.10572.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-10-01_SSB__Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2023-10-01_SSB__Simple_but_Strong_Baseline_for_Boosting_Performance_of_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "64dc93a71c087a1983c5410e4e27bec5e6ee3042", "publication_date": "2024", "title": "Data Augmentation with Diffusion for Open-Set Semi-Supervised Learning", "authors": "Seonghyun Ban, Heesan Kong, Kee-Eung Kim", "venue": "Neural Information Processing Systems", "citation_count": 2, "influential_citation_count": 0, "abstract": null, "pdf_url": "https://proceedings.neurips.cc/paper_files/paper/2024/file/777cc2af0ab984e6dc48d168ce7b754f-Paper-Conference.pdf", "pdf_filepath": "data/semantic/pdf_files/2024_Data_Augmentation_with_Diffusion_for_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2024_Data_Augmentation_with_Diffusion_for_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "7b5d2b10d75e4f09223193141bc2d8343c297b25", "publication_date": "2023-03-21", "title": "Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning", "authors": "Yang Yu, Danruo Deng, Fu-Lun Liu, Yueming Jin, Q. Dou, Guangyong Chen, P. Heng", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 4, "influential_citation_count": 2, "abstract": "Semi-supervised learning (SSL) methods assume that labeled\ndata, unlabeled data and test data are from the same distribution. Open-set semi-supervised learning (Open-set SSL) con-\nsiders a more practical scenario, where unlabeled data and\ntest data contain new categories (outliers) not observed in\nlabeled data (inliers). Most previous works focused on out-\nlier detection via binary classifiers, which suffer from insufficient scalability and inability to distinguish different types\nof uncertainty. In this paper, we propose a novel framework,\nAdaptive Negative Evidential Deep Learning (ANEDL) to\ntackle these limitations. Concretely, we first introduce evidential deep learning (EDL) as an outlier detector to quantify\ndifferent types of uncertainty, and design different uncertainty\nmetrics for self-training and inference. Furthermore, we propose a novel adaptive negative optimization strategy, making\nEDL more tailored to the unlabeled dataset containing both\ninliers and outliers. As demonstrated empirically, our proposed method outperforms existing state-of-the-art methods\nacross four datasets.", "pdf_url": "https://arxiv.org/pdf/2303.12091.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-03-21_Adaptive_Negative_Evidential_Deep_Learning_for_Open-set_Semi-supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2023-03-21_Adaptive_Negative_Evidential_Deep_Learning_for_Open-set_Semi-supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ca6587d6d5c217fb85d116afcdc5180b7b7df7bc", "publication_date": "2021", "title": "On The Consistency Training for Open-Set Semi-Supervised Learning", "authors": "Huixiang Luo, Hao Cheng, Yuting Gao, Ke Li, Mengdan Zhang, Fanxu Meng, Xiao-Wei Guo, Feiyue Huang, Xing Sun", "venue": "arXiv.org", "citation_count": 20, "influential_citation_count": 1, "abstract": null, "pdf_url": "https://arxiv.org/pdf/2101.08237", "pdf_filepath": "data/semantic/pdf_files/2021_On_The_Consistency_Training_for_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2021_On_The_Consistency_Training_for_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "8ad0412e6fe5ec505a04652bdb3606653f4d2253", "publication_date": "2024-07-01", "title": "Knowing the unknowns: Network traffic detection with open-set semi-supervised learning", "authors": "Rui Chen, Lailong Luo, Xiaodong Wang, Bangbang Ren, Deke Guo, Shi Zhu", "venue": "Comput. Networks", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "283ffe259563101460d291fd6f4cb8d3e34eb2e4", "publication_date": "2024", "title": "Binary Decomposition: A Problem Transformation Perspective for Open-Set Semi-Supervised Learning", "authors": "Jun-Yi Hang, Min-Ling Zhang", "venue": "International Conference on Machine Learning", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": "https://openreview.net/pdf?id=Irkcamqg4d", "pdf_filepath": "data/semantic/pdf_files/2024_Binary_Decomposition__A_Problem_Transformation_Perspective_for_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2024_Binary_Decomposition__A_Problem_Transformation_Perspective_for_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "0a76cee261445bf7b99c88cb4f4fb3fef488a3ba", "publication_date": "2022-09-28", "title": "Prompt-driven efficient Open-set Semi-supervised Learning", "authors": "Haoran Li, Chun-Mei Feng, Tao Zhou, Yong Xu, Xiaojun Chang", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Open-set semi-supervised learning (OSSL) has attracted growing interest, which investigates a more practical scenario where out-of-distribution (OOD) samples are only contained in unlabeled data. Existing OSSL methods like OpenMatch learn an OOD detector to identify outliers, which often update all modal parameters (i.e., full fine-tuning) to propagate class information from labeled data to unlabeled ones. Currently, prompt learning has been developed to bridge gaps between pre-training and fine-tuning, which shows higher computational efficiency in several downstream tasks. In this paper, we propose a prompt-driven efficient OSSL framework, called OpenPrompt, which can propagate class information from labeled to unlabeled data with only a small number of trainable parameters. We propose a prompt-driven joint space learning mechanism to detect OOD data by maximizing the distribution gap between ID and OOD samples in unlabeled data, thereby our method enables the outliers to be detected in a new way. The experimental results on three public datasets show that OpenPrompt outperforms state-of-the-art methods with less than 1% of trainable parameters. More importantly, OpenPrompt achieves a 4% improvement in terms of AUROC on outlier detection over a fully supervised model on CIFAR10.", "pdf_url": "https://arxiv.org/pdf/2209.14205.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-09-28_Prompt-driven_efficient_Open-set_Semi-supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2022-09-28_Prompt-driven_efficient_Open-set_Semi-supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "3903072a7b790851ff9e41a473e200bd93951f87", "publication_date": "2023-10-20", "title": "LaRW: boosting open-set semi-supervised learning with label-guided re-weighting", "authors": "Jihong Ouyang, Dong Mao, Qingyi Meng", "venue": "Multim. Tools Appl.", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "9d61aacf945002347135a660a0e73ad7a76c8279", "publication_date": "2023-08-29", "title": "Prototype Fission: Closing Set for Robust Open-set Semi-supervised Learning", "authors": "Xuwei Tan, Yi-Jie Huang, Yaqian Li", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Semi-supervised Learning (SSL) has been proven vulnerable to out-of-distribution (OOD) samples in realistic large-scale unsupervised datasets due to over-confident pseudo-labeling OODs as in-distribution (ID). A key underlying problem is class-wise latent space spreading from closed seen space to open unseen space, and the bias is further magnified in SSL's self-training loops. To close the ID distribution set so that OODs are better rejected for safe SSL, we propose Prototype Fission(PF) to divide class-wise latent spaces into compact sub-spaces by automatic fine-grained latent space mining, driven by coarse-grained labels only. Specifically, we form multiple unique learnable sub-class prototypes for each class, optimized towards both diversity and consistency. The Diversity Modeling term encourages samples to be clustered by one of the multiple sub-class prototypes, while the Consistency Modeling term clusters all samples of the same class to a global prototype. Instead of\"opening set\", i.e., modeling OOD distribution, Prototype Fission\"closes set\"and makes it hard for OOD samples to fit in sub-class latent space. Therefore, PF is compatible with existing methods for further performance gains. Extensive experiments validate the effectiveness of our method in open-set SSL settings in terms of successfully forming sub-classes, discriminating OODs from IDs and improving overall accuracy. Codes will be released.", "pdf_url": "https://arxiv.org/pdf/2308.15575.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-08-29_Prototype_Fission__Closing_Set_for_Robust_Open-set_Semi-supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-29_Prototype_Fission__Closing_Set_for_Robust_Open-set_Semi-supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "630bb51965a99477b09d3961937fde6397f338c3", "publication_date": "2023-06-30", "title": "Exploration and Exploitation of Unlabeled Data for Open-Set Semi-Supervised Learning", "authors": "Ganlong Zhao, Guanbin Li, Yipeng Qin, Jinjin Zhang, Z. Chai, Xiaolin Wei, Liang Lin, Yizhou Yu", "venue": "International Journal of Computer Vision", "citation_count": 1, "influential_citation_count": 0, "abstract": "In this paper, we address a complex but practical scenario in semi-supervised learning (SSL) named open-set SSL, where unlabeled data contain both in-distribution (ID) and out-of-distribution (OOD) samples. Unlike previous methods that only consider ID samples to be useful and aim to filter out OOD ones completely during training, we argue that the exploration and exploitation of both ID and OOD samples can benefit SSL. To support our claim, i) we propose a prototype-based clustering and identification algorithm that explores the inherent similarity and difference among samples at feature level and effectively cluster them around several predefined ID and OOD prototypes, thereby enhancing feature learning and facilitating ID/OOD identification; ii) we propose an importance-based sampling method that exploits the difference in importance of each ID and OOD sample to SSL, thereby reducing the sampling bias and improving the training. Our proposed method achieves state-of-the-art in several challenging benchmarks, and improves upon existing SSL methods even when ID samples are totally absent in unlabeled data.", "pdf_url": "https://arxiv.org/pdf/2306.17699.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-06-30_Exploration_and_Exploitation_of_Unlabeled_Data_for_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2023-06-30_Exploration_and_Exploitation_of_Unlabeled_Data_for_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "39b78531ba54110d3e1cc9a452a5c941a1cc08dc", "publication_date": "2022-05-02", "title": "Open-Set Semi-Supervised Learning for 3D Point Cloud Understanding", "authors": "Xian Shi, Xun Xu, Wanyue Zhang, Xiatian Zhu, Chuan-Sheng Foo, K. Jia", "venue": "International Conference on Pattern Recognition", "citation_count": 5, "influential_citation_count": 0, "abstract": "Semantic understanding of 3D point cloud relies on learning models with massively annotated data, which, in many cases, are expensive or difficult to collect. This has led to an emerging research interest in semi-supervised learning (SSL) for 3D point cloud. It is commonly assumed in SSL that the unlabeled data are drawn from the same distribution as that of the labeled ones; This assumption, however, rarely holds true in realistic environments. Blindly using out-of-distribution (OOD) unlabeled data could harm SSL performance. In this work, we propose to selectively utilize unlabeled data through sample weighting, so that only conducive unlabeled data would be prioritized. To estimate the weights, we adopt a bi-level optimization framework which iteratively optimizes a meta-objective on a held-out validation set and a task-objective on a training set. Faced with the instability of efficient bi-level optimizers, we further propose three regularization techniques to enhance the training stability. Extensive experiments on 3D point cloud classification and segmentation tasks verify the effectiveness of our proposed method. We also demonstrate the feasibility of a more efficient training strategy. Our code is released on Github1.", "pdf_url": "https://arxiv.org/pdf/2205.01006.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-05-02_Open-Set_Semi-Supervised_Learning_for_3D_Point_Cloud_Understanding.pdf", "markdown_path": "data/semantic/markdown_files/2022-05-02_Open-Set_Semi-Supervised_Learning_for_3D_Point_Cloud_Understanding.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "4b324aafefcafbc49c70ccfcc1323e65ff2238c2", "publication_date": "2021-01-19", "title": "An Empirical Study and Analysis on Open-Set Semi-Supervised Learning", "authors": "Huixiang Luo, Hao Cheng, Fanxu Meng, Yuting Gao, Ke Li, Mengdan Zhang, Xing Sun", "venue": "", "citation_count": 8, "influential_citation_count": 1, "abstract": "Pseudo-labeling (PL) and Data Augmentation-based Consistency Training (DACT) are two approaches widely used in Semi-Supervised Learning (SSL) methods. These methods exhibit great power in many machine learning tasks by utilizing unlabeled data for efficient training. But in a more realistic setting (termed as open-set SSL), where unlabeled dataset contains out-of-distribution (OOD) samples, the traditional SSL methods suffer severe performance degradation. Recent approaches mitigate the negative influence of OOD samples by filtering them out from the unlabeled data. However, it is not clear whether directly removing the OOD samples is the best choice. Furthermore, why PL and DACT could perform differently in open-set SSL remains a mystery. In this paper, we thoroughly analyze various SSL methods (PL and DACT) on open-set SSL and discuss pros and cons of these two approaches separately. Based on our analysis, we propose Style Disturbance to improve traditional SSL methods on open-set SSL and experimentally show our approach can achieve state-of-the-art results on various datasets by utilizing OOD samples properly. We believe our study can bring new insights for SSL research.", "pdf_url": "https://arxiv.org/pdf/2101.08237.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-01-19_An_Empirical_Study_and_Analysis_on_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2021-01-19_An_Empirical_Study_and_Analysis_on_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ca61ddc0c59af7aded9b53a8762198eded9a012d", "publication_date": "2024-11-15", "title": "OPN: Open-Set Semi-Supervised Learning for Intelligent Fault Diagnosis of Rotating Machinery", "authors": "Zuqiang Su, Xiaolong Zhang, Guoyin Wang, Sheng Lu, Song Feng, Baoping Tang", "venue": "IEEE Sensors Journal", "citation_count": 0, "influential_citation_count": 0, "abstract": "Semi-supervised learning (SSL) is effective in addressing the scarcity of label information in the fault diagnosis of rotating machinery. However, existing SSL methods generally assume that the labeled and unlabeled fault samples share a consistent label space, which is difficult to guarantee in practical applications and limits the applicability of SSL. To address this issue, this study presents a method denoted as open-set semi-supervised learning (O3SL) for intelligent fault diagnosis (IFD). First, an orthogonal projection network (OPN) is proposed to classify fault samples based on feature projection. Moreover, an open-set recognition (OSR) module based on feature projection residual (FPR) is further presented to discover potential unknown fault types in unlabeled fault samples. Finally, a pseudo-label correction updating (PLCU) module is developed to further dynamically generate corrected pseudo-labels and thus to improve the performance of OPN. Extensive experiments on two gearbox fault datasets have validated the effectiveness of the proposed OPN-based O3SL method.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "58cadf791b7512ecb84365a679515e69f4c24694", "publication_date": "2024-06-30", "title": "Open-Set Semi-Supervised Learning by Distribution Alignment", "authors": "Qiao Xiao, Jinjing Zhu, Boqian Wu, Yu Zhang", "venue": "IEEE International Joint Conference on Neural Network", "citation_count": 0, "influential_citation_count": 0, "abstract": "Semi-Supervised Learning (SSL) has been shown to be effective in the closed-set case where the label spaces in labeled and unlabeled data are the same. However, in open-set SSL, its performance is seriously degraded since unlabeled data contains some classes not seen in the labeled data, leading to the distribution mismatch between labeled and unlabeled data. To solve this problem, we propose a Distribution Aligned Openset SSL (DAOSSL) method, which aims to explicitly reduce the empirical distribution mismatch between the labeled and unlabeled data. Specifically, we first introduce a progressive separation mechanism that utilizes a coarse-to-fine pipeline to weigh the unlabeled data. Based on this weighting strategy, we then propose a weighted distribution alignment approach to minimize the distribution discrepancy between the labeled and unlabeled data. These two strategies can be easily integrated into existing deep SSL approaches for open-set SSL tasks. The effectiveness of the proposed DAOSSL method is demonstrated through empirical studies, which show that the method is able to successfully reduce the distribution mismatch between labeled and unlabeled data, resulting in performance improvement in open-set SSL tasks.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "25bfb942b3556ba11c4bb6060ab62e92783e7783", "publication_date": "2022-05-13", "title": "Knowledge Distillation Meets Open-Set Semi-Supervised Learning", "authors": "Jing Yang, Xiatian Zhu, Adrian Bulat, Brais Mart\u00ednez, Georgios Tzimiropoulos", "venue": "International Journal of Computer Vision", "citation_count": 10, "influential_citation_count": 1, "abstract": "Existing knowledge distillation methods mostly focus on distillation of teacher\u2019s prediction and intermediate activation. However, the structured representation, which arguably is one of the most critical ingredients of deep models, is largely overlooked. In this work, we propose a novel semantic representational distillation (SRD) method dedicated for distilling representational knowledge semantically from a pretrained teacher to a target student. The key idea is that we leverage the teacher\u2019s classifier as a semantic critic for evaluating the representations of both teacher and student and distilling the semantic knowledge with high-order structured information over all feature dimensions. This is accomplished by introducing a notion of cross-network logit computed through passing student\u2019s representation into teacher\u2019s classifier. Further, considering the set of seen classes as a basis for the semantic space in a combinatorial perspective, we scale SRD to unseen classes for enabling effective exploitation of largely available, arbitrary unlabeled training data. At the problem level, this establishes an interesting connection between knowledge distillation with open-set semi-supervised learning (SSL). Extensive experiments show that our SRD outperforms significantly previous state-of-the-art knowledge distillation methods on both coarse object classification and fine face recognition tasks, as well as less studied yet practically crucial binary network distillation. Under more realistic open-set SSL settings we introduce, we reveal that knowledge distillation is generally more effective than existing out-of-distribution sample detection, and our proposed SRD is superior over both previous distillation and SSL competitors. The source code is available at https://github.com/jingyang2017/SRD_ossl.", "pdf_url": "https://arxiv.org/pdf/2205.06701.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-05-13_Knowledge_Distillation_Meets_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2022-05-13_Knowledge_Distillation_Meets_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "54d400ea6b2522582191062a3e508129410d0d81", "publication_date": "2025-04-17", "title": "The Others: Naturally Isolating Out-of-Distribution Samples for Robust Open-Set Semi-Supervised Learning", "authors": "You Rim Choi, Subeom Park, Seojun Heo, Eunchung Noh, Hyung-Sin Kim", "venue": "arXiv.org", "citation_count": 0, "influential_citation_count": 0, "abstract": "Open-Set Semi-Supervised Learning (OSSL) tackles the practical challenge of learning from unlabeled data that may include both in-distribution (ID) and unknown out-of-distribution (OOD) classes. However, existing OSSL methods form suboptimal feature spaces by either excluding OOD samples, interfering with them, or overtrusting their information during training. In this work, we introduce MagMatch, a novel framework that naturally isolates OOD samples through a prototype-based contrastive learning paradigm. Unlike conventional methods, MagMatch does not assign any prototypes to OOD samples; instead, it selectively aligns ID samples with class prototypes using an ID-Selective Magnetic (ISM) module, while allowing OOD samples - the\"others\"- to remain unaligned in the feature space. To support this process, we propose Selective Magnetic Alignment (SMA) loss for unlabeled data, which dynamically adjusts alignment based on sample confidence. Extensive experiments on diverse datasets demonstrate that MagMatch significantly outperforms existing methods in both closed-set classification accuracy and OOD detection AUROC, especially in generalizing to unseen OOD data.", "pdf_url": "https://arxiv.org/pdf/2504.12569.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-04-17_The_Others__Naturally_Isolating_Out-of-Distribution_Samples_for_Robust_Open-Set_Semi-Supervised_Lear.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-17_The_Others__Naturally_Isolating_Out-of-Distribution_Samples_for_Robust_Open-Set_Semi-Supervised_Lear.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "2d08b2bddeea882d4bab2a338e68303d2271241c", "publication_date": "2025", "title": "Enhancing Respiratory Sound Classification Based on Open-Set Semi-Supervised Learning", "authors": "Won-Yang Cho, Sangjun Lee", "venue": "Computers, Materials &amp; Continua", "citation_count": 0, "influential_citation_count": 0, "abstract": ": The classification of respiratory sounds is crucial in diagnosing and monitoring respiratory diseases. However, auscultation is highly subjective, making it challenging to analyze respiratory sounds accurately. Although deep learning has been increasingly applied to this task, most existing approaches have primarily relied on supervised learning. Since supervised learning requires large amounts of labeled data, recent studies have explored self-supervised and semi-supervised methods to overcome this limitation. However, these approaches have largely assumed a closed-set setting, where the classes present in the unlabeled data are considered identical to those in the labeled data. In contrast, this study explores an open-set semi-supervised learning setting, where the unlabeled data may contain additional, unknown classes. To address this challenge, a distance-based prototype network is employed to classify respiratory sounds in an open-set setting. In the first stage, the prototype network is trained using labeled and unlabeled data to derive prototype representations of known classes. In the second stage, distances between unlabeled data and known class prototypes are computed, and samples exceeding an adaptive threshold are identified as unknown. A new prototype is then calculated for this unknown class. In the final stage, semi-supervised learning is employed to classify labeled and unlabeled data into known and unknown classes. Compared to conventional closed-set semi-supervised learning approaches, the proposed method achieved an average classification accuracy improvement of 2%\u20135%. Additionally, in cases of data scarcity, utilizing unlabeled data further improved classification performance by 6%\u20138%. The findings of this study are expected to significantly enhance respiratory sound classification performance in practical clinical settings.", "pdf_url": "https://www.techscience.com/cmc/online/detail/23396/pdf", "pdf_filepath": "data/semantic/pdf_files/2025_Enhancing_Respiratory_Sound_Classification_Based_on_Open-Set_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2025_Enhancing_Respiratory_Sound_Classification_Based_on_Open-Set_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "8fe06c0ce3bc987a03b98460a8e455e61ef9df41", "publication_date": "2025-04-14", "title": "Open-Set Semi-Supervised Learning for Long-Tailed Medical Datasets", "authors": "D. Kareem, Jean Lahoud, M. Fiaz, Amandeep Kumar, Hisham Cholakkal", "venue": "IEEE International Symposium on Biomedical Imaging", "citation_count": 0, "influential_citation_count": 0, "abstract": "Many practical medical imaging scenarios include categories that are under-represented but still crucial. The relevance of image recognition models to real-world applications lies in their ability to generalize to these rare classes as well as unseen classes. Real-world generalization requires taking into account the various complexities that can be encountered in the real-world. First, training data is highly imbalanced, which may lead to model exhibiting bias toward the more frequently represented classes. Moreover, real-world data may contain unseen classes that need to be identified, and model performance is affected by the data scarcity. While medical image recognition has been extensively addressed in the literature, current methods do not take into account all the intricacies in the real-world scenarios. To this end, we propose an open-set learning method for highly imbal-anced medical datasets using a semi-supervised approach. Understanding the adverse impact of long-tail distribution at the inherent model characteristics, we implement a reg-ularization strategy at the feature level complemented by a classifier normalization technique. We conduct extensive experiments on the publicly available datasets, ISIC20 18, ISIC2019, and TissueMNIST with various numbers of labelled samples. Our analysis shows that addressing the impact of long-tail data in classification significantly improves the overall performance of the network in terms of closed-set and open-set accuracies on all datasets. Our code and trained models will be made publicly available at https://github.com/Daniyanaj/OpenLTR.", "pdf_url": "https://arxiv.org/pdf/2505.14846.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-04-14_Open-Set_Semi-Supervised_Learning_for_Long-Tailed_Medical_Datasets.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-14_Open-Set_Semi-Supervised_Learning_for_Long-Tailed_Medical_Datasets.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "51144ecc84d601c0556b4126a74e48039afd0488", "publication_date": "2024-12-01", "title": "Closed loop networks for open-set semi-supervised learning", "authors": "Jihong Ouyang, Qingyi Meng, Ximing Li, Zhengjie Zhang, C. Li, Wenting Wang", "venue": "Information Sciences", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "7158479d7e2ef251a7c21d22ff87fe85030e3d12", "publication_date": "2024-05-11", "title": "Robust Semi-Supervised Learning by Wisely Leveraging Open-Set Data", "authors": "Yang Yang, Nan Jiang, Yi Xu, De-Chuan Zhan", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citation_count": 18, "influential_citation_count": 0, "abstract": "Open-set Semi-supervised Learning (OSSL) holds a realistic setting that unlabeled data may come from classes unseen in the labeled set, i.e., out-of-distribution (OOD) data, which could cause performance degradation in conventional SSL models. To handle this issue, except for the traditional in-distribution (ID) classifier, some existing OSSL approaches employ an extra OOD detection module to avoid the potential negative impact of the OOD data. Nevertheless, these approaches typically employ the entire set of open-set data during their training process, which may contain data unfriendly to the OSSL task that can negatively influence the model performance. This inspires us to develop a robust open-set data selection strategy for OSSL. Through a theoretical understanding from the perspective of learning theory, we propose Wise Open-set Semi-supervised Learning (WiseOpen), a generic OSSL framework that selectively leverages the open-set data for training the model. By applying a gradient-variance-based selection mechanism, WiseOpen exploits a friendly subset instead of the whole open-set dataset to enhance the model's capability of ID classification. Moreover, to reduce the computational expense, we also propose two practical variants of WiseOpen by adopting low-frequency update and loss-based selection respectively. Extensive experiments demonstrate the effectiveness of WiseOpen in comparison with the state-of-the-art.", "pdf_url": "https://arxiv.org/pdf/2405.06979.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-05-11_Robust_Semi-Supervised_Learning_by_Wisely_Leveraging_Open-Set_Data.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-11_Robust_Semi-Supervised_Learning_by_Wisely_Leveraging_Open-Set_Data.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "d1232747682f81dfed184fc32047808e7073f96f", "publication_date": "2024-12-19", "title": "An Open-Set Semi-Supervised Multi-Task Learning Framework for Context Classification in Biomedical Texts", "authors": "Difei Tang, Thomas Yu Chow Tam, Haomiao Luo, C. Telmer, Natasa Miskov-Zivanov", "venue": "bioRxiv", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "70f0862c41a3abd2ba2b247955fef637e62223a1", "publication_date": "2024-11-20", "title": "Collaborative Feature-Logits Contrastive Learning for Open-Set Semi-Supervised Object Detection", "authors": "Xinhao Zhong, Siyu Jiao, Yao Zhao, Yunchao Wei", "venue": "ACM Multimedia Asia", "citation_count": 0, "influential_citation_count": 0, "abstract": "Current Semi-Supervised Object Detection (SSOD) methods enhance detector performance by leveraging large amounts of unlabeled data, assuming that both labeled and unlabeled data share the same label space. However, in open-set scenarios, the unlabeled dataset contains both in-distribution (ID) classes and out-of-distribution (OOD) classes. Applying semi-supervised detectors in such settings can lead to misclassifying OOD class as ID classes. To alleviate this issue, we propose a simple yet effective method, termed Collaborative Feature-Logits Detector (CFL-Detector). Specifically, we introduce a feature-level clustering method using contrastive loss to clarify vector boundaries in the feature space and highlight class differences. Additionally, by optimizing the logits-level uncertainty classification loss, the model enhances its ability to effectively distinguish between ID and OOD classes. Extensive experiments demonstrate that our method achieves state-of-the-art performance compared to existing methods.", "pdf_url": "https://arxiv.org/pdf/2411.13001.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-11-20_Collaborative_Feature-Logits_Contrastive_Learning_for_Open-Set_Semi-Supervised_Object_Detection.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-20_Collaborative_Feature-Logits_Contrastive_Learning_for_Open-Set_Semi-Supervised_Object_Detection.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "6090e038294df604b6da851e34349da4b77b5cf8", "publication_date": "2020", "title": "I NTRODUCTION TO QUASI - OPEN SET SEMI - SUPERVISED LEARNING FOR BIG DATA ANALYTICS", "authors": "E. Engelbrecht, J. D. Preez", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ca6101451283bd33473a609ae42a3852bea8df08", "publication_date": "2024-04-19", "title": "Category-aware Filtering for Open-set Semi-Supervised Object Detection", "authors": "Yiqi Zou, Kuo Wang, Dongyu Zhang, Mingzhi Mao, Guanbin Li", "venue": "2024 5th International Conference on Computer Vision, Image and Deep Learning (CVIDL)", "citation_count": 0, "influential_citation_count": 0, "abstract": "Semi-Supervised Object Detection (SSOD) has gained significant interest in recent years. However, the majority of existing methods are based on the close-set assumption. In this paper, we address a challenging but more practical scenario, Open-Set Semi-Supervised Object Detection (OSSOD), where out-of-distribution (OOD) samples are contained in unlabeled data. The previous approach employs an offline detector to eliminate OOD pseudo labels, which is intricate and time-consuming. And the limited availability of labeled data hampers the performance of the OOD detector. In contrast, we propose a simple yet effective approach that facilitates the detector\u2019s performance in open scenarios. Specifically, we employ soft-distribution on all identified instances as our training objective to enhance the model\u2019s feature extraction capability. And we further design a radius-aware matching approach to filter OOD samples according to categories with varying diversity in unlabeled data. Our category-aware design has been proven effective through extensive experiments, surpassing current state-of-the-art work.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "866169f5b40c631dc2c81bbe2378232dff728e0a", "publication_date": "2021-05-28", "title": "OpenMatch: Open-set Consistency Regularization for Semi-supervised Learning with Outliers", "authors": "Kuniaki Saito, Donghyun Kim, Kate Saenko", "venue": "Neural Information Processing Systems", "citation_count": 65, "influential_citation_count": 20, "abstract": "Semi-supervised learning (SSL) is an effective means to leverage unlabeled data to improve a model's performance. Typical SSL methods like FixMatch assume that labeled and unlabeled data share the same label space. However, in practice, unlabeled data can contain categories unseen in the labeled set, i.e., outliers, which can significantly harm the performance of SSL algorithms. To address this problem, we propose a novel Open-set Semi-Supervised Learning (OSSL) approach called OpenMatch. Learning representations of inliers while rejecting outliers is essential for the success of OSSL. To this end, OpenMatch unifies FixMatch with novelty detection based on one-vs-all (OVA) classifiers. The OVA-classifier outputs the confidence score of a sample being an inlier, providing a threshold to detect outliers. Another key contribution is an open-set soft-consistency regularization loss, which enhances the smoothness of the OVA-classifier with respect to input transformations and greatly improves outlier detection. OpenMatch achieves state-of-the-art performance on three datasets, and even outperforms a fully supervised model in detecting outliers unseen in unlabeled data on CIFAR10.", "pdf_url": "https://arxiv.org/pdf/2105.14148.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-05-28_OpenMatch__Open-set_Consistency_Regularization_for_Semi-supervised_Learning_with_Outliers.pdf", "markdown_path": "data/semantic/markdown_files/2021-05-28_OpenMatch__Open-set_Consistency_Regularization_for_Semi-supervised_Learning_with_Outliers.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "a6adafce25ec2a1938f54922b12a2bfc7338280e", "publication_date": "2025-02-01", "title": "Robust contrastive learning based on evidential uncertainty for open-set semi-supervised industrial fault diagnosis.", "authors": "Shuaijie Chen, Chuang Peng, Lei Chen, Kuangrong Hao", "venue": "ISA transactions", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "778b1791b42eb3115b1a0ba8361e354de64ba3e5", "publication_date": "2023-10-01", "title": "Rethinking Safe Semi-supervised Learning: Transferring the Open-set Problem to A Close-set One", "authors": "Qiankun Ma, Jiyao Gao, Bo Zhan, Yunpeng Guo, Jiliu Zhou, Yan Wang", "venue": "IEEE International Conference on Computer Vision", "citation_count": 11, "influential_citation_count": 1, "abstract": "Conventional semi-supervised learning (SSL) lies in the close-set assumption that the labeled and unlabeled sets contain data with the same seen classes, called in-distribution (ID) data. In contrast, safe SSL investigates a more challenging open-set problem where unlabeled set may involve some out-of-distribution (OOD) data with unseen classes, which could harm the performance of SSL. When we are experimenting with the mainstream safe SSL methods, we have a surprising finding that all OOD data show a clear tendency to gather in the feature space. This inspires us to solve the safe SSL problem from a fresh perspective. Specifically, for a classification task with K seen classes, we utilize a prototype network not only to generate K prototypes of all seen classes, but also explicitly model an additional prototype for the OOD data, transferring the K-way classification on the open-set to the (K+1)-way on the close-set. In this way, the typical SSL techniques (e.g., consistency regularization and pseudo labeling) can be applied to tackle the safe SSL problem without additional consideration of OOD data processing like other safe SSL methods do. Particularly, considering the possible low-confidence pseudo labels, we further propose an iterative negative learning (INL) paradigm to enforce the network learning knowledge from complementary labels on wider classes, improving the network\u2019s classification performance. Extensive experiments on four benchmark datasets show that our approach remarkably lifts the performance on safe SSL and outperforms the state-of-the-art methods.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "5866785ca6c9b47af5a55f1e5ecd4f179110da31", "publication_date": "2022-07-01", "title": "End-to-End Open-Set Semi-Supervised Node Classification with Out-of-Distribution Detection", "authors": "Tiancheng Huang, Donglin Wang, Yuan Fang, Zhengyu Chen", "venue": "International Joint Conference on Artificial Intelligence", "citation_count": 11, "influential_citation_count": 0, "abstract": "Out-Of-Distribution (OOD) samples are prevalent in real-world applications. The OOD issue becomes even more severe on graph data, as the effect of OOD nodes can be potentially amplified by propagation through the graph topology. Recent works have considered the OOD detection problem, which is critical for reducing the uncertainty in learning and improving the robustness. However, no prior work considers simultaneously OOD detection and node classification on graphs in an end-to-end manner. In this paper, we study a novel problem of end-to-end open-set semi-supervised node classification (OSSNC) on graphs, which deals with node classification in the presence of OOD nodes. Given the lack of supervision on OOD nodes, we introduce a latent variable to indicate in-distribution or OOD nodes in a variational inference framework, and further propose a novel algorithm named as Learning to Mix Neighbors (LMN) which learns to dampen the influence of OOD nodes through the messaging-passing in typical graph neural networks. Extensive experiments on various datasets show that the proposed method outperforms state-of-the-art baselines in terms of both node classification and OOD detection.", "pdf_url": "https://www.ijcai.org/proceedings/2022/0290.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-07-01_End-to-End_Open-Set_Semi-Supervised_Node_Classification_with_Out-of-Distribution_Detection.pdf", "markdown_path": "data/semantic/markdown_files/2022-07-01_End-to-End_Open-Set_Semi-Supervised_Node_Classification_with_Out-of-Distribution_Detection.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "3e25f2446a5346ce605a8054ca9af247f50fc3b1", "publication_date": "2023", "title": "Linking generative semi-supervised learning and generative open-set recognition", "authors": "E. Engelbrecht, J. D. Preez", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "\u2014This study investigates the relationship between semi-supervised learning (SSL) and open-set recognition (OSR) in the context of generative adversarial networks (GANs). Although no previous study has formally linked SSL and OSR, their respective methods share striking similarities. Speci\ufb01cally, SSL-GANs and OSR-GANs require generator to produce samples in the complementary space. Subsequently, by regularising networks with generated samples, both SSL and OSR classi\ufb01ers generalize the open space. To demonstrate the connection between SSL and OSR, we theoretically and experimentally compare state-of-the-art SSL-GAN methods with state-of-the-art OSR-GAN methods. Our results indicate that the SSL optimised margin-GANs, which have a stronger foundation in literature, set the new standard for the combined SSL-OSR task and achieves new state-of-other art results in certain general OSR experiments. However, the OSR optimised adversarial reciprocal point (ARP)-GANs still slightly out-performed margin-GANs at other OSR experiments. This result indicates unique insights for the combined optimisation task of SSL-OSR.", "pdf_url": "https://arxiv.org/abs/2303.11702/pdf/2303.11702", "pdf_filepath": "data/semantic/pdf_files/2023_Linking_generative_semi-supervised_learning_and_generative_open-set_recognition.pdf", "markdown_path": "data/semantic/markdown_files/2023_Linking_generative_semi-supervised_learning_and_generative_open-set_recognition.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "238e7dc34835cc06e6622446ee6557225438b630", "publication_date": "2025-03-28", "title": "Diversify and Conquer: Open-Set Disagreement for Robust Semi-Supervised Learning With Outliers", "authors": "Heejo Kong, Sung-Jin Kim, Gunho Jung, Seong-Whan Lee", "venue": "IEEE Transactions on Neural Networks and Learning Systems", "citation_count": 0, "influential_citation_count": 0, "abstract": "Conventional semi-supervised learning (SSL) ideally assumes that labeled and unlabeled data share an identical class distribution; however, in practice, this assumption is easily violated, as unlabeled data often includes unknown class data, i.e., outliers. The outliers are treated as noise, considerably degrading the performance of SSL models. To address this drawback, we propose a novel framework, diversify and conquer (DAC), to enhance SSL robustness in the context of open-set SSL (OSSL). In particular, we note that existing OSSL methods rely on prediction discrepancies between inliers and outliers from a single model trained on labeled data. This approach can be easily failed when the labeled data are insufficient, leading to performance degradation that is worse than naive SSL that do not account for outliers. In contrast, our approach exploits prediction disagreements among multiple models that are differently biased toward the unlabeled distribution. By leveraging the discrepancies arising from training on unlabeled data, our method enables robust outlier detection, even when the labeled data are underspecified. Our key contribution is constructing a collection of differently biased models through a single training process. By encouraging divergent heads to be differently biased toward outliers while making consistent predictions for inliers, we exploit the disagreement among these heads as a measure to identify unknown concepts. Extensive experiments demonstrate that our method significantly surpasses state-of-the-art OSSL methods across various protocols.", "pdf_url": "https://arxiv.org/pdf/2505.24443.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-03-28_Diversify_and_Conquer__Open-Set_Disagreement_for_Robust_Semi-Supervised_Learning_With_Outliers.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-28_Diversify_and_Conquer__Open-Set_Disagreement_for_Robust_Semi-Supervised_Learning_With_Outliers.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "39e3d557378ad29d9f2546eb8199b454295daa22", "publication_date": "2023", "title": "DeCAB: Debiased Semi-supervised Learning for Imbalanced Open-Set Data", "authors": "Xiaolin Huang, Mengke Li, Yang Lu, Hanzi Wang", "venue": "Chinese Conference on Pattern Recognition and Computer Vision", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "107d466276520c2b3df2977769e1add4ff03e365", "publication_date": "2023-03-21", "title": "On the link between generative semi-supervised learning and generative open-set recognition", "authors": "E. Engelbrecht, Johan A. du Preez", "venue": "Scientific African", "citation_count": 2, "influential_citation_count": 0, "abstract": null, "pdf_url": "https://arxiv.org/pdf/2303.11702.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-03-21_On_the_link_between_generative_semi-supervised_learning_and_generative_open-set_recognition.pdf", "markdown_path": "data/semantic/markdown_files/2023-03-21_On_the_link_between_generative_semi-supervised_learning_and_generative_open-set_recognition.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "c39cb060e8649ba017901056ce66bfb2b50796bc", "publication_date": "2021-06-29", "title": "OpenCoS: Contrastive Semi-supervised Learning for Handling Open-set Unlabeled Data", "authors": "Jongjin Park, Sukmin Yun, Jongheon Jeong, Jinwoo Shin", "venue": "ECCV Workshops", "citation_count": 29, "influential_citation_count": 1, "abstract": "Semi-supervised learning (SSL) has been a powerful strategy to incorporate few labels in learning better representations. In this paper, we focus on a practical scenario that one aims to apply SSL when unlabeled data may contain out-of-class samples - those that cannot have one-hot encoded labels from a closed-set of classes in label data, i.e., the unlabeled data is an open-set. Specifically, we introduce OpenCoS, a simple framework for handling this realistic semi-supervised learning scenario based upon a recent framework of self-supervised visual representation learning. We first observe that the out-of-class samples in the open-set unlabeled dataset can be identified effectively via self-supervised contrastive learning. Then, OpenCoS utilizes this information to overcome the failure modes in the existing state-of-the-art semi-supervised methods, by utilizing one-hot pseudo-labels and soft-labels for the identified in- and out-of-class unlabeled data, respectively. Our extensive experimental results show the effectiveness of OpenCoS under the presence of out-of-class samples, fixing up the state-of-the-art semi-supervised methods to be suitable for diverse scenarios involving open-set unlabeled data.", "pdf_url": "https://arxiv.org/pdf/2107.08943.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-06-29_OpenCoS__Contrastive_Semi-supervised_Learning_for_Handling_Open-set_Unlabeled_Data.pdf", "markdown_path": "data/semantic/markdown_files/2021-06-29_OpenCoS__Contrastive_Semi-supervised_Learning_for_Handling_Open-set_Unlabeled_Data.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "d8428f5231486e1d6d23e516f566625d79e08018", "publication_date": "2022-10-01", "title": "A Semi-Supervised Learning Method for Hyperspectral-Image Open Set Classification", "authors": "Zhaolin Duan, Hao Chen, Xiaohua Li, Jiliu Zhou, Yuanyuan Wang", "venue": "Photogrammetric Engineering &amp; Remote Sensing", "citation_count": 3, "influential_citation_count": 1, "abstract": "We present a conceptually simple and flexible method for hyperspectral-image open set classification. Unlike previous methods, where the abundant unlabeled data inherent in the data set are ignored completely and unknown classes are inferred using score post-calibration, our approach\n makes the unlabeled data join in and help to train a simple and practical model for open set classification. The model is able to provide an explicit decision score for both unknown classes and each known class. The main idea of the proposed method is augmenting the original training set of\n K known classes using the pseudo-labeled unknown-category samples that are detected elaborately from the unlabeled data using modified OpenMax and semi-supervised iterative learning. Then a (K + 1)-class deep convolutional neural network model is trained based on the augmented training set\n with (K + 1) class samples. The model can not only classify instances of each known class but also refuse instances of unknown class explicitly. We validated the proposed method on four well-known hyperspectral-image data sets, obtaining superior performance over previous methods.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "d40d4d096b6ddce83c3fb8bfd414f7134b5e148f", "publication_date": "2025", "title": "Semi-Supervised Graph Constraint Dual Classifier Network With Unknown Class Feature Learning for Hyperspectral Image Open-Set Classification", "authors": "Na Li, Xiaopeng Song, Yongxu Liu, Wenxiang Zhu, Chuang Li, Wei-Tao Zhang, Yinghui Quan", "venue": "IEEE Geoscience and Remote Sensing Letters", "citation_count": 0, "influential_citation_count": 0, "abstract": "In view of the practical value of open datasets of hyperspectral images (HSIs), HSI open-set classification (OSC) has attracted more and more attention. Existing HSI OSC methods are usually based on learning labeled samples to identify unknown classes. However, due to the complex high-dimensional characteristics of HSIs and the limited number of labeled samples, the recognition of unknown classes based only on limited labeled samples often has low and unstable accuracy. To address this problem, we propose a semi-supervised graph constraint dual classifier network (SSGCDCN) that can achieve efficient and stable OSC by learning unknown class features and relationships among samples. First, a dual classifier consisting of a multiclassifier and multiple binary classifiers is constructed, which has the ability to discover the unknown class samples by assigning and enabling pseudo-labels to participate in model training to achieve unknown class feature learning. Then, to improve the classification accuracy of both known and unknown classes, a homogeneous graph constraint is imposed on SSGCDCN to learn the relationship information among samples (including labeled and unlabeled samples). This constraint can bring the features of similar samples closer while pushing apart features of dissimilar samples. Experiments evaluated on three datasets demonstrate that the proposed method can obtain superior OSC performance than other state-of-the-art classification methods.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "5e9d90ff6b3b06ef592808a38a32cebadd9abd69", "publication_date": "2022", "title": "Open-Set Fault Diagnosis Method for Industrial Process Based on Semi-supervised Learning", "authors": "Jiaren Liu, Hong Song, Jianguo Wang", "venue": "International Conference on Intelligent Robotics and Applications", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "154bb63c2bdd660d86bdb07518e5bcd1740f85c3", "publication_date": "2022-08-01", "title": "CAPT: Contrastive Pre-Training based Semi-Supervised Open-Set Learning", "authors": "Zhuoyi Wang, Yibo Hu, L. Khan, Kevin W. Hamlen, B. Thuraisingham", "venue": "Conference on Multimedia Information Processing and Retrieval", "citation_count": 1, "influential_citation_count": 1, "abstract": "Deep Semi-Supervised Learning (SSL) has shown very effective performance in recent years, such methods are typically under assumptions of a closed-world setting, where instances in the labeled and unlabeled data share the same class set. However, in real-world applications, samples with novel classes may be contained in the unlabeled data during the model deployment (open-set scenario), i.e. new types of scene images may occur in a self-driving system. In this paper, we advocate a two-stage semi-supervised learning approach CAPT, a framework for handling this realistic sce-nario based on a self-supervised pre-training step. The key idea is to introduce the embedding from pre-training into the SSL open-set classifier, so that the model can recognize the seen classes and cluster the instances from novel categories simultaneously. Our framework first pre-train a semantically meaningful representation of all samples from the labeled and unlabeled dataset. Next, CAPT applies the learned embedding as initialization to build a semisupervised classifier for clustering novel classes. We thoroughly evaluate our framework on large-scale image benchmarks CIFAR10, CIFAR100, obtaining state-of-the-art results.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "4dc007686394c4e32e8a37ec480ae0e692222400", "publication_date": "2020-02-20", "title": "Multi-Task Curriculum Learning for Open-Set Semi-Supervised Recognition", "authors": "Yu Qing, Irie Go, Aizawa Kiyoharu", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "11da6c90c29fbb8ddff6eaeeea40212b6624c226", "publication_date": "2024-08-01", "title": "Open-Domain Semi-Supervised Learning via Glocal Cluster Structure Exploitation", "authors": "Zekun Li, Lei Qi, Yawen Li, Yinghuan Shi, Yang Gao", "venue": "IEEE Transactions on Knowledge and Data Engineering", "citation_count": 1, "influential_citation_count": 0, "abstract": "Semi-supervised learning (SSL) aims to reduce the heavy reliance of current deep models on costly manual annotation by leveraging a large amount of unlabeled data in combination with a much smaller set of labeled data. However, most existing SSL methods assume that all labeled and unlabeled data are drawn from the same feature distribution, which can be impractical in real-world applications. In this study, we take the initial step to systematically investigate the open-domain semi-supervised learning setting, where a feature distribution mismatch exists between labeled and unlabeled data. In pursuit of an effective solution for open-domain SSL, we propose a novel framework called GlocalMatch, which aims to exploit both global and local (i.e., glocal) cluster structure of open-domain unlabeled data. The glocal cluster structure is utilized in two complementary ways. First, GlocalMatch optimizes a Glocal Cluster Compacting (GCC) objective, that encourages feature representations of the same class, whether with in the same domain or across different domains, to become closer to each other. Second, GlocalMatch incorporates a Glocal Semantic Aggregation (GSA) strategy to produce more reliable pseudo-labels by aggregating predictions from neighboring clusters. Extensive experiments demonstrate that GlocalMatch outperforms the state-of-the-art SSL methods significantly, achieving superior performance for both in-domain and out-of-domain generalization.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "23784d956043af0c247d7e985f15be407a3edd68", "publication_date": "2023-11-06", "title": "A Graph-Theoretic Framework for Understanding Open-World Semi-Supervised Learning", "authors": "Yiyou Sun, Zhenmei Shi, Yixuan Li", "venue": "Neural Information Processing Systems", "citation_count": 23, "influential_citation_count": 1, "abstract": "Open-world semi-supervised learning aims at inferring both known and novel classes in unlabeled data, by harnessing prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for this problem. This paper bridges the gap by formalizing a graph-theoretic framework tailored for the open-world setting, where the clustering can be theoretically characterized by graph factorization. Our graph-theoretic framework illuminates practical algorithms and provides guarantees. In particular, based on our graph formulation, we apply the algorithm called Spectral Open-world Representation Learning (SORL), and show that minimizing our loss is equivalent to performing spectral decomposition on the graph. Such equivalence allows us to derive a provable error bound on the clustering performance for both known and novel classes, and analyze rigorously when labeled data helps. Empirically, SORL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.", "pdf_url": "https://arxiv.org/pdf/2311.03524.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-11-06_A_Graph-Theoretic_Framework_for_Understanding_Open-World_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2023-11-06_A_Graph-Theoretic_Framework_for_Understanding_Open-World_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "7dbb50f47fbd28929dba42af64d83a8ac9680532", "publication_date": "2025-05-28", "title": "SS-OPDet: A Semi-Supervised Open-Set Detection Framework for Dead Pine Wood Detection", "authors": "Xiaojian Lu, Shiguo Huang, Songqing Wu, Feiping Zhang, Mingqing Weng, Jianlong Luo, Xiaolin Li", "venue": "Italian National Conference on Sensors", "citation_count": 0, "influential_citation_count": 0, "abstract": "Pine wilt disease poses a significant threat to pine forests worldwide, necessitating efficient and accurate detection of dead pine wood for effective disease control and forest management. Traditional deep learning methods based on supervised closed-set paradigms often struggle to address unknown interfering objects, causing false positives, missed detection, and increased annotation burdens. To overcome these challenges, we propose SS-OPDet, a semi-supervised open-set detection framework that leverages a small amount of labeled data along with abundant unlabeled data. SS-OPDet integrates a Weighted Multi-scale Feature Fusion module to dynamically integrate global- and local-scale features, thereby significantly improving representational accuracy for dead pine wood. Additionally, a Dynamic Confidence Pseudo-Label Generation strategy categorizes predictions by confidence level, effectively reducing training noise and maximizing the use of reliable unlabeled data. Experimental results from 7733 UAV images demonstrate that SS-OPDet achieves an average precision (APK) of 84.73%, a recall (RK) of 94.48%, an Absolute Open-Set Error (AOSE) of 271 and a Wilderness Impact (WI) of 0.0917%. Cross-region validation further confirms the robustness and generalization capability of the proposed framework. The proposed method offers a cost-effective and accurate solution for timely detection of pine wilt disease, providing substantial benefits to forest monitoring and management.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "9fdd0407a09072ecf3a9fd90af492d3f391b589c", "publication_date": "2019", "title": "Operational classifier development using quasi-open set semi-supervised training and GANs", "authors": "E. Engelbrecht, J. D. Preez", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "b7706fad7960d0e4124969369dee02c2072e5207", "publication_date": "2023-12-01", "title": "Robust Semi-Supervised Learning for Self-learning Open-World Classes", "authors": "Wenjuan Xi, Xin Song, Weili Guo, Yang Yang", "venue": "Industrial Conference on Data Mining", "citation_count": 13, "influential_citation_count": 0, "abstract": "Existing semi-supervised learning (SSL) methods assume that labeled and unlabeled data share the same class space. However, in real-world applications, unlabeled data always contain classes not present in the labeled set, which may cause classification performance degradation of known classes. Therefore, open-world SSL approaches are researched to handle the presence of multiple unknown classes in the unlabeled data, which aims to accurately classify known classes while fine-grained distinguishing different unknown classes. To address this challenge, in this paper, we propose an open-world SSL method for Self-learning Open-world Classes (SSOC), which can explicitly self-learn multiple unknown classes. Specifically, SSOC first defines class center tokens for both known and unknown classes and autonomously learns token representations according to all samples with the cross-attention mechanism. To effectively discover novel classes, SSOC further designs a pairwise similarity loss in addition to the entropy loss, which can wisely exploit the information available in unlabeled data from instances\u2019 predictions and relationships. Extensive experiments demonstrate that SSOC outperforms the state-of-the-art baselines on multiple popular classification benchmarks. Specifically, on the ImageNet-100 dataset with a novel ratio of $90 \\%$, SSOC achieves a remarkable $16 \\%$ improvement.", "pdf_url": "https://arxiv.org/pdf/2401.07551.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-01_Robust_Semi-Supervised_Learning_for_Self-learning_Open-World_Classes.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-01_Robust_Semi-Supervised_Learning_for_Self-learning_Open-World_Classes.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "713aa6b019fb3cf277f88dcf71e34a196e76617c", "publication_date": "2022-07-05", "title": "OpenLDN: Learning to Discover Novel Classes for Open-World Semi-Supervised Learning", "authors": "Mamshad Nayeem Rizve, Navid Kardan, Salman H. Khan, F. Khan, M. Shah", "venue": "European Conference on Computer Vision", "citation_count": 50, "influential_citation_count": 6, "abstract": "Semi-supervised learning (SSL) is one of the dominant approaches to address the annotation bottleneck of supervised learning. Recent SSL methods can effectively leverage a large repository of unlabeled data to improve performance while relying on a small set of labeled data. One common assumption in most SSL methods is that the labeled and unlabeled data are from the same data distribution. However, this is hardly the case in many real-world scenarios, which limits their applicability. In this work, instead, we attempt to solve the challenging open-world SSL problem that does not make such an assumption. In the open-world SSL problem, the objective is to recognize samples of known classes, and simultaneously detect and cluster samples belonging to novel classes present in unlabeled data. This work introduces OpenLDN that utilizes a pairwise similarity loss to discover novel classes. Using a bi-level optimization rule this pairwise similarity loss exploits the information available in the labeled set to implicitly cluster novel class samples, while simultaneously recognizing samples from known classes. After discovering novel classes, OpenLDN transforms the open-world SSL problem into a standard SSL problem to achieve additional performance gains using existing SSL methods. Our extensive experiments demonstrate that OpenLDN outperforms the current state-of-the-art methods on multiple popular classification benchmarks while providing a better accuracy/training time trade-off.", "pdf_url": "https://arxiv.org/pdf/2207.02261.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-07-05_OpenLDN__Learning_to_Discover_Novel_Classes_for_Open-World_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2022-07-05_OpenLDN__Learning_to_Discover_Novel_Classes_for_Open-World_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "098d72267a1ad58b0a295c9bdb98a7b1719b06d9", "publication_date": "2021-03-17", "title": "SODA: Detecting COVID-19 in Chest X-Rays With Semi-Supervised Open Set Domain Adaptation", "authors": "Jieli Zhou, Baoyu Jing, Zeya Wang", "venue": "IEEE/ACM Transactions on Computational Biology & Bioinformatics", "citation_count": 42, "influential_citation_count": 1, "abstract": "Due to the shortage of COVID-19 viral testing kits, radiology imaging is used to complement the screening process. Deep learning based methods are promising in automatically detecting COVID-19 disease in chest x-ray images. Most of these works first train a Convolutional Neural Network (CNN) on an existing large-scale chest x-ray image dataset and then fine-tune the model on the newly collected COVID-19 chest x-ray dataset, often at a much smaller scale. However, simple fine-tuning may lead to poor performance for the CNN model due to two issues, first the large domain shift present in chest x-ray datasets and second the relatively small scale of the COVID-19 chest x-ray dataset. In an attempt to address these two important issues, we formulate the problem of COVID-19 chest x-ray image classification in a semi-supervised open set domain adaptation setting and propose a novel domain adaptation method, Semi-supervised Open set Domain Adversarial network (SODA). SODA is designed to align the data distributions across different domains in the general domain space and also in the common subspace of source and target data. In our experiments, SODA achieves a leading classification performance compared with recent state-of-the-art models in separating COVID-19 with common pneumonia. We also present initial results showing that SODA can produce better pathology localizations in the chest x-rays.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "8abda693d8223c3bc2f414a0291664cf484c7806", "publication_date": "2013-05-26", "title": "Open-set semi-supervised audio-visual speaker recognition using co-training LDA and Sparse Representation Classifiers", "authors": "Xuran Zhao, N. Evans, J. Dugelay", "venue": "IEEE International Conference on Acoustics, Speech, and Signal Processing", "citation_count": 2, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "b82ea48f183d1708229ead6ea820b55f4b3ef8e5", "publication_date": "2024-03-24", "title": "Unknown-Aware Graph Regularization for Robust Semi-supervised Learning from Uncurated Data", "authors": "Heejo Kong, Suneung Kim, Ho-Joong Kim, Seong-Whan Lee", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 2, "influential_citation_count": 0, "abstract": "Recent advances in semi-supervised learning (SSL) have relied on the optimistic assumption that labeled and unlabeled data share the same class distribution. However, this assumption is often violated in real-world scenarios, where unlabeled data may contain out-of-class samples. SSL with such uncurated unlabeled data leads training models to be corrupted. In this paper, we propose a robust SSL method for learning from uncurated real-world data within the context of open-set semi-supervised learning (OSSL). Unlike previous works that rely on feature similarity distance, our method exploits uncertainty in logits. By leveraging task-dependent predictions of logits, our method is capable of robust learning even in the presence of highly correlated outliers. Our key contribution is to present an unknown-aware graph regularization (UAG), a novel technique that enhances the performance of uncertainty-based OSSL frameworks. The technique addresses not only the conflict between training objectives for inliers and outliers but also the limitation of applying the same training rule for all outlier classes, which are existed on previous uncertainty-based approaches. Extensive experiments demonstrate that UAG surpasses state-of-the-art OSSL methods by a large margin across various protocols. Codes are available at https://github.com/heejokong/UAGreg.", "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/view/29227/30315", "pdf_filepath": "data/semantic/pdf_files/2024-03-24_Unknown-Aware_Graph_Regularization_for_Robust_Semi-supervised_Learning_from_Uncurated_Data.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-24_Unknown-Aware_Graph_Regularization_for_Robust_Semi-supervised_Learning_from_Uncurated_Data.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "919820e81a1123f5d99b84d42aaea56b1069b646", "publication_date": "2021-12-15", "title": "Semi-supervised Open-set Recognition of Radar Active Jamming", "authors": "Hao Li, Xueli Fang, Lei Zhang, Hui Kang, Wei Zhang", "venue": "Radar", "citation_count": 3, "influential_citation_count": 0, "abstract": "With the emergence of various kinds of complex radar jamming, radar jamming intelligent recognition technology has increasingly become the key to electronic counter-counter measures. To achieve radar jamming open-set recognition with a small number of tagged samples, Generative adversarial network-based pseudolabeled convolutional neural network (GAN-PL-CNN) model is proposed in this paper. Firstly, radar jamming is modelled, and the radar jamming datasets with known and unknown types are established after time-frequency transformation and image processing. Then, the adaptive pseudolabeling method is used to achieve semi-supervised recognition of radar jamming by combining the learning capability of convolutional neural networks and the characteristics of pseudolabeling to increase labeled samples intelligently. Finally, generative adversarial networks are introduced to enhance the recognition ability of the model and the discrimination ability of the unknown type through the game between the generator and the discriminator in the iterative process. Experimental results show that the GAN-PL-CNN model achieves 89.7%-95.1% for known types and 30.7%-86.8% for unknown types at 3%-6% labeling rate. As the number of labeled samples increases, the recognition effect becomes better and has a greater ability to exclude unknown type.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "35e7fce98f1d39e2c566ebe3555f5270bcd9d457", "publication_date": "2020-08-11", "title": "S2OSC: A Holistic Semi-Supervised Approach for Open Set Classification", "authors": "Yang Yang, Zhensheng Sun, Hui Xiong, Jian Yang", "venue": "ACM Transactions on Knowledge Discovery from Data", "citation_count": 23, "influential_citation_count": 0, "abstract": "Open set classification (OSC) tackles the problem of determining whether the data are in-class or out-of-class during inference, when only provided with a set of in-class examples at training time. Traditional OSC methods usually train discriminative or generative models with the owned in-class data, and then utilize the pre-trained models to classify test data directly. However, these methods always suffer from the embedding confusion problem, i.e., partial out-of-class instances are mixed with in-class ones of similar semantics, making it difficult to classify. To solve this problem, we unify semi-supervised learning to develop a novel OSC algorithm, S2OSC, which incorporates out-of-class instances filtering and model re-training in a transductive manner. In detail, given a pool of newly coming test data, S2OSC firstly filters the mostly distinct out-of-class instances using the pre-trained model, and annotates super-class for them. Then, S2OSC trains a holistic classification model by combing in-class and out-of-class labeled data with the remaining unlabeled test data in a semi-supervised paradigm. Furthermore, considering that data are usually in the streaming form in real applications, we extend S2OSC into an incremental update framework (I-S2OSC), and adopt a knowledge memory regularization to mitigate the catastrophic forgetting problem in incremental update. Despite the simplicity of proposed models, the experimental results show that S2OSC achieves state-of-the-art performance across a variety of OSC tasks, including 85.4% of F1 on CIFAR-10 with only 300 pseudo-labels. We also demonstrate how S2OSC can be expanded to incremental OSC setting effectively with streaming data.", "pdf_url": "https://arxiv.org/pdf/2008.04662.pdf", "pdf_filepath": "data/semantic/pdf_files/2020-08-11_S2OSC__A_Holistic_Semi-Supervised_Approach_for_Open_Set_Classification.pdf", "markdown_path": "data/semantic/markdown_files/2020-08-11_S2OSC__A_Holistic_Semi-Supervised_Approach_for_Open_Set_Classification.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "797ed8880d902c506bf82eac2940728abaae81fe", "publication_date": "2023-12-21", "title": "OWETC: Open world encrypted traffic classification based on semi-supervised class incremental learning", "authors": "Meng Zhao, Zhu Di, Zhe Xia, Jing Tian, Jianwen Xiang, Jun Lin", "venue": "2023 IEEE Intl Conf on Parallel & Distributed Processing with Applications, Big Data & Cloud Computing, Sustainable Computing & Communications, Social Computing & Networking (ISPA/BDCloud/SocialCom/SustainCom)", "citation_count": 1, "influential_citation_count": 0, "abstract": "To address the dynamic changes in network environments and effectively tackle the open-world traffic classification challenge, we introduce a novel approach. Conventional traffic classification methods are constrained by their reliance on closed traffic sets and offline training scenarios, limiting their ability to recognize a fixed number of traffic classes and identify unknown traffic types. Our solution involves a traffic classification method founded on a combination of semi-supervised class-incremental learning and open-set recognition. To mitigate the issue of catastrophic forgetting in class-incremental learning, we leverage a substantial amount of external unlabeled traffic data. Specifically, we employ a class anchor clustering loss classifier with a discriminator to select external unlabeled traffic data as replay samples. This approach effectively mitigates the problem of catastrophic forgetting in class-incremental learning. Furthermore, the class anchor clustering loss is employed for incremental model training, enabling the model to identify unknown traffic data. We validate the performance of the model on encrypted traffic classical datasets, and the experimental results show that our method significantly outperforms traffic classification models based on other incremental learning methods. In particular, OWETC has a 3.28% performance improvement in average accuracy over multiple incremental sessions compared to the best baseline. Additionally, our enhanced open-set sampler displays a notable 17% reduction in false alarm rates with only a minor 1% accuracy degradation, surpassing the capabilities of existing open-set recognition methods.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ff78249accc3233c4f99bd934ec04db5a1bd4f15", "publication_date": "2023-08-27", "title": "Semi-Supervised Learning in the Few-Shot Zero-Shot Scenario", "authors": "Noam Fluss, Guy Hacohen, D. Weinshall", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Semi-Supervised Learning (SSL) is a framework that utilizes both labeled and unlabeled data to enhance model performance. Conventional SSL methods operate under the assumption that labeled and unlabeled data share the same label space. However, in practical real-world scenarios, especially when the labeled training dataset is limited in size, some classes may be totally absent from the labeled set. To address this broader context, we propose a general approach to augment existing SSL methods, enabling them to effectively handle situations where certain classes are missing. This is achieved by introducing an additional term into their objective function, which penalizes the KL-divergence between the probability vectors of the true class frequencies and the inferred class frequencies. Our experimental results reveal significant improvements in accuracy when compared to state-of-the-art SSL, open-set SSL, and open-world SSL methods. We conducted these experiments on two benchmark image classification datasets, CIFAR-100 and STL-10, with the most remarkable improvements observed when the labeled data is severely limited, with only a few labeled examples per class", "pdf_url": "https://arxiv.org/pdf/2308.14119.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-08-27_Semi-Supervised_Learning_in_the_Few-Shot_Zero-Shot_Scenario.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-27_Semi-Supervised_Learning_in_the_Few-Shot_Zero-Shot_Scenario.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "3eb72040df8e0f336b14f3dcb1ddaaaad1d1ce36", "publication_date": "2023-11-14", "title": "A Study on Sonar Image Recognition based on Realistic Semi-Supervised Learning", "authors": "Sichen Lv, Hong Liang", "venue": "International Conference on Signal Processing, Communications and Computing", "citation_count": 0, "influential_citation_count": 0, "abstract": "The majority of existing work on sonar image recognition focuses on closed set, where system tends to make incorrect classifications when encountering unknown underwater targets. Therefore, the problem of sonar image recognition in open world scenario needs to be addressed. In this paper, we apply open world recognition algorithm architecture based on self-supervised learning to sonar image. After improving the feature extraction network to accommodate the characteristics of sonar image, we use three datasets of sonar image to validate the approach. By performing augmentation operations on the three datasets, the recognition network generates class distribution-aware pseudo-labels for the unlabeled data in the sonar datasets. These pseudo-labels are then used to supervise the learning process. Ultimately, the accuracy of all three sonar datasets exceeded 84%, surpassing the accuracy achieved on most fine-grained datasets. The result validates that our improved open world recognition algorithm based on semi-supervised learning for sonar image is effective.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "5db8ce783cc6960bfb2865a53f4202e63100139c", "publication_date": "2020-05-22", "title": "SODA: Detecting Covid-19 in Chest X-rays with Semi-supervised Open Set Domain Adaptation", "authors": "Jieli Zhou, Baoyu Jing, Zeya Wang", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Due to the shortage of COVID-19 viral testing kits and the long waiting time, radiology imaging is used to complement the screening process and triage patients into different risk levels. Deep learning based methods have taken an active role in automatically detecting COVID-19 disease in chest x-ray images, as witnessed in many recent works in early 2020. Most of these works first train a Convolutional Neural Network (CNN) on an existing large-scale chest x-ray image dataset and then fine-tune it with a COVID-19 dataset at a much smaller scale. However, direct transfer across datasets from different domains may lead to poor performance for CNN due to two issues, the large domain shift present in the biomedical imaging datasets and the extremely small scale of the COVID-19 chest x-ray dataset. In an attempt to address these two important issues, we formulate the problem of COVID-19 chest x-ray image classification in a semi-supervised open set domain adaptation setting and propose a novel domain adaptation method, Semi-supervised Open set Domain Adversarial network (SODA). SODA is able to align the data distributions across different domains in a general domain space and also in a common subspace of source and target data. In our experiments, SODA achieves a leading classification performance compared with recent state-of-the-art models in separating COVID-19 with common pneumonia. We also present initial results showing that SODA can produce better pathology localizations in the chest x-rays.", "pdf_url": "https://arxiv.org/pdf/2005.11003.pdf", "pdf_filepath": "data/semantic/pdf_files/2020-05-22_SODA__Detecting_Covid-19_in_Chest_X-rays_with_Semi-supervised_Open_Set_Domain_Adaptation.pdf", "markdown_path": "data/semantic/markdown_files/2020-05-22_SODA__Detecting_Covid-19_in_Chest_X-rays_with_Semi-supervised_Open_Set_Domain_Adaptation.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "fcc4cdeb322edf38d2dce221b601a44202eb5b11", "publication_date": "2020-12-08", "title": "Semi-supervised learning with an open augmenting unknown class for cost-effective training and reliable classifications.", "authors": "E. Engelbrecht, J. D. Preez", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "69be09f45a34d11f5cc53f588c883e9bea539456", "publication_date": "2021-06-10", "title": "DASO: Distribution-Aware Semantics-Oriented Pseudo-label for Imbalanced Semi-Supervised Learning", "authors": "Youngtaek Oh, Dong-Jin Kim, In-So Kweon", "venue": "Computer Vision and Pattern Recognition", "citation_count": 64, "influential_citation_count": 18, "abstract": "The capability of the traditional semi-supervised learning (SSL) methods is far from real-world application due to severely biased pseudo-labels caused by (1) class imbalance and (2) class distribution mismatch between labeled and unlabeled data. This paper addresses such a relatively under-explored problem. First, we propose a general pseudo-labeling framework that class-adaptively blends the semantic pseudo-label from a similarity-based classifier to the linear one from the linear classifier, after making the observation that both types of pseudo-labels have complementary properties in terms of bias. We further introduce a novel semantic alignment loss to establish balanced feature representation to reduce the biased predictions from the classifier. We term the whole framework as Distribution-Aware Semantics-Oriented (DASO) Pseudo-label. We conduct extensive experiments in a wide range of imbalanced benchmarks: CIFAR10/100-LT, STL10-LT, and large-scale long-tailed Semi-Aves with open-set class, and demonstrate that, the proposed DASO framework reliably improves SSL learners with unlabeled data especially when both (1) class imbalance and (2) distribution mismatch dominate.", "pdf_url": "https://arxiv.org/pdf/2106.05682.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-06-10_DASO__Distribution-Aware_Semantics-Oriented_Pseudo-label_for_Imbalanced_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2021-06-10_DASO__Distribution-Aware_Semantics-Oriented_Pseudo-label_for_Imbalanced_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "bef2153c209fee21a71a82bdba342657011b43b7", "publication_date": "2021-08-13", "title": "Progressive Representative Labeling for Deep Semi-Supervised Learning", "authors": "Xiaopeng Yan, Riquan Chen, Litong Feng, Jingkang Yang, Huabin Zheng, Wayne Zhang", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Deep semi-supervised learning (SSL) has experienced significant attention in recent years, to leverage a huge amount of unlabeled data to improve the performance of deep learning with limited labeled data. Pseudo-labeling is a popular approach to expand the labeled dataset. However, whether there is a more effective way of labeling remains an open problem. In this paper, we propose to label only the most representative samples to expand the labeled set. Representative samples, selected by indegree of corresponding nodes on a directed k-nearest neighbor (kNN) graph, lie in the k-nearest neighborhood of many other samples. We design a graph neural network (GNN) labeler to label them in a progressive learning manner. Aided by the progressive GNN labeler, our deep SSL approach outperforms state-of-the-art methods on several popular SSL benchmarks including CIFAR-10, SVHN, and ILSVRC-2012. Notably, we achieve 72.1% top-1 accuracy, surpassing the previous best result by 3.3%, on the challenging ImageNet benchmark with only $10\\%$ labeled data.", "pdf_url": "https://arxiv.org/pdf/2108.06070.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-08-13_Progressive_Representative_Labeling_for_Deep_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2021-08-13_Progressive_Representative_Labeling_for_Deep_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "1ac05a08365557e5dbf284bc7457c4d56031848c", "publication_date": "2022-11-17", "title": "Contrastive Credibility Propagation for Reliable Semi-Supervised Learning", "authors": "Brody Kutt, P. Toman, Xavier Mignot, Sujit Rokka Chhetri, Shan Huang, Nandini Ramanan, Min Du, W. Hewlett", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 0, "influential_citation_count": 0, "abstract": "Producing labels for unlabeled data is error-prone, making semi-supervised learning (SSL) troublesome. Often, little is known about when and why an algorithm fails to outperform a supervised baseline. Using benchmark datasets, we craft five common real-world SSL data scenarios: few-label, open-set, noisy-label, and class distribution imbalance/misalignment in the labeled and unlabeled sets. We propose a novel algorithm called Contrastive Credibility Propagation (CCP) for deep SSL via iterative transductive pseudo-label refinement. CCP unifies semi-supervised learning and noisy label learning for the goal of reliably outperforming a supervised baseline in any data scenario. Compared to prior methods which focus on a subset of scenarios, CCP uniquely outperforms the supervised baseline in all scenarios, supporting practitioners when the qualities of labeled or unlabeled data are unknown.", "pdf_url": "https://arxiv.org/pdf/2211.09929.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-11-17_Contrastive_Credibility_Propagation_for_Reliable_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2022-11-17_Contrastive_Credibility_Propagation_for_Reliable_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "8e10a391605da43d211f490e7eeedb3934acd76a", "publication_date": "2021", "title": "Universal Semi-Supervised Learning", "authors": "Zhuo Huang, Chao Xue, Bo Han, Jian Yang, Chen Gong", "venue": "Neural Information Processing Systems", "citation_count": 48, "influential_citation_count": 9, "abstract": null, "pdf_url": "https://proceedings.neurips.cc/paper_files/paper/2021/file/e06f967fb0d355592be4e7674fa31d26-Paper.pdf", "pdf_filepath": "data/semantic/pdf_files/2021_Universal_Semi-Supervised_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2021_Universal_Semi-Supervised_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "9d97041fb36e950ccb0679bada9e9cd8e72655af", "publication_date": "2023-05-22", "title": "Open-world Semi-supervised Novel Class Discovery", "authors": "Jiaming Liu, Yangqiming Wang, Tongze Zhang, Yulu Fan, Qinli Yang, Junming Shao", "venue": "International Joint Conference on Artificial Intelligence", "citation_count": 18, "influential_citation_count": 2, "abstract": "Traditional semi-supervised learning tasks assume that both labeled and unlabeled data follow the same class distribution, but the realistic open-world scenarios are of more complexity with unknown novel classes mixed in the unlabeled set. Therefore, it is of great challenge to not only recognize samples from known classes but also discover the unknown number of novel classes within the unlabeled data. In this paper, we introduce a new open-world semi-supervised novel class discovery approach named OpenNCD, a progressive bi-level contrastive learning method over multiple prototypes. The proposed method is composed of two reciprocally enhanced parts. First, a bi-level contrastive learning method is introduced, which maintains the pair-wise similarity of the prototypes and the prototype group levels for better representation learning. Then, a reliable prototype similarity metric is proposed based on the common representing instances. Prototypes with high similarities will be grouped progressively for known class recognition and novel class discovery. Extensive experiments on three image datasets are conducted and the results show the effectiveness of the proposed method in open-world scenarios, especially with scarce known classes and labels.", "pdf_url": "https://arxiv.org/pdf/2305.13095.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-05-22_Open-world_Semi-supervised_Novel_Class_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-05-22_Open-world_Semi-supervised_Novel_Class_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "76b9d2931374d060ab55b220af51bffc10479432", "publication_date": "2023", "title": "RIGNN: A Rationale Perspective for Semi-supervised Open-world Graph Classification", "authors": "Xiao Luo, Yusheng Zhao, Zhengyan Mao, Yifang Qin, Wei Ju, Ming Zhang, Yizhou Sun", "venue": "Trans. Mach. Learn. Res.", "citation_count": 10, "influential_citation_count": 0, "abstract": null, "pdf_url": "https://openreview.net/pdf?id=qcCE4mC2jI", "pdf_filepath": "data/semantic/pdf_files/2023_RIGNN__A_Rationale_Perspective_for_Semi-supervised_Open-world_Graph_Classification.pdf", "markdown_path": "data/semantic/markdown_files/2023_RIGNN__A_Rationale_Perspective_for_Semi-supervised_Open-world_Graph_Classification.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "70d6372d91afb38048e520afba394793fff834e8", "publication_date": "2023-07-28", "title": "Generalized Open-World Semi-Supervised Object Detection", "authors": "Garvita Allabadi, Ana Lucic, Peter Pao-Huang, Yu-Xiong Wang, Vikram S. Adve", "venue": "", "citation_count": 1, "influential_citation_count": 1, "abstract": "Traditional semi-supervised object detection methods assume a fixed set of object classes (in-distribution or ID classes) during training and deployment, which limits performance in real-world scenarios where unseen classes (out-of-distribution or OOD classes) may appear. In such cases, OOD data is often misclassified as ID, thus harming the ID classes accuracy. Open-set methods address this limitation by filtering OOD data to improve ID performance, thereby limiting the learning process to ID classes. We extend this to a more natural open-world setting, where the OOD classes are not only detected but also incorporated into the learning process. Specifically, we explore two key questions: 1) how to accurately detect OOD samples, and, most importantly, 2) how to effectively learn from the OOD samples in a semi-supervised object detection pipeline without compromising ID accuracy. To address this, we introduce an ensemble-based OOD Explorer for detection and classification, and an adaptable semi-supervised object detection framework that integrates both ID and OOD data. Through extensive evaluation on different open-world scenarios, we demonstrate that our method performs competitively against state-of-the-art OOD detection algorithms and also significantly boosts the semi-supervised learning performance for both ID and OOD classes.", "pdf_url": "https://arxiv.org/pdf/2307.15710.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-07-28_Generalized_Open-World_Semi-Supervised_Object_Detection.pdf", "markdown_path": "data/semantic/markdown_files/2023-07-28_Generalized_Open-World_Semi-Supervised_Object_Detection.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "9c5b8f2fe4a75500a02c24c2dd45375271439448", "publication_date": "2024-07-10", "title": "A Guide To Effectively Leveraging LLMs for Low-Resource Text Summarization: Data Augmentation and Semi-supervised Approaches", "authors": "Gaurav Sahu, Olga Vechtomova, I. Laradji", "venue": "North American Chapter of the Association for Computational Linguistics", "citation_count": 2, "influential_citation_count": 0, "abstract": "Existing approaches for low-resource text summarization primarily employ large language models (LLMs) like GPT-3 or GPT-4 at inference time to generate summaries directly; however, such approaches often suffer from inconsistent LLM outputs and are difficult to adapt to domain-specific data in low-resource scenarios. In this work, we propose two novel methods to effectively utilize LLMs for low-resource text summarization: 1) MixSumm, an LLM-based data augmentation regime that synthesizes high-quality documents (short and long) for few-shot text summarization, and 2) PPSL, a prompt-based pseudolabeling strategy for sample-efficient semi-supervised text summarization. Specifically, MixSumm leverages the open-source LLaMA-3-70b-Instruct model to generate new documents by mixing topical information derived from a small seed set, and PPSL leverages the LLaMA-3-70b-Instruct model to generate high-quality pseudo-labels in a semi-supervised learning setup. We evaluate our methods on the TweetSumm, WikiHow, and ArXiv/PubMed datasets and use L-Eval, a LLaMA-3-based evaluation metric, and ROUGE scores to measure the quality of generated summaries. Our experiments on extractive and abstractive summarization show that MixSumm and PPSL achieve competitive ROUGE scores as a fully supervised method with 5% of the labeled data.", "pdf_url": "https://arxiv.org/pdf/2407.07341.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-07-10_A_Guide_To_Effectively_Leveraging_LLMs_for_Low-Resource_Text_Summarization__Data_Augmentation_and_Se.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-10_A_Guide_To_Effectively_Leveraging_LLMs_for_Low-Resource_Text_Summarization__Data_Augmentation_and_Se.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "b8d8a9a318689bcc74524cc5b3ef869ee18210f5", "publication_date": "2020", "title": "Semi-Supervised Learning of Protein Secondary Structure from Single Sequences", "authors": "Lewis Moffat, David T. Jones", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "b5c9debfabc04bd0633696a89e9a52772881354a", "publication_date": "2024-12-08", "title": "Generative Representation and Discriminative Classification for Few-shot Open-set Object Detection", "authors": "Peixue Shen, Ruoqing Li, Yan Luo, Yiru Zhao, Chao Gao, Chongyang Zhang", "venue": "Visual Communications and Image Processing", "citation_count": 0, "influential_citation_count": 0, "abstract": "Open-Set Object Detection (OSOD) aims to train detectors on closed-set datasets to detect known objects and identify unknown objects in open-set conditions. Traditional discriminative classifier-based OSOD methods struggle to accurately learn the decision boundary between known and unknown classes, often resulting in the misclassification of unknown samples. In this work, we aim to combine generative representation with discriminative classification to alleviate the issue of misclassification by transforming known-unknown recognition into a binary classification problem. The proposed two-stage OSOD approach proceeds as follows: during the generative representation stage, we employ Class-Conditioned Normalizing Flow (CCNF) to establish distribution mapping for each known category; In the discriminative classification stage, by utilizing a small number of unknown class samples, semi-push-pull supervised learning and entropy contrast learning are used to separate known and unknown classes. Extensive experiments demonstrate that our method significantly enhances OSOD performance, evidenced by a 25.8%-28.6% reduction in the Wilderness Index and a decrease of 4391-8870 units in Absolute Open-Set Errors on the test set VOC-COCO-T1.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "5920712345b0781fb798577e6502b451b030cc38", "publication_date": "2022-09-18", "title": "Online Learning of Open-set Speaker Identification by Active User-registration", "authors": "Eunkyung Yoo, H. Song, Taehyeong Kim, Chul Lee", "venue": "Interspeech", "citation_count": 1, "influential_citation_count": 0, "abstract": "Registering each user\u2019s identity for voice assistants is bur-densome and complex for multi-user environments like a household scenario. This is particularly true when the registration needs to happen on-the-fly with a relatively minimum effort. Most of the prior works for speaker identification (SID) do not seamlessly allow the addition of new speakers as these do not support online updates. To deal with such limitation, we introduce a novel online learning approach to open-set SID that can actively register unknown users in the household setting. Based on MPART (Message Passing Adaptive Resonance Theory), our method performs online active semi-supervised learning for open-set SID by using speaking embedding vectors to infer new speakers and request user\u2019s identity. Our method progressively improves the overall SID performance without forgetting, making it attractive for many interactive real-world applications. We evaluate our model for the online learning setting of an open-set SID task where new speakers are added on-the-fly, demonstrating its superior performance.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "2a3626722de69ece429b36c9c340ed0eb22775d7", "publication_date": "2024-02-07", "title": "Semi-Supervised Implicit Augmentation for Data-Scarce VQA", "authors": "Kuan-Chuan Peng, Abhishek Aich, Ziyan Wu, Bhargav Dodla, Kartik Hegde, A. N. Rajagopalan", "venue": "The 2nd AAAI Workshop on Artificial Intelligence with Biased or Scarce Data (AIBSD)", "citation_count": 1, "influential_citation_count": 0, "abstract": ": Vision-language models (VLMs) have demonstrated increasing potency in solving complex vision-language tasks in the recent past. Visual question answering (VQA) is one of the primary downstream tasks for assessing the capability of VLMs, as it helps in gauging the multimodal understanding of a VLM in answering open-ended questions. The vast contextual information learned during the pretraining stage in VLMs can be utilised effectively to finetune the VQA model for specific datasets. In particular, special types of VQA datasets, such as OK-VQA, A-OKVQA (outside knowledge-based), and ArtVQA (domain-specific), have a relatively smaller number of images and corresponding question-answer annotations in the training set. Such datasets can be categorised as data-scarce. This hinders the effective learning of VLMs due to the low information availability. We introduce SemIAug ( Sem i-Supervised I mplicit Aug mentation), a model and dataset agnostic strategy specially designed to address the challenges faced by limited data availability in the domain-specific VQA datasets. SemIAug uses the annotated image-question data present within the chosen dataset and augments it with meaningful new image-question associations. We show that SemIAug improves the VQA performance on data-scarce datasets without the need for additional data or labels.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "1adf37f34c8d8bdc99fca75b95fdcef5c8aaa580", "publication_date": "2024-12-28", "title": "SimLTD: Simple Supervised and Semi-Supervised Long-Tailed Object Detection", "authors": "Phi Vu Tran", "venue": "arXiv.org", "citation_count": 0, "influential_citation_count": 0, "abstract": "While modern visual recognition systems have made significant advancements, many continue to struggle with the open problem of learning from few exemplars. This paper focuses on the task of object detection in the setting where object classes follow a natural long-tailed distribution. Existing methods for long-tailed detection resort to external ImageNet labels to augment the low-shot training instances. However, such dependency on a large labeled database has limited utility in practical scenarios. We propose a versatile and scalable approach to leverage optional unlabeled images, which are easy to collect without the burden of human annotations. Our SimLTD framework is straightforward and intuitive, and consists of three simple steps: (1) pre-training on abundant head classes; (2) transfer learning on scarce tail classes; and (3) fine-tuning on a sampled set of both head and tail classes. Our approach can be viewed as an improved head-to-tail model transfer paradigm without the added complexities of meta-learning or knowledge distillation, as was required in past research. By harnessing supplementary unlabeled images, without extra image labels, SimLTD establishes new record results on the challenging LVIS v1 benchmark across both supervised and semi-supervised settings.", "pdf_url": "https://arxiv.org/pdf/2412.20047.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-28_SimLTD__Simple_Supervised_and_Semi-Supervised_Long-Tailed_Object_Detection.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-28_SimLTD__Simple_Supervised_and_Semi-Supervised_Long-Tailed_Object_Detection.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "1c045e1197f22adde314e724f06700d2ac5d968b", "publication_date": "2020-08-01", "title": "Dynamic Android Malware Category Classification using Semi-Supervised Deep Learning", "authors": "Samaneh Mahdavifar, A. A. Kadir, Rasool Fatemi, Dima Alhadidi, A. Ghorbani", "venue": "2020 IEEE Intl Conf on Dependable, Autonomic and Secure Computing, Intl Conf on Pervasive Intelligence and Computing, Intl Conf on Cloud and Big Data Computing, Intl Conf on Cyber Science and Technology Congress (DASC/PiCom/CBDCom/CyberSciTech)", "citation_count": 178, "influential_citation_count": 18, "abstract": "Due to the significant threat of Android mobile malware, its detection has become increasingly important. Despite the academic and industrial attempts, devising a robust and efficient solution for Android malware detection and category classification is still an open problem. Supervised machine learning has been used to solve this issue. However, it is far to be perfect because it requires a significant amount of malicious and benign code to be identified and labeled beforehand. Since labeled data is expensive and difficult to get while unlabeled data is abundant and cheap in this context, we resort to a semi-supervised learning technique for deep neural networks, namely pseudo-label, which we train using a set of labeled and unlabeled instances. We use dynamic analysis to craft dynamic behavior profiles as feature vectors. Furthermore, we develop a new dataset, namely CICMalDroid2020, which includes 17,341 most recent samples of five different Android apps categories: Adware, Banking, SMS, Riskware, and Benign. Our offered dataset comprises the most complete captured static and dynamic features among publicly available datasets. We evaluate our proposed model on CICMalDroid2020 and conduct a comparison with Label Propagation (LP), a well-known semi-supervised machine learning technique, and other common machine learning algorithms. The experimental results show that the model can classify Android apps with respect to malware category with F1-Score of 97.84 percent and a false positive rate of 2.76 percent, considerably higher than LP. These results demonstrate the robustness of our model despite the small number of labeled instances.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "a096aed889737167920e9f718702a5bda8b73fb3", "publication_date": "2019", "title": "Building High Resolution Maps for Humanitarian Aid and Development with Weakly- and Semi-Supervised Learning", "authors": "Derrick Bonafilia, J. Gill, Saikat Basu, David Yang", "venue": "CVPR Workshops", "citation_count": 37, "influential_citation_count": 2, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "e44d333323b2cce56cb50a0ee09a481f34f67fae", "publication_date": "2023-10-26", "title": "Semi-Supervised Panoptic Narrative Grounding", "authors": "Danni Yang, Jiayi Ji, Xiaoshuai Sun, Haowei Wang, Yinan Li, Yiwei Ma, Rongrong Ji", "venue": "ACM Multimedia", "citation_count": 5, "influential_citation_count": 1, "abstract": "Despite considerable progress, the advancement of Panoptic Narrative Grounding (PNG) remains hindered by costly annotations. In this paper, we introduce a novel Semi-Supervised Panoptic Narrative Grounding (SS-PNG) learning scheme, capitalizing on a smaller set of labeled image-text pairs and a larger set of unlabeled pairs to achieve competitive performance. Unlike visual segmentation tasks, PNG involves one pixel belonging to multiple open-ended nouns. As a result, existing multi-class based semi-supervised segmentation frameworks cannot be directly applied to this task. To address this challenge, we first develop a novel SS-PNG Network (SS-PNG-NW) tailored to the SS-PNG setting. We thoroughly investigate strategies such as Burn-In and data augmentation to determine the optimal generic configuration for the SS-PNG-NW. Additionally, to tackle the issue of imbalanced pseudo-label quality, we propose a Quality-Based Loss Adjustment (QLA) approach to adjust the semi-supervised objective, resulting in an enhanced SS-PNG-NW+. Employing our proposed QLA, we improve BCE Loss and Dice loss at pixel and mask levels, respectively. We conduct extensive experiments on PNG datasets, with our SS-PNG-NW+ demonstrating promising results comparable to fully-supervised models across all data ratios. Remarkably, our SS-PNG-NW+ outperforms fully-supervised models with only 30% and 50% supervision data, exceeding their performance by 0.8% and 1.1% respectively. This highlights the effectiveness of our proposed SS-PNG-NW+ in overcoming the challenges posed by limited annotations and enhancing the applicability of PNG tasks. The source code is available at https://github.com/nini0919/SSPNG.", "pdf_url": "https://arxiv.org/pdf/2310.18142.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-10-26_Semi-Supervised_Panoptic_Narrative_Grounding.pdf", "markdown_path": "data/semantic/markdown_files/2023-10-26_Semi-Supervised_Panoptic_Narrative_Grounding.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "2d3e9f727e61196a36b1ef186313d6d3ac26d4a2", "publication_date": "2023", "title": "SMC-NCA: Semantic-guided Multi-level Contrast for Semi-supervised Action Segmentation", "authors": "Feixiang Zhou, Zheheng Jiang, Huiyu Zhou, Xuelong Li", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "\u2014Semi-supervised action segmentation aims to perform frame-wise classification in long untrimmed videos, where only a fraction of videos in the training set have labels. Recent studies have shown the potential of contrastive learning in unsupervised representation learning using unlabelled data. However, learning the representation of each frame by unsupervised contrastive learning for action segmentation remains an open and challenging problem. In this paper, we propose a novel Semantic-guided Multi-level Contrast scheme with a Neighbourhood-Consistency-Aware unit (SMC-NCA) to extract strong frame-wise representations for semi-supervised action segmentation. Specifically, for representation learning, SMC is firstly used to explore intra-and inter-information variations in a unified and contrastive way, based on dynamic clustering process of the original input, encoded semantic and temporal features. Then, the NCA module, which is responsible for enforcing spatial consistency between neighbourhoods centered at different frames to alleviate over-segmentation issues, works alongside SMC for semi-supervised learning. Our SMC outperforms the other state-of-the-art methods on three benchmarks, offering improvements of up to 17.8 % and 12.6 % in terms of edit distance and accuracy, respectively. Additionally, the NCA unit results in significant better segmentation performance against the others in the presence of only 5 % labelled videos. We also demonstrate the effectiveness of the proposed method on our Parkinson\u2019s Disease Mouse Behaviour (PDMB) dataset. The code and datasets will be made publicly available.", "pdf_url": "https://arxiv.org/abs/2312.12347/pdf/2312.12347", "pdf_filepath": "data/semantic/pdf_files/2023_SMC-NCA__Semantic-guided_Multi-level_Contrast_for_Semi-supervised_Action_Segmentation.pdf", "markdown_path": "data/semantic/markdown_files/2023_SMC-NCA__Semantic-guided_Multi-level_Contrast_for_Semi-supervised_Action_Segmentation.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "567423fddc5f23bdde31b463823f2329d82a9c83", "publication_date": "2023-12-19", "title": "SMC-NCA: Semantic-Guided Multi-Level Contrast for Semi-Supervised Temporal Action Segmentation", "authors": "Feixiang Zhou, Zheheng Jiang, Huiyu Zhou, Xuelong Li", "venue": "IEEE transactions on multimedia", "citation_count": 0, "influential_citation_count": 0, "abstract": "Semi-supervised temporal action segmentation (SS-TAS) aims to perform frame-wise classification in long untrimmed videos, where only a fraction of videos in the training set have labels. Recent studies have shown the potential of contrastive learning in unsupervised representation learning using unlabelled data. However, learning the representation of each frame by unsupervised contrastive learning for action segmentation remains an open and challenging problem. In this paper, we propose a novel Semantic-guided Multi-level Contrast scheme with a Neighbourhood-Consistency-Aware unit (SMC-NCA) to extract strong frame-wise representations for SS-TAS. Specifically, for representation learning, SMC is first used to explore intra- and inter-information variations in a unified and contrastive way, based on action-specific semantic information and temporal information highlighting relations between actions. Then, the NCA module, which is responsible for enforcing spatial consistency between neighbourhoods centered at different frames to alleviate over-segmentation issues, works alongside SMC for semi-supervised learning (SSL). Our SMC outperforms the other state-of-the-art methods on three benchmarks, offering improvements of up to 17.8<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> and 12.6<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> in terms of Edit distance and accuracy, respectively. Additionally, the NCA unit results in significantly better segmentation performance in the presence of only 5<inline-formula><tex-math notation=\"LaTeX\">$\\%$</tex-math></inline-formula> labelled videos. We also demonstrate the generalizability and effectiveness of the proposed method on our Parkinson's Disease Mouse Behaviour (PDMB) dataset.", "pdf_url": "https://arxiv.org/pdf/2312.12347.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-19_SMC-NCA__Semantic-Guided_Multi-Level_Contrast_for_Semi-Supervised_Temporal_Action_Segmentation.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-19_SMC-NCA__Semantic-Guided_Multi-Level_Contrast_for_Semi-Supervised_Temporal_Action_Segmentation.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "62d431d28eef05fc8c94b293ccb8e068b729e178", "publication_date": "2021-10-23", "title": "A semi-supervised approach to dark matter searches in direct detection data with machine learning", "authors": "J. Herrero-Garc\u00eda, Riley Patrick, A. Scaffidi", "venue": "Journal of Cosmology and Astroparticle Physics", "citation_count": 15, "influential_citation_count": 0, "abstract": "The dark matter sector remains completely unknown. It is therefore crucial to keep an open mind regarding its nature and possible interactions. Focusing on the case of Weakly Interacting Massive Particles, in this work we make this general philosophy more concrete by applying modern machine learning techniques to dark matter direct detection. We do this by encoding and decoding the graphical representation of background events in the XENONnT experiment with a convolutional variational autoencoder. We describe a methodology that utilizes the `anomaly score' derived from the reconstruction loss of the convolutional variational autoencoder as well as a pre-trained standard convolutional neural network, in a semi-supervised fashion. Indeed, we observe that optimum results are obtained only when both unsupervised and supervised anomaly scores are considered together. A data set that has a higher proportion of anomaly score is deemed anomalous and deserves further investigation. Contrary to classical analyses, in principle all information about the events is used, preventing unnecessary information loss. Lastly, we demonstrate the reach of learning-focused anomaly detection in this context by comparing results with classical inference, observing that, if tuned properly, these techniques have the potential to outperform likelihood-based methods.", "pdf_url": "https://arxiv.org/pdf/2110.12248.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-10-23_A_semi-supervised_approach_to_dark_matter_searches_in_direct_detection_data_with_machine_learning.pdf", "markdown_path": "data/semantic/markdown_files/2021-10-23_A_semi-supervised_approach_to_dark_matter_searches_in_direct_detection_data_with_machine_learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "18d522c3d97587d82539b97df3a584aee88c941f", "publication_date": "2016-10-08", "title": "Efficient and Robust Semi-supervised Learning Over a Sparse-Regularized Graph", "authors": "Hang Su, Jun Zhu, Zhaozheng Yin, Yinpeng Dong, Bo Zhang", "venue": "European Conference on Computer Vision", "citation_count": 4, "influential_citation_count": 0, "abstract": null, "pdf_url": "https://link.springer.com/content/pdf/10.1007/978-3-319-46484-8_35.pdf?pdf=inline%20link", "pdf_filepath": "data/semantic/pdf_files/2016-10-08_Efficient_and_Robust_Semi-supervised_Learning_Over_a_Sparse-Regularized_Graph.pdf", "markdown_path": "data/semantic/markdown_files/2016-10-08_Efficient_and_Robust_Semi-supervised_Learning_Over_a_Sparse-Regularized_Graph.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "fd6b6f5e6939e7234f29c1163107408fd051b35a", "publication_date": "2025-04-11", "title": "Int*-Match: Balancing Intra-Class Compactness and Inter-Class Discrepancy for Semi-Supervised Speaker Recognition", "authors": "Xingmei Wang, Jinghan Liu, Jiaxiang Meng, Boquan Li, Zijian Liu", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 0, "influential_citation_count": 0, "abstract": "Open-set speaker recognition is to identify whether the voices are from the same speaker. One challenge of speaker recognition is collecting large amounts of high-quality data. Based on the promising results of image classification, one intuitively feasible solution is semi-supervised learning (SSL) which uses confidence thresholds to assign pseudo labels for unlabeled data. However, we empirically demonstrated that applying SSL methods to speaker recognition is non-trivial. These methods focus solely on inter-class discrepancy as thresholds to select pseudo labels, overlooking intra-class compactness, which is particularly important for open-set speaker recognition tasks. Motivated by this, we propose Int*-Match, a semi-supervised speaker recognition method selecting reliable pseudo labels with intra-class compactness and inter-class discrepancy for speaker recognition. In particular, we use the inter-class discrepancy of labeled data as the threshold for pseudo-label selection and adjust the threshold based on the intra-class compactness of the pseudo labels dynamically and adaptively. Our systematic experiments demonstrate the superiority of Int*-Match, presenting an outstanding Equal Error Rate (EER) of 1.00% on the VoxCeleb1 original test set, which is merely 0.06% below the performance achieved by fully supervised learning.", "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/view/34729/36884", "pdf_filepath": "data/semantic/pdf_files/2025-04-11_Int_-Match__Balancing_Intra-Class_Compactness_and_Inter-Class_Discrepancy_for_Semi-Supervised_Speake.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-11_Int_-Match__Balancing_Intra-Class_Compactness_and_Inter-Class_Discrepancy_for_Semi-Supervised_Speake.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "63a1f67c57e83974b34135902901cb169d2e8195", "publication_date": "2025-04-11", "title": "Towards Realistic Semi-supervised Medical Image Classification", "authors": "Wenxue Li, Lie Ju, Feilong Tang, Peng Xia, Xinyu Xiong, Ming Hu, Lei Zhu, Zongyuan Ge", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 0, "influential_citation_count": 0, "abstract": "Existing semi-supervised learning (SSL) approaches follow the idealized closed-world assumption, neglecting the challenges present in realistic medical scenarios, such as open-set distribution and imbalanced class distribution. Although some methods in natural domains attempt to address the open-set problem, they are insufficient for medical domains, where intertwined challenges like class imbalance and small inter-class lesion discrepancies persist. Thus, this paper presents a novel self-recalibrated semantic training framework, which is tailored for SSL in medical imaging by ingeniously harvesting realistic unlabeled samples. Inspired by the observation that certain open-set samples share some similar disease-related representations with in-distribution samples, we first propose an informative sample selection strategy that identifies high-value samples to serve as augmentations, thereby effectively enriching the semantics of known categories. Furthermore, we adopt a compact semantic clustering strategy to address the semantic confusion raised by the above newly introduced open-set semantics. Moreover, to mitigate the interference of class imbalance in open-set SSL, we introduce a less biased dual-balanced classifier with similarity pseudo-label regularization and category-customized regularization. Extensive experiments on a variety of medical image datasets demonstrate the superior performance of our proposed method over state-of-the-art Closed-set and Open-set SSL methods.", "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/view/32526/34681", "pdf_filepath": "data/semantic/pdf_files/2025-04-11_Towards_Realistic_Semi-supervised_Medical_Image_Classification.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-11_Towards_Realistic_Semi-supervised_Medical_Image_Classification.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "fb1ecd47eb3429f8e62b4a29d08280217bfb221b", "publication_date": "2025-02-19", "title": "Semi-supervised classification of bird vocalizations", "authors": "Simen Hexeberg, M. Chitre, M. Hoffmann\u2010Kuhnt, Bing Wen Low", "venue": "arXiv.org", "citation_count": 0, "influential_citation_count": 0, "abstract": "Changes in bird populations can indicate broader changes in ecosystems, making birds one of the most important animal groups to monitor. Combining machine learning and passive acoustics enables continuous monitoring over extended periods without direct human involvement. However, most existing techniques require extensive expert-labeled datasets for training and cannot easily detect time-overlapping calls in busy soundscapes. We propose a semi-supervised acoustic bird detector designed to allow both the detection of time-overlapping calls (when separated in frequency) and the use of few labeled training samples. The classifier is trained and evaluated on a combination of community-recorded open-source data and long-duration soundscape recordings from Singapore. It achieves a mean F0.5 score of 0.701 across 315 classes from 110 bird species on a hold-out test set, with an average of 11 labeled training samples per class. It outperforms the state-of-the-art BirdNET classifier on a test set of 103 bird species despite significantly fewer labeled training samples. The detector is further tested on 144 microphone-hours of continuous soundscape data. The rich soundscape in Singapore makes suppression of false positives a challenge on raw, continuous data streams. Nevertheless, we demonstrate that achieving high precision in such environments with minimal labeled training data is possible.", "pdf_url": "https://arxiv.org/pdf/2502.13440.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-02-19_Semi-supervised_classification_of_bird_vocalizations.pdf", "markdown_path": "data/semantic/markdown_files/2025-02-19_Semi-supervised_classification_of_bird_vocalizations.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "e5e8a36e5933522a71ab0b82e8423c8cd89ddce5", "publication_date": "2020-02-04", "title": "End-to-end deep learning for big data analytics under a quasi-open set assumption", "authors": "E. Engelbrecht, J. D. Preez", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "473923bdfdf26a62e508c06032de2bcf1aea2fe1", "publication_date": "2020-02-04", "title": "Open-set learning with augmented categories by exploiting unlabelled data", "authors": "E. Engelbrecht, J. D. Preez", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": "Novel categories are commonly defined as those unobserved during training but present during testing. However, partially labelled training datasets can contain unlabelled training samples that belong to novel categories, meaning these can be present in training and testing. This research is the first to generalise between what we call observed-novel and unobserved-novel categories within a new learning policy called open-set learning with augmented category by exploiting unlabelled data or Open-LACU. After surveying existing learning policies, we introduce Open-LACU as a unified policy of positive and unlabelled learning, semi-supervised learning and open-set recognition. Subsequently, we develop the first Open-LACU model using an algorithmic training process of the relevant research fields. The proposed Open-LACU classifier achieves state-of-the-art and first-of-its-kind results.", "pdf_url": "https://arxiv.org/pdf/2002.01368.pdf", "pdf_filepath": "data/semantic/pdf_files/2020-02-04_Open-set_learning_with_augmented_categories_by_exploiting_unlabelled_data.pdf", "markdown_path": "data/semantic/markdown_files/2020-02-04_Open-set_learning_with_augmented_categories_by_exploiting_unlabelled_data.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "4cc2273cf8640ddd497e86d949dfd79057e5caea", "publication_date": "2016-04-24", "title": "Semi-supervised Vocabulary-Informed Learning", "authors": "Yanwei Fu, L. Sigal", "venue": "Computer Vision and Pattern Recognition", "citation_count": 132, "influential_citation_count": 12, "abstract": "Despite significant progress in object categorization, in recent years, a number of important challenges remain, mainly, ability to learn from limited labeled data and ability to recognize object classes within large, potentially open, set of labels. Zero-shot learning is one way of addressing these challenges, but it has only been shown to work with limited sized class vocabularies and typically requires separation between supervised and unsupervised classes, allowing former to inform the latter but not vice versa. We propose the notion of semi-supervised vocabulary-informed learning to alleviate the above mentioned challenges and address problems of supervised, zero-shot and open set recognition using a unified framework. Specifically, we propose a maximum margin framework for semantic manifold-based recognition that incorporates distance constraints from (both supervised and unsupervised) vocabulary atoms, ensuring that labeled samples are projected closest to their correct prototypes, in the embedding space, than to others. We show that resulting model shows improvements in supervised, zero-shot, and large open set recognition, with up to 310K class vocabulary on AwA and ImageNet datasets.", "pdf_url": "https://arxiv.org/pdf/1604.07093.pdf", "pdf_filepath": "data/semantic/pdf_files/2016-04-24_Semi-supervised_Vocabulary-Informed_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2016-04-24_Semi-supervised_Vocabulary-Informed_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ed2d31c75f0375652af2c451f199da41d6b593b7", "publication_date": "2019-10-15", "title": "Open Set Deep Learning with A Bayesian Nonparametric Generative Model", "authors": "Xulun Ye, Jieyu Zhao", "venue": "ACM Multimedia", "citation_count": 2, "influential_citation_count": 0, "abstract": "Being a widely studied model in machine learning and multimedia community, Deep Neural Network (DNN) has achieved an encouraging success in various applications. However, conventional DNN suffers the difficulty when handling the open set learning problem, in which the true class number is unknown, and the predication label in the testing dataset usually has unseen classes which are not contained in the training set. In this paper, we aim to tackle this problem by unifying deep neural network and Dirichlet process mixture model. Firstly, to learn the deep feature and enable the incorporation of DNN and the Bayesian nonparametric model, we extend deep metric learning to a semi-supervised framework. Secondly, with the learned deep feature, we construct our open set classification method by expanding the Dirichlet process mixture model to a semi-supervised framework. To infer our semi-supervised Bayesian model, the corresponding variational inference algorithm has also been derived. Experiment on synthetic and real world datasets validates our theory analysis and demonstrates the state-of-the-art performance.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "c339baa8fed4f270782cfd5696683e79310e8e19", "publication_date": "2006", "title": "Adopting Semi-supervised Learning Algorithms for Mining Remote Sensing Imagery : Summary of Results and Open Research Problems", "authors": "Ranga Raju Vatsavai, S. Shekhar, T. Burk", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "1d29d3186b5955258b051e6deb50432e84210e1c", "publication_date": "2017-08-14", "title": "A GPU Accelerated Text Classification Method in E-learning Environment Based on Semi-supervised NMF and SVM", "authors": "Feng Liu, Liu-tao Zhao, Qiang Chen", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": "With the beginning of revolution in education E-learning become increasingly popular. It is widespread among people while E-learning platform is used by more people to publish their own resources freely. As a result, a large number of document data need to be processed. Text classification is a key technology to this problem. In this paper, we propose a frame based on semi-supervised NMF and SVM for text classification. The method of semi-supervised NMF can work out a so called open set problem well. And we also proposed an accelerated version of the algorithm base on CUDA and GPU parallel architecture. These methods can work out the problems well. And finally we test the algorithms in the E-learning environment, than we give the conclusion according to the results.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "893addc88beefe22942868aa84a37c3facc6e385", "publication_date": "2022-08-11", "title": "The semi-automatic classification of an open-ended question on panel survey motivation and its application in attrition analysis", "authors": "Anna Haensch, Bernd Weiss, Patricia Steins, P. Chyrva, Katja Bitz", "venue": "Frontiers in Big Data", "citation_count": 4, "influential_citation_count": 0, "abstract": "In this study, we demonstrate how supervised learning can extract interpretable survey motivation measurements from a large number of responses to an open-ended question. We manually coded a subsample of 5,000 responses to an open-ended question on survey motivation from the GESIS Panel (25,000 responses in total); we utilized supervised machine learning to classify the remaining responses. We can demonstrate that the responses on survey motivation in the GESIS Panel are particularly well suited for automated classification, since they are mostly one-dimensional. The evaluation of the test set also indicates very good overall performance. We present the pre-processing steps and methods we used for our data, and by discussing other popular options that might be more suitable in other cases, we also generalize beyond our use case. We also discuss various minor problems, such as a necessary spelling correction. Finally, we can showcase the analytic potential of the resulting categorization of panelists' motivation through an event history analysis of panel dropout. The analytical results allow a close look at respondents' motivations: they span a wide range, from the urge to help to interest in questions or the incentive and the wish to influence those in power through their participation. We conclude our paper by discussing the re-usability of the hand-coded responses for other surveys, including similar open questions to the GESIS Panel question.", "pdf_url": "https://www.frontiersin.org/journals/big-data/articles/10.3389/fdata.2022.880554/pdf", "pdf_filepath": "data/semantic/pdf_files/2022-08-11_The_semi-automatic_classification_of_an_open-ended_question_on_panel_survey_motivation_and_its_appli.pdf", "markdown_path": "data/semantic/markdown_files/2022-08-11_The_semi-automatic_classification_of_an_open-ended_question_on_panel_survey_motivation_and_its_appli.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "a34c6ce69a4049efdf1f0c590dcc079d44341d9d", "publication_date": "2020-10-15", "title": "Pulsar candidate identification using semi-supervised generative adversarial networks", "authors": "V. Balakrishnan, D. Champion, E. Barr, Michael Kramer, R. Sengar, M. Bailes", "venue": "Monthly notices of the Royal Astronomical Society", "citation_count": 13, "influential_citation_count": 0, "abstract": "\n Machine learning methods are increasingly helping astronomers identify new radio pulsars. However, they require a large amount of labelled data, which is time consuming to produce and biased. Here, we describe a Semi-supervised generative adversarial network, which achieves better classification performance than the standard supervised algorithms using majority unlabelled data sets. We achieved an accuracy and mean F-Score of 94.9\u00a0per\u2009cent trained on only 100 labelled candidates and 5000 unlabelled candidates compared to our standard supervised baseline which scored at 81.1\u00a0per\u2009cent and 82.7\u00a0per\u2009cent, respectively. Our final model trained on a much larger labelled data set achieved an accuracy and mean F-score value of 99.2\u00a0per\u2009cent and a recall rate of 99.7 per\u2009cent. This technique allows for high-quality classification during the early stages of pulsar surveys on new instruments when limited labelled data are available. We open-source our work along with a new pulsar-candidate data set produced from the High Time Resolution Universe \u2013 South Low Latitude Survey. This data set has the largest number of pulsar detections of any public data set and we hope it will be a valuable tool for benchmarking future machine learning models.", "pdf_url": "https://arxiv.org/pdf/2010.07457.pdf", "pdf_filepath": "data/semantic/pdf_files/2020-10-15_Pulsar_candidate_identification_using_semi-supervised_generative_adversarial_networks.pdf", "markdown_path": "data/semantic/markdown_files/2020-10-15_Pulsar_candidate_identification_using_semi-supervised_generative_adversarial_networks.md"}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ebedbe3d710109589898e543ab200b466383c3fc", "publication_date": "2020-09-01", "title": "Comparative Assessment of Data Augmentation for Semi-Supervised Polyphonic Sound Event Detection", "authors": "L. Delphin-Poulat, R. Nicol, C. Plapous, K. Peron", "venue": "Conference of the Open Innovations Association", "citation_count": 6, "influential_citation_count": 0, "abstract": "In the context of audio ambient intelligence systems in Smart Buildings, polyphonic Sound Event Detection aims at detecting, localizing and classifying any sound event recorded in a room. Today, most of models are based on Deep Learning, requiring large databases to be trained. We propose a CRNN system exploiting unlabeled data with semi-supervised learning based on the \u201cMean teacher\u201d method, in combination with data augmentation to overcome the limited size of the training dataset and to further improve the performances. This model was submitted to the challenge DCASE 2019 and was ranked second out of 58 systems submitted. In the present study, several conventional solutions of data augmentation are compared: time or frequency shifting, and background noise addition. It is shown that data augmentation with time shifting and noise addition, in combination with class-dependent median filtering, improves the performance by 9%, leading to an event-based F1-score of 43.2% with DCASE 2019 validation set. However, these tools rely on a coarse modelling (i.e. random variation of data) of intra-class variability observed in real life. Injecting acoustic knowledge into the design of augmentation methods seems to be a promising way forward, leading us to propose strategies of physics-inspired modelling for future work.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "d8fec6db8468a9cd17ebd98911a2300eaa695573", "publication_date": "2021-12-22", "title": "A Supervised Learning Method for Improving the Generalization of Speaker Verification Systems by Learning Metrics from a Mean Teacher", "authors": "Ju-ho Kim, Hye-jin Shim, Jee-weon Jung, Ha-jin Yu", "venue": "Applied Sciences", "citation_count": 3, "influential_citation_count": 0, "abstract": "The majority of recent speaker verification tasks are studied under open-set evaluation scenarios considering real-world conditions. The characteristics of these tasks imply that the generalization towards unseen speakers is a critical capability. Thus, this study aims to improve the generalization of the system for the performance enhancement of speaker verification. To achieve this goal, we propose a novel supervised-learning-method-based speaker verification system using the mean teacher framework. The mean teacher network refers to the temporal averaging of deep neural network parameters, which can produce a more accurate, stable representations than fixed weights at the end of training and is conventionally used for semi-supervised learning. Leveraging the success of the mean teacher framework in many studies, the proposed supervised learning method exploits the mean teacher network as an auxiliary model for better training of the main model, the student network. By learning the reliable intermediate representations derived from the mean teacher network as well as one-hot speaker labels, the student network is encouraged to explore more discriminative embedding spaces. The experimental results demonstrate that the proposed method relatively reduces the equal error rate by 11.61%, compared to the baseline system.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "2b1c1e526159c4785fe5d71151b37ca03d59f6f0", "publication_date": "2019-01-01", "title": "Semi-supervised Classification Based Mixed Sampling for Imbalanced Data", "authors": "Jianhua Zhao, Ning Liu", "venue": "Open Physics", "citation_count": 8, "influential_citation_count": 1, "abstract": "Abstract In practical application, there are a large amount of imbalanced data containing only a small number of labeled data. In order to improve the classification performance of this kind of problem, this paper proposes a semi-supervised learning algorithm based on mixed sampling for imbalanced data classification (S2MAID), which combines semi-supervised learning, over sampling, under sampling and ensemble learning. Firstly, a kind of under sampling algorithm UD-density is provided to select samples with high information content from majority class set for semi-supervised learning. Secondly, a safe supervised-learning method is used to mark unlabeled sample and expand the labeled sample. Thirdly, a kind of over sampling algorithm SMOTE-density is provided to make the imbalanced data set become balance set. Fourthly, an ensemble technology is used to generate a strong classifier. Finally, the experiment is carried out on imbalanced data with containing only a few labeled samples, and semi-supervised learning process is simulated. The proposed S2MAID is verified and the experimental result shows that the proposed S2MAID has a better classification performance.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ccf153c557aa7a18a354066e7478d0f156a5bc28", "publication_date": "2013-08-01", "title": "Semi-supervised multi-feature learning for person re-identification", "authors": "Dario Figueira, Loris Bazzani, H. Q. Minh, M. Cristani, Alexandre Bernardino, Vittorio Murino", "venue": "2013 10th IEEE International Conference on Advanced Video and Signal Based Surveillance", "citation_count": 61, "influential_citation_count": 4, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "f457a06163cbdc1be98d3b314c576eba6ed8c9cb", "publication_date": "2010-01-05", "title": "Semi-supervised Learning for SVM-KNN", "authors": "Kunlun Li, Xuerong Luo, Ming Jin", "venue": "Journal of Computers", "citation_count": 16, "influential_citation_count": 1, "abstract": "Compared with labeled data, unlabeled data are significantly easier to obtain. Currently, classification of unlabeled data is an open issue. In this paper a novel SVM-KNN classification methodology based on Semi-supervised learning is proposed, we consider the problem of using a large number of unlabeled data to boost performance of the classifier when only a small set of labeled examples is available. We use the few labeled data to train a weaker SVM classifier and make use of the boundary vectors to improve the weaker SVM iteratively by introducing KNN. Using KNN classifier doesn\u2019t enlarge the number of training examples only, but also improves the quality of the new training examples which are transformed from the boundary vectors. Experiments on UCI data sets show that the proposed methodology can evidently improve the accuracy of the final SVM classifier by tuning the parameters and can reduce the cost of labeling unlabeled examples.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "22c6c9fa1900ccaa9847e404881d0f12ae491651", "publication_date": "2019-09-04", "title": "A Semi-supervised Method to Classify Educational Videos", "authors": "A. Stoica, S. H. Barber\u00e1, Javier Palanca, V. Juli\u00e1n, M. Mih\u0103escu", "venue": "Hybrid Artificial Intelligence Systems", "citation_count": 7, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "d54c171c2c4373fc0b441b3b78a5ad67d331e957", "publication_date": "2019-10-11", "title": "Hierarchical Open-Set Object Detection in Unseen Data", "authors": "Kim Yeong Hyeon, Shin Dong Kyun, Minhaz Uddin Ahmed, P. Rhee", "venue": "Symmetry", "citation_count": 1, "influential_citation_count": 0, "abstract": "In this paper, we propose an open-set object detection framework based on a dynamic hierarchical structure with incremental learning capabilities for unseen object classes. We were motivated by the observation that deep features extracted from visual objects show a strong hierarchical clustering property. The hierarchical feature model (HFM) was used to learn a new object class by using collaborative sampling (CS), and open-set-aware active semi-supervised learning (ASSL) algorithms. We divided object proposals into superclasses by using the agglomerative clustering algorithm. Data samples in each superclass node were classified into multiple augmented class nodes instead of directly associating with regular object classes. One or more augmented class nodes are related to a regular object class, and each augmented class has only one superclass. Object proposals from inexperienced data distribution are assigned to an augmented class node. Dynamic HFM nodes in the decision path are assembled to constitute an ensemble prediction, and the new augmented object is associated with a new regular object class. Our experimental results showed that the proposed method uses standard benchmark datasets such as PASCAL VOC, MS COCO, ILSVRC DET, and local datasets to perform better than state-of-the-art techniques.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "bb57af33e505681b1649366e494681e5684bdec7", "publication_date": "2024-03-20", "title": "SPTNet: An Efficient Alternative Framework for Generalized Category Discovery with Spatial Prompt Tuning", "authors": "Hongjun Wang, S. Vaze, Kai Han", "venue": "International Conference on Learning Representations", "citation_count": 21, "influential_citation_count": 3, "abstract": "Generalized Category Discovery (GCD) aims to classify unlabelled images from both `seen' and `unseen' classes by transferring knowledge from a set of labelled `seen' class images. A key theme in existing GCD approaches is adapting large-scale pre-trained models for the GCD task. An alternate perspective, however, is to adapt the data representation itself for better alignment with the pre-trained model. As such, in this paper, we introduce a two-stage adaptation approach termed SPTNet, which iteratively optimizes model parameters (i.e., model-finetuning) and data parameters (i.e., prompt learning). Furthermore, we propose a novel spatial prompt tuning method (SPT) which considers the spatial property of image data, enabling the method to better focus on object parts, which can transfer between seen and unseen classes. We thoroughly evaluate our SPTNet on standard benchmarks and demonstrate that our method outperforms existing GCD methods. Notably, we find our method achieves an average accuracy of 61.4% on the SSB, surpassing prior state-of-the-art methods by approximately 10%. The improvement is particularly remarkable as our method yields extra parameters amounting to only 0.117% of those in the backbone architecture. Project page: https://visual-ai.github.io/sptnet.", "pdf_url": "https://arxiv.org/pdf/2403.13684.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-20_SPTNet__An_Efficient_Alternative_Framework_for_Generalized_Category_Discovery_with_Spatial_Prompt_Tu.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-20_SPTNet__An_Efficient_Alternative_Framework_for_Generalized_Category_Discovery_with_Spatial_Prompt_Tu.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "e6936c5da35d1de228c427704f97eb93ff5382cd", "publication_date": "2022-01-07", "title": "Generalized Category Discovery", "authors": "S. Vaze, Kai Han, A. Vedaldi, Andrew Zisserman", "venue": "Computer Vision and Pattern Recognition", "citation_count": 198, "influential_citation_count": 96, "abstract": "In this paper, we consider a highly general image recognition setting wherein, given a labelled and unlabelled set of images, the task is to categorize all images in the unlabelled set. Here, the unlabelled images may come from labelled classes or from novel ones. Existing recognition methods are not able to deal with this setting, because they make several restrictive assumptions, such as the unlabelled instances only coming from known \u2013 or unknown \u2013 classes, and the number of unknown classes being known a-priori. We address the more unconstrained setting, naming it \u2018Generalized Category Discovery\u2019, and challenge all these assumptions. We first establish strong baselines by taking state-of-the-art algorithms from novel category discovery and adapting them for this task. Next, we propose the use of vision transformers with contrastive representation learning for this open-world setting. We then introduce a simple yet effective semi-supervised k-means method to cluster the unlabelled data into seen and unseen classes automatically, substantially outperforming the baselines. Finally, we also propose a new approach to estimate the number of classes in the unlabelled data. We thoroughly evaluate our approach on public datasets for generic object classification and on fine-grained datasets, leveraging the recent Semantic Shift Benchmark suite. Code: https://www.robots.ox.ac.uk/~vgg/research/gcd", "pdf_url": "https://arxiv.org/pdf/2201.02609.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-01-07_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2022-01-07_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "c240a6faaf1293877356f19043a83c4840aac323", "publication_date": "2024", "title": "Novel Category Discovery Without Forgetting for Automatic Target Recognition", "authors": "Heqing Huang, F. Gao, J. Sun, Jun Wang, Amir Hussain, Huiyu Zhou", "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing", "citation_count": 21, "influential_citation_count": 1, "abstract": "In this article, we explore a cutting-edge concept known as class incremental learning (CIL) in novel category discovery for synthetic aperture radar (SAR) targets (CNTs). This innovative task involves the challenge of identifying categories within unlabeled datasets by utilizing a provided labeled dataset as reference. In contrast to the conventional category discover approaches, our method introduces novel categories without relying on old labeled classes and effectively mitigates the issue of catastrophic forgetting. Specifically, to reduce the bias of the established categories toward unknown ones, CNT extracts representational information via self-supervised learning, gleaned directly from the SAR data itself to facilitate generalization. To retain the model's competence in classifying previously acquired knowledge, we employ a dual strategy incorporating the rehearsal of base category feature prototypes and the application of knowledge distillation. Our methodology integrates multiview and pseudolabeling strategies. In addition, we introduce a novel approach that focuses on enhancing the discernibility of class spaces. This strategy primarily ensures distinct separation of the unlabeled classes from base class prototypes, and imposes stringent constraints on the internal relationships among individual samples and their corresponding perspectives. To the best of our knowledge, this is the first study on category discovery in the CIL scenario. The experimental results show that our method significantly improves the performance on SAR images compared to the previous optimal method, which indicates the effectiveness of our method.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "3f7a8d9877d0a3aa1834bc4f0de5e6f82eabffa3", "publication_date": "2024-03-07", "title": "Active Generalized Category Discovery", "authors": "Shijie Ma, Fei Zhu, Zhun Zhong, Xu-Yao Zhang, Cheng-Lin Liu", "venue": "Computer Vision and Pattern Recognition", "citation_count": 15, "influential_citation_count": 0, "abstract": "Generalized Category Discovery (GCD) is a pragmatic and challenging open-world task, which endeavors to cluster unlabeled samples from both novel and old classes, leveraging some labeled data of old classes. Given that knowledge learned from old classes is not fully transferable to new classes, and that novel categories are fully unlabeled, GCD inherently faces intractable problems, including imbalanced classification performance and inconsistent confidence between old and new classes, especially in the low-labeling regime. Hence, some annotations of new classes are deemed necessary. However, labeling new classes is extremely costly. To address this issue, we take the spirit of active learning and propose a new setting called Active Generalized Category Discovery (AGCD). The goal is to improve the performance of GCD by actively selecting a limited amount of valuable samples for labeling from the oracle. To solve this problem, we devise an adaptive sampling strategy, which jointly considers novelty, informativeness and diversity to adaptively select novel samples with proper uncertainty. However, owing to the varied orderings of label indices caused by the clustering of novel classes, the queried labels are not directly applicable to subsequent training. To overcome this issue, we further propose a stable label mapping algorithm that transforms ground truth labels to the label space of the classifier, thereby ensuring consistent training across different active selection stages. Our method achieves state-of-the-art performance on both generic and fine-grained datasets. Our code is available at https://github.com/mashijie1028/ActiveGCD", "pdf_url": "https://arxiv.org/pdf/2403.04272.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-07_Active_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-07_Active_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a684d26a0d751af49c7f8eeea65883c765fbaf71", "publication_date": "2024-04-15", "title": "Contrastive Mean-Shift Learning for Generalized Category Discovery", "authors": "Sua Choi, Dahyun Kang, Minsu Cho", "venue": "Computer Vision and Pattern Recognition", "citation_count": 11, "influential_citation_count": 2, "abstract": "We address the problem of generalized category discovery (GCD) that aims to partition a partially labeled collection of images; only a small part of the collection is labeled and the total number of target classes is unknown. To address this generalized image clustering problem, we revisit the mean-shift algorithm, i.e., a classic, powerful technique for mode seeking, and incorporate it into a contrastive learning framework. The proposed method, dubbed Contrastive Mean-Shift (CMS) learning, trains an embedding network to produce representations with better clustering properties by an iterative process of mean shift and contrastive update. Experiments demonstrate that our method, both in settings with and without the total number of clusters being known, achieves state-of-the-art performance on six public GCD benchmarks without bells and whistles.", "pdf_url": "https://arxiv.org/pdf/2404.09451.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-15_Contrastive_Mean-Shift_Learning_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-15_Contrastive_Mean-Shift_Learning_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "48aaa0155ecc9bdd5971ced96e5693b2cbc40edd", "publication_date": "2024", "title": "Actively Learn from LLMs with Uncertainty Propagation for Generalized Category Discovery", "authors": "Jinggui Liang, Lizi Liao, Hao Fei, Bobo Li, Jing Jiang", "venue": "North American Chapter of the Association for Computational Linguistics", "citation_count": 10, "influential_citation_count": 2, "abstract": "Generalized category discovery faces a key issue: the lack of supervision for new and unseen data categories. Traditional methods typically combine supervised pretraining with self-supervised learning to create models, and then employ clustering for category identification. However, these approaches tend to become overly tailored to known categories, failing to fully resolve the core issue. Hence, we propose to integrate the feedback from LLMs into an active learning paradigm. Specifically, our method innovatively employs uncertainty propagation to select data samples from high-uncertainty regions, which are then labeled using LLMs through a comparison-based prompting scheme. This not only eases the labeling task but also enhances accuracy in identifying new categories. Additionally, a soft feedback propagation mechanism is introduced to minimize the spread of inaccurate feedback. Experiments on various datasets demonstrate our framework\u2019s efficacy and generalizability, significantly improving baseline models at a nominal average cost.", "pdf_url": "https://aclanthology.org/2024.naacl-long.434.pdf", "pdf_filepath": "data/semantic/pdf_files/2024_Actively_Learn_from_LLMs_with_Uncertainty_Propagation_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024_Actively_Learn_from_LLMs_with_Uncertainty_Propagation_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "e59b9aa28f62fff25bd553cd8c90d0c583bf9ca2", "publication_date": "2023-03-30", "title": "Dynamic Conceptional Contrastive Learning for Generalized Category Discovery", "authors": "Nan Pu, Zhun Zhong, N. Sebe", "venue": "Computer Vision and Pattern Recognition", "citation_count": 64, "influential_citation_count": 10, "abstract": "Generalized category discovery (GCD) is a recently proposed open-world problem, which aims to automatically cluster partially labeled data. The main challenge is that the unlabeled data contain instances that are not only from known categories of the labeled data but also from novel categories. This leads traditional novel category discovery (NCD) methods to be incapacitated for GCD, due to their assumption of unlabeled data are only from novel categories. One effective way for GCD is applying self-supervised learning to learn discriminate representation for unlabeled data. However, this manner largely ignores underlying relationships between instances of the same concepts (e.g., class, super-class, and sub-class), which results in inferior representation learning. In this paper, we propose a Dynamic Conceptional Contrastive Learning (DCCL)framework, which can effectively improve clustering accuracy by alternately estimating underlying visual conceptions and learning conceptional representation. In addition, we design a dynamic conception generation and update mechanism, which is able to ensure consistent conception learning and thus further facilitate the optimization of DCCL. Extensive experiments show that DCCL achieves new state-of-the-art performances on six generic and fine-grained visual recognition datasets, especially on fine-grained ones. For example, our method significantly surpasses the best competitor by 16.2% on the new classes for the CUB-200 dataset. Code is available at https://github.com/TPCD/DCCL", "pdf_url": "https://arxiv.org/pdf/2303.17393.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-03-30_Dynamic_Conceptional_Contrastive_Learning_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-03-30_Dynamic_Conceptional_Contrastive_Learning_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a569160c7d4c0deeb4e41bcb833380534003be71", "publication_date": "2023-05-10", "title": "Learning Semi-supervised Gaussian Mixture Models for Generalized Category Discovery", "authors": "Bingchen Zhao, Xin Wen, Kai Han", "venue": "IEEE International Conference on Computer Vision", "citation_count": 51, "influential_citation_count": 5, "abstract": "In this paper, we address the problem of generalized category discovery (GCD), i.e., given a set of images where part of them are labelled and the rest are not, the task is to automatically cluster the images in the unlabelled data, leveraging the information from the labelled data, while the unlabelled data contain images from the labelled classes and also new ones. GCD is similar to semi-supervised learning (SSL) but is more realistic and challenging, as SSL assumes all the unlabelled images are from the same classes as the labelled ones. We also do not assume the class number in the unlabelled data is known a-priori, making the GCD problem even harder. To tackle the problem of GCD without knowing the class number, we propose an EM-like framework that alternates between representation learning and class number estimation. We propose a semi-supervised variant of the Gaussian Mixture Model (GMM) with a stochastic splitting and merging mechanism to dynamically determine the prototypes by examining the cluster compactness and separability. With these prototypes, we leverage prototypical contrastive learning for representation learning on the partially labelled data subject to the constraints imposed by the labelled data. Our framework alternates between these two steps until convergence. The cluster assignment for an unlabelled instance can then be retrieved by identifying its nearest prototype. We comprehensively evaluate our framework on both generic image classification datasets and challenging fine-grained object recognition datasets, achieving state-of-the-art performance. Our code is available at https://github.com/DTennant/GPC.", "pdf_url": "https://arxiv.org/pdf/2305.06144.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-05-10_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-05-10_Learning_Semi-supervised_Gaussian_Mixture_Models_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a12e9bec9e8d6cf782c92eb623537a761e94a819", "publication_date": "2023-11-28", "title": "No Representation Rules Them All in Category Discovery", "authors": "S. Vaze, A. Vedaldi, A. Zisserman", "venue": "Neural Information Processing Systems", "citation_count": 34, "influential_citation_count": 6, "abstract": "In this paper we tackle the problem of Generalized Category Discovery (GCD). Specifically, given a dataset with labelled and unlabelled images, the task is to cluster all images in the unlabelled subset, whether or not they belong to the labelled categories. Our first contribution is to recognize that most existing GCD benchmarks only contain labels for a single clustering of the data, making it difficult to ascertain whether models are using the available labels to solve the GCD task, or simply solving an unsupervised clustering problem. As such, we present a synthetic dataset, named 'Clevr-4', for category discovery. Clevr-4 contains four equally valid partitions of the data, i.e based on object shape, texture, color or count. To solve the task, models are required to extrapolate the taxonomy specified by the labelled set, rather than simply latching onto a single natural grouping of the data. We use this dataset to demonstrate the limitations of unsupervised clustering in the GCD setting, showing that even very strong unsupervised models fail on Clevr-4. We further use Clevr-4 to examine the weaknesses of existing GCD algorithms, and propose a new method which addresses these shortcomings, leveraging consistent findings from the representation learning literature to do so. Our simple solution, which is based on 'mean teachers' and termed $\\mu$GCD, substantially outperforms implemented baselines on Clevr-4. Finally, when we transfer these findings to real data on the challenging Semantic Shift Benchmark (SSB), we find that $\\mu$GCD outperforms all prior work, setting a new state-of-the-art. For the project webpage, see https://www.robots.ox.ac.uk/~vgg/data/clevr4/", "pdf_url": "https://arxiv.org/pdf/2311.17055.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-11-28_No_Representation_Rules_Them_All_in_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-11-28_No_Representation_Rules_Them_All_in_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "47c3676051770cf50d28ed371b11134c73404af2", "publication_date": "2024-06-16", "title": "Solving the Catastrophic Forgetting Problem in Generalized Category Discovery", "authors": "Xinzi Cao, Xiawu Zheng, Guanhong Wang, Weijiang Yu, Yunhang Shen, Ke Li, Yutong Lu, Yonghong Tian", "venue": "Computer Vision and Pattern Recognition", "citation_count": 6, "influential_citation_count": 2, "abstract": "Generalized Category Discovery (GCD) aims to identify a mix of known and novel categories within unlabeled data sets, providing a more realistic setting for image recognition. Essentially, GCD needs to remember existing patterns thoroughly to recognize novel categories. Recent state-of-the-art method SimGCD transfers the knowledge from known-class data to the learning of novel classes through debiased learning. However, some patterns are catastrophically forgot during adaptation and thus lead to poor performance in novel categories classification. To address this issue, we propose a novel learning approach, LegoGCD, which is seamlessly integrated into previous methods to enhance the discrimination of novel classes while maintaining performance on previously encountered known classes. Specifically, we design two types of techniques termed as Local Entropy Regularization (LER) and Dual-views Kullback-Leibler divergence constraint (DKL). The LER optimizes the distribution of potential known class samples in unlabeled data, thus ensuring the preservation of knowledge related to known categories while learning novel classes. Meanwhile, DKL introduces Kullback-Leibler divergence to encourage the model to produce a similar prediction distribution of two view samples from the same image. In this way, it successfully avoids mismatched prediction and generates more reliable potential known class samples simultaneously. Extensive experiments validate that the proposed LegoGCD effectively addresses the known category forgetting issue across all datasets, e.g., delivering a 7.74% and 2.51% accuracy boost on known and novel classes in CUB, respectively. Our code is available at: https://github.com/Cliffia123/LegoGCD.", "pdf_url": "https://arxiv.org/pdf/2501.05272.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-06-16_Solving_the_Catastrophic_Forgetting_Problem_in_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-16_Solving_the_Catastrophic_Forgetting_Problem_in_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "2c9a49d66422afccb69928a66a3aae0265a4e1e7", "publication_date": "2024-07-26", "title": "PromptCCD: Learning Gaussian Mixture Prompt Pool for Continual Category Discovery", "authors": "Fernando Julio Cendra, Bingchen Zhao, Kai Han", "venue": "European Conference on Computer Vision", "citation_count": 6, "influential_citation_count": 0, "abstract": "We tackle the problem of Continual Category Discovery (CCD), which aims to automatically discover novel categories in a continuous stream of unlabeled data while mitigating the challenge of catastrophic forgetting -- an open problem that persists even in conventional, fully supervised continual learning. To address this challenge, we propose PromptCCD, a simple yet effective framework that utilizes a Gaussian Mixture Model (GMM) as a prompting method for CCD. At the core of PromptCCD lies the Gaussian Mixture Prompting (GMP) module, which acts as a dynamic pool that updates over time to facilitate representation learning and prevent forgetting during category discovery. Moreover, GMP enables on-the-fly estimation of category numbers, allowing PromptCCD to discover categories in unlabeled data without prior knowledge of the category numbers. We extend the standard evaluation metric for Generalized Category Discovery (GCD) to CCD and benchmark state-of-the-art methods on diverse public datasets. PromptCCD significantly outperforms existing methods, demonstrating its effectiveness. Project page: https://visual-ai.github.io/promptccd .", "pdf_url": "https://arxiv.org/pdf/2407.19001.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-07-26_PromptCCD__Learning_Gaussian_Mixture_Prompt_Pool_for_Continual_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-26_PromptCCD__Learning_Gaussian_Mixture_Prompt_Pool_for_Continual_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "565672cb02ad49ef7cf512896a342f20bec1b9c6", "publication_date": "2024-01-03", "title": "Guided Cluster Aggregation: A Hierarchical Approach to Generalized Category Discovery", "authors": "Jona Otholt, Christoph Meinel, Haojin Yang", "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision", "citation_count": 7, "influential_citation_count": 0, "abstract": "Despite advances in image recognition, recognizing novel categories in unlabeled data remains challenging for machine learning methods, even though humans can perform this task with ease. A recently developed setting to tackle this problem is Generalized Category Discovery (GCD), in which the task is to, given a labeled dataset, classify an unlabeled dataset, where the unlabeled dataset contains both known classes and novel classes that do not appear in the labeled data. Existing GCD methods mostly focus on learning strong image representations, on which they then apply a clustering algorithm such as k-means. Despite obtaining good performance, they do not fully exploit the potential of the learned features due to the simple nature of the clustering mechanism. To address this issue, we make use of the fact that local neighborhoods in self-supervised feature spaces are highly homogeneous. We leverage this observation to develop Guided Cluster Aggregation (GCA), a hierarchical approach that first groups the data into small clusters of high purity, then aggregates them into larger clusters. Experiments show that GCA outperforms semi-supervised k-means in most cases, especially in fine-grained classification tasks. Code available at https://github.com/J-L-O/guidedcluster-aggregation.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "8a570e095982deaaa891b11da99acda9ee65989d", "publication_date": "2024-01-03", "title": "AMEND: Adaptive Margin and Expanded Neighborhood for Efficient Generalized Category Discovery", "authors": "Anwesha Banerjee, Liyana Sahir Kallooriyakath, Soma Biswas", "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision", "citation_count": 7, "influential_citation_count": 0, "abstract": "Generalized Category Discovery aims to discover and cluster images from previously unseen classes, in addition to classifying images from seen classes correctly. In this work, we propose a simple, yet effective framework for this task, which not only performs on-par or better with the current approaches but is also significantly more efficient in terms of computational requirements. Our first contribution is to use expanded neighborhood information in contrastive learning to generate robust and generalizable features. To generate more discriminative feature representations, especially for fine-grained datasets and confusing classes, we propose a class-wise adaptive margin regularizer that aims at increasing the angular separation among the prototypes of all classes. Extensive experiments on three generic as well as four fine-grained benchmark datasets show the usefulness of the proposed Adaptive Margin and Expanded Neighborhood (AMEND) framework.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a6cb3c1f1120332b6c859e580b209398fd017a55", "publication_date": "2024-10-09", "title": "Happy: A Debiased Learning Framework for Continual Generalized Category Discovery", "authors": "Shijie Ma, Fei Zhu, Zhun Zhong, Wenzhuo Liu, Xu-Yao Zhang, Cheng-Lin Liu", "venue": "Neural Information Processing Systems", "citation_count": 8, "influential_citation_count": 0, "abstract": "Constantly discovering novel concepts is crucial in evolving environments. This paper explores the underexplored task of Continual Generalized Category Discovery (C-GCD), which aims to incrementally discover new classes from unlabeled data while maintaining the ability to recognize previously learned classes. Although several settings are proposed to study the C-GCD task, they have limitations that do not reflect real-world scenarios. We thus study a more practical C-GCD setting, which includes more new classes to be discovered over a longer period, without storing samples of past classes. In C-GCD, the model is initially trained on labeled data of known classes, followed by multiple incremental stages where the model is fed with unlabeled data containing both old and new classes. The core challenge involves two conflicting objectives: discover new classes and prevent forgetting old ones. We delve into the conflicts and identify that models are susceptible to prediction bias and hardness bias. To address these issues, we introduce a debiased learning framework, namely Happy, characterized by Hardness-aware prototype sampling and soft entropy regularization. For the prediction bias, we first introduce clustering-guided initialization to provide robust features. In addition, we propose soft entropy regularization to assign appropriate probabilities to new classes, which can significantly enhance the clustering performance of new classes. For the harness bias, we present the hardness-aware prototype sampling, which can effectively reduce the forgetting issue for previously seen classes, especially for difficult classes. Experimental results demonstrate our method proficiently manages the conflicts of C-GCD and achieves remarkable performance across various datasets, e.g., 7.5% overall gains on ImageNet-100. Our code is publicly available at https://github.com/mashijie1028/Happy-CGCD.", "pdf_url": "https://arxiv.org/pdf/2410.06535.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-09_Happy__A_Debiased_Learning_Framework_for_Continual_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-09_Happy__A_Debiased_Learning_Framework_for_Continual_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "78456bde33c9cc73d2af9f14cbcfa8d107356d67", "publication_date": "2023-08-21", "title": "MetaGCD: Learning to Continually Learn in Generalized Category Discovery", "authors": "Yanan Wu, Zhixiang Chi, Yang Wang, Songhe Feng", "venue": "IEEE International Conference on Computer Vision", "citation_count": 29, "influential_citation_count": 6, "abstract": "In this paper, we consider a real-world scenario where a model that is trained on pre-defined classes continually encounters unlabeled data that contains both known and novel classes. The goal is to continually discover novel classes while maintaining the performance in known classes. We name the setting Continual Generalized Category Discovery (C-GCD). Existing methods for novel class discovery cannot directly handle the C-GCD setting due to some unrealistic assumptions, such as the unlabeled data only containing novel classes. Furthermore, they fail to discover novel classes in a continual fashion. In this work, we lift all these assumptions and propose an approach, called MetaGCD, to learn how to incrementally discover with less forgetting. Our proposed method uses a meta-learning framework and leverages the offline labeled data to simulate the testing incremental learning process. A meta-objective is defined to revolve around two conflicting learning objectives to achieve novel class discovery without forgetting. Furthermore, a soft neighborhood-based contrastive network is proposed to discriminate uncorrelated images while attracting correlated images. We build strong baselines and conduct extensive experiments on three widely used benchmarks to demonstrate the superiority of our method.", "pdf_url": "https://arxiv.org/pdf/2308.11063.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-08-21_MetaGCD__Learning_to_Continually_Learn_in_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-21_MetaGCD__Learning_to_Continually_Learn_in_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "9556cee39e6505082ea466f6af8016c0b2d7b282", "publication_date": "2024-08-26", "title": "SelEx: Self-Expertise in Fine-Grained Generalized Category Discovery", "authors": "Sarah Rastegar, Mohammadreza Salehi, Yuki M. Asano, Hazel Doughty, Cees G. M. Snoek", "venue": "European Conference on Computer Vision", "citation_count": 4, "influential_citation_count": 1, "abstract": "In this paper, we address Generalized Category Discovery, aiming to simultaneously uncover novel categories and accurately classify known ones. Traditional methods, which lean heavily on self-supervision and contrastive learning, often fall short when distinguishing between fine-grained categories. To address this, we introduce a novel concept called `self-expertise', which enhances the model's ability to recognize subtle differences and uncover unknown categories. Our approach combines unsupervised and supervised self-expertise strategies to refine the model's discernment and generalization. Initially, hierarchical pseudo-labeling is used to provide `soft supervision', improving the effectiveness of self-expertise. Our supervised technique differs from traditional methods by utilizing more abstract positive and negative samples, aiding in the formation of clusters that can generalize to novel categories. Meanwhile, our unsupervised strategy encourages the model to sharpen its category distinctions by considering within-category examples as `hard' negatives. Supported by theoretical insights, our empirical results showcase that our method outperforms existing state-of-the-art techniques in Generalized Category Discovery across several fine-grained datasets. Our code is available at: https://github.com/SarahRastegar/SelEx.", "pdf_url": "https://arxiv.org/pdf/2408.14371.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-08-26_SelEx__Self-Expertise_in_Fine-Grained_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-08-26_SelEx__Self-Expertise_in_Fine-Grained_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "530e55cfe7264542394d0d4912d16204535df6de", "publication_date": "2024-08-08", "title": "HiLo: A Learning Framework for Generalized Category Discovery Robust to Domain Shifts", "authors": "Hongjun Wang, S. Vaze, Kai Han", "venue": "arXiv.org", "citation_count": 5, "influential_citation_count": 0, "abstract": "Generalized Category Discovery (GCD) is a challenging task in which, given a partially labelled dataset, models must categorize all unlabelled instances, regardless of whether they come from labelled categories or from new ones. In this paper, we challenge a remaining assumption in this task: that all images share the same domain. Specifically, we introduce a new task and method to handle GCD when the unlabelled data also contains images from different domains to the labelled set. Our proposed `HiLo' networks extract High-level semantic and Low-level domain features, before minimizing the mutual information between the representations. Our intuition is that the clusterings based on domain information and semantic information should be independent. We further extend our method with a specialized domain augmentation tailored for the GCD task, as well as a curriculum learning approach. Finally, we construct a benchmark from corrupted fine-grained datasets as well as a large-scale evaluation on DomainNet with real-world domain shifts, reimplementing a number of GCD baselines in this setting. We demonstrate that HiLo outperforms SoTA category discovery models by a large margin on all evaluations.", "pdf_url": "https://arxiv.org/pdf/2408.04591.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-08-08_HiLo__A_Learning_Framework_for_Generalized_Category_Discovery_Robust_to_Domain_Shifts.pdf", "markdown_path": "data/semantic/markdown_files/2024-08-08_HiLo__A_Learning_Framework_for_Generalized_Category_Discovery_Robust_to_Domain_Shifts.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "8dd32c39e86a9af90ff532bea86e692ffa05087b", "publication_date": "2024-07-29", "title": "Contextuality Helps Representation Learning for Generalized Category Discovery", "authors": "Tingzhang Luo, Mingxuan Du, Jiatao Shi, Xinxiang Chen, Bingchen Zhao, Shaoguang Huang", "venue": "International Conference on Information Photonics", "citation_count": 4, "influential_citation_count": 0, "abstract": "This paper introduces a novel approach to Generalized Category Discovery (GCD) by leveraging the concept of contextuality to enhance the identification and classification of categories in unlabeled datasets. Drawing inspiration from human cognition's ability to recognize objects within their context, we propose a dual-context based method. Our model integrates two levels of contextuality: instance-level, where nearest-neighbor contexts are utilized for contrastive learning, and cluster-level, employing prototypical contrastive learning based on category prototypes. The integration of the contextual information effectively improves the feature learning and thereby the classification accuracy of all categories, which better deals with the real-world datasets. Different from the traditional semi-supervised and novel category discovery techniques, our model focuses on a more realistic and challenging scenario where both known and novel categories are present in the unlabeled data. Extensive experimental results on several benchmark data sets demonstrate that the proposed model outperforms the state-of-the-art. Code is available at: https://github.com/Clarence-CV/Contexuality-GCD", "pdf_url": "https://arxiv.org/pdf/2407.19752.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-07-29_Contextuality_Helps_Representation_Learning_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-29_Contextuality_Helps_Representation_Learning_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "1ce04411cfbcd47c41f1645bc827e03e6e8fd086", "publication_date": "2024-03-15", "title": "GET: Unlocking the Multi-modal Potential of CLIP for Generalized Category Discovery", "authors": "Enguang Wang, Zhimao Peng, Zhengyuan Xie, Xialei Liu, Ming-Ming Cheng", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Given unlabelled datasets containing both old and new categories, generalized category discovery (GCD) aims to accurately discover new classes while correctly classifying old classes. Current GCD methods only use a single visual modality of information, resulting in a poor classification of visually similar classes. As a different modality, text information can provide complementary discriminative information, which motivates us to introduce it into the GCD task. However, the lack of class names for unlabelled data makes it impractical to utilize text information. To tackle this challenging problem, in this paper, we propose a Text Embedding Synthesizer (TES) to generate pseudo text embeddings for unlabelled samples. Specifically, our TES leverages the property that CLIP can generate aligned vision-language features, converting visual embeddings into tokens of the CLIP's text encoder to generate pseudo text embeddings. Besides, we employ a dual-branch framework, through the joint learning and instance consistency of different modality branches, visual and semantic information mutually enhance each other, promoting the interaction and fusion of visual and text knowledge. Our method unlocks the multi-modal potentials of CLIP and outperforms the baseline methods by a large margin on all GCD benchmarks, achieving new state-of-the-art. Our code is available at: https://github.com/enguangW/GET.", "pdf_url": "https://arxiv.org/pdf/2403.09974.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-15_GET__Unlocking_the_Multi-modal_Potential_of_CLIP_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-15_GET__Unlocking_the_Multi-modal_Potential_of_CLIP_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "19bcbf41a0c6fa515fb118b8e476044767f3d474", "publication_date": "2024-06-07", "title": "Labeled Data Selection for Category Discovery", "authors": "Bingchen Zhao, Nico Lang, Serge J. Belongie, Oisin Mac Aodha", "venue": "European Conference on Computer Vision", "citation_count": 3, "influential_citation_count": 0, "abstract": "Category discovery methods aim to find novel categories in unlabeled visual data. At training time, a set of labeled and unlabeled images are provided, where the labels correspond to the categories present in the images. The labeled data provides guidance during training by indicating what types of visual properties and features are relevant for performing discovery in the unlabeled data. As a result, changing the categories present in the labeled set can have a large impact on what is ultimately discovered in the unlabeled set. Despite its importance, the impact of labeled data selection has not been explored in the category discovery literature to date. We show that changing the labeled data can significantly impact discovery performance. Motivated by this, we propose two new approaches for automatically selecting the most suitable labeled data based on the similarity between the labeled and unlabeled data. Our observation is that, unlike in conventional supervised transfer learning, the best labeled is neither too similar, nor too dissimilar, to the unlabeled categories. Our resulting approaches obtains state-of-the-art discovery performance across a range of challenging fine-grained benchmark datasets.", "pdf_url": "https://arxiv.org/pdf/2406.04898.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-06-07_Labeled_Data_Selection_for_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-07_Labeled_Data_Selection_for_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "357926a1416b3208e8afbaeb240ceece722c15f3", "publication_date": "2024-03-24", "title": "A Unified Knowledge Transfer Network for Generalized Category Discovery", "authors": "Wenkai Shi, Wenbin An, Feng Tian, Yan Chen, Y. Wu, Qianying Wang, Ping Chen", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 3, "influential_citation_count": 0, "abstract": "Generalized Category Discovery (GCD) aims to recognize both known and novel categories in an unlabeled dataset by leveraging another labeled dataset with only known categories. Without considering knowledge transfer from known to novel categories, current methods usually perform poorly on novel categories due to the lack of corresponding supervision. To mitigate this issue, we propose a unified Knowledge Transfer Network (KTN), which solves two obstacles to knowledge transfer in GCD. First, the mixture of known and novel categories in unlabeled data makes it difficult to identify transfer candidates (i.e., samples with novel categories). For this, we propose an entropy-based method that leverages knowledge in the pre-trained classifier to differentiate known and novel categories without requiring extra data or parameters. Second, the lack of prior knowledge of novel categories presents challenges in quantifying semantic relationships between categories to decide the transfer weights. For this, we model different categories with prototypes and treat their similarities as transfer weights to measure the semantic similarities between categories. On the basis of two treatments, we transfer knowledge from known to novel categories by conducting pre-adjustment of logits and post-adjustment of labels for transfer candidates based on the transfer weights between different categories. With the weighted adjustment, KTN can generate more accurate pseudo-labels for unlabeled data, which helps to learn more discriminative features and boost model performance on novel categories. Extensive experiments show that our method outperforms state-of-the-art models on all evaluation metrics across multiple benchmark datasets. Furthermore, different from previous clustering-based methods that can only work offline with abundant data, KTN can be deployed online conveniently with faster inference speed. Code and data are available at https://github.com/yibai-shi/KTN.", "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/view/29862/31503", "pdf_filepath": "data/semantic/pdf_files/2024-03-24_A_Unified_Knowledge_Transfer_Network_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-24_A_Unified_Knowledge_Transfer_Network_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "dea92ce089809b5b9f3a57e3dbd176711c126bce", "publication_date": "2022-11-21", "title": "Parametric Classification for Generalized Category Discovery: A Baseline Study", "authors": "Xin Wen, Bingchen Zhao, Xiaojuan Qi", "venue": "IEEE International Conference on Computer Vision", "citation_count": 72, "influential_citation_count": 37, "abstract": "Generalized Category Discovery (GCD) aims to discover novel categories in unlabelled datasets using knowledge learned from labelled samples. Previous studies argued that parametric classifiers are prone to overfitting to seen categories, and endorsed using a non-parametric classifier formed with semi-supervised k-means. However, in this study, we investigate the failure of parametric classifiers, verify the effectiveness of previous design choices when high-quality supervision is available, and identify unreliable pseudo-labels as a key problem. We demonstrate that two prediction biases exist: the classifier tends to predict seen classes more often, and produces an imbalanced distribution across seen and novel categories. Based on these findings, we propose a simple yet effective parametric classification method that benefits from entropy regularisation, achieves state-of-the-art performance on multiple GCD benchmarks and shows strong robustness to unknown class numbers. We hope the investigation and proposed simple framework can serve as a strong baseline to facilitate future studies in this field. Our code is available at: https://github.com/CVMI-Lab/SimGCD.", "pdf_url": "https://arxiv.org/pdf/2211.11727.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-11-21_Parametric_Classification_for_Generalized_Category_Discovery__A_Baseline_Study.pdf", "markdown_path": "data/semantic/markdown_files/2022-11-21_Parametric_Classification_for_Generalized_Category_Discovery__A_Baseline_Study.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "7c5643e5e062859eb0e1a832813e3f392671d79b", "publication_date": "2024-05-31", "title": "Revisiting Mutual Information Maximization for Generalized Category Discovery", "authors": "Zhaorui Tan, Chengrui Zhang, Xi Yang, Jie Sun, Kaizhu Huang", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Generalized category discovery presents a challenge in a realistic scenario, which requires the model's generalization ability to recognize unlabeled samples from known and unknown categories. This paper revisits the challenge of generalized category discovery through the lens of information maximization (InfoMax) with a probabilistic parametric classifier. Our findings reveal that ensuring independence between known and unknown classes while concurrently assuming a uniform probability distribution across all classes, yields an enlarged margin among known and unknown classes that promotes the model's performance. To achieve the aforementioned independence, we propose a novel InfoMax-based method, Regularized Parametric InfoMax (RPIM), which adopts pseudo labels to supervise unlabeled samples during InfoMax, while proposing a regularization to ensure the quality of the pseudo labels. Additionally, we introduce novel semantic-bias transformation to refine the features from the pre-trained model instead of direct fine-tuning to rescue the computational costs. Extensive experiments on six benchmark datasets validate the effectiveness of our method. RPIM significantly improves the performance regarding unknown classes, surpassing the state-of-the-art method by an average margin of 3.5%.", "pdf_url": "https://arxiv.org/pdf/2405.20711.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-05-31_Revisiting_Mutual_Information_Maximization_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-31_Revisiting_Mutual_Information_Maximization_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "3517bf58099cbb4e424b7968d11d4ce09b5c5a5a", "publication_date": "2024-10-24", "title": "Prototypical Hash Encoding for On-the-Fly Fine-Grained Category Discovery", "authors": "Haiyang Zheng, Nan Pu, Wenjing Li, N. Sebe, Zhun Zhong", "venue": "Neural Information Processing Systems", "citation_count": 2, "influential_citation_count": 0, "abstract": "In this paper, we study a practical yet challenging task, On-the-fly Category Discovery (OCD), aiming to online discover the newly-coming stream data that belong to both known and unknown classes, by leveraging only known category knowledge contained in labeled data. Previous OCD methods employ the hash-based technique to represent old/new categories by hash codes for instance-wise inference. However, directly mapping features into low-dimensional hash space not only inevitably damages the ability to distinguish classes and but also causes\"high sensitivity\"issue, especially for fine-grained classes, leading to inferior performance. To address these issues, we propose a novel Prototypical Hash Encoding (PHE) framework consisting of Category-aware Prototype Generation (CPG) and Discriminative Category Encoding (DCE) to mitigate the sensitivity of hash code while preserving rich discriminative information contained in high-dimension feature space, in a two-stage projection fashion. CPG enables the model to fully capture the intra-category diversity by representing each category with multiple prototypes. DCE boosts the discrimination ability of hash code with the guidance of the generated category prototypes and the constraint of minimum separation distance. By jointly optimizing CPG and DCE, we demonstrate that these two components are mutually beneficial towards an effective OCD. Extensive experiments show the significant superiority of our PHE over previous methods, e.g., obtaining an improvement of +5.3% in ALL ACC averaged on all datasets. Moreover, due to the nature of the interpretable prototypes, we visually analyze the underlying mechanism of how PHE helps group certain samples into either known or unknown categories. Code is available at https://github.com/HaiyangZheng/PHE.", "pdf_url": "https://arxiv.org/pdf/2410.19213.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-24_Prototypical_Hash_Encoding_for_On-the-Fly_Fine-Grained_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-24_Prototypical_Hash_Encoding_for_On-the-Fly_Fine-Grained_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "78ca20ef7420354ff3c16d02d67094e6f91a515a", "publication_date": "2024-06-18", "title": "A Generic Method for Fine-grained Category Discovery in Natural Language Texts", "authors": "Chang Tian, M. Blaschko, Wenpeng Yin, Mingzhe Xing, Yinliang Yue, Marie-Francine Moens", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 2, "influential_citation_count": 0, "abstract": "Fine-grained category discovery using only coarse-grained supervision is a cost-effective yet challenging task. Previous training methods focus on aligning query samples with positive samples and distancing them from negatives. They often neglect intra-category and inter-category semantic similarities of fine-grained categories when navigating sample distributions in the embedding space. Furthermore, some evaluation techniques that rely on pre-collected test samples are inadequate for real-time applications. To address these shortcomings, we introduce a method that successfully detects fine-grained clusters of semantically similar texts guided by a novel objective function. The method uses semantic similarities in a logarithmic space to guide sample distributions in the Euclidean space and to form distinct clusters that represent fine-grained categories. We also propose a centroid inference mechanism to support real-time applications. The efficacy of the method is both theoretically justified and empirically confirmed on three benchmark tasks. The proposed objective function is integrated in multiple contrastive learning based neural models. Its results surpass existing state-of-the-art approaches in terms of Accuracy, Adjusted Rand Index and Normalized Mutual Information of the detected fine-grained categories. Code and data are publicly available at https://github.com/changtianluckyforever/F-grained-STAR.", "pdf_url": "https://arxiv.org/pdf/2406.13103.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-06-18_A_Generic_Method_for_Fine-grained_Category_Discovery_in_Natural_Language_Texts.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-18_A_Generic_Method_for_Fine-grained_Category_Discovery_in_Natural_Language_Texts.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "3ab62182ff9f4d59ad0970659f3b36693be540ae", "publication_date": "2024-04-08", "title": "CDAD-Net: Bridging Domain Gaps in Generalized Category Discovery", "authors": "Sai Bhargav Rongali, Sarthak Mehrotra, Ankit Jha, Mohamad Hassan N C, Shirsha Bose, Tanisha Gupta, M. Singha, Biplab Banerjee", "venue": "2024 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "citation_count": 2, "influential_citation_count": 0, "abstract": "In Generalized Category Discovery (GCD), we cluster unlabeled samples of known and novel classes, leveraging a training dataset of known classes. A salient challenge arises due to domain shifts between these datasets. To address this, we present a novel setting: Across Domain Generalized Category Discovery (AD-GCD) and bring forth CDAD-Net (Class Discoverer Across Domains) as a remedy. CDAD-Net is architected to synchronize potential known class samples across both the labeled (source) and unlabeled (target) datasets, while emphasizing the distinct categorization of the target data. To facilitate this, we propose an entropy-driven adversarial learning strategy that accounts for the distance distributions of target samples relative to source-domain class prototypes. Parallelly, the discriminative nature of the shared space is upheld through a fusion of three metric learning objectives. In the source domain, our focus is on refining the proximity between samples and their affiliated class prototypes, while in the target domain, we integrate a neighborhood-centric contrastive learning mechanism, enriched with an adept neighbors-mining approach. To further accentuate the nuanced feature interrelation among semantically aligned images, we champion the concept of conditional image inpainting, underscoring the premise that semantically analogous images prove more efficacious to the task than their disjointed counterparts. Experimentally, CDAD-Net eclipses existing literature with a performance increment of 8-15% on three AD-GCD benchmarks we present.", "pdf_url": "https://arxiv.org/pdf/2404.05366.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-08_CDAD-Net__Bridging_Domain_Gaps_in_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-08_CDAD-Net__Bridging_Domain_Gaps_in_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "d7c0e5cad9a36baf70241786dcb3963b5e9235ab", "publication_date": "2024-03-24", "title": "Semantic-Guided Novel Category Discovery", "authors": "Weishuai Wang, Ting Lei, Qingchao Chen, Yang Liu", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 1, "influential_citation_count": 0, "abstract": "The Novel Category Discovery problem aims to cluster an unlabeled set with the help of a labeled set consisting of disjoint but related classes. However, existing models treat class names as discrete one-hot labels and ignore the semantic understanding of these classes. In this paper, we propose a new setting named Semantic-guided Novel Category Discovery (SNCD), which requires the model to not only cluster the unlabeled images but also semantically recognize these images based on a set of their class names. The first challenge we confront pertains to effectively leveraging the class names of unlabeled images, given the inherent gap between the visual and linguistic domains. To address this issue, we incorporate a semantic-aware recognition mechanism. This is achieved by constructing dynamic class-wise visual prototypes as well as a semantic similarity matrix that enables the projection of visual features into the semantic space. The second challenge originates from the granularity disparity between the classification and clustering tasks. To deal with this, we develop a semantic-aware clustering process to facilitate the exchange of knowledge between the two tasks. Through extensive experiments, we demonstrate the mutual benefits of the recognition and clustering tasks, which can be jointly optimized. Experimental results on multiple datasets confirm the effectiveness of our proposed method. Our code is available at https://github.com/wang-weishuai/Semantic-guided-NCD.", "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/view/28371/28726", "pdf_filepath": "data/semantic/pdf_files/2024-03-24_Semantic-Guided_Novel_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-24_Semantic-Guided_Novel_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "57348e5783e8bd245da20b087252dc18a1060772", "publication_date": "2024-09-29", "title": "Flipped Classroom: Aligning Teacher Attention with Student in Generalized Category Discovery", "authors": "Haonan Lin, Wenbin An, Jiahao Wang, Yan Chen, Feng Tian, Mengmeng Wang, Guang Dai, Qianying Wang, Jingdong Wang", "venue": "Neural Information Processing Systems", "citation_count": 2, "influential_citation_count": 0, "abstract": "Recent advancements have shown promise in applying traditional Semi-Supervised Learning strategies to the task of Generalized Category Discovery (GCD). Typically, this involves a teacher-student framework in which the teacher imparts knowledge to the student to classify categories, even in the absence of explicit labels. Nevertheless, GCD presents unique challenges, particularly the absence of priors for new classes, which can lead to the teacher's misguidance and unsynchronized learning with the student, culminating in suboptimal outcomes. In our work, we delve into why traditional teacher-student designs falter in open-world generalized category discovery as compared to their success in closed-world semi-supervised learning. We identify inconsistent pattern learning across attention layers as the crux of this issue and introduce FlipClass, a method that dynamically updates the teacher to align with the student's attention, instead of maintaining a static teacher reference. Our teacher-student attention alignment strategy refines the teacher's focus based on student feedback from an energy perspective, promoting consistent pattern recognition and synchronized learning across old and new classes. Extensive experiments on a spectrum of benchmarks affirm that FlipClass significantly surpasses contemporary GCD methods, establishing new standards for the field.", "pdf_url": "https://arxiv.org/pdf/2409.19659.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-09-29_Flipped_Classroom__Aligning_Teacher_Attention_with_Student_in_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-29_Flipped_Classroom__Aligning_Teacher_Attention_with_Student_in_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "9bd31ad0df069f3f9c41affcb61d9c42dd3a13c3", "publication_date": "2024-08-24", "title": "Online Continuous Generalized Category Discovery", "authors": "Keon-Hee Park, Hakyung Lee, Kyungwoo Song, Gyeong-Moon Park", "venue": "European Conference on Computer Vision", "citation_count": 0, "influential_citation_count": 0, "abstract": "With the advancement of deep neural networks in computer vision, artificial intelligence (AI) is widely employed in real-world applications. However, AI still faces limitations in mimicking high-level human capabilities, such as novel category discovery, for practical use. While some methods utilizing offline continual learning have been proposed for novel category discovery, they neglect the continuity of data streams in real-world settings. In this work, we introduce Online Continuous Generalized Category Discovery (OCGCD), which considers the dynamic nature of data streams where data can be created and deleted in real time. Additionally, we propose a novel method, DEAN, Discovery via Energy guidance and feature AugmentatioN, which can discover novel categories in an online manner through energy-guided discovery and facilitate discriminative learning via energy-based contrastive loss. Furthermore, DEAN effectively pseudo-labels unlabeled data through variance-based feature augmentation. Experimental results demonstrate that our proposed DEAN achieves outstanding performance in proposed OCGCD scenario.", "pdf_url": "https://arxiv.org/pdf/2408.13492.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-08-24_Online_Continuous_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-08-24_Online_Continuous_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a7a64b100bd103d975024bc4c19cfb3ada6444fd", "publication_date": "2024-09-18", "title": "Multimodal Generalized Category Discovery", "authors": "Yuchang Su, Renping Zhou, Siyu Huang, Xingjian Li, Tianyang Wang, Ziyue Wang, Min Xu", "venue": "arXiv.org", "citation_count": 0, "influential_citation_count": 0, "abstract": "Generalized Category Discovery (GCD) aims to classify inputs into both known and novel categories, a task crucial for open-world scientific discoveries. However, current GCD methods are limited to unimodal data, overlooking the inherently multimodal nature of most real-world data. In this work, we extend GCD to a multimodal setting, where inputs from different modalities provide richer and complementary information. Through theoretical analysis and empirical validation, we identify that the key challenge in multimodal GCD lies in effectively aligning heterogeneous information across modalities. To address this, we propose MM-GCD, a novel framework that aligns both the feature and output spaces of different modalities using contrastive learning and distillation techniques. MM-GCD achieves new state-of-the-art performance on the UPMC-Food101 and N24News datasets, surpassing previous methods by 11.5\\% and 4.7\\%, respectively.", "pdf_url": "https://arxiv.org/pdf/2409.11624.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-09-18_Multimodal_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-18_Multimodal_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "cbecd51ad2e5a96df7ff475492a2837c914542ef", "publication_date": "2024", "title": "Open Set Recognition and Category Discovery Framework for SAR Target Classification Based on K-Contrast Loss and Deep Clustering", "authors": "Mingyao Chen, Jingyuan Xia, Tianpeng Liu, Li Liu, Yongxiang Liu", "venue": "IEEE Journal of Selected Topics in Applied Earth Observations and Remote Sensing", "citation_count": 8, "influential_citation_count": 0, "abstract": "Synthetic aperture radar automatic target recognition (SAR\u2009ATR) has been widely studied in recent years. Most ATR models are designed based on the traditional closed-set assumption. This type of ATR model can only identify target categories existing in the training set, and it will result in missed detection or misclassification of unseen target categories encountered in battlefield reconnaissance, posing a potential threat. Therefore, it is of great significance to design a model that can simultaneously achieve known class classification and unknown class judgment. In addition, researchers usually use the obtained unknown class data for model relearning to enable it to recognize new categories. However, before this process, it is necessary to manually interpret and annotate the obtained unknown class data, which undoubtedly requires a large time cost and is difficult to meet the timeliness requirements. To solve these problems, we propose a framework that integrates the open-set recognition module and the novel class discovery module. By introducing the K-contrast loss, the open-set recognition module can accurately distinguish unknown class data, classify known class data, and then transfer the known class knowledge through deep clustering for clustering annotation of unknown class data. Extensive experimental results on the MSTAR benchmark dataset demonstrate the effectiveness of the proposed methods.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "c2c114fb7747dc7eb240a8657a810ab229c4ee49", "publication_date": "2023-04-14", "title": "CiPR: An Efficient Framework with Cross-instance Positive Relations for Generalized Category Discovery", "authors": "Shaozhe Hao, Kai Han, Kwan-Yee K. Wong", "venue": "Trans. Mach. Learn. Res.", "citation_count": 17, "influential_citation_count": 3, "abstract": "We tackle the issue of generalized category discovery (GCD). GCD considers the open-world problem of automatically clustering a partially labelled dataset, in which the unlabelled data may contain instances from both novel categories and labelled classes. In this paper, we address the GCD problem with an unknown category number for the unlabelled data. We propose a framework, named CiPR, to bootstrap the representation by exploiting Cross-instance Positive Relations in the partially labelled data for contrastive learning, which have been neglected in existing methods. To obtain reliable cross-instance relations to facilitate representation learning, we introduce a semi-supervised hierarchical clustering algorithm, named selective neighbor clustering (SNC), which can produce a clustering hierarchy directly from the connected components of a graph constructed from selective neighbors. We further present a method to estimate the unknown class number using SNC with a joint reference score that considers clustering indexes of both labelled and unlabelled data, and extend SNC to allow label assignment for the unlabelled instances with a given class number. We thoroughly evaluate our framework on public generic image recognition datasets and challenging fine-grained datasets, and establish a new state-of-the-art. Code: https://github.com/haoosz/CiPR", "pdf_url": "https://arxiv.org/pdf/2304.06928.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-04-14_CiPR__An_Efficient_Framework_with_Cross-instance_Positive_Relations_for_Generalized_Category_Discove.pdf", "markdown_path": "data/semantic/markdown_files/2023-04-14_CiPR__An_Efficient_Framework_with_Cross-instance_Positive_Relations_for_Generalized_Category_Discove.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "4f818684a18fb8ebc62ad2f5bfe7d0ac53d93fe4", "publication_date": "2023-10-30", "title": "Learn to Categorize or Categorize to Learn? Self-Coding for Generalized Category Discovery", "authors": "Sarah Rastegar, Hazel Doughty, Cees G. M. Snoek", "venue": "Neural Information Processing Systems", "citation_count": 17, "influential_citation_count": 7, "abstract": "In the quest for unveiling novel categories at test time, we confront the inherent limitations of traditional supervised recognition models that are restricted by a predefined category set. While strides have been made in the realms of self-supervised and open-world learning towards test-time category discovery, a crucial yet often overlooked question persists: what exactly delineates a \\textit{category}? In this paper, we conceptualize a \\textit{category} through the lens of optimization, viewing it as an optimal solution to a well-defined problem. Harnessing this unique conceptualization, we propose a novel, efficient and self-supervised method capable of discovering previously unknown categories at test time. A salient feature of our approach is the assignment of minimum length category codes to individual data instances, which encapsulates the implicit category hierarchy prevalent in real-world datasets. This mechanism affords us enhanced control over category granularity, thereby equipping our model to handle fine-grained categories adeptly. Experimental evaluations, bolstered by state-of-the-art benchmark comparisons, testify to the efficacy of our solution in managing unknown categories at test time. Furthermore, we fortify our proposition with a theoretical foundation, providing proof of its optimality. Our code is available at: \\url{https://github.com/SarahRastegar/InfoSieve}.", "pdf_url": "https://arxiv.org/pdf/2310.19776.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-10-30_Learn_to_Categorize_or_Categorize_to_Learn__Self-Coding_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-10-30_Learn_to_Categorize_or_Categorize_to_Learn__Self-Coding_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "038ae50a186204163e501d066ab9af69b826be71", "publication_date": "2023-07-20", "title": "Proxy Anchor-based Unsupervised Learning for Continuous Generalized Category Discovery", "authors": "Hyungmin Kim, Sungho Suh, Daehwan Kim, Daun Jeong, Hansang Cho, Junmo Kim", "venue": "IEEE International Conference on Computer Vision", "citation_count": 12, "influential_citation_count": 5, "abstract": "Recent advances in deep learning have significantly improved the performance of various computer vision applications. However, discovering novel categories in an incremental learning scenario remains a challenging problem due to the lack of prior knowledge about the number and nature of new categories. Existing methods for novel category discovery are limited by their reliance on labeled datasets and prior knowledge about the number of novel categories and the proportion of novel samples in the batch. To address the limitations and more accurately reflect real-world scenarios, in this paper, we propose a novel unsupervised class incremental learning approach for discovering novel categories on unlabeled sets without prior knowledge. The proposed method fine-tunes the feature extractor and proxy anchors on labeled sets, then splits samples into old and novel categories and clusters on the unlabeled dataset. Furthermore, the proxy anchors-based exemplar generates representative category vectors to mitigate catastrophic forgetting. Experimental results demonstrate that our proposed approach outperforms the state-of-the-art methods on fine-grained datasets under real-world scenarios.", "pdf_url": "https://arxiv.org/pdf/2307.10943.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-07-20_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-07-20_Proxy_Anchor-based_Unsupervised_Learning_for_Continuous_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "22737ff95741b47251c1b15f4411e7fa93aeb504", "publication_date": "2023-06-01", "title": "On-the-Fly Category Discovery", "authors": "Ruoyi Du, Dongliang Chang, Kongming Liang, Timothy M. Hospedales, Yi-Zhe Song, Zhanyu Ma", "venue": "Computer Vision and Pattern Recognition", "citation_count": 12, "influential_citation_count": 3, "abstract": "Although machines have surpassed humans on visual recognition problems, they are still limited to providing closed-set answers. Unlike machines, humans can cognize novel categories at the first observation. Novel category discovery (NCD) techniques, transferring knowledge from seen categories to distinguish unseen categories, aim to bridge the gap. However, current NCD methods assume a transductive learning and offline inference paradigm, which restricts them to a predefined query set and renders them unable to deliver instant feedback. In this paper, we study on-the-fly category discovery (OCD) aimed at making the model instantaneously aware of novel category samples (i.e., enabling inductive learning and streaming inference). We first design a hash coding-based expandable recognition model as a practical baseline. Afterwards, noticing the sensitivity of hash codes to intra-category variance, we further propose a novel Sign-Magnitude dIsentangLEment (SMILE) architecture to alleviate the disturbance it brings. Our experimental results demonstrate the superiority of SMILE against our baseline model and prior art. Our code is available at https://github.com/PRIS-CV/On-the-fly-Category-Discovery.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "12a38b9fe713014812d33aafab82874614b11846", "publication_date": "2023-10-02", "title": "Towards Distribution-Agnostic Generalized Category Discovery", "authors": "Jianhong Bai, Zuo-Qiang Liu, Hualiang Wang, Ruizhe Chen, Lianrui Mu, Xiaomeng Li, J. Zhou, Yang Feng, Jian Wu, Haoji Hu", "venue": "Neural Information Processing Systems", "citation_count": 11, "influential_citation_count": 3, "abstract": "Data imbalance and open-ended distribution are two intrinsic characteristics of the real visual world. Though encouraging progress has been made in tackling each challenge separately, few works dedicated to combining them towards real-world scenarios. While several previous works have focused on classifying close-set samples and detecting open-set samples during testing, it's still essential to be able to classify unknown subjects as human beings. In this paper, we formally define a more realistic task as distribution-agnostic generalized category discovery (DA-GCD): generating fine-grained predictions for both close- and open-set classes in a long-tailed open-world setting. To tackle the challenging problem, we propose a Self-Balanced Co-Advice contrastive framework (BaCon), which consists of a contrastive-learning branch and a pseudo-labeling branch, working collaboratively to provide interactive supervision to resolve the DA-GCD task. In particular, the contrastive-learning branch provides reliable distribution estimation to regularize the predictions of the pseudo-labeling branch, which in turn guides contrastive learning through self-balanced knowledge transfer and a proposed novel contrastive loss. We compare BaCon with state-of-the-art methods from two closely related fields: imbalanced semi-supervised learning and generalized category discovery. The effectiveness of BaCon is demonstrated with superior performance over all baselines and comprehensive analysis across various datasets. Our code is publicly available.", "pdf_url": "https://arxiv.org/pdf/2310.01376.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-10-02_Towards_Distribution-Agnostic_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-10-02_Towards_Distribution-Agnostic_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "47f97856e4890b9d96daa5dfdf008eda148e0d70", "publication_date": "2023-12-18", "title": "Generalized Category Discovery with Large Language Models in the Loop", "authors": "Wenbin An, Wenkai Shi, Feng Tian, Haonan Lin, Qianying Wang, Y. Wu, Mingxiang Cai, Luyan Wang, Yan Chen, Haiping Zhu, Ping Chen", "venue": "Annual Meeting of the Association for Computational Linguistics", "citation_count": 11, "influential_citation_count": 4, "abstract": "Generalized Category Discovery (GCD) is a crucial task that aims to recognize both known and novel categories from a set of unlabeled data by utilizing a few labeled data with only known categories. Due to the lack of supervision and category information, current methods usually perform poorly on novel categories and struggle to reveal semantic meanings of the discovered clusters, which limits their applications in the real world. To mitigate the above issues, we propose Loop, an end-to-end active-learning framework that introduces Large Language Models (LLMs) into the training loop, which can boost model performance and generate category names without relying on any human efforts. Specifically, we first propose Local Inconsistent Sampling (LIS) to select samples that have a higher probability of falling to wrong clusters, based on neighborhood prediction consistency and entropy of cluster assignment probabilities. Then we propose a Scalable Query strategy to allow LLMs to choose true neighbors of the selected samples from multiple candidate samples. Based on the feedback from LLMs, we perform Refined Neighborhood Contrastive Learning (RNCL) to pull samples and their neighbors closer to learn clustering-friendly representations. Finally, we select representative samples from clusters corresponding to novel categories to allow LLMs to generate category names for them. Extensive experiments on three benchmark datasets show that Loop outperforms SOTA models by a large margin and generates accurate category names for the discovered clusters. Code and data are available at https://github.com/Lackel/LOOP.", "pdf_url": "https://arxiv.org/pdf/2312.10897.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-18_Generalized_Category_Discovery_with_Large_Language_Models_in_the_Loop.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-18_Generalized_Category_Discovery_with_Large_Language_Models_in_the_Loop.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "cb7c09307f3e628d5c132734cb1be0b32eb3bafe", "publication_date": "2023-05-17", "title": "CLIP-GCD: Simple Language Guided Generalized Category Discovery", "authors": "Rabah Ouldnoughi, Chia-Wen Kuo, Z. Kira", "venue": "arXiv.org", "citation_count": 14, "influential_citation_count": 0, "abstract": "Generalized Category Discovery (GCD) requires a model to both classify known categories and cluster unknown categories in unlabeled data. Prior methods leveraged self-supervised pre-training combined with supervised fine-tuning on the labeled data, followed by simple clustering methods. In this paper, we posit that such methods are still prone to poor performance on out-of-distribution categories, and do not leverage a key ingredient: Semantic relationships between object categories. We therefore propose to leverage multi-modal (vision and language) models, in two complementary ways. First, we establish a strong baseline by replacing uni-modal features with CLIP, inspired by its zero-shot performance. Second, we propose a novel retrieval-based mechanism that leverages CLIP's aligned vision-language representations by mining text descriptions from a text corpus for the labeled and unlabeled set. We specifically use the alignment between CLIP's visual encoding of the image and textual encoding of the corpus to retrieve top-k relevant pieces of text and incorporate their embeddings to perform joint image+text semi-supervised clustering. We perform rigorous experimentation and ablations (including on where to retrieve from, how much to retrieve, and how to combine information), and validate our results on several datasets including out-of-distribution domains, demonstrating state-of-art results.", "pdf_url": "https://arxiv.org/pdf/2305.10420.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-05-17_CLIP-GCD__Simple_Language_Guided_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-05-17_CLIP-GCD__Simple_Language_Guided_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "f8cceaafe5aca25808ced4a18dd77adbdb18aeeb", "publication_date": "2023-05-23", "title": "Federated Generalized Category Discovery", "authors": "Nan Pu, Zhun Zhong, Xinyuan Ji, N. Sebe", "venue": "Computer Vision and Pattern Recognition", "citation_count": 13, "influential_citation_count": 0, "abstract": "Generalized category discovery (GCD) aims at grouping unlabeled samples from known and unknown classes, given labeled data of known classes. To meet the recent decen-tralization trend in the community, we introduce a practical yet challenging task, Federated GCD (Fed-GCD), where the training data are distributed among local clients and cannot be shared among clients. Fed-GCD aims to train a generic GCD model by client collaboration under the privacy-protected constraint. The Fed-GCD leads to two challenges: 1) representation degradation caused by training each client model with fewer data than centralized GCD learning, and 2) highly heterogeneous label spaces across different clients. To this end, we propose a novel Asso-ciated Gaussian Contrastive Learning (AGCL) framework based on learnable GMMs, which consists of a Client Se-mantics Association (CSA) and a global-local GMM Contrastive Learning (GCL). On the server, CSA aggregates the heterogeneous categories of local-client GMMs to generate a global GMM containing more comprehensive category knowledge. On each client, GCL builds class-level contrastive learning with both local and global GMMs. The local GCL learns robust representation with limited local data. The global GCL encourages the model to produce more discriminative representation with the comprehensive category relationships that may not exist in local data. We build a benchmark based on six visual datasets to facilitate the study of Fed-GCD. Extensive experiments show that our AGCL outperforms multiple baselines on all datasets. Code is available at https://github.com/TPCD/FedGCD.", "pdf_url": "https://arxiv.org/pdf/2305.14107.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-05-23_Federated_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-05-23_Federated_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "be817cd931182d516569768be888bd3631c13d4a", "publication_date": "2023-12-27", "title": "Transfer and Alignment Network for Generalized Category Discovery", "authors": "Wenbin An, Feng Tian, Wenkai Shi, Yan Chen, Y. Wu, Qianying Wang, Ping Chen", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 10, "influential_citation_count": 2, "abstract": "Generalized Category Discovery (GCD) is a crucial real-world task that aims to recognize both known and novel categories from an unlabeled dataset by leveraging another labeled dataset with only known categories. Despite the improved performance on known categories, current methods perform poorly on novel categories. We attribute the poor performance to two reasons: biased knowledge transfer between labeled and unlabeled data and noisy representation learning on the unlabeled data. The former leads to unreliable estimation of learning targets for novel categories and the latter hinders models from learning discriminative features. To mitigate these two issues, we propose a Transfer and Alignment Network (TAN), which incorporates two knowledge transfer mechanisms to calibrate the biased knowledge and two feature alignment mechanisms to learn discriminative features.\nSpecifically, we model different categories with prototypes and transfer the prototypes in labeled data to correct model bias towards known categories. On the one hand, we pull instances with known categories in unlabeled data closer to these prototypes to form more compact clusters and avoid boundary overlap between known and novel categories. On the other hand, we use these prototypes to calibrate noisy prototypes estimated from unlabeled data based on category similarities, which allows for more accurate estimation of prototypes for novel categories that can be used as reliable learning targets later. After knowledge transfer, we further propose two feature alignment mechanisms to acquire both instance- and category-level knowledge from unlabeled data by aligning instance features with both augmented features and the calibrated prototypes, which can boost model performance on both known and novel categories with less noise. Experiments on three benchmark datasets show that our model outperforms SOTA methods, especially on novel categories. Theoretical analysis is provided for an in-depth understanding of our model in general.\nOur code and data are available at https://github.com/Lackel/TAN.", "pdf_url": "https://arxiv.org/pdf/2312.16467.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-27_Transfer_and_Alignment_Network_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-27_Transfer_and_Alignment_Network_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "e79da14432e594590cf43e0f245d4e35aa6eb301", "publication_date": "2023-11-20", "title": "Generalized Category Discovery in Semantic Segmentation", "authors": "Zhengyuan Peng, Qijian Tian, Jianqing Xu, Yizhang Jin, Xuequan Lu, Xin Tan, Yuan Xie, Lizhuang Ma", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "This paper explores a novel setting called Generalized Category Discovery in Semantic Segmentation (GCDSS), aiming to segment unlabeled images given prior knowledge from a labeled set of base classes. The unlabeled images contain pixels of the base class or novel class. In contrast to Novel Category Discovery in Semantic Segmentation (NCDSS), there is no prerequisite for prior knowledge mandating the existence of at least one novel class in each unlabeled image. Besides, we broaden the segmentation scope beyond foreground objects to include the entire image. Existing NCDSS methods rely on the aforementioned priors, making them challenging to truly apply in real-world situations. We propose a straightforward yet effective framework that reinterprets the GCDSS challenge as a task of mask classification. Additionally, we construct a baseline method and introduce the Neighborhood Relations-Guided Mask Clustering Algorithm (NeRG-MaskCA) for mask categorization to address the fragmentation in semantic representation. A benchmark dataset, Cityscapes-GCD, derived from the Cityscapes dataset, is established to evaluate the GCDSS framework. Our method demonstrates the feasibility of the GCDSS problem and the potential for discovering and segmenting novel object classes in unlabeled images. We employ the generated pseudo-labels from our approach as ground truth to supervise the training of other models, thereby enabling them with the ability to segment novel classes. It paves the way for further research in generalized category discovery, broadening the horizons of semantic segmentation and its applications. For details, please visit https://github.com/JethroPeng/GCDSS", "pdf_url": "https://arxiv.org/pdf/2311.11525.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-11-20_Generalized_Category_Discovery_in_Semantic_Segmentation.pdf", "markdown_path": "data/semantic/markdown_files/2023-11-20_Generalized_Category_Discovery_in_Semantic_Segmentation.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "14618099f2d150b289e95996cab1d3f9a9695cb0", "publication_date": "2023-12-04", "title": "ImbaGCD: Imbalanced Generalized Category Discovery", "authors": "Ziyun Li, Ben Dai, Furkan Simsek, Christoph Meinel, Haojin Yang", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "Generalized class discovery (GCD) aims to infer known and unknown categories in an unlabeled dataset leveraging prior knowledge of a labeled set comprising known classes. Existing research implicitly/explicitly assumes that the frequency of occurrence for each category, whether known or unknown, is approximately the same in the unlabeled data. However, in nature, we are more likely to encounter known/common classes than unknown/uncommon ones, according to the long-tailed property of visual classes. Therefore, we present a challenging and practical problem, Imbalanced Generalized Category Discovery (ImbaGCD), where the distribution of unlabeled data is imbalanced, with known classes being more frequent than unknown ones. To address these issues, we propose ImbaGCD, A novel optimal transport-based expectation maximization framework that accomplishes generalized category discovery by aligning the marginal class prior distribution. ImbaGCD also incorporates a systematic mechanism for estimating the imbalanced class prior distribution under the GCD setup. Our comprehensive experiments reveal that ImbaGCD surpasses previous state-of-the-art GCD methods by achieving an improvement of approximately 2 - 4% on CIFAR-100 and 15 - 19% on ImageNet-100, indicating its superior effectiveness in solving the Imbalanced GCD problem.", "pdf_url": "https://arxiv.org/pdf/2401.05353.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-04_ImbaGCD__Imbalanced_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-04_ImbaGCD__Imbalanced_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "727c52baabd1f75f4bd5768c486b9aa712e62f5a", "publication_date": "2023-10-30", "title": "Generalized Category Discovery with Clustering Assignment Consistency", "authors": "Xiangli Yang, Xinglin Pan, Irwin King, Zenglin Xu", "venue": "International Conference on Neural Information Processing", "citation_count": 2, "influential_citation_count": 0, "abstract": "Generalized category discovery (GCD) is a recently proposed open-world task. Given a set of images consisting of labeled and unlabeled instances, the goal of GCD is to automatically cluster the unlabeled samples using information transferred from the labeled dataset. The unlabeled dataset comprises both known and novel classes. The main challenge is that unlabeled novel class samples and unlabeled known class samples are mixed together in the unlabeled dataset. To address the GCD without knowing the class number of unlabeled dataset, we propose a co-training-based framework that encourages clustering consistency. Specifically, we first introduce weak and strong augmentation transformations to generate two sufficiently different views for the same sample. Then, based on the co-training assumption, we propose a consistency representation learning strategy, which encourages consistency between feature-prototype similarity and clustering assignment. Finally, we use the discriminative embeddings learned from the semi-supervised representation learning process to construct an original sparse network and use a community detection method to obtain the clustering results and the number of categories simultaneously. Extensive experiments show that our method achieves state-of-the-art performance on three generic benchmarks and three fine-grained visual recognition datasets. Especially in the ImageNet-100 data set, our method significantly exceeds the best baseline by 15.5\\% and 7.0\\% on the \\texttt{Novel} and \\texttt{All} classes, respectively.", "pdf_url": "https://arxiv.org/pdf/2310.19210.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-10-30_Generalized_Category_Discovery_with_Clustering_Assignment_Consistency.pdf", "markdown_path": "data/semantic/markdown_files/2023-10-30_Generalized_Category_Discovery_with_Clustering_Assignment_Consistency.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "2d41c762d7acd024d9ea2063d7ec5b2a50fbfbd8", "publication_date": "2023-08-23", "title": "Category Adaptation Meets Projected Distillation in Generalized Continual Category Discovery", "authors": "Grzegorz Rype's'c, Daniel Marczak, Sebastian Cygert, Tomasz Trzci'nski, Bart\u0142omiej Twardowski", "venue": "European Conference on Computer Vision", "citation_count": 3, "influential_citation_count": 0, "abstract": "Generalized Continual Category Discovery (GCCD) tackles learning from sequentially arriving, partially labeled datasets while uncovering new categories. Traditional methods depend on feature distillation to prevent forgetting the old knowledge. However, this strategy restricts the model's ability to adapt and effectively distinguish new categories. To address this, we introduce a novel technique integrating a learnable projector with feature distillation, thus enhancing model adaptability without sacrificing past knowledge. The resulting distribution shift of the previously learned categories is mitigated with the auxiliary category adaptation network. We demonstrate that while each component offers modest benefits individually, their combination - dubbed CAMP (Category Adaptation Meets Projected distillation) - significantly improves the balance between learning new information and retaining old. CAMP exhibits superior performance across several GCCD and Class Incremental Learning scenarios. The code is available at https://github.com/grypesc/CAMP.", "pdf_url": "https://arxiv.org/pdf/2308.12112.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-08-23_Category_Adaptation_Meets_Projected_Distillation_in_Generalized_Continual_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-23_Category_Adaptation_Meets_Projected_Distillation_in_Generalized_Continual_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "0ad71b85c9a3372de75508a503e4868615c40528", "publication_date": "2023", "title": "Generalized Continual Category Discovery", "authors": "Daniel Marczak, Grzegorz Rypesc, Sebastian Cygert, Tomasz Trzcinski, Bart\u0142omiej Twardowski", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 1, "abstract": "Most of Continual Learning (CL) methods push the limit of supervised learning settings, where an agent is expected to learn new labeled tasks and not forget previous knowledge. However, these settings are not well aligned with real-life scenarios, where a learning agent has access to a vast amount of unlabeled data encompassing both novel (entirely unlabeled) classes and examples from known classes. Drawing inspiration from Generalized Category Discovery (GCD), we introduce a novel framework that relaxes this assumption. Precisely, in any task, we allow for the existence of novel and known classes, and one must use continual version of unsupervised learning methods to discover them. We call this setting Generalized Continual Category Discovery (GCCD). It uni \ufb01 es CL and GCD, bridging the gap between synthetic benchmarks and real-life scenarios. With a series of experiments, we present that existing methods fail to accumulate knowledge from subsequent tasks in which unlabeled samples of novel classes are present. In light of these limitations, we propose a method that incorporates both supervised and unsupervised signals and mitigates the forgetting through the use of centroid adaptation. Our method surpasses strong CL methods adopted for GCD techniques and presents a superior representation learning performance.", "pdf_url": "https://arxiv.org/abs/2308.12112/pdf/2308.12112", "pdf_filepath": "data/semantic/pdf_files/2023_Generalized_Continual_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2023_Generalized_Continual_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "d591a4510cd5b44a0e3d362fd255f706867740fc", "publication_date": "2022-12-11", "title": "PromptCAL: Contrastive Affinity Learning via Auxiliary Prompts for Generalized Novel Category Discovery", "authors": "Shengxiang Zhang, Salman A. Khan, Zhiqiang Shen, Muzammal Naseer, Guangyi Chen, F. Khan", "venue": "Computer Vision and Pattern Recognition", "citation_count": 59, "influential_citation_count": 7, "abstract": "Although existing semi-supervised learning models achieve remarkable success in learning with unannotated in-distribution data, they mostly fail to learn on unlabeled data sampled from novel semantic classes due to their closed-set assumption. In this work, we target a pragmatic but under-explored Generalized Novel Category Discovery (GNCD) setting. The GNCD setting aims to categorize unlabeled training data coming from known and novel classes by leveraging the information of partially labeled known classes. We propose a two-stage Contrastive Affinity Learning method with auxiliary visual Prompts, dubbed PromptCAL, to address this challenging problem. Our approach discovers reliable pairwise sample affinities to learn better semantic clustering of both known and novel classes for the class token and visual prompts. First, we propose a discriminative prompt regularization loss to reinforce semantic discriminativeness of prompt-adapted pre-trained vision transformer for refined affinity relationships. Besides, we propose contrastive affinity learning to calibrate semantic representations based on our iterative semi-supervised affinity graph generation method for semantically-enhanced supervision. Extensive experimental evaluation demonstrates that our PromptCAL method is more effective in discovering novel classes even with limited annotations and surpasses the current state-of-the-art on generic and fine-grained benchmarks (e.g., with nearly 11% gain on CUB-200, and 9% on ImageNet-100) on overall accuracy. Our code is available at https://github.com/sheng-eatamath/PromptCAL.", "pdf_url": "https://arxiv.org/pdf/2212.05590.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-12-11_PromptCAL__Contrastive_Affinity_Learning_via_Auxiliary_Prompts_for_Generalized_Novel_Category_Discov.pdf", "markdown_path": "data/semantic/markdown_files/2022-12-11_PromptCAL__Contrastive_Affinity_Learning_via_Auxiliary_Prompts_for_Generalized_Novel_Category_Discov.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "9a6f06a7a03380a09e7bee185054d9bac9c32ac9", "publication_date": "2022-11-28", "title": "Generalized Category Discovery with Decoupled Prototypical Network", "authors": "Wenbin An, Feng Tian, Qinghua Zheng, Wei Ding, Qianying Wang, Ping Chen", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 45, "influential_citation_count": 5, "abstract": "Generalized Category Discovery (GCD) aims to recognize both known and novel categories from a set of unlabeled data, based on another dataset labeled with only known categories. Without considering differences between known and novel categories, current methods learn about them in a coupled manner, which can hurt model's generalization and discriminative ability. Furthermore, the coupled training approach prevents these models transferring category-specific knowledge explicitly from labeled data to unlabeled data, which can lose high-level semantic information and impair model performance. To mitigate above limitations, we present a novel model called Decoupled Prototypical Network (DPN). By formulating a bipartite matching problem for category prototypes, DPN can not only decouple known and novel categories to achieve different training targets effectively, but also align known categories in labeled and unlabeled data to transfer category-specific knowledge explicitly and capture high-level semantics. Furthermore, DPN can learn more discriminative features for both known and novel categories through our proposed Semantic-aware Prototypical Learning (SPL). Besides capturing meaningful semantic information, SPL can also alleviate the noise of hard pseudo labels through semantic-weighted soft assignment. Extensive experiments show that DPN outperforms state-of-the-art models by a large margin on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/Lackel/DPN.", "pdf_url": "https://arxiv.org/pdf/2211.15115.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-11-28_Generalized_Category_Discovery_with_Decoupled_Prototypical_Network.pdf", "markdown_path": "data/semantic/markdown_files/2022-11-28_Generalized_Category_Discovery_with_Decoupled_Prototypical_Network.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "f9025048aec2fcb4f2ba26f2bd46a618711beee9", "publication_date": "2022-08-03", "title": "XCon: Learning with Experts for Fine-grained Category Discovery", "authors": "Yixin Fei, Zhongkai Zhao, S. Yang, Bingchen Zhao", "venue": "British Machine Vision Conference", "citation_count": 39, "influential_citation_count": 7, "abstract": "We address the problem of generalized category discovery (GCD) in this paper, i.e. clustering the unlabeled images leveraging the information from a set of seen classes, where the unlabeled images could contain both seen classes and unseen classes. The seen classes can be seen as an implicit criterion of classes, which makes this setting different from unsupervised clustering where the cluster criteria may be ambiguous. We mainly concern the problem of discovering categories within a fine-grained dataset since it is one of the most direct applications of category discovery, i.e. helping experts discover novel concepts within an unlabeled dataset using the implicit criterion set forth by the seen classes. State-of-the-art methods for generalized category discovery leverage contrastive learning to learn the representations, but the large inter-class similarity and intra-class variance pose a challenge for the methods because the negative examples may contain irrelevant cues for recognizing a category so the algorithms may converge to a local-minima. We present a novel method called Expert-Contrastive Learning (XCon) to help the model to mine useful information from the images by first partitioning the dataset into sub-datasets using k-means clustering and then performing contrastive learning on each of the sub-datasets to learn fine-grained discriminative features. Experiments on fine-grained datasets show a clear improved performance over the previous best methods, indicating the effectiveness of our method.", "pdf_url": "https://arxiv.org/pdf/2208.01898.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-08-03_XCon__Learning_with_Experts_for_Fine-grained_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2022-08-03_XCon__Learning_with_Experts_for_Fine-grained_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "2956f0763b01212c14ef028aabc5a22133490993", "publication_date": "2021-07-07", "title": "Novel Visual Category Discovery with Dual Ranking Statistics and Mutual Knowledge Distillation", "authors": "Bingchen Zhao, Kai Han", "venue": "Neural Information Processing Systems", "citation_count": 107, "influential_citation_count": 11, "abstract": "In this paper, we tackle the problem of novel visual category discovery, i.e., grouping unlabelled images from new classes into different semantic partitions by leveraging a labelled dataset that contains images from other different but relevant categories. This is a more realistic and challenging setting than conventional semi-supervised learning. We propose a two-branch learning framework for this problem, with one branch focusing on local part-level information and the other branch focusing on overall characteristics. To transfer knowledge from the labelled data to the unlabelled, we propose using dual ranking statistics on both branches to generate pseudo labels for training on the unlabelled data. We further introduce a mutual knowledge distillation method to allow information exchange and encourage agreement between the two branches for discovering new categories, allowing our model to enjoy the benefits of global and local features. We comprehensively evaluate our method on public benchmarks for generic object classification, as well as the more challenging datasets for fine-grained visual recognition, achieving state-of-the-art performance.", "pdf_url": "https://arxiv.org/pdf/2107.03358.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-07-07_Novel_Visual_Category_Discovery_with_Dual_Ranking_Statistics_and_Mutual_Knowledge_Distillation.pdf", "markdown_path": "data/semantic/markdown_files/2021-07-07_Novel_Visual_Category_Discovery_with_Dual_Ranking_Statistics_and_Mutual_Knowledge_Distillation.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "99b3046c43706e0c6f2de6be32cde9f074cd82b3", "publication_date": "2022", "title": "A Simple Parametric Classification Baseline for Generalized Category Discovery", "authors": "Xin Wen, Bingchen Zhao, Xiaojuan Qi", "venue": "arXiv.org", "citation_count": 13, "influential_citation_count": 5, "abstract": "Generalized category discovery (GCD) is a problem setting where the goal is to discover novel categories within an unlabelled dataset using the knowledge learned from a set of labelled samples. Recent works in GCD argue that a non-parametric classi\ufb01er formed using semi-supervised k - means can outperform strong baselines which use parametric classi\ufb01ers as it can alleviate the over-\ufb01tting to seen categories in the labelled set. In this paper, we revisit the reason that makes previous parametric classi\ufb01ers fail to recognise new classes for GCD. By investigating the design choices of parametric classi\ufb01ers from the perspective of model architecture, representation learning, and classi\ufb01er learning, we conclude that the less discriminative representations and unreliable pseudo-labelling strategy are key factors that make parametric classi\ufb01ers lag behind non-parametric ones. Motivated by our investigation, we present a simple yet effective parametric classi\ufb01cation baseline that out-performs the previous best methods by a large margin on multiple popular GCD benchmarks. We hope the investigations and the simple baseline can serve as a corner-stone to facilitate future", "pdf_url": "https://arxiv.org/abs/2211.11727/pdf/2211.11727", "pdf_filepath": "data/semantic/pdf_files/2022_A_Simple_Parametric_Classification_Baseline_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2022_A_Simple_Parametric_Classification_Baseline_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "d078a0fb395c4c964123790873c8c748a2a73463", "publication_date": "2022-10-14", "title": "Fine-grained Category Discovery under Coarse-grained supervision with Hierarchical Weighted Self-contrastive Learning", "authors": "Wenbin An, Feng Tian, Ping Chen, Siliang Tang, Qinghua Zheng, Qianying Wang", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 17, "influential_citation_count": 3, "abstract": "Novel category discovery aims at adapting models trained on known categories to novel categories. Previous works only focus on the scenario where known and novel categories are of the same granularity.In this paper, we investigate a new practical scenario called Fine-grained Category Discovery under Coarse-grained supervision (FCDC). FCDC aims at discovering fine-grained categories with only coarse-grained labeled data, which can adapt models to categories of different granularity from known ones and reduce significant labeling cost. It is also a challenging task since supervised training on coarse-grained categories tends to focus on inter-class distance (distance between coarse-grained classes) but ignore intra-class distance (distance between fine-grained sub-classes) which is essential for separating fine-grained categories.Considering most current methods cannot transfer knowledge from coarse-grained level to fine-grained level, we propose a hierarchical weighted self-contrastive network by building a novel weighted self-contrastive module and combining it with supervised learning in a hierarchical manner.Extensive experiments on public datasets show both effectiveness and efficiency of our model over compared methods.", "pdf_url": "https://arxiv.org/pdf/2210.07733.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-10-14_Fine-grained_Category_Discovery_under_Coarse-grained_supervision_with_Hierarchical_Weighted_Self-con.pdf", "markdown_path": "data/semantic/markdown_files/2022-10-14_Fine-grained_Category_Discovery_under_Coarse-grained_supervision_with_Hierarchical_Weighted_Self-con.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "25146c373586d31645782b0656e541e0dd567080", "publication_date": "2022-12-01", "title": "Parametric Information Maximization for Generalized Category Discovery", "authors": "Florent Chiaroni, J. Dolz, Imtiaz Masud Ziko, A. Mitiche, Ismail Ben Ayed", "venue": "IEEE International Conference on Computer Vision", "citation_count": 16, "influential_citation_count": 2, "abstract": "We introduce a Parametric Information Maximization (PIM) model for the Generalized Category Discovery (GCD) problem. Specifically, we propose a bi-level optimization formulation, which explores a parameterized family of objective functions, each evaluating a weighted mutual information between the features and the latent labels, subject to supervision constraints from the labeled samples. Our formulation mitigates the class-balance bias encoded in standard information maximization approaches, thereby handling effectively both short-tailed and long-tailed data sets. We report extensive experiments and comparisons demonstrating that our PIM model consistently sets new state-of-the-art performances in GCD across six different datasets, more so when dealing with challenging fine-grained problems. Our code: https://github.com/ThalesGroup/pim-generalized-category-discovery.", "pdf_url": "https://arxiv.org/pdf/2212.00334.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-12-01_Parametric_Information_Maximization_for_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2022-12-01_Parametric_Information_Maximization_for_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "b844c23a08b23a768acdc130e05632d45bba2e9d", "publication_date": "2022-11-21", "title": "Boosting Novel Category Discovery Over Domains with Soft Contrastive Learning and All in One Classifier", "authors": "Z. Zang, Lei Shang, Senqiao Yang, Fei Wang, Baigui Sun, Xuansong Xie, Stan Z. Li", "venue": "IEEE International Conference on Computer Vision", "citation_count": 14, "influential_citation_count": 2, "abstract": "Unsupervised domain adaptation (UDA) has proven to be highly effective in transferring knowledge from a label-rich source domain to a label-scarce target domain. However, the presence of additional novel categories in the target domain has led to the development of open-set domain adaptation (ODA) and universal domain adaptation (UNDA). Existing ODA and UNDA methods treat all novel categories as a single, unified unknown class and attempt to detect it during training. However, we found that domain variance can lead to more significant view-noise in unsupervised data augmentation, which affects the effectiveness of contrastive learning (CL) and causes the model to be overconfident in novel category discovery. To address these issues, a framework named Soft-contrastive All-in-one Network (SAN) is proposed for ODA and UNDA tasks. SAN includes a novel data-augmentation-based soft contrastive learning (SCL) loss to fine-tune the backbone for feature transfer and a more human-intuitive classifier to improve new class discovery capability. The SCL loss weakens the adverse effects of the data augmentation view-noise problem which is amplified in domain transfer tasks. The All-in-One (AIO) classifier overcomes the overconfidence problem of current mainstream closed-set and open-set classifiers. Visualization and ablation experiments demonstrate the effectiveness of the proposed innovations. Furthermore, extensive experiment results on ODA and UNDA show that SAN outperforms existing state-of-the-art methods.", "pdf_url": "https://arxiv.org/pdf/2211.11262.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-11-21_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_and_All_in_One_Classif.pdf", "markdown_path": "data/semantic/markdown_files/2022-11-21_Boosting_Novel_Category_Discovery_Over_Domains_with_Soft_Contrastive_Learning_and_All_in_One_Classif.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "e8bc2dd1321e295c6a9499f00cdc2ede38917d52", "publication_date": "2022-01-24", "title": "Residual Tuning: Toward Novel Category Discovery Without Labels", "authors": "Yu Liu, T. Tuytelaars", "venue": "IEEE Transactions on Neural Networks and Learning Systems", "citation_count": 26, "influential_citation_count": 7, "abstract": "Discovering novel visual categories from a set of unlabeled images is a crucial and essential capability for intelligent vision systems since it enables them to automatically learn new concepts with no need for human-annotated supervision anymore. To tackle this problem, existing approaches first pretrain a neural network with a set of labeled images and then fine-tune the network to cluster unlabeled images into a few categorical groups. However, their unified feature representation hits a tradeoff bottleneck between feature preservation on labeled data and feature adaptation on unlabeled data. To circumvent this bottleneck, we propose a residual-tuning approach, which estimates a new residual feature from the pretrained network and adds it with a previous basic feature to compute the clustering objective together. Our disentangled representation approach facilitates adjusting visual representations for unlabeled images and overcoming forgetting old knowledge acquired from labeled images, with no need of replaying the labeled images again. In addition, residual-tuning is an efficient solution, adding few parameters and consuming modest training time. Our results on three common benchmarks show consistent and considerable gains over other state-of-the-art methods, and further reduce the performance gap to the fully supervised learning setup. Moreover, we explore two extended scenarios, including using fewer labeled classes and continually discovering more unlabeled sets, where the results further signify the advantages and effectiveness of our residual-tuning approach against previous approaches. Our code is available at https://github.com/liuyudut/ResTune.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "8abf6dfb00aeada6473a857ccbe752f4a187235d", "publication_date": "2021-04-26", "title": "Joint Representation Learning and Novel Category Discovery on Single- and Multi-modal Data", "authors": "Xu Jia, Kai Han, Yukun Zhu, Bradley Green", "venue": "IEEE International Conference on Computer Vision", "citation_count": 58, "influential_citation_count": 4, "abstract": "This paper studies the problem of novel category discovery on single- and multi-modal data with labels from different but relevant categories. We present a generic, end-to-end framework to jointly learn a reliable representation and assign clusters to unlabelled data. To avoid over-fitting the learnt embedding to labelled data, we take inspiration from self-supervised representation learning by noise-contrastive estimation and extend it to jointly handle labelled and unlabelled data. In particular, we propose using category discrimination on labelled data and cross-modal discrimination on multi-modal data to augment instance discrimination used in conventional contrastive learning approaches. We further employ Winner-Take-All (WTA) hashing algorithm on the shared representation space to generate pairwise pseudo labels for unlabelled data to better predict cluster assignments. We thoroughly evaluate our framework on large-scale multi-modal video benchmarks Kinetics-400 and VGG-Sound, and image benchmarks CIFAR10, CIFAR100 and ImageNet, obtaining state-of-the-art results.", "pdf_url": "https://arxiv.org/pdf/2104.12673.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-04-26_Joint_Representation_Learning_and_Novel_Category_Discovery_on_Single-_and_Multi-modal_Data.pdf", "markdown_path": "data/semantic/markdown_files/2021-04-26_Joint_Representation_Learning_and_Novel_Category_Discovery_on_Single-_and_Multi-modal_Data.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "5641cf2602d0bd119d67bff71e5ea8e193d5e377", "publication_date": "2022-06-28", "title": "Self-Labeling Framework for Novel Category Discovery over Domains", "authors": "Qing Yu, Daiki Ikami, Go Irie, K. Aizawa", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 26, "influential_citation_count": 2, "abstract": "Unsupervised domain adaptation (UDA) has been highly successful in transferring knowledge acquired from a label-rich source domain to a label-scarce target domain. Open-set domain adaptation (open-set DA) and universal domain adaptation (UniDA) have been proposed as solutions to the problem concerning the presence of additional novel categories in the target domain. Existing open-set DA and UniDA approaches treat all novel categories as one unified unknown class and attempt to detect this unknown class during the training process. However, the features of the novel categories learned by these methods are not discriminative. This limits the applicability of UDA in the further classification of these novel categories into their original categories, rather than assigning them to a single unified class. In this paper, we propose a self-labeling framework to cluster all target samples, including those in the ''unknown'' categories. We train the network to learn the representations of target samples via self-supervised learning (SSL) and to identify the seen and unseen (novel) target-sample categories simultaneously by maximizing the mutual information between labels and input data. We evaluated our approach under different DA settings and concluded that our method generally outperformed existing ones by a wide margin.", "pdf_url": "https://ojs.aaai.org/index.php/AAAI/article/view/20224/19983", "pdf_filepath": "data/semantic/pdf_files/2022-06-28_Self-Labeling_Framework_for_Novel_Category_Discovery_over_Domains.pdf", "markdown_path": "data/semantic/markdown_files/2022-06-28_Self-Labeling_Framework_for_Novel_Category_Discovery_over_Domains.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "df873fdb2e48b923c4a2a8df76755c9733a5effc", "publication_date": "2022", "title": "Mutual Information-based Generalized Category Discovery", "authors": "Florent Chiaroni, J. Dolz, Imtiaz Masud Ziko, A. Mitiche, Ismail Ben Ayed", "venue": "arXiv.org", "citation_count": 6, "influential_citation_count": 2, "abstract": "We introduce an information-maximization approach for the Generalized Category Discovery (GCD) problem. Speci\ufb01cally, we explore a parametric family of loss functions evaluating the mutual information between the features and the labels, and \ufb01nd automatically the one that maximizes the predictive performances. Furthermore, we introduce the Elbow Maximum Centroid-Shift (EMaCS) technique, which estimates the number of classes in the unlabeled set. We report comprehensive experiments, which show that our mutual information-based approach (MIB) is both versatile and highly competitive under various GCD scenarios. The gap between the proposed approach and the existing methods is signi\ufb01cant, more so when dealing with \ufb01ne-grained classi\ufb01cation problems. Our code:", "pdf_url": "https://arxiv.org/abs/2212.00334/pdf/2212.00334", "pdf_filepath": "data/semantic/pdf_files/2022_Mutual_Information-based_Generalized_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2022_Mutual_Information-based_Generalized_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "b851511b5a1c5e014fc571207f0bc0d8cfad6753", "publication_date": "2021-04-20", "title": "Progressive Self-Supervised Clustering With Novel Category Discovery", "authors": "Jingyu Wang, Zhenyu Ma, F. Nie, Xuelong Li", "venue": "IEEE Transactions on Cybernetics", "citation_count": 19, "influential_citation_count": 0, "abstract": "These days, clustering is one of the most classical themes to analyze data structures in machine learning and pattern recognition. Recently, the anchor-based graph has been widely adopted to promote the clustering accuracy of plentiful graph-based clustering techniques. In order to achieve more satisfying clustering performance, we propose a novel clustering approach referred to as the progressive self-supervised clustering method with novel category discovery (PSSCNCD), which consists of three separate procedures specifically. First, we propose a new semisupervised framework with novel category discovery to guide label propagation processing, which is reinforced by the parameter-insensitive anchor-based graph obtained from balanced $K$ -means and hierarchical $K$ -means (BKHK). Second, we design a novel representative point selected strategy based on our semisupervised framework to discover each representative point and endow pseudolabel progressively, where every pseudolabel hypothetically corresponds to a real category in each self-supervised label propagation. Third, when sufficient representative points have been found, the labels of all samples will be finally predicted to obtain terminal clustering results. In addition, the experimental results on several toy examples and benchmark data sets comprehensively demonstrate that our method outperforms other clustering approaches.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "5bf95ade668c711b40e9ad1c5e4780b74ed01acb", "publication_date": "2022", "title": "Generalized Category Discovery Appendices", "authors": "", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "5f7de346cbcc787beed208c4ef6a4806464ba80d", "publication_date": "2025-02-25", "title": "GLEAN: Generalized Category Discovery with Diverse and Quality-Enhanced LLM Feedback", "authors": "Henry Peng Zou, Siffi Singh, Yi Nian, Jianfeng He, Jason Cai, Saab Mansour, Hang Su", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 1, "abstract": "Generalized Category Discovery (GCD) is a practical and challenging open-world task that aims to recognize both known and novel categories in unlabeled data using limited labeled data from known categories. Due to the lack of supervision, previous GCD methods face significant challenges, such as difficulty in rectifying errors for confusing instances, and inability to effectively uncover and leverage the semantic meanings of discovered clusters. Therefore, additional annotations are usually required for real-world applicability. However, human annotation is extremely costly and inefficient. To address these issues, we propose GLEAN, a unified framework for generalized category discovery that actively learns from diverse and quality-enhanced LLM feedback. Our approach leverages three different types of LLM feedback to: (1) improve instance-level contrastive features, (2) generate category descriptions, and (3) align uncertain instances with LLM-selected category descriptions. Extensive experiments demonstrate the superior performance of \\MethodName over state-of-the-art models across diverse datasets, metrics, and supervision settings. Our code is available at https://github.com/amazon-science/Glean.", "pdf_url": "https://arxiv.org/pdf/2502.18414.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-02-25_GLEAN__Generalized_Category_Discovery_with_Diverse_and_Quality-Enhanced_LLM_Feedback.pdf", "markdown_path": "data/semantic/markdown_files/2025-02-25_GLEAN__Generalized_Category_Discovery_with_Diverse_and_Quality-Enhanced_LLM_Feedback.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "05d397266c99e107fff5f383644e03978d9a2358", "publication_date": "2025-05-13", "title": "Few-shot Novel Category Discovery", "authors": "Chunming Li, Shidong Wang, Haofeng Zhang", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": "The recently proposed Novel Category Discovery (NCD) adapt paradigm of transductive learning hinders its application in more real-world scenarios. In fact, few labeled data in part of new categories can well alleviate this burden, which coincides with the ease that people can label few of new category data. Therefore, this paper presents a new setting in which a trained agent is able to flexibly switch between the tasks of identifying examples of known (labelled) classes and clustering novel (completely unlabeled) classes as the number of query examples increases by leveraging knowledge learned from only a few (handful) support examples. Drawing inspiration from the discovery of novel categories using prior-based clustering algorithms, we introduce a novel framework that further relaxes its assumptions to the real-world open set level by unifying the concept of model adaptability in few-shot learning. We refer to this setting as Few-Shot Novel Category Discovery (FSNCD) and propose Semi-supervised Hierarchical Clustering (SHC) and Uncertainty-aware K-means Clustering (UKC) to examine the model's reasoning capabilities. Extensive experiments and detailed analysis on five commonly used datasets demonstrate that our methods can achieve leading performance levels across different task settings and scenarios.", "pdf_url": "https://arxiv.org/pdf/2505.08260.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-05-13_Few-shot_Novel_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2025-05-13_Few-shot_Novel_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "600b177b96d21126f7505d7915baf9e1f5be3412", "publication_date": "2025-04-08", "title": "Hyperbolic Category Discovery", "authors": "Yuanpei Liu, Zhenqi He, Kai Han", "venue": "arXiv.org", "citation_count": 0, "influential_citation_count": 0, "abstract": "Generalized Category Discovery (GCD) is an intriguing open-world problem that has garnered increasing attention. Given a dataset that includes both labelled and unlabelled images, GCD aims to categorize all images in the unlabelled subset, regardless of whether they belong to known or unknown classes. In GCD, the common practice typically involves applying a spherical projection operator at the end of the self-supervised pretrained backbone, operating within Euclidean or spherical space. However, both of these spaces have been shown to be suboptimal for encoding samples that possesses hierarchical structures. In contrast, hyperbolic space exhibits exponential volume growth relative to radius, making it inherently strong at capturing the hierarchical structure of samples from both seen and unseen categories. Therefore, we propose to tackle the category discovery challenge in the hyperbolic space. We introduce HypCD, a simple \\underline{Hyp}erbolic framework for learning hierarchy-aware representations and classifiers for generalized \\underline{C}ategory \\underline{D}iscovery. HypCD first transforms the Euclidean embedding space of the backbone network into hyperbolic space, facilitating subsequent representation and classification learning by considering both hyperbolic distance and the angle between samples. This approach is particularly helpful for knowledge transfer from known to unknown categories in GCD. We thoroughly evaluate HypCD on public GCD benchmarks, by applying it to various baseline and state-of-the-art methods, consistently achieving significant improvements.", "pdf_url": "https://arxiv.org/pdf/2504.06120.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-04-08_Hyperbolic_Category_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-08_Hyperbolic_Category_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "d2b4a05769feb80d21ea6290873e6c5fc7655ccd", "publication_date": "2025-02-01", "title": "Mutual-support generalized category discovery", "authors": "Yu Duan, Zhanxuan Hu, Rong Wang, Zhensheng Sun, Feiping Nie, Xuelong Li", "venue": "Information Fusion", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "b797f3fa4e732d52092f9eb863350440d5de8bb1", "publication_date": "2016-03-25", "title": "Unsupervised Category Discovery via Looped Deep Pseudo-Task Optimization Using a Large Scale Radiology Image Database", "authors": "Xiaosong Wang, Le Lu, Hoo-Chang Shin, Lauren Kim, Isabella Nogues, Jianhua Yao, R. Summers", "venue": "arXiv.org", "citation_count": 16, "influential_citation_count": 0, "abstract": "Obtaining semantic labels on a large scale radiology image database (215,786 key images from 61,845 unique patients) is a prerequisite yet bottleneck to train highly effective deep convolutional neural network (CNN) models for image recognition. Nevertheless, conventional methods for collecting image labels (e.g., Google search followed by crowd-sourcing) are not applicable due to the formidable difficulties of medical annotation tasks for those who are not clinically trained. This type of image labeling task remains non-trivial even for radiologists due to uncertainty and possible drastic inter-observer variation or inconsistency. \nIn this paper, we present a looped deep pseudo-task optimization procedure for automatic category discovery of visually coherent and clinically semantic (concept) clusters. Our system can be initialized by domain-specific (CNN trained on radiology images and text report derived labels) or generic (ImageNet based) CNN models. Afterwards, a sequence of pseudo-tasks are exploited by the looped deep image feature clustering (to refine image labels) and deep CNN training/classification using new labels (to obtain more task representative deep features). Our method is conceptually simple and based on the hypothesized \"convergence\" of better labels leading to better trained CNN models which in turn feed more effective deep image features to facilitate more meaningful clustering/labels. We have empirically validated the convergence and demonstrated promising quantitative and qualitative results. Category labels of significantly higher quality than those in previous work are discovered. This allows for further investigation of the hierarchical semantic nature of the given large-scale radiology image database.", "pdf_url": "https://arxiv.org/pdf/1603.07965.pdf", "pdf_filepath": "data/semantic/pdf_files/2016-03-25_Unsupervised_Category_Discovery_via_Looped_Deep_Pseudo-Task_Optimization_Using_a_Large_Scale_Radiolo.pdf", "markdown_path": "data/semantic/markdown_files/2016-03-25_Unsupervised_Category_Discovery_via_Looped_Deep_Pseudo-Task_Optimization_Using_a_Large_Scale_Radiolo.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "455d562bf02dcb5161c98668a5f5e470d02b70b8", "publication_date": "2018-06-28", "title": "A probabilistic constrained clustering for transfer learning and image category discovery", "authors": "Yen-Chang Hsu, Zhaoyang Lv, Joel Schlosser, Phillip Odom, Z. Kira", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 1, "abstract": "Neural network-based clustering has recently gained popularity, and in particular a constrained clustering formulation has been proposed to perform transfer learning and image category discovery using deep learning. The core idea is to formulate a clustering objective with pairwise constraints that can be used to train a deep clustering network; therefore the cluster assignments and their underlying feature representations are jointly optimized end-to-end. In this work, we provide a novel clustering formulation to address scalability issues of previous work in terms of optimizing deeper networks and larger amounts of categories. The proposed objective directly minimizes the negative log-likelihood of cluster assignment with respect to the pairwise constraints, has no hyper-parameters, and demonstrates improved scalability and performance on both supervised learning and unsupervised transfer learning.", "pdf_url": "https://arxiv.org/pdf/1806.11078.pdf", "pdf_filepath": "data/semantic/pdf_files/2018-06-28_A_probabilistic_constrained_clustering_for_transfer_learning_and_image_category_discovery.pdf", "markdown_path": "data/semantic/markdown_files/2018-06-28_A_probabilistic_constrained_clustering_for_transfer_learning_and_image_category_discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "247760cf185accbabaa3c947b19809434f9de20a", "publication_date": "2019-10-07", "title": "Contour analysis for interpretable leaf shape category discovery", "authors": "Jorge Victorino, Francisco G\u00f3mez", "venue": "Plant Methods", "citation_count": 9, "influential_citation_count": 1, "abstract": "The categorical description of leaf shapes is of paramount importance in ecology, taxonomy and paleobotanical studies. Classification systems proposed by domain experts support these descriptions. Despite the importance of these visual descriptive systems, classifications based on this expert\u2019s knowledge may be ambiguous or limited when representing shapes in unknown scenarios, as expected for biological exploratory domains. This work proposes a novel strategy to automatically discover the shape categories in a set of unlabeled leaves by only using the leaf-shape information. In particular, we overcome the task of discovering shape categories from different plant species for three different biological settings. The proposed method may successfully infer the unknown underlying shape categories with an F-score greater than 92%. The approach also provided high levels of visual interpretability, an essential requirement in the description of biological objects. This method may support morphological analysis of biological objects in exploratory domains.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a3af53662843e026ec239250de418c3fdd285ce7", "publication_date": "2016-12-05", "title": "Deep Image Category Discovery using a Transferred Similarity Function", "authors": "Yen-Chang Hsu, Zhaoyang Lv, Z. Kira", "venue": "arXiv.org", "citation_count": 15, "influential_citation_count": 2, "abstract": "Automatically discovering image categories in unlabeled natural images is one of the important goals of unsupervised learning. However, the task is challenging and even human beings define visual categories based on a large amount of prior knowledge. In this paper, we similarly utilize prior knowledge to facilitate the discovery of image categories. We present a novel end-to-end network to map unlabeled images to categories as a clustering network. We propose that this network can be learned with contrastive loss which is only based on weak binary pair-wise constraints. Such binary constraints can be learned from datasets in other domains as transferred similarity functions, which mimic a simple knowledge transfer. We first evaluate our experiments on the MNIST dataset as a proof of concept, based on predicted similarities trained on Omniglot, showing a 99\\% accuracy which significantly outperforms clustering based approaches. Then we evaluate the discovery performance on Cifar-10, STL-10, and ImageNet, which achieves both state-of-the-art accuracy and shows it can be scalable to various large natural images.", "pdf_url": "https://arxiv.org/pdf/1612.01253.pdf", "pdf_filepath": "data/semantic/pdf_files/2016-12-05_Deep_Image_Category_Discovery_using_a_Transferred_Similarity_Function.pdf", "markdown_path": "data/semantic/markdown_files/2016-12-05_Deep_Image_Category_Discovery_using_a_Transferred_Similarity_Function.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "3121fda2ff8eddbf7a4678958da5c3a0cdc693ed", "publication_date": "2022-08-01", "title": "Ingredient-Guided Region Discovery and Relationship Modeling for Food Category-Ingredient Prediction", "authors": "Zhiling Wang, Weiqing Min, Zhu Li, Liping Kang, Xiaoming Wei, Xiaolin Wei, Shuqiang Jiang", "venue": "IEEE Transactions on Image Processing", "citation_count": 33, "influential_citation_count": 3, "abstract": "Recognizing the category and its ingredient composition from food images facilitates automatic nutrition estimation, which is crucial to various health relevant applications, such as nutrition intake management and healthy diet recommendation. Since food is composed of ingredients, discovering ingredient-relevant visual regions can help identify its corresponding category and ingredients. Furthermore, various ingredient relationships like co-occurrence and exclusion are also critical for this task. For that, we propose an ingredient-oriented multi-task food category-ingredient joint learning framework for simultaneous food recognition and ingredient prediction. This framework mainly involves learning an ingredient dictionary for ingredient-relevant visual region discovery and building an ingredient-based semantic-visual graph for ingredient relationship modeling. To obtain ingredient-relevant visual regions, we build an ingredient dictionary to capture multiple ingredient regions and obtain the corresponding assignment map, and then pool the region features belonging to the same ingredient to identify the ingredients more accurately and meanwhile improve the classification performance. For ingredient-relationship modeling, we utilize the visual ingredient representations as nodes and the semantic similarity between ingredient embeddings as edges to construct an ingredient graph, and then learn their relationships via the graph convolutional network to make label embeddings and visual features interact with each other to improve the performance. Finally, fused features from both ingredient-oriented region features and ingredient-relationship features are used in the following multi-task category-ingredient joint learning. Extensive evaluation on three popular benchmark datasets (ETH Food-101, Vireo Food-172 and ISIA Food-200) demonstrates the effectiveness of our method. Further visualization of ingredient assignment maps and attention maps also shows the superiority of our method.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "06f2222d4aef3db1f9e704389cabcbeca80d506c", "publication_date": "2015-02-01", "title": "Adaptive Scene Category Discovery With Generative Learning and Compositional Sampling", "authors": "Liang Lin, Ruimao Zhang, Xiaohua Duan", "venue": "IEEE transactions on circuits and systems for video technology (Print)", "citation_count": 20, "influential_citation_count": 0, "abstract": "This paper investigates a general framework to discover categories of unlabeled scene images according to their appearances (i.e., textures and structures). We jointly solve the two coupled tasks in an unsupervised manner: 1) classifying images without predetermining the number of categories and 2) pursuing generative model for each category. In our method, each image is represented by two types of image descriptors that are effective to capture image appearances from different aspects. By treating each image as a graph vertex, we build up a graph and pose the image categorization as a graph partition process. Specifically, a partitioned subgraph can be regarded as a category of scenes and we define the probabilistic model of graph partition by accumulating the generative models of all separated categories. For efficient inference with the graph, we employ a stochastic cluster sampling algorithm, which is designed based on the Metropolis-Hasting mechanism. During the iterations of inference, the model of each category is analytically updated by a generative learning algorithm. In the experiments, our approach is validated on several challenging databases, and it outperforms other popular state-of-the-art methods. The implementation details and empirical analysis are presented as well.", "pdf_url": "https://arxiv.org/pdf/1502.00374.pdf", "pdf_filepath": "data/semantic/pdf_files/2015-02-01_Adaptive_Scene_Category_Discovery_With_Generative_Learning_and_Compositional_Sampling.pdf", "markdown_path": "data/semantic/markdown_files/2015-02-01_Adaptive_Scene_Category_Discovery_With_Generative_Learning_and_Compositional_Sampling.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a930c623e485fba4133faae4e4f8ee5dc5e8b6bd", "publication_date": "2014-05-01", "title": "Iterative Category Discovery via Multiple Kernel Metric Learning", "authors": "C. Galleguillos, Brian McFee, Gert R. G. Lanckriet", "venue": "International Journal of Computer Vision", "citation_count": 15, "influential_citation_count": 2, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "549628bf7d64b59b38e0e64eb5aac516a08cc66e", "publication_date": "2014-11-01", "title": "A Novel Context-Aware Topic Model for Category Discovery in Natural Scenes", "authors": "Ze-Huan Yuan, Tong Lu", "venue": "Asian Conference on Computer Vision", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "6fb24075c6d525b8c8c8f529264bf7b92064c6b4", "publication_date": "2021-03-30", "title": "Cross-Category Defect Discovery from Online Reviews: Supplementing Sentiment with Category-Specific Semantics", "authors": "Nohel Zaman, David M. Goldberg, Richard Gruss, A. Abrahams, Siriporn Srisawas, Peter Ractham, Michelle M. H. \u015eeref", "venue": "Information Systems Frontiers", "citation_count": 14, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "63f7a5c5f29252394df30249d6e25b09b47d6dc7", "publication_date": "2021-12-13", "title": "Discovery of an ancient MHC category with both class I and class II features", "authors": "K. Okamura, J. M. Dijkstra, Kentaro Tsukamoto, U. Grimholt, G. Wiegertjes, A. Kondow, H. Yamaguchi, K. Hashimoto", "venue": "Proceedings of the National Academy of Sciences of the United States of America", "citation_count": 12, "influential_citation_count": 1, "abstract": "Significance Two classes of major histocompatibility complex (MHC) molecules, MHC class I and MHC class II, constitute the basis of our elaborate, adaptive immune system as antigen-presenting molecules. They perform distinct, critical functions: especially, MHC class I in case of antivirus and antitumor defenses, and MHC class II, in case of effective antibody responses. This important class diversification has long been enigmatic, as vestiges of the evolutionary molecular changes have not been found. The revealed ancient MHC category represents a plausible intermediate group between the two classes, and the data suggest that class II preceded class I in molecular evolution. Fundamental understanding of the molecular evolution of MHC molecules should contribute to understanding the basis of our complex biological defense system. Two classes of major histocompatibility complex (MHC) molecules, MHC class I and class II, play important roles in our immune system, presenting antigens to functionally distinct T lymphocyte populations. However, the origin of this essential MHC class divergence is poorly understood. Here, we discovered a category of MHC molecules (W-category) in the most primitive jawed vertebrates, cartilaginous fish, and also in bony fish and tetrapods. W-category, surprisingly, possesses class II\u2013type \u03b1- and \u03b2-chain organization together with class I\u2013specific sequence motifs for interdomain binding, and the W-category \u03b12 domain shows unprecedented, phylogenetic similarity with \u03b22-microglobulin of class I. Based on the results, we propose a model in which the ancestral MHC class I molecule evolved from class II\u2013type W-category. The discovery of the ancient MHC group, W-category, sheds a light on the long-standing critical question of the MHC class divergence and suggests that class II type came first.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "2dd1149cb96d3124e9b83bef4c51ea9090ffe106", "publication_date": "None", "title": "Edinburgh Research Explorer Incremental Generalized Category Discovery", "authors": "Bingchen Zhao, Oisin Mac Aodha", "venue": "", "citation_count": 19, "influential_citation_count": 3, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "ba7892fc2f7bb5851cff243257da0da0f2d5bc05", "publication_date": "2013-12-07", "title": "Iterative Category Discovery via Multiple Kernel Metric Learning", "authors": "C. Galleguillos, Brian McFee, Gert R. G. Lanckriet", "venue": "International Journal of Computer Vision", "citation_count": 2, "influential_citation_count": 1, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "5299021119a5b887bf5e83046f5a73a0aac73e7c", "publication_date": "2013-05-06", "title": "Unsupervised 3D category discovery and point labeling from a large urban environment", "authors": "Quanshi Zhang, Xuan Song, Xiaowei Shao, Huijing Zhao, R. Shibasaki", "venue": "IEEE International Conference on Robotics and Automation", "citation_count": 11, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a7d713f3b465feff60a5f897df9618f8c4b53103", "publication_date": "2012-02-01", "title": "Object-Graphs for Context-Aware Visual Category Discovery", "authors": "Yong Jae Lee, K. Grauman", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citation_count": 75, "influential_citation_count": 5, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "3939cac38611f9d9a53e10b196ff3275b4fb77a6", "publication_date": "2020-02-01", "title": "Discovery of O-Linked Carbohydrate on HIV-1 Envelope and Its Role in Shielding against One Category of Broadly Neutralizing Antibodies.", "authors": "Z. Silver, A. Antonopoulos, S. Haslam, A. Dell, G. Dickinson, M. Seaman, R. Desrosiers", "venue": "Cell Reports", "citation_count": 29, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "c2e9728db91c96665a7fb7a0e0f4a7bc37399b1e", "publication_date": "2018-05-08", "title": "Category-Based Deep CCA for Fine-Grained Venue Discovery From Multimodal Data", "authors": "Yi Yu, Suhua Tang, K. Aizawa, Akiko Aizawa", "venue": "IEEE Transactions on Neural Networks and Learning Systems", "citation_count": 100, "influential_citation_count": 6, "abstract": "In this work, travel destinations and business locations are taken as venues. Discovering a venue by a photograph is very important for visual context-aware applications. Unfortunately, few efforts paid attention to complicated real images such as venue photographs generated by users. Our goal is fine-grained venue discovery from heterogeneous social multimodal data. To this end, we propose a novel deep learning model, category-based deep canonical correlation analysis. Given a photograph as input, this model performs: 1) exact venue search (find the venue where the photograph was taken) and 2) group venue search (find relevant venues that have the same category as the photograph), by the cross-modal correlation between the input photograph and textual description of venues. In this model, data in different modalities are projected to a same space via deep networks. Pairwise correlation (between different modality data from the same venue) for exact venue search and category-based correlation (between different modality data from different venues with the same category) for group venue search are jointly optimized. Because a photograph cannot fully reflect rich text description of a venue, the number of photographs per venue in the training phase is increased to capture more aspects of a venue. We build a new venue-aware multimodal data set by integrating Wikipedia featured articles and Foursquare venue photographs. Experimental results on this data set confirm the feasibility of the proposed method. Moreover, the evaluation over another publicly available data set confirms that the proposed method outperforms state of the arts for cross-modal retrieval between image and text.", "pdf_url": "https://arxiv.org/pdf/1805.02997.pdf", "pdf_filepath": "data/semantic/pdf_files/2018-05-08_Category-Based_Deep_CCA_for_Fine-Grained_Venue_Discovery_From_Multimodal_Data.pdf", "markdown_path": "data/semantic/markdown_files/2018-05-08_Category-Based_Deep_CCA_for_Fine-Grained_Venue_Discovery_From_Multimodal_Data.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a58d3f890a602e820a7bed761f0706f128751a12", "publication_date": "2023-03-12", "title": "Universal Instance Perception as Object Discovery and Retrieval", "authors": "B. Yan, Yi Jiang, Jiannan Wu, D. Wang, Ping Luo, Zehuan Yuan, Huchuan Lu", "venue": "Computer Vision and Pattern Recognition", "citation_count": 171, "influential_citation_count": 26, "abstract": "All instance perception tasks aim at finding certain objects specified by some queries such as category names, language expressions, and target annotations, but this complete field has been split into multiple independent sub-tasks. In this work, we present a universal instance perception model of the next generation, termed UNINEXT. UNINEXT reformulates diverse instance perception tasks into a unified object discovery and retrieval paradigm and can flexibly perceive different types of objects by simply changing the input prompts. This unified formulation brings the following benefits: (1) enormous data from different tasks and label vocabularies can be exploited for jointly training general instance-level representations, which is especially beneficial for tasks lacking in training data. (2) the unified model is parameter-efficient and can save redundant computation when handling multiple tasks simultaneously. UNINEXT shows superior performance on 20 challenging benchmarks from 10 instance-level tasks including classical image-level tasks (object detection and instance segmentation), vision-and-language tasks (referring expression comprehension and segmentation), and six video-level object tracking tasks. Code is available at https://github.com/MasterBin-IIAU/UNINEXT.", "pdf_url": "https://arxiv.org/pdf/2303.06674.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-03-12_Universal_Instance_Perception_as_Object_Discovery_and_Retrieval.pdf", "markdown_path": "data/semantic/markdown_files/2023-03-12_Universal_Instance_Perception_as_Object_Discovery_and_Retrieval.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "2b4d4f2e8e75c7c5e67671cb291d10b6415a867a", "publication_date": "2011-06-20", "title": "From region similarity to category discovery", "authors": "C. Galleguillos, Brian McFee, Serge J. Belongie, Gert R. G. Lanckriet", "venue": "Computer Vision and Pattern Recognition", "citation_count": 15, "influential_citation_count": 1, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "4cadbde77746f962cb244f6037bfa59281f38099", "publication_date": "2018", "title": "Relational Discovery in Category Learning", "authors": "Micah B. Goldwater, Hilary J Don, Moritz J. F. Krusche, E. Livesey", "venue": "Journal of experimental psychology. General", "citation_count": 49, "influential_citation_count": 2, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "8a1440354e299d5cac6f80f1f4102cc6c6546311", "publication_date": "2011-06-20", "title": "Learning the easy things first: Self-paced visual category discovery", "authors": "Yong Jae Lee, K. Grauman", "venue": "Computer Vision and Pattern Recognition", "citation_count": 221, "influential_citation_count": 20, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "f929915cefe8f581e3425c9d94639e25771e759d", "publication_date": "2012-12-24", "title": "Constructing dynamic category hierarchies for novel visual category discovery", "authors": "Jianhua Zhang, Jianwei Zhang, Shengyong Chen, Ying Hu, Hao Guan", "venue": "2012 IEEE/RSJ International Conference on Intelligent Robots and Systems", "citation_count": 12, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "fdebffe62fab300193e4084a172784e56aa7ee56", "publication_date": "2010-06-13", "title": "Object-graphs for context-aware category discovery", "authors": "Yong Jae Lee, K. Grauman", "venue": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition", "citation_count": 114, "influential_citation_count": 8, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "a61557446d476262e530cc5a129faca888b804be", "publication_date": "2011-08-05", "title": "Exploiting context aware category discovery for image labeling", "authors": "Han Liu, Yanyun Qu", "venue": "International Conference on Internet Multimedia Computing and Service", "citation_count": 2, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "16d12e9edda41fecfb3f7793bcc85d7c011d03c3", "publication_date": "2010-06-13", "title": "Finding meaning on YouTube: Tag recommendation and category discovery", "authors": "G. Toderici, H. Aradhye, Marius Pasca, L. Sbaiz, J. Yagnik", "venue": "2010 IEEE Computer Society Conference on Computer Vision and Pattern Recognition", "citation_count": 102, "influential_citation_count": 3, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "7c82e4a9c48944dc9c24ac0c9b695244e74c109c", "publication_date": "2010-10-25", "title": "Unsupervised object category discovery via information bottleneck method", "authors": "Zhengzheng Lou, Yangdong Ye, Dong Liu", "venue": "ACM Multimedia", "citation_count": 9, "influential_citation_count": 1, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "f5da7feea53a071e16b381788bcc39753ccaced3", "publication_date": "2022-10-18", "title": "Plant-derived natural products for drug discovery: current approaches and prospects", "authors": "Noohi Nasim, I. S. Sandeep, Sujata Mohanty", "venue": "The Nucleus", "citation_count": 251, "influential_citation_count": 0, "abstract": "Nature has abundant source of drugs that need to be identified/purified for use as essential biologics, either individually or in combination in the modern medical field. These drugs are divided into small bio-molecules, plant-made biologics, and a recently introduced third category known as phytopharmaceutical drugs. The development of phytopharmaceutical medicines is based on the ethnopharmacological approach, which relies on the traditional medicine system. The concept of \u2018one-disease one-target drug\u2019 is becoming less popular, and the use of plant extracts, fractions, and molecules is the new paradigm that holds promising scope to formulate appropriate drugs. This led to discovering a new concept known as polypharmacology, where natural products from varying sources can engage with multiple human physiology targets. This article summarizes different approaches for phytopharmaceutical drug development and discusses the progress in systems biology and computational tools for identifying drug targets. We review the existing drug delivery methods to facilitate the efficient delivery of drugs to the targets. In addition, we describe different analytical techniques for the authentication and fingerprinting of plant materials. Finally, we highlight the role of biopharming in developing plant-based biologics.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "85f92578b3b78c89e0bb56215bc5c868b23d4b0a", "publication_date": "2023-05-05", "title": "Virtual Screening Algorithms in Drug Discovery: A Review Focused on Machine and Deep Learning Methods", "authors": "Tiago Alves de Oliveira, Michel Pires da Silva, Eduardo H. B. Maia, Alisson Marques da Silva, A. Taranto", "venue": "Drugs and Drug Candidates", "citation_count": 56, "influential_citation_count": 2, "abstract": "Drug discovery and repositioning are important processes for the pharmaceutical industry. These processes demand a high investment in resources and are time-consuming. Several strategies have been used to address this problem, including computer-aided drug design (CADD). Among CADD approaches, it is essential to highlight virtual screening (VS), an in silico approach based on computer simulation that can select organic molecules toward the therapeutic targets of interest. The techniques applied by VS are based on the structure of ligands (LBVS), receptors (SBVS), or fragments (FBVS). Regardless of the type of VS to be applied, they can be divided into categories depending on the used algorithms: similarity-based, quantitative, machine learning, meta-heuristics, and other algorithms. Each category has its objectives, advantages, and disadvantages. This review presents an overview of the algorithms used in VS, describing them and showing their use in drug design and their contribution to the drug development process.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "43af9208f12c1fb20ec63032461247d9fc4a2cfb", "publication_date": "2015-07-09", "title": "Challenges in drug discovery for overcoming \u2018dysfunctional pain\u2019: an emerging category of chronic pain", "authors": "Y. Nagakura", "venue": "Expert Opinion on Drug Discovery", "citation_count": 35, "influential_citation_count": 1, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "553af83248c24ed292d815a6b94911aaaf101a8b", "publication_date": "2023-08-07", "title": "Strategies for senolytic drug discovery", "authors": "H. Power, P. Valtchev, F. Dehghani, A. Schindeler", "venue": "Aging Cell", "citation_count": 28, "influential_citation_count": 0, "abstract": "Senolytics are a category of drugs that reduce the impact of cellular senescence, an effect associated with a range of chronic and age\u2010related diseases. Since the discovery of the first senolytics in 2015, the number of known senolytic agents has grown dramatically. This review discusses the broad categories of known senolytics\u2014kinase inhibitors, Bcl\u20102 family protein inhibitors, naturally occurring polyphenols, heat shock protein inhibitors, BET family protein inhibitors, P53 stabilizers, repurposed anti\u2010cancer drugs, cardiac steroids, PPAR\u2010alpha agonists, and antibiotics. The approaches used to screen for new senolytics are articulated including a range of methods to induce senescence, different target cell types, various senolytic assays, and markers. The choice of methods can greatly influence the outcomes of a screen, with high\u2010quality screens featuring robust systems, adequate controls, and extensive validation in alternate assays. Recent advances in single\u2010cell analysis and computational methods for senolytic identification are also discussed. There is significant potential for further drug discovery, but this will require additional research into drug targets and mechanisms of actions and their subsequent rigorous evaluation in pre\u2010clinical models and human trials.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "78a763ba54911697670150a565c626930b3e3557", "publication_date": "2023-03-17", "title": "Causal Discovery from Temporal Data: An Overview and New Perspectives", "authors": "Chang Gong, Di Yao, Chuzhe Zhang, Wenbin Li, Jingping Bi", "venue": "ACM Computing Surveys", "citation_count": 18, "influential_citation_count": 0, "abstract": "Temporal data, representing chronological observations of complex systems, has always been a typical data structure that can be widely generated by many domains, such as industry, finance, healthcare, and climatology. Analyzing the underlying structures, i.e., the causal relations, could be extremely valuable for various applications. Recently, causal discovery from temporal data has been considered as an interesting yet critical task and attracted much research attention. According to the nature and structure of temporal data, existing causal discovery works can be divided into two highly correlated categories i.e., multivariate time series causal discovery, and event sequence causal discovery. However, most previous surveys are only focused on the multivariate time series causal discovery but ignore the second category. In this article, we specify the similarity between the two categories and provide an overview of existing solutions. Furthermore, we provide public datasets, evaluation metrics, and new perspectives for temporal data causal discovery.", "pdf_url": "https://arxiv.org/pdf/2303.10112.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-03-17_Causal_Discovery_from_Temporal_Data__An_Overview_and_New_Perspectives.pdf", "markdown_path": "data/semantic/markdown_files/2023-03-17_Causal_Discovery_from_Temporal_Data__An_Overview_and_New_Perspectives.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "ca91e93c1cbb6c1ff7373e0337ba1d6cbe3f5381", "publication_date": "2023-12-04", "title": "Generalized Categories Discovery for Long-tailed Recognition", "authors": "Ziyun Li, Christoph Meinel, Haojin Yang", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Generalized Class Discovery (GCD) plays a pivotal role in discerning both known and unknown categories from unlabeled datasets by harnessing the insights derived from a labeled set comprising recognized classes. A significant limitation in prevailing GCD methods is their presumption of an equitably distributed category occurrence in unlabeled data. Contrary to this assumption, visual classes in natural environments typically exhibit a long-tailed distribution, with known or prevalent categories surfacing more frequently than their rarer counterparts. Our research endeavors to bridge this disconnect by focusing on the long-tailed Generalized Category Discovery (Long-tailed GCD) paradigm, which echoes the innate imbalances of real-world unlabeled datasets. In response to the unique challenges posed by Long-tailed GCD, we present a robust methodology anchored in two strategic regularizations: (i) a reweighting mechanism that bolsters the prominence of less-represented, tail-end categories, and (ii) a class prior constraint that aligns with the anticipated class distribution. Comprehensive experiments reveal that our proposed method surpasses previous state-of-the-art GCD methods by achieving an improvement of approximately 6 - 9% on ImageNet100 and competitive performance on CIFAR100.", "pdf_url": "https://arxiv.org/pdf/2401.05352.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-04_Generalized_Categories_Discovery_for_Long-tailed_Recognition.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-04_Generalized_Categories_Discovery_for_Long-tailed_Recognition.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "81f86cd44c57a06d423d1265c5476e438cf4969f", "publication_date": "2022-04-12", "title": "Towards Open-Set Object Detection and Discovery", "authors": "Jiyang Zheng, Weihao Li, Jie Hong, L. Petersson, Nick Barnes", "venue": "2022 IEEE/CVF Conference on Computer Vision and Pattern Recognition Workshops (CVPRW)", "citation_count": 65, "influential_citation_count": 2, "abstract": "With the human pursuit of knowledge, open-set object detection (OSOD) has been designed to identify unknown objects in a dynamic world. However, an issue with the current setting is that all the predicted unknown objects share the same category as \"unknown\", which require incremental learning via a human-in-the-loop approach to label novel classes. In order to address this problem, we present a new task, namely Open-Set Object Detection and Discovery (OSODD). This new task aims to extend the ability of open-set object detectors to further discover the categories of unknown objects based on their visual appearance without human effort. We propose a two-stage method that first uses an open-set object detector to predict both known and unknown objects. Then, we study the representation of predicted objects in an unsupervised manner and discover new categories from the set of unknown objects. With this method, a detector is able to detect objects belonging to known classes and define novel categories for objects of unknown classes with minimal supervision. We show the performance of our model on the MS-COCO dataset under a thorough evaluation protocol. We hope that our work will promote further research towards a more robust real-world detection system.", "pdf_url": "https://arxiv.org/pdf/2204.05604.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-04-12_Towards_Open-Set_Object_Detection_and_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2022-04-12_Towards_Open-Set_Object_Detection_and_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "00c7109cff82564a071aa0f75d7459bb2ce238be", "publication_date": "2022-10-09", "title": "Grow and Merge: A Unified Framework for Continuous Categories Discovery", "authors": "Xinwei Zhang, Jianwen Jiang, Yutong Feng, Zhi-Fan Wu, Xibin Zhao, Hai Wan, Mingqian Tang, Rong Jin, Yue Gao", "venue": "Neural Information Processing Systems", "citation_count": 30, "influential_citation_count": 9, "abstract": "Although a number of studies are devoted to novel category discovery, most of them assume a static setting where both labeled and unlabeled data are given at once for finding new categories. In this work, we focus on the application scenarios where unlabeled data are continuously fed into the category discovery system. We refer to it as the {\\bf Continuous Category Discovery} ({\\bf CCD}) problem, which is significantly more challenging than the static setting. A common challenge faced by novel category discovery is that different sets of features are needed for classification and category discovery: class discriminative features are preferred for classification, while rich and diverse features are more suitable for new category mining. This challenge becomes more severe for dynamic setting as the system is asked to deliver good performance for known classes over time, and at the same time continuously discover new classes from unlabeled data. To address this challenge, we develop a framework of {\\bf Grow and Merge} ({\\bf GM}) that works by alternating between a growing phase and a merging phase: in the growing phase, it increases the diversity of features through a continuous self-supervised learning for effective category mining, and in the merging phase, it merges the grown model with a static one to ensure satisfying performance for known classes. Our extensive studies verify that the proposed GM framework is significantly more effective than the state-of-the-art approaches for continuous category discovery.", "pdf_url": "https://arxiv.org/pdf/2210.04174.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-10-09_Grow_and_Merge__A_Unified_Framework_for_Continuous_Categories_Discovery.pdf", "markdown_path": "data/semantic/markdown_files/2022-10-09_Grow_and_Merge__A_Unified_Framework_for_Continuous_Categories_Discovery.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "ddf2d6b3ab3bf5f596927c460846839d5cb46fcf", "publication_date": "2022-02-28", "title": "PartAfford: Part-level Affordance Discovery from 3D Objects", "authors": "Chao Xu, Yixin Chen, He Wang, Song-Chun Zhu, Yixin Zhu, Siyuan Huang", "venue": "arXiv.org", "citation_count": 27, "influential_citation_count": 0, "abstract": "Understanding what objects could furnish for humans-namely, learning object affordance-is the crux to bridge perception and action. In the vision community, prior work primarily focuses on learning object affordance with dense (e.g., at a per-pixel level) supervision. In stark contrast, we humans learn the object affordance without dense labels. As such, the fundamental question to devise a computational model is: What is the natural way to learn the object affordance from visual appearance and geometry with humanlike sparse supervision? In this work, we present a new task of part-level affordance discovery (PartAfford): Given only the affordance labels per object, the machine is tasked to (i) decompose 3D shapes into parts and (ii) discover how each part of the object corresponds to a certain affordance category. We propose a novel learning framework for PartAfford, which discovers part-level representations by leveraging only the affordance set supervision and geometric primitive regularization, without dense supervision. The proposed approach consists of two main components: (i) an abstraction encoder with slot attention for unsupervised clustering and abstraction, and (ii) an affordance decoder with branches for part reconstruction, affordance prediction, and cuboidal primitive regularization. To learn and evaluate PartAfford, we construct a part-level, cross-category 3D object affordance dataset, annotated with 24 affordance categories shared among>25, 000 objects. We demonstrate that our method enables both the abstraction of 3D objects and part-level affordance discovery, with generalizability to difficult and cross-category examples. Further ablations reveal the contribution of each component.", "pdf_url": "https://arxiv.org/pdf/2202.13519.pdf", "pdf_filepath": "data/semantic/pdf_files/2022-02-28_PartAfford__Part-level_Affordance_Discovery_from_3D_Objects.pdf", "markdown_path": "data/semantic/markdown_files/2022-02-28_PartAfford__Part-level_Affordance_Discovery_from_3D_Objects.md"}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "00b987a2e9f60aea9fc630f3e56910bf47d79324", "publication_date": "2022-10-10", "title": "Dual Part Discovery Network for Zero-Shot Learning", "authors": "Jiannan Ge, Hongtao Xie, Shaobo Min, P. Li, Yongdong Zhang", "venue": "ACM Multimedia", "citation_count": 20, "influential_citation_count": 1, "abstract": "Zero-Shot Learning (ZSL) aims to recognize unseen classes by transferring knowledge from seen classes. Recent methods focus on learning a common semantic space to align visual and attribute information. However, they always over-relied on provided attributes and ignored the category discriminative information that contributes to accurate unseen class recognition, resulting in weak transferability. To this end, we propose a novel Dual Part Discovery Network (DPDN) that considers both attribute and category discriminative information by discovering attribute-guided parts and category-guided parts simultaneously to improve knowledge transfer. Specifically, for attribute-guided parts discovery, DPDN can localize the regions with specific attribute information and significantly bridge the gap between visual and semantic information guided by the given attributes. For category-guided parts discovery, the local parts are explored to discover other important regions that bring latent crucial details ignored by attributes, with the guidance of adaptive category prototypes. To better mine the transferable knowledge, we impose class correlations constraints to regularize the category prototypes. Finally, attribute- and category-guided parts complement each other and provide adequate discriminative subtle information for more accurate unseen class recognition. Extensive experimental results demonstrate that DPDN can discover discriminative parts and outperform state-of-the-art methods on three standard benchmarks.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "ac7556a9616b46b6d32bbb4c1a8e1bc3cac8ebd1", "publication_date": "2021-01-01", "title": "Carbon dots: Discovery, structure, fluorescent properties, and applications", "authors": "A. M. El-Shafey", "venue": "Green Processing and Synthesis", "citation_count": 64, "influential_citation_count": 1, "abstract": "Abstract Nanotechnology has become one of the most important topics since the beginning of the twenty-first century in numerous fields including drug synthesis and delivery, environmental protection, electronics manufacture, and astronomy due to their nanoscale particles and their properties. The traditional semi-quantum dots are replaced by a new category of fluorescent carbon nanomaterials. Carbon dots (CDs) have been explored in the last few years for their simple synthetic accession, good bio-consonance, and several revelation applications. This review explains the fluorescent properties of CDs in brief, giving also a background on CDs discovery, structure, and composition, as well as on nanocomposites, green synthesis, and their applications. Resources conservation can be achieved by using recycled substances for sustainable development which lead to a new technology. Fluorescent CDs synthesized from food wastes like bananas, orange peel waste, sugarcane bagasse, Trapa bispinosa peels, bread, and jaggery have several applications such as sensing, drug delivery, gene transfer, biological imaging, and food safety. In this study, we concentrate on CDs greener methods to prepare effective and biocompatible CDs.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Category Discovery", "paper_id": "8b77c6499139840e8f9287840d1a9feb1975fe74", "publication_date": "2021-04-22", "title": "KeypointDeformer: Unsupervised 3D Keypoint Discovery for Shape Control", "authors": "Tomas Jakab, Richard Tucker, A. Makadia, Jiajun Wu, Noah Snavely, Angjoo Kanazawa", "venue": "Computer Vision and Pattern Recognition", "citation_count": 60, "influential_citation_count": 12, "abstract": "We introduce KeypointDeformer, a novel unsupervised method for shape control through automatically discovered 3D keypoints. We cast this as the problem of aligning a source 3D object to a target 3D object from the same object category. Our method analyzes the difference between the shapes of the two objects by comparing their latent representations. This latent representation is in the form of 3D keypoints that are learned in an unsupervised way. The difference between the 3D keypoints of the source and the target objects then informs the shape deformation algorithm that deforms the source object into the target object. The whole model is learned end-to-end and simultaneously discovers 3D keypoints while learning to use them for deforming object shapes. Our approach produces intuitive and semantically consistent control of shape deformations. Moreover, our discovered 3D keypoints are consistent across object category instances despite large shape variations. As our method is unsupervised, it can be readily deployed to new object categories without requiring annotations for 3D keypoints and deformations. Project page: http://tomasjakab.github.io/KeypointDeformer.", "pdf_url": "https://arxiv.org/pdf/2104.11224.pdf", "pdf_filepath": "data/semantic/pdf_files/2021-04-22_KeypointDeformer__Unsupervised_3D_Keypoint_Discovery_for_Shape_Control.pdf", "markdown_path": "data/semantic/markdown_files/2021-04-22_KeypointDeformer__Unsupervised_3D_Keypoint_Discovery_for_Shape_Control.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "8ba57771dd6345821a0cbe83c4c7eb50f66b7b65", "publication_date": "2024-03-02", "title": "AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks", "authors": "Yifan Zeng, Yiran Wu, Xiao Zhang, Huazheng Wang, Qingyun Wu", "venue": "arXiv.org", "citation_count": 73, "influential_citation_count": 4, "abstract": "Despite extensive pre-training in moral alignment to prevent generating harmful information, large language models (LLMs) remain vulnerable to jailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense framework that filters harmful responses from LLMs. With the response-filtering mechanism, our framework is robust against different jailbreak attack prompts, and can be used to defend different victim models. AutoDefense assigns different roles to LLM agents and employs them to complete the defense task collaboratively. The division in tasks enhances the overall instruction-following of LLMs and enables the integration of other defense components as tools. With AutoDefense, small open-source LMs can serve as agents and defend larger models against jailbreak attacks. Our experiments show that AutoDefense can effectively defense against different jailbreak attacks, while maintaining the performance at normal user request. For example, we reduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using LLaMA-2-13b with a 3-agent system. Our code and data are publicly available at https://github.com/XHMY/AutoDefense.", "pdf_url": "https://arxiv.org/pdf/2403.04783.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-02_AutoDefense__Multi-Agent_LLM_Defense_against_Jailbreak_Attacks.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-02_AutoDefense__Multi-Agent_LLM_Defense_against_Jailbreak_Attacks.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "6e212b711e334ae4df26bbd57dc8eab925f98474", "publication_date": "2024-12-02", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "authors": "S. Motwani, Chandler Smith, Rocktim Jyoti Das, Markian Rybchuk, Philip Torr, Ivan Laptev, Fabio Pizzati, Ronald Clark, Christian Schr\u00f6der de Witt", "venue": "arXiv.org", "citation_count": 14, "influential_citation_count": 1, "abstract": "Large Language Models (LLMs) often produce answers with a single chain-of-thought, which restricts their ability to explore reasoning paths or self-correct flawed outputs in complex tasks. In this paper, we introduce MALT (Multi-Agent LLM Training), a novel post-training strategy that divides the reasoning process into generation, verification, and refinement steps using a sequential pipeline of heterogeneous agents. During data generation, each agent is repeatedly sampled to form a multi-agent search tree, where final outputs are graded against ground-truth data. We then apply value iteration to propagate reward signals back to each role-conditioned model, automatically producing multi-agent post-training data without human or teacher-model supervision. Our off-policy approach allows each agent to specialize by learning from correct and incorrect trajectories, ultimately improving the end-to-end reasoning chain. On MATH, GSM8K, and CSQA, MALT surpasses the same baseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40% respectively, making it an important advance towards multi-agent cooperative training.", "pdf_url": "https://arxiv.org/pdf/2412.01928.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-02_MALT__Improving_Reasoning_with_Multi-Agent_LLM_Training.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-02_MALT__Improving_Reasoning_with_Multi-Agent_LLM_Training.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "b92ec2ef54e4df2d08cbc66e4dda3e37b6362dbd", "publication_date": "2024-10-03", "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions", "authors": "Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-655, Chris Bamford, Devendra Singh, Diego Chaplot, laume Lample, L\u00e9lio Lucile Saulnier, Renard Lavaud, M. Lachaux, Pierre Stock, Teven Le Scao, Jerry Kang, Mark W. Bennett, Devon Carbado, Pam Casey, P. Liang, Chiyu Wu, Louis-philippe Morency, Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, S. Welleck, Amir Yazdan Bakhsh, ing Bao, Mo Bavarian, J. Belgum, Ir-wan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Made-laine Boyd, Anna-Luisa Brakman, Greg Brock-724 man, Tim Brooks, M. Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Su-Hong Chen, Ruby Chen, Jason Chen, Mark Chen, Benjamin Chess, Chester Cho, Hyung Casey Chu, Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Tarun Goel, Gabriel Gogineni, Rapha Goh, Jonathan Gontijo-738 Lopes, Morgan Gordon, Scott Grafstein, Ryan Gray, Joshua Greene, Shixiang Shane Gross, Yufei Gu, Chris Guo, Jesse Hallacy, Jeff Han, Harris Yuchen, Mike He, Johannes Heaton, C. Heidecke, Alan Hesse, W. Hickey, Peter Hickey, Hoeschele Brandon, Kenny Houghton, Shengli Hsu, Xin Hu, Joost Hu, Shantanu Huizinga, Shawn Jain, Jain Joanne, Angela Jang, Roger Jiang, Haozhun Jiang, Denny Jin, Shino Jin, Billie Jomoto, Hee-woo Jonn, Tomer Jun, \u0141ukasz Kaftan, Ali Kaiser, Ingmar Ka-748 mali, Kanitscheider, Nitish Shirish, Keskar Tabarak, Logan Khan, J. Kilpatrick, Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirch-751 ner, J. Kiros, Matthew Knight, Daniel Kokotajlo, \u0141ukasz Kondraciuk, Andrew Kondrich, Aris Kon-753 stantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Chak Daniel Levy, Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Ma-teusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, A. Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, S. McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, An-drey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel P. Mossing, Tong Mu, Mira Murati, O. Murk, David M\u00e9ly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Ouyang Long, Cullen O'Keefe, J. Pachocki, A. Paino, Joe Palermo, Ashley Pantuliano, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-779 der, Mario D. Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qim-ing Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Tianhao Shengjia Zhao, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Sandhini Agarwal, Alex Gray, Jacob Hilton, Fraser Kelton, Luke Miller, Amanda Askell, P. Welinder, Paul F. Christiano, Joon Sung Park, Joseph O\u2019Brien, Carrie J. Cai, Ringel Morris, Percy Liang, Michael S. Bern-814, Alec Radford, Karthik Narasimhan, Tim Salimans, Rachel Rudinger, Jason Naradowsky, Brian Leonard, Nisan Stiennon, Ryan Ziegler, Chelsea Lowe, Alec Voss, Radford, Dario Amodei, Christiano. 2020. Learn-842, Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jie Zhao, Diba Mirza, Kai-Wei Belding, Chang William, Yang Wang, Yixin Wan, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, Nanyun Peng, \u201ckelly", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 13, "influential_citation_count": 0, "abstract": "As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain insights into various societal aspects, it is essential to mitigate these biases. To that end, our study investigates the presence of implicit gender biases in multi-agent LLM interactions and proposes two strategies to mitigate these biases. We begin by creating a dataset of scenarios where implicit gender biases might arise, and subsequently develop a metric to assess the presence of biases. Our empirical analysis reveals that LLMs generate outputs characterized by strong implicit bias associations (>= 50\\% of the time). Furthermore, these biases tend to escalate following multi-agent interactions. To mitigate them, we propose two strategies: self-reflection with in-context examples (ICE); and supervised fine-tuning. Our research demonstrates that both methods effectively mitigate implicit biases, with the ensemble of fine-tuning and self-reflection proving to be the most successful.", "pdf_url": "https://arxiv.org/pdf/2410.02584.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-03_Towards_Implicit_Bias_Detection_and_Mitigation_in_Multi-Agent_LLM_Interactions.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_Towards_Implicit_Bias_Detection_and_Mitigation_in_Multi-Agent_LLM_Interactions.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "efde8940a0b924e93d35184c4a1e8f9670b94fe7", "publication_date": "2024-10-03", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "authors": "Patara Trirat, Wonyong Jeong, Sung Ju Hwang", "venue": "arXiv.org", "citation_count": 16, "influential_citation_count": 0, "abstract": "Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposes AutoML-Agent, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment. AutoML-Agent takes user's task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed results and guide the code generation LLM in implementing successful solutions. Extensive experiments on seven downstream tasks using fourteen datasets show that AutoML-Agent achieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.", "pdf_url": "https://arxiv.org/pdf/2410.02958.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-03_AutoML-Agent__A_Multi-Agent_LLM_Framework_for_Full-Pipeline_AutoML.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_AutoML-Agent__A_Multi-Agent_LLM_Framework_for_Full-Pipeline_AutoML.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "2c797fb1f140f254d4bcdbfadcb34e246dca6564", "publication_date": "2024", "title": "Conformity, Confabulation, and Impersonation: Persona Inconstancy in Multi-Agent LLM Collaboration", "authors": "Razan Baltaji, Babak Hemmatian, L. Varshney", "venue": "C3NLP", "citation_count": 8, "influential_citation_count": 1, "abstract": "This study explores the sources of instability in maintaining cultural personas and opinions within multi-agent LLM systems. Drawing on simulations of inter-cultural collaboration and debate, we analyze agents\u2019 pre- and post-discussion private responses alongside chat transcripts to assess the stability of cultural personas and the impact of opinion diversity on group outcomes. Our findings suggest that multi-agent discussions can encourage collective decisions that reflect diverse perspectives, yet this benefit is tempered by the agents\u2019 susceptibility to conformity due to perceived peer pressure and challenges in maintaining consistent personas and opinions. Counterintuitively, instructions that encourage debate in support of one\u2019s opinions increase the rate of instability. Without addressing the factors we identify, the full potential of multi-agent frameworks for producing more culturally diverse AI outputs will remain untapped.", "pdf_url": "https://arxiv.org/abs/2405.03862/pdf/2405.03862", "pdf_filepath": "data/semantic/pdf_files/2024_Conformity__Confabulation__and_Impersonation__Persona_Inconstancy_in_Multi-Agent_LLM_Collaboration.pdf", "markdown_path": "data/semantic/markdown_files/2024_Conformity__Confabulation__and_Impersonation__Persona_Inconstancy_in_Multi-Agent_LLM_Collaboration.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "c83b6a023a5c5ec71b44920a41b41fc007266c44", "publication_date": "2025-03-17", "title": "Why Do Multi-Agent LLM Systems Fail?", "authors": "Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, K. Ramchandran, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica", "venue": "arXiv.org", "citation_count": 29, "influential_citation_count": 4, "abstract": "Despite growing enthusiasm for Multi-Agent LLM Systems (MAS), their performance gains on popular benchmarks often remain minimal compared with single-agent frameworks. This gap highlights the need to systematically analyze the challenges hindering MAS effectiveness. We present MAST (Multi-Agent System Failure Taxonomy), the first empirically grounded taxonomy designed to understand MAS failures. We analyze seven popular MAS frameworks across over 200 tasks, involving six expert human annotators. Through this process, we identify 14 unique failure modes, organized into 3 overarching categories, (i) specification issues, (ii) inter-agent misalignment, and (iii) task verification. MAST emerges iteratively from rigorous inter-annotator agreement studies, achieving a Cohen's Kappa score of 0.88. To support scalable evaluation, we develop a validated LLM-as-a-Judge pipeline integrated with MAST. We leverage two case studies to demonstrate MAST's practical utility in analyzing failures and guiding MAS development. Our findings reveal that identified failures require more complex solutions, highlighting a clear roadmap for future research. We open source our comprehensive dataset and LLM annotator to facilitate further development of MAS.", "pdf_url": "https://arxiv.org/pdf/2503.13657.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-03-17_Why_Do_Multi-Agent_LLM_Systems_Fail_.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-17_Why_Do_Multi-Agent_LLM_Systems_Fail_.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "d0aab1a022d8ebe3afc83f3c21a52e50e5759494", "publication_date": "2024-12-22", "title": "KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis", "authors": "Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio", "venue": "arXiv.org", "citation_count": 9, "influential_citation_count": 0, "abstract": "Integrating Large Language Models (LLMs) in healthcare diagnosis demands systematic frameworks that can handle complex medical scenarios while maintaining specialized expertise. We present KG4Diagnosis, a novel hierarchical multi-agent framework that combines LLMs with automated knowledge graph construction, encompassing 362 common diseases across medical specialties. Our framework mirrors real-world medical systems through a two-tier architecture: a general practitioner (GP) agent for initial assessment and triage, coordinating with specialized agents for in-depth diagnosis in specific domains. The core innovation lies in our end-to-end knowledge graph generation methodology, incorporating: (1) semantic-driven entity and relation extraction optimized for medical terminology, (2) multi-dimensional decision relationship reconstruction from unstructured medical texts, and (3) human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an extensible foundation for specialized medical diagnosis systems, with capabilities to incorporate new diseases and medical knowledge. The framework's modular design enables seamless integration of domain-specific enhancements, making it valuable for developing targeted medical diagnosis systems. We provide architectural guidelines and protocols to facilitate adoption across medical contexts.", "pdf_url": "https://arxiv.org/pdf/2412.16833.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-22_KG4Diagnosis__A_Hierarchical_Multi-Agent_LLM_Framework_with_Knowledge_Graph_Enhancement_for_Medical_.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-22_KG4Diagnosis__A_Hierarchical_Multi-Agent_LLM_Framework_with_Knowledge_Graph_Enhancement_for_Medical_.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "1343c620c0625c95e32d9735ece30ff0a702a879", "publication_date": "2024-12-29", "title": "Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning", "authors": "Hang Ni, Yuzhi Wang, Hao Liu", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.", "pdf_url": "https://arxiv.org/pdf/2412.20505.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-29_Planning__Living_and_Judging__A_Multi-agent_LLM-based_Framework_for_Cyclical_Urban_Planning.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-29_Planning__Living_and_Judging__A_Multi-agent_LLM-based_Framework_for_Cyclical_Urban_Planning.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "6b9e4b6803b8eb8bbe3b72c14fce90a853311503", "publication_date": "2024", "title": "Synthetic Arabic Medical Dialogues Using Advanced Multi-Agent LLM Techniques", "authors": "Mariam Almutairi, Lulwah Alkulaib, M. Aktas, Sara A. Alsalamah, Chang-Tien Lu", "venue": "ARABICNLP", "citation_count": 3, "influential_citation_count": 0, "abstract": "The increasing use of artificial intelligence in healthcare requires robust datasets for training and validation, particularly in the domain of medical conversations. However, the creation and accessibility of such datasets in Arabic face significant challenges, especially due to the sensitivity and privacy concerns that are associated with medical conversations. These conversations are rarely recorded or preserved, making the availability of comprehensive Arabic medical dialogue datasets scarce. This limitation slows down not only the development of effective natural language processing models but also restricts the opportunity for open comparison of algorithms and their outcomes. Recent advancements in large language models (LLMs) like ChatGPT, GPT-4, Gemini-pro, and Claude-3 show promising capabilities in generating synthetic data. To address this gap, we introduce a novel Multi-Agent LLM approach capable of generating synthetic Arabic medical dialogues from patient notes, regardless of the original language. This development presents a significant step towards overcoming the barriers in dataset availability, enhancing the potential for broader research and application in AI-driven medical dialogue systems.", "pdf_url": "https://aclanthology.org/2024.arabicnlp-1.2.pdf", "pdf_filepath": "data/semantic/pdf_files/2024_Synthetic_Arabic_Medical_Dialogues_Using_Advanced_Multi-Agent_LLM_Techniques.pdf", "markdown_path": "data/semantic/markdown_files/2024_Synthetic_Arabic_Medical_Dialogues_Using_Advanced_Multi-Agent_LLM_Techniques.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "6130bafdaa0e4c22ffc7844ba2bd4e5cf8ba5451", "publication_date": "2024-11-22", "title": "Regulator-Manufacturer AI Agents Modeling: Mathematical Feedback-Driven Multi-Agent LLM Framework", "authors": "Yu Han, Zekun Guo", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "The increasing complexity of regulatory updates from global authorities presents significant challenges for medical device manufacturers, necessitating agile strategies to sustain compliance and maintain market access. Concurrently, regulatory bodies must effectively monitor manufacturers' responses and develop strategic surveillance plans. This study employs a multi-agent modeling approach, enhanced with Large Language Models (LLMs), to simulate regulatory dynamics and examine the adaptive behaviors of key actors, including regulatory bodies, manufacturers, and competitors. These agents operate within a simulated environment governed by regulatory flow theory, capturing the impacts of regulatory changes on compliance decisions, market adaptation, and innovation strategies. Our findings illuminate the influence of regulatory shifts on industry behaviour and identify strategic opportunities for improving regulatory practices, optimizing compliance, and fostering innovation. By leveraging the integration of multi-agent systems and LLMs, this research provides a novel perspective and offers actionable insights for stakeholders navigating the evolving regulatory landscape of the medical device industry.", "pdf_url": "https://arxiv.org/pdf/2411.15356.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-11-22_Regulator-Manufacturer_AI_Agents_Modeling__Mathematical_Feedback-Driven_Multi-Agent_LLM_Framework.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-22_Regulator-Manufacturer_AI_Agents_Modeling__Mathematical_Feedback-Driven_Multi-Agent_LLM_Framework.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "8e39c6435cd4b030c32065a72ef4d97358323852", "publication_date": "2024-07-30", "title": "Forensic Analysis of Artifacts from Microsoft's Multi-Agent LLM Platform AutoGen", "authors": "Clinton Walker, Taha Gharaibeh, Ruba Alsmadi, C. Hall, Ibrahim M. Baggili", "venue": "ARES", "citation_count": 2, "influential_citation_count": 0, "abstract": "Innovations in technology bring new challenges that need to be addressed, especially in the field of technical artifact discovery and analysis that enables digital forensic practitioners. Digital forensic analysis of these innovations is a constant challenge for digital investigators. In the rapidly evolving landscape of Artificial Intelligence (AI), keeping up with the digital forensic analysis of each new tool is a difficult task. New, advanced Large Language Model (LLM)s can produce human-like artifacts because of their complex textual processing capabilities. One of the newest innovations is a multi-agent Large Language Model (LLM) framework by Microsoft called AutoGen. AutoGen enables the creation of a team of specialist Large Language Model (LLM)-backed agents where the agents \"chat\" with each other to plan, iterate, and determine when a given task is complete. Typically one of the agents represents the human user while the other agents work autonomously after the human gives each agent a responsibility on the team. Thus, from a digital forensics perspective, it is necessary to determine which artifacts are created by the human user and which artifacts are created by the autonomous agents. Analysis in this work indicates that the current implementation of AutoGen has little in artifacts for attribution outside of particular memory artifacts, yet has strong indicators of usage in disk and network artifacts. Our research provides the initial account on the digital artifacts of the Large Language Model (LLM) technology AutoGen and first artifact examination for a Large Language Model (LLM) framework.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "03702ca194d23145b9b9b2ed2f31145e08366436", "publication_date": "2024-10-30", "title": "ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration", "authors": "Andrew Estornell, Jean-Fran\u00e7ois Ton, Yuanshun Yao, Yang Liu", "venue": "International Conference on Learning Representations", "citation_count": 2, "influential_citation_count": 0, "abstract": "Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models. While these paradigms show promise in improving model efficacy, most works in this area treat collaboration as an emergent behavior, rather than a learned behavior. In doing so, current multi-agent frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. To address this limitation, we propose ACC-Collab, an Actor-Critic based learning framework to produce a two-agent team (an actor-agent and a critic-agent) specialized in collaboration. We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.", "pdf_url": "https://arxiv.org/pdf/2411.00053.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-30_ACC-Collab__An_Actor-Critic_Approach_to_Multi-Agent_LLM_Collaboration.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-30_ACC-Collab__An_Actor-Critic_Approach_to_Multi-Agent_LLM_Collaboration.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "0fcf26cf17ecc9e2cc2aea069c6f8a3eccd375a4", "publication_date": "2025-03-31", "title": "Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks", "authors": "Rana Muhammad Shahroz Khan, Zhen Tan, Sukwon Yun, Charles Flemming, Tianlong Chen", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 1, "abstract": "Most discussions about Large Language Model (LLM) safety have focused on single-agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and decentralized reasoning. In this work, we innovatively focus on attacking pragmatic systems that have constrains such as limited token bandwidth, latency between message delivery, and defense mechanisms. We design a $\\textit{permutation-invariant adversarial attack}$ that optimizes prompt distribution across latency and bandwidth-constraint network topologies to bypass distributed safety mechanisms within the system. Formulating the attack path as a problem of $\\textit{maximum-flow minimum-cost}$, coupled with the novel $\\textit{Permutation-Invariant Evasion Loss (PIEL)}$, we leverage graph-based optimization to maximize attack success rate while minimizing detection risk. Evaluating across models including $\\texttt{Llama}$, $\\texttt{Mistral}$, $\\texttt{Gemma}$, $\\texttt{DeepSeek}$ and other variants on various datasets like $\\texttt{JailBreakBench}$ and $\\texttt{AdversarialBench}$, our method outperforms conventional attacks by up to $7\\times$, exposing critical vulnerabilities in multi-agent systems. Moreover, we demonstrate that existing defenses, including variants of $\\texttt{Llama-Guard}$ and $\\texttt{PromptGuard}$, fail to prohibit our attack, emphasizing the urgent need for multi-agent specific safety mechanisms.", "pdf_url": "https://arxiv.org/pdf/2504.00218.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-03-31_Agents_Under_Siege__Breaking_Pragmatic_Multi-Agent_LLM_Systems_with_Optimized_Prompt_Attacks.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-31_Agents_Under_Siege__Breaking_Pragmatic_Multi-Agent_LLM_Systems_with_Optimized_Prompt_Attacks.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "5bd02af3887d41a79aba5c5ac614bf7d980d0519", "publication_date": "2024-11-05", "title": "SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction", "authors": "Shlomo Neuberger, Niv Eckhaus, Uri Berger, Amir Taubenfeld, Gabriel Stanovsky, Ariel Goldstein", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Many human interactions, such as political debates, are carried out in group settings, where there are arbitrarily many participants, each with different views and agendas. To explore such complex social settings, we present SAUCE: a customizable Python platform, allowing researchers to plug-and-play various LLMs participating in discussions on any topic chosen by the user. Our platform takes care of instantiating the models, scheduling their responses, managing the discussion history, and producing a comprehensive output log, all customizable through configuration files, requiring little to no coding skills. A novel feature of SAUCE is our asynchronous communication feature, where models decide when to speak in addition to what to say, thus modeling an important facet of human communication. We show SAUCE's attractiveness in two initial experiments, and invite the community to use it in simulating various group simulations.", "pdf_url": "https://arxiv.org/pdf/2411.03397.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-11-05_SAUCE__Synchronous_and_Asynchronous_User-Customizable_Environment_for_Multi-Agent_LLM_Interaction.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-05_SAUCE__Synchronous_and_Asynchronous_User-Customizable_Environment_for_Multi-Agent_LLM_Interaction.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "a9c0d81fcf801fa689e04438289e09098659c1dd", "publication_date": "2025-04-24", "title": "A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation", "authors": "Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, J. Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. R. Alexander, Robert B. Ross, Yan Feng, L. Levy, Weijie J. Su, C. J. Taylor", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.", "pdf_url": "https://arxiv.org/pdf/2504.17200.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-04-24_A_RAG-Based_Multi-Agent_LLM_System_for_Natural_Hazard_Resilience_and_Adaptation.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-24_A_RAG-Based_Multi-Agent_LLM_System_for_Natural_Hazard_Resilience_and_Adaptation.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "646aa75e6394652f265da46ee5c07cc804210f8c", "publication_date": "2023-12-24", "title": "Agent4Ranking: Semantic Robust Ranking via Personalized Query Rewriting Using Multi-agent LLM", "authors": "Xiaopeng Li, Lixin Su, Pengyue Jia, Xiangyu Zhao, Suqi Cheng, Junfeng Wang, Dawei Yin", "venue": "arXiv.org", "citation_count": 15, "influential_citation_count": 0, "abstract": "Search engines are crucial as they provide an efficient and easy way to access vast amounts of information on the internet for diverse information needs. User queries, even with a specific need, can differ significantly. Prior research has explored the resilience of ranking models against typical query variations like paraphrasing, misspellings, and order changes. Yet, these works overlook how diverse demographics uniquely formulate identical queries. For instance, older individuals tend to construct queries more naturally and in varied order compared to other groups. This demographic diversity necessitates enhancing the adaptability of ranking models to diverse query formulations. To this end, in this paper, we propose a framework that integrates a novel rewriting pipeline that rewrites queries from various demographic perspectives and a novel framework to enhance ranking robustness. To be specific, we use Chain of Thought (CoT) technology to utilize Large Language Models (LLMs) as agents to emulate various demographic profiles, then use them for efficient query rewriting, and we innovate a robust Multi-gate Mixture of Experts (MMoE) architecture coupled with a hybrid loss function, collectively strengthening the ranking models' robustness. Our extensive experimentation on both public and industrial datasets assesses the efficacy of our query rewriting approach and the enhanced accuracy and robustness of the ranking model. The findings highlight the sophistication and effectiveness of our proposed model.", "pdf_url": "https://arxiv.org/pdf/2312.15450.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-24_Agent4Ranking__Semantic_Robust_Ranking_via_Personalized_Query_Rewriting_Using_Multi-agent_LLM.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-24_Agent4Ranking__Semantic_Robust_Ranking_via_Personalized_Query_Rewriting_Using_Multi-agent_LLM.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "356b85ae926b2a8b4cd794e10fe8f37891ebf8d7", "publication_date": "2025-03-15", "title": "SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning", "authors": "Edward Y. Chang, Longling Geng", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Recent LLM-based agent frameworks have demonstrated impressive capabilities in task delegation and workflow orchestration, but face significant challenges in maintaining context awareness and ensuring planning consistency. This paper presents SagaLLM, a structured multi-agent framework that addresses four fundamental limitations in current LLM approaches: inadequate self-validation, context narrowing, lacking transaction properties, and insufficient inter-agent coordination. By implementing specialized context management agents and validation protocols, SagaLLM preserves critical constraints and state information throughout complex planning processes, enabling robust and consistent decision-making even during disruptions. We evaluate our approach using selected problems from the REALM benchmark, focusing on sequential and reactive planning scenarios that challenge both context retention and adaptive reasoning. Our experiments with state-of-the-art LLMs, Claude 3.7, DeepSeek R1, GPT-4o, and GPT-o1, demonstrate that while these models exhibit impressive reasoning capabilities, they struggle with maintaining global constraint awareness during complex planning tasks, particularly when adapting to unexpected changes. In contrast, the distributed cognitive architecture of SagaLLM shows significant improvements in planning consistency, constraint enforcement, and adaptation to disruptions in various scenarios.", "pdf_url": "https://arxiv.org/pdf/2503.11951.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-03-15_SagaLLM__Context_Management__Validation__and_Transaction_Guarantees_for_Multi-Agent_LLM_Planning.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-15_SagaLLM__Context_Management__Validation__and_Transaction_Guarantees_for_Multi-Agent_LLM_Planning.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "50bc4f98893dde3039a0d1b11145963c165c2f94", "publication_date": "2025-02-03", "title": "PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback", "authors": "Kanika Goswami, Puneet Mathur, Ryan A. Rossi, Franck Dernoncourt", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Scientific data visualization is pivotal for transforming raw data into comprehensible visual representations, enabling pattern recognition, forecasting, and the presentation of data-driven insights. However, novice users often face difficulties due to the complexity of selecting appropriate tools and mastering visualization techniques. Large Language Models (LLMs) have recently demonstrated potential in assisting code generation, though they struggle with accuracy and require iterative debugging. In this paper, we propose PlotGen, a novel multi-agent framework aimed at automating the creation of precise scientific visualizations. PlotGen orchestrates multiple LLM-based agents, including a Query Planning Agent that breaks down complex user requests into executable steps, a Code Generation Agent that converts pseudocode into executable Python code, and three retrieval feedback agents - a Numeric Feedback Agent, a Lexical Feedback Agent, and a Visual Feedback Agent - that leverage multimodal LLMs to iteratively refine the data accuracy, textual labels, and visual correctness of generated plots via self-reflection. Extensive experiments show that PlotGen outperforms strong baselines, achieving a 4-6 percent improvement on the MatPlotBench dataset, leading to enhanced user trust in LLM-generated visualizations and improved novice productivity due to a reduction in debugging time needed for plot errors.", "pdf_url": "https://arxiv.org/pdf/2502.00988.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-02-03_PlotGen__Multi-Agent_LLM-based_Scientific_Data_Visualization_via_Multimodal_Feedback.pdf", "markdown_path": "data/semantic/markdown_files/2025-02-03_PlotGen__Multi-Agent_LLM-based_Scientific_Data_Visualization_via_Multimodal_Feedback.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "f7a636f9fba4e3e2107569a68580ed1acbb5f639", "publication_date": "2025-04-02", "title": "Self-Resource Allocation in Multi-Agent LLM Systems", "authors": "Alfonso Amayuelas, Jingbo Yang, Saaket Agashe, Ashwin Nagarajan, Antonis Antoniades, Xin Eric Wang, W. Wang", "venue": "arXiv.org", "citation_count": 5, "influential_citation_count": 0, "abstract": "With the development of LLMs as agents, there is a growing interest in connecting multiple agents into multi-agent systems to solve tasks concurrently, focusing on their role in task assignment and coordination. This paper explores how LLMs can effectively allocate computational tasks among multiple agents, considering factors such as cost, efficiency, and performance. In this work, we address key questions, including the effectiveness of LLMs as orchestrators and planners, comparing their effectiveness in task assignment and coordination. Our experiments demonstrate that LLMs can achieve high validity and accuracy in resource allocation tasks. We find that the planner method outperforms the orchestrator method in handling concurrent actions, resulting in improved efficiency and better utilization of agents. Additionally, we show that providing explicit information about worker capabilities enhances the allocation strategies of planners, particularly when dealing with suboptimal workers.", "pdf_url": "https://arxiv.org/pdf/2504.02051.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-04-02_Self-Resource_Allocation_in_Multi-Agent_LLM_Systems.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-02_Self-Resource_Allocation_in_Multi-Agent_LLM_Systems.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "58a4c3f8015865da42ba260676e193c93b3e8eb3", "publication_date": "2025-03-12", "title": "Multi-Agent LLM Actor-Critic Framework for Social Robot Navigation", "authors": "Weizheng Wang, Ike Obi, Byung-Cheol Min", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Recent advances in robotics and large language models (LLMs) have sparked growing interest in human-robot collaboration and embodied intelligence. To enable the broader deployment of robots in human-populated environments, socially-aware robot navigation (SAN) has become a key research area. While deep reinforcement learning approaches that integrate human-robot interaction (HRI) with path planning have demonstrated strong benchmark performance, they often struggle to adapt to new scenarios and environments. LLMs offer a promising avenue for zero-shot navigation through commonsense inference. However, most existing LLM-based frameworks rely on centralized decision-making, lack robust verification mechanisms, and face inconsistencies in translating macro-actions into precise low-level control signals. To address these challenges, we propose SAMALM, a decentralized multi-agent LLM actor-critic framework for multi-robot social navigation. In this framework, a set of parallel LLM actors, each reflecting distinct robot personalities or configurations, directly generate control signals. These actions undergo a two-tier verification process via a global critic that evaluates group-level behaviors and individual critics that assess each robot's context. An entropy-based score fusion mechanism further enhances self-verification and re-query, improving both robustness and coordination. Experimental results confirm that SAMALM effectively balances local autonomy with global oversight, yielding socially compliant behaviors and strong adaptability across diverse multi-robot scenarios. More details and videos about this work are available at: https://sites.google.com/view/SAMALM.", "pdf_url": "https://arxiv.org/pdf/2503.09758.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-03-12_Multi-Agent_LLM_Actor-Critic_Framework_for_Social_Robot_Navigation.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-12_Multi-Agent_LLM_Actor-Critic_Framework_for_Social_Robot_Navigation.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "82f5b9da7ca932129f849f3fe7319e747855af37", "publication_date": "2025-03-18", "title": "MANTRA: Enhancing Automated Method-Level Refactoring with Contextual RAG and Multi-Agent LLM Collaboration", "authors": "Yisen Xu, Feng Lin, Jinqiu Yang, Tse-Hsun Chen, Nikolaos Tsantalis", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 1, "abstract": "Maintaining and scaling software systems relies heavily on effective code refactoring, yet this process remains labor-intensive, requiring developers to carefully analyze existing codebases and prevent the introduction of new defects. Although recent advancements have leveraged Large Language Models (LLMs) to automate refactoring tasks, current solutions are constrained in scope and lack mechanisms to guarantee code compilability and successful test execution. In this work, we introduce MANTRA, a comprehensive LLM agent-based framework that automates method-level refactoring. MANTRA integrates Context-Aware Retrieval-Augmented Generation, coordinated Multi-Agent Collaboration, and Verbal Reinforcement Learning to emulate human decision-making during refactoring while preserving code correctness and readability. Our empirical study, conducted on 703 instances of\"pure refactorings\"(i.e., code changes exclusively involving structural improvements), drawn from 10 representative Java projects, covers the six most prevalent refactoring operations. Experimental results demonstrate that MANTRA substantially surpasses a baseline LLM model (RawGPT ), achieving an 82.8% success rate (582/703) in producing code that compiles and passes all tests, compared to just 8.7% (61/703) with RawGPT. Moreover, in comparison to IntelliJ's LLM-powered refactoring tool (EM-Assist), MANTRA exhibits a 50% improvement in generating Extract Method transformations. A usability study involving 37 professional developers further shows that refactorings performed by MANTRA are perceived to be as readable and reusable as human-written code, and in certain cases, even more favorable. These results highlight the practical advantages of MANTRA and emphasize the growing potential of LLM-based systems in advancing the automation of software refactoring tasks.", "pdf_url": "https://arxiv.org/pdf/2503.14340.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-03-18_MANTRA__Enhancing_Automated_Method-Level_Refactoring_with_Contextual_RAG_and_Multi-Agent_LLM_Collabo.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-18_MANTRA__Enhancing_Automated_Method-Level_Refactoring_with_Contextual_RAG_and_Multi-Agent_LLM_Collabo.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "b4e979f4407cd3dd7fee0b8a87eab6b571f38514", "publication_date": "2025-04-01", "title": "When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)", "authors": "Mahak Agarwal, Divyam Khanna", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 1, "abstract": "In many real-world scenarios, a single Large Language Model (LLM) may encounter contradictory claims-some accurate, others forcefully incorrect-and must judge which is true. We investigate this risk in a single-turn, multi-agent debate framework: one LLM-based agent provides a factual answer from TruthfulQA, another vigorously defends a falsehood, and the same LLM architecture serves as judge. We introduce the Confidence-Weighted Persuasion Override Rate (CW-POR), which captures not only how often the judge is deceived but also how strongly it believes the incorrect choice. Our experiments on five open-source LLMs (3B-14B parameters), where we systematically vary agent verbosity (30-300 words), reveal that even smaller models can craft persuasive arguments that override truthful answers-often with high confidence. These findings underscore the importance of robust calibration and adversarial testing to prevent LLMs from confidently endorsing misinformation.", "pdf_url": "https://arxiv.org/pdf/2504.00374.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-04-01_When_Persuasion_Overrides_Truth_in_Multi-Agent_LLM_Debates__Introducing_a_Confidence-Weighted_Persua.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-01_When_Persuasion_Overrides_Truth_in_Multi-Agent_LLM_Debates__Introducing_a_Confidence-Weighted_Persua.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "7cac6fd998b511d0e58d6463e8212a0c3d3c28cd", "publication_date": "2025-04-09", "title": "Modeling Response Consistency in Multi-Agent LLM Systems: A Comparative Analysis of Shared and Separate Context Approaches", "authors": "Tooraj Helmi", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Large Language Models (LLMs) are increasingly utilized in multi-agent systems (MAS) to enhance collaborative problem-solving and interactive reasoning. Recent advancements have enabled LLMs to function as autonomous agents capable of understanding complex interactions across multiple topics. However, deploying LLMs in MAS introduces challenges related to context management, response consistency, and scalability, especially when agents must operate under memory limitations and handle noisy inputs. While prior research has explored optimizing context sharing and response latency in LLM-driven MAS, these efforts often focus on either fully centralized or decentralized configurations, each with distinct trade-offs. In this paper, we develop a probabilistic framework to analyze the impact of shared versus separate context configurations on response consistency and response times in LLM-based MAS. We introduce the Response Consistency Index (RCI) as a metric to evaluate the effects of context limitations, noise, and inter-agent dependencies on system performance. Our approach differs from existing research by focusing on the interplay between memory constraints and noise management, providing insights into optimizing scalability and response times in environments with interdependent topics. Through this analysis, we offer a comprehensive understanding of how different configurations impact the efficiency of LLM-driven multi-agent systems, thereby guiding the design of more robust architectures.", "pdf_url": "https://arxiv.org/pdf/2504.07303.pdf", "pdf_filepath": "data/semantic/pdf_files/2025-04-09_Modeling_Response_Consistency_in_Multi-Agent_LLM_Systems__A_Comparative_Analysis_of_Shared_and_Separ.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-09_Modeling_Response_Consistency_in_Multi-Agent_LLM_Systems__A_Comparative_Analysis_of_Shared_and_Separ.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c", "publication_date": "2023", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework", "authors": "Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang", "venue": "arXiv.org", "citation_count": 643, "influential_citation_count": 51, "abstract": null, "pdf_url": "https://arxiv.org/pdf/2308.08155", "pdf_filepath": "data/semantic/pdf_files/2023_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Multi-Agent_Conversation_Framework.pdf", "markdown_path": "data/semantic/markdown_files/2023_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Multi-Agent_Conversation_Framework.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "e89ee3f84f1f07229a7ba211bad3465d2c80a325", "publication_date": "2024-02-28", "title": "Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?", "authors": "Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, Yangqiu Song", "venue": "Annual Meeting of the Association for Computational Linguistics", "citation_count": 76, "influential_citation_count": 2, "abstract": "Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, we reevaluate this claim through systematic experiments, where we propose a novel group discussion framework to enrich the set of discussion mechanisms. Interestingly, our results show that a single-agent LLM with strong prompts can achieve almost the same performance as the best existing discussion approach on a wide range of reasoning tasks and backbone LLMs. We observe that the multi-agent discussion performs better than a single agent only when there is no demonstration in the prompt. Further study reveals the common interaction mechanisms of LLMs during the discussion.", "pdf_url": "https://arxiv.org/pdf/2402.18272.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-02-28_Rethinking_the_Bounds_of_LLM_Reasoning__Are_Multi-Agent_Discussions_the_Key_.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-28_Rethinking_the_Bounds_of_LLM_Reasoning__Are_Multi-Agent_Discussions_the_Key_.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "fc8ce12d6186ddaa797e2b36d5e8eb7921425308", "publication_date": "2024-10-08", "title": "A survey on LLM-based multi-agent systems: workflow, infrastructure, and challenges", "authors": "Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu, Yi Yang", "venue": "Vicinagearth", "citation_count": 50, "influential_citation_count": 3, "abstract": "The pursuit of more intelligent and credible autonomous systems, akin to human society, has been a long-standing endeavor for humans. Leveraging the exceptional reasoning and planning capabilities of large language models (LLMs), LLM-based agents have been proposed and have achieved remarkable success across a wide array of tasks. Notably, LLM-based multi-agent systems (MAS) are considered a promising pathway towards realizing general artificial intelligence that is equivalent to or surpasses human-level intelligence. In this paper, we present a comprehensive survey of these studies, offering a systematic review of LLM-based MAS. Adhering to the workflow of LLM-based multi-agent systems, we synthesize a general structure encompassing five key components: profile, perception, self-action, mutual interaction, and evolution. This unified framework encapsulates much of the previous work in the field. Furthermore, we illuminate the extensive applications of LLM-based MAS in two principal areas: problem-solving and world simulation. Finally, we discuss in detail several contemporary challenges and provide insights into potential future directions in this domain.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "006c4c7470566327e5b02b94936d0be0033fc9f5", "publication_date": "2024-03-26", "title": "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution", "authors": "Wei Tao, Yucheng Zhou, Wenqiang Zhang, Yu-Xi Cheng", "venue": "Neural Information Processing Systems", "citation_count": 41, "influential_citation_count": 3, "abstract": "In software development, resolving the emergent issues within GitHub repositories is a complex challenge that involves not only the incorporation of new code but also the maintenance of existing code. Large Language Models (LLMs) have shown promise in code generation but face difficulties in resolving Github issues, particularly at the repository level. To overcome this challenge, we empirically study the reason why LLMs fail to resolve GitHub issues and analyze the major factors. Motivated by the empirical findings, we propose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution, MAGIS, consisting of four agents customized for software evolution: Manager, Repository Custodian, Developer, and Quality Assurance Engineer agents. This framework leverages the collaboration of various agents in the planning and coding process to unlock the potential of LLMs to resolve GitHub issues. In experiments, we employ the SWE-bench benchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub issues, significantly outperforming the baselines. Specifically, MAGIS achieves an eight-fold increase in resolved ratio over the direct application of GPT-4, the advanced LLM.", "pdf_url": "https://arxiv.org/pdf/2403.17927.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-26_MAGIS__LLM-Based_Multi-Agent_Framework_for_GitHub_Issue_Resolution.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-26_MAGIS__LLM-Based_Multi-Agent_Framework_for_GitHub_Issue_Resolution.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "ab6f63877fdb55ce0b05964476e6fb303fc376af", "publication_date": "2024-04-26", "title": "A Unified Debugging Approach via LLM-Based Multi-Agent Synergy", "authors": "Cheryl Lee, Chun Xia, Jen-Tse Huang, Zhouruixing Zhu, Lingming Zhang, Michael R. Lyu", "venue": "", "citation_count": 37, "influential_citation_count": 4, "abstract": "Software debugging is a time-consuming endeavor involving a series of steps, such as fault localization and patch generation, each requiring thorough analysis and a deep understanding of the underlying logic. While large language models (LLMs) demonstrate promising potential in coding tasks, their performance in debugging remains limited. Current LLM-based methods often focus on isolated steps and struggle with complex bugs. In this paper, we propose the first end-to-end framework, FixAgent, for unified debugging through multi-agent synergy. It mimics the entire cognitive processes of developers, with each agent specialized as a particular component of this process rather than mirroring the actions of an independent expert as in previous multi-agent systems. Agents are coordinated through a three-level design, following a cognitive model of debugging, allowing adaptive handling of bugs with varying complexities. Experiments on extensive benchmarks demonstrate that FixAgent significantly outperforms state-of-the-art repair methods, fixing 1.25$\\times$ to 2.56$\\times$ bugs on the repo-level benchmark, Defects4J. This performance is achieved without requiring ground-truth root-cause code statements, unlike the baselines. Our source code is available on https://github.com/AcceptePapier/UniDebugger.", "pdf_url": "https://arxiv.org/pdf/2404.17153.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-26_A_Unified_Debugging_Approach_via_LLM-Based_Multi-Agent_Synergy.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-26_A_Unified_Debugging_Approach_via_LLM-Based_Multi-Agent_Synergy.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "c5cb68ac59f98fafc7cb96b86fca27e662e0cba8", "publication_date": "2024-04-02", "title": "Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization", "authors": "Yoichi Ishibashi, Yoshimasa Nishimura", "venue": "arXiv.org", "citation_count": 39, "influential_citation_count": 3, "abstract": "Recent advancements in automatic code generation using large language model (LLM) agent have brought us closer to the future of automated software development. However, existing single-agent approaches face limitations in generating and improving large-scale, complex codebases due to constraints in context length. To tackle this challenge, we propose Self-Organized multi-Agent framework (SoA), a novel multi-agent framework that enables the scalable and efficient generation and optimization of large-scale code. In SoA, self-organized agents operate independently to generate and modify code components while seamlessly collaborating to construct the overall codebase. A key feature of our framework is the automatic multiplication of agents based on problem complexity, allowing for dynamic scalability. This enables the overall code volume to be increased indefinitely according to the number of agents, while the amount of code managed by each agent remains constant. We evaluate SoA on the HumanEval benchmark and demonstrate that, compared to a single-agent system, each agent in SoA handles significantly less code, yet the overall generated code is substantially greater. Moreover, SoA surpasses the powerful single-agent baseline by 5% in terms of Pass@1 accuracy.", "pdf_url": "https://arxiv.org/pdf/2404.02183.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-02_Self-Organized_Agents__A_LLM_Multi-Agent_Framework_toward_Ultra_Large-Scale_Code_Generation_and_Opti.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-02_Self-Organized_Agents__A_LLM_Multi-Agent_Framework_toward_Ultra_Large-Scale_Code_Generation_and_Opti.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "6d1ef839db3d637977392f4a7046c26bfea37d46", "publication_date": "2024-02-05", "title": "LLM Multi-Agent Systems: Challenges and Open Problems", "authors": "Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu, Chaoyang He", "venue": "arXiv.org", "citation_count": 42, "influential_citation_count": 3, "abstract": "This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.", "pdf_url": "https://arxiv.org/pdf/2402.03578.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-02-05_LLM_Multi-Agent_Systems__Challenges_and_Open_Problems.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-05_LLM_Multi-Agent_Systems__Challenges_and_Open_Problems.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "3d814347e382fc3fcc071876744f139d2c101be7", "publication_date": "2024-07-10", "title": "Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities", "authors": "Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu", "venue": "arXiv.org", "citation_count": 27, "influential_citation_count": 3, "abstract": "The rapid adoption of large language models (LLMs) in multi-agent systems has highlighted their impressive capabilities in various applications, such as collaborative problem-solving and autonomous negotiation. However, the security implications of these LLM-based multi-agent systems have not been thoroughly investigated, particularly concerning the spread of manipulated knowledge. In this paper, we investigate this critical issue by constructing a detailed threat model and a comprehensive simulation environment that mirrors real-world multi-agent deployments in a trusted platform. Subsequently, we propose a novel two-stage attack method involving Persuasiveness Injection and Manipulated Knowledge Injection to systematically explore the potential for manipulated knowledge (i.e., counterfactual and toxic knowledge) spread without explicit prompt manipulation. Our method leverages the inherent vulnerabilities of LLMs in handling world knowledge, which can be exploited by attackers to unconsciously spread fabricated information. Through extensive experiments, we demonstrate that our attack method can successfully induce LLM-based agents to spread both counterfactual and toxic knowledge without degrading their foundational capabilities during agent communication. Furthermore, we show that these manipulations can persist through popular retrieval-augmented generation frameworks, where several benign agents store and retrieve manipulated chat histories for future interactions. This persistence indicates that even after the interaction has ended, the benign agents may continue to be influenced by manipulated knowledge. Our findings reveal significant security risks in LLM-based multi-agent systems, emphasizing the imperative need for robust defenses against manipulated knowledge spread, such as introducing ``guardian'' agents and advanced fact-checking tools.", "pdf_url": "https://arxiv.org/pdf/2407.07791.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-07-10_Flooding_Spread_of_Manipulated_Knowledge_in_LLM-Based_Multi-Agent_Communities.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-10_Flooding_Spread_of_Manipulated_Knowledge_in_LLM-Based_Multi-Agent_Communities.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "165921d2aa4f1d110d25d488ea8b205d134b16e6", "publication_date": "2024-10-09", "title": "Prompt Infection: LLM-to-LLM Prompt Injection within Multi-Agent Systems", "authors": "Donghyun Lee, Mo Tiwari", "venue": "arXiv.org", "citation_count": 20, "influential_citation_count": 3, "abstract": "As Large Language Models (LLMs) grow increasingly powerful, multi-agent systems are becoming more prevalent in modern AI applications. Most safety research, however, has focused on vulnerabilities in single-agent LLMs. These include prompt injection attacks, where malicious prompts embedded in external content trick the LLM into executing unintended or harmful actions, compromising the victim's application. In this paper, we reveal a more dangerous vector: LLM-to-LLM prompt injection within multi-agent systems. We introduce Prompt Infection, a novel attack where malicious prompts self-replicate across interconnected agents, behaving much like a computer virus. This attack poses severe threats, including data theft, scams, misinformation, and system-wide disruption, all while propagating silently through the system. Our extensive experiments demonstrate that multi-agent systems are highly susceptible, even when agents do not publicly share all communications. To address this, we propose LLM Tagging, a defense mechanism that, when combined with existing safeguards, significantly mitigates infection spread. This work underscores the urgent need for advanced security measures as multi-agent LLM systems become more widely adopted.", "pdf_url": "https://arxiv.org/pdf/2410.07283.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-09_Prompt_Infection__LLM-to-LLM_Prompt_Injection_within_Multi-Agent_Systems.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-09_Prompt_Infection__LLM-to-LLM_Prompt_Injection_within_Multi-Agent_Systems.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "8bf02bb6762641924feb5bade378ef57024cc534", "publication_date": "None", "title": "Reliable Decision-Making for Multi-Agent LLM Systems", "authors": "Xian Yeow, Shunichi Lee, Lasitha Akatsuka, Vidyaratne Aman, Ahmed Kumar, Chetan Farahat, Gupta", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "ec58a564fdda29e6a9a0a7bab5eeb4c290f716d7", "publication_date": "2023-08-14", "title": "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate", "authors": "Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shan Zhang, Jie Fu, Zhiyuan Liu", "venue": "arXiv.org", "citation_count": 489, "influential_citation_count": 31, "abstract": "Text evaluation has historically posed significant challenges, often demanding substantial labor and time cost. With the emergence of large language models (LLMs), researchers have explored LLMs' potential as alternatives for human evaluation. While these single-agent-based approaches show promise, experimental results suggest that further advancements are needed to bridge the gap between their current effectiveness and human-level evaluation quality. Recognizing that best practices of human evaluation processes often involve multiple human annotators collaborating in the evaluation, we resort to a multi-agent debate framework, moving beyond single-agent prompting strategies. The multi-agent-based approach enables a group of LLMs to synergize with an array of intelligent counterparts, harnessing their distinct capabilities and expertise to enhance efficiency and effectiveness in handling intricate tasks. In this paper, we construct a multi-agent referee team called ChatEval to autonomously discuss and evaluate the quality of generated responses from different models on open-ended questions and traditional natural language generation (NLG) tasks. Our analysis shows that ChatEval transcends mere textual scoring, offering a human-mimicking evaluation process for reliable assessments. Our code is available at https://github.com/chanchimin/ChatEval.", "pdf_url": "https://arxiv.org/pdf/2308.07201.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-08-14_ChatEval__Towards_Better_LLM-based_Evaluators_through_Multi-Agent_Debate.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-14_ChatEval__Towards_Better_LLM-based_Evaluators_through_Multi-Agent_Debate.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "174fab182b3968879884a5af2ef2344ef2623516", "publication_date": "None", "title": "MASON - A Multi-Agent LLM Framework for No-Code Development", "authors": "Muhammed Roshan, Kayvan Palayamkot, Karim", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "e1b62c7ee4e22ab63e3b0c9968563e6675833e36", "publication_date": "2024-05-23", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "authors": "Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Xuelong Li, Zhen Wang", "venue": "arXiv.org", "citation_count": 31, "influential_citation_count": 1, "abstract": "Grounding the reasoning ability of large language models (LLMs) for embodied tasks is challenging due to the complexity of the physical world. Especially, LLM planning for multi-agent collaboration requires communication of agents or credit assignment as the feedback to re-adjust the proposed plans and achieve effective coordination. However, existing methods that overly rely on physical verification or self-reflection suffer from excessive and inefficient querying of LLMs. In this paper, we propose a novel framework for multi-agent collaboration that introduces Reinforced Advantage feedback (ReAd) for efficient self-refinement of plans. Specifically, we perform critic regression to learn a sequential advantage function from LLM-planned data, and then treat the LLM planner as an optimizer to generate actions that maximize the advantage function. It endows the LLM with the foresight to discern whether the action contributes to accomplishing the final task. We provide theoretical analysis by extending advantage-weighted regression in reinforcement learning to multi-agent systems. Experiments on Overcooked-AI and a difficult variant of RoCoBench show that ReAd surpasses baselines in success rate, and also significantly decreases the interaction steps of agents and query rounds of LLMs, demonstrating its high efficiency for grounding LLMs. More results are given at https://read-llm.github.io/.", "pdf_url": "https://arxiv.org/pdf/2405.14314.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-05-23_Towards_Efficient_LLM_Grounding_for_Embodied_Multi-Agent_Collaboration.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-23_Towards_Efficient_LLM_Grounding_for_Embodied_Multi-Agent_Collaboration.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "dd38755291d108ab86c68d1aac7485921bb8e647", "publication_date": "2024-05-17", "title": "LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions", "authors": "Chuanneng Sun, Songjun Huang, D. Pompili", "venue": "arXiv.org", "citation_count": 32, "influential_citation_count": 0, "abstract": "In recent years, Large Language Models (LLMs) have shown great abilities in various tasks, including question answering, arithmetic problem solving, and poem writing, among others. Although research on LLM-as-an-agent has shown that LLM can be applied to Reinforcement Learning (RL) and achieve decent results, the extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as many aspects, such as coordination and communication between agents, are not considered in the RL frameworks of a single agent. To inspire more research on LLM-based MARL, in this letter, we survey the existing LLM-based single-agent and multi-agent RL frameworks and provide potential research directions for future research. In particular, we focus on the cooperative tasks of multiple agents with a common goal and communication among them. We also consider human-in/on-the-loop scenarios enabled by the language component in the framework.", "pdf_url": "https://arxiv.org/pdf/2405.11106.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-05-17_LLM-based_Multi-Agent_Reinforcement_Learning__Current_and_Future_Directions.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-17_LLM-based_Multi-Agent_Reinforcement_Learning__Current_and_Future_Directions.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "9ea0757c750ab1222a7442d3485a74d1c526b04c", "publication_date": "2023-08-16", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation", "authors": "Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, A. Awadallah, Ryen W. White, Doug Burger, Chi Wang", "venue": "", "citation_count": 350, "influential_citation_count": 28, "abstract": "AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.", "pdf_url": "https://arxiv.org/pdf/2308.08155.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-08-16_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Multi-Agent_Conversation.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-16_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Multi-Agent_Conversation.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "b93ac10de176c4a7aaa2cc652b90bb25636532cd", "publication_date": "2024-02-18", "title": "Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation", "authors": "Siyuan Wang, Zhuohan Long, Zhihao Fan, Zhongyu Wei, Xuanjing Huang", "venue": "International Conference on Computational Linguistics", "citation_count": 33, "influential_citation_count": 2, "abstract": "This paper presents a benchmark self-evolving framework to dynamically evaluate rapidly advancing Large Language Models (LLMs), aiming for a more accurate assessment of their capabilities and limitations. We utilize a multi-agent system to manipulate the context or question of original instances, reframing new evolving instances with high confidence that dynamically extend existing benchmarks. Towards a more scalable, robust and fine-grained evaluation, we implement six reframing operations to construct evolving instances testing LLMs against diverse queries, data noise and probing their problem-solving sub-abilities. With this framework, we extend benchmark datasets of four tasks. Experimental results show a general performance decline in most LLMs against their original results. This decline under our scalable and robust evaluations, alongside our fine-grained evaluation, more accurately reflect models' capabilities. Besides, our framework widens performance discrepancies both between different models and within the same model across various tasks, facilitating more informed model selection for specific tasks (Code and data are available at https://github.com/NanshineLoong/Self-Evolving-Benchmark).", "pdf_url": "https://arxiv.org/pdf/2402.11443.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-02-18_Benchmark_Self-Evolving__A_Multi-Agent_Framework_for_Dynamic_LLM_Evaluation.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-18_Benchmark_Self-Evolving__A_Multi-Agent_Framework_for_Dynamic_LLM_Evaluation.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "0b41a6899c29a04e1217e6cc80a3d915ea18e2d8", "publication_date": "2024-07-09", "title": "FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making", "authors": "Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W. Suchow, Rong Liu, Zhenyu Cui, Denghui Zhang, K. Subbalakshmi, Guojun Xiong, Yueru He, Jimin Huang, Dong Li, Qianqian Xie", "venue": "Neural Information Processing Systems", "citation_count": 25, "influential_citation_count": 1, "abstract": "Large language models (LLMs) have demonstrated notable potential in conducting complex tasks and are increasingly utilized in various financial applications. However, high-quality sequential financial investment decision-making remains challenging. These tasks require multiple interactions with a volatile environment for every decision, demanding sufficient intelligence to maximize returns and manage risks. Although LLMs have been used to develop agent systems that surpass human teams and yield impressive investment returns, opportunities to enhance multi-sourced information synthesis and optimize decision-making outcomes through timely experience refinement remain unexplored. Here, we introduce the FinCon, an LLM-based multi-agent framework with CONceptual verbal reinforcement tailored for diverse FINancial tasks. Inspired by effective real-world investment firm organizational structures, FinCon utilizes a manager-analyst communication hierarchy. This structure allows for synchronized cross-functional agent collaboration towards unified goals through natural language interactions and equips each agent with greater memory capacity than humans. Additionally, a risk-control component in FinCon enhances decision quality by episodically initiating a self-critiquing mechanism to update systematic investment beliefs. The conceptualized beliefs serve as verbal reinforcement for the future agent's behavior and can be selectively propagated to the appropriate node that requires knowledge updates. This feature significantly improves performance while reducing unnecessary peer-to-peer communication costs. Moreover, FinCon demonstrates strong generalization capabilities in various financial tasks, including single stock trading and portfolio management.", "pdf_url": "https://arxiv.org/pdf/2407.06567.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-07-09_FinCon__A_Synthesized_LLM_Multi-Agent_System_with_Conceptual_Verbal_Reinforcement_for_Enhanced_Finan.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-09_FinCon__A_Synthesized_LLM_Multi-Agent_System_with_Conceptual_Verbal_Reinforcement_for_Enhanced_Finan.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "dd565137ec79da38bf2d01319bba195c66733212", "publication_date": "2024-07-13", "title": "CellAgent: An LLM-driven Multi-Agent Framework for Automated Single-cell Data Analysis", "authors": "Yihang Xiao, Jinyi Liu, Yan Zheng, Xiaohan Xie, Jianye Hao, Mingzhi Li, Ruitao Wang, Fei Ni, Yuxiao Li, Jintian Luo, Shaoqing Jiao, Jiajie Peng", "venue": "arXiv.org", "citation_count": 21, "influential_citation_count": 1, "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is crucial for biological research, as it enables the precise characterization of cellular heterogeneity. However, manual manipulation of various tools to achieve desired outcomes can be labor-intensive for researchers. To address this, we introduce CellAgent (http://cell.agent4science.cn/), an LLM-driven multi-agent framework, specifically designed for the automatic processing and execution of scRNA-seq data analysis tasks, providing high-quality results with no human intervention. Firstly, to adapt general LLMs to the biological field, CellAgent constructs LLM-driven biological expert roles - planner, executor, and evaluator - each with specific responsibilities. Then, CellAgent introduces a hierarchical decision-making mechanism to coordinate these biological experts, effectively driving the planning and step-by-step execution of complex data analysis tasks. Furthermore, we propose a self-iterative optimization mechanism, enabling CellAgent to autonomously evaluate and optimize solutions, thereby guaranteeing output quality. We evaluate CellAgent on a comprehensive benchmark dataset encompassing dozens of tissues and hundreds of distinct cell types. Evaluation results consistently show that CellAgent effectively identifies the most suitable tools and hyperparameters for single-cell analysis tasks, achieving optimal performance. This automated framework dramatically reduces the workload for science data analyses, bringing us into the\"Agent for Science\"era.", "pdf_url": "https://arxiv.org/pdf/2407.09811.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-07-13_CellAgent__An_LLM-driven_Multi-Agent_Framework_for_Automated_Single-cell_Data_Analysis.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-13_CellAgent__An_LLM-driven_Multi-Agent_Framework_for_Automated_Single-cell_Data_Analysis.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "d4656bba3a424a25fcd9e1fbf3966f080ace9c2f", "publication_date": "2024-01-02", "title": "LLM Harmony: Multi-Agent Communication for Problem Solving", "authors": "Sumedh Rasal", "venue": "arXiv.org", "citation_count": 23, "influential_citation_count": 0, "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving. Traditional techniques like chain-of-thought prompting necessitate explicit human guidance. This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs' autonomous problem-solving capabilities. The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios. Extensive experimentation demonstrates the framework's superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.", "pdf_url": "https://arxiv.org/pdf/2401.01312.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-01-02_LLM_Harmony__Multi-Agent_Communication_for_Problem_Solving.pdf", "markdown_path": "data/semantic/markdown_files/2024-01-02_LLM_Harmony__Multi-Agent_Communication_for_Problem_Solving.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "d0a074d5da6dc44177b7a9533f700b0d8fda23be", "publication_date": "2024", "title": "LLM-Based Multi-Agent Systems for Software Engineering: Vision and the Road Ahead", "authors": "Junda He, Christoph Treude, David Lo", "venue": "arXiv.org", "citation_count": 16, "influential_citation_count": 0, "abstract": "Integrating Large Language Models(LLMs) intoautonomousagents marks a signi\ufb01cant shift in the research landscape by o\ufb00ering cognitive abilities competitive to human planning and reasoning. This paper envisions the evolution of LLM-based Multi-Agent (LMA) systems in addressing complex and multi-faceted software engineering challenges. LMA systems introduce numerous bene\ufb01ts, including enhanced robustness throughcollaborativecross-examination, autonomous problem-solving, and scalable solutions to complex software projects. By examining the role of LMA systems in future software engineering practices, this vision paper highlights the potential applications and emerging challenges. We further point to speci\ufb01c opportunities for research and conclude with a research agenda with a set of research questions to guide future research directions", "pdf_url": "https://arxiv.org/abs/2404.04834/pdf/2404.04834", "pdf_filepath": "data/semantic/pdf_files/2024_LLM-Based_Multi-Agent_Systems_for_Software_Engineering__Vision_and_the_Road_Ahead.pdf", "markdown_path": "data/semantic/markdown_files/2024_LLM-Based_Multi-Agent_Systems_for_Software_Engineering__Vision_and_the_Road_Ahead.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "aebfeb42bbd155c1541a67fddf0a6e2bc5d6ae34", "publication_date": "2024-10-03", "title": "Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems", "authors": "Guibin Zhang, Yanwei Yue, Zhixun Li, Sukwon Yun, Guancheng Wan, Kun Wang, Dawei Cheng, Jeffrey Xu Yu, Tianlong Chen", "venue": "arXiv.org", "citation_count": 17, "influential_citation_count": 0, "abstract": "Recent advancements in large language model (LLM)-powered agents have shown that collective intelligence can significantly outperform individual capabilities, largely attributed to the meticulously designed inter-agent communication topologies. Though impressive in performance, existing multi-agent pipelines inherently introduce substantial token overhead, as well as increased economic costs, which pose challenges for their large-scale deployments. In response to this challenge, we propose an economical, simple, and robust multi-agent communication framework, termed $\\texttt{AgentPrune}$, which can seamlessly integrate into mainstream multi-agent systems and prunes redundant or even malicious communication messages. Technically, $\\texttt{AgentPrune}$ is the first to identify and formally define the \\textit{communication redundancy} issue present in current LLM-based multi-agent pipelines, and efficiently performs one-shot pruning on the spatial-temporal message-passing graph, yielding a token-economic and high-performing communication topology. Extensive experiments across six benchmarks demonstrate that $\\texttt{AgentPrune}$ \\textbf{(I)} achieves comparable results as state-of-the-art topologies at merely $\\$5.6$ cost compared to their $\\$43.7$, \\textbf{(II)} integrates seamlessly into existing multi-agent frameworks with $28.1\\%\\sim72.8\\%\\downarrow$ token reduction, and \\textbf{(III)} successfully defend against two types of agent-based adversarial attacks with $3.5\\%\\sim10.8\\%\\uparrow$ performance boost.", "pdf_url": "https://arxiv.org/pdf/2410.02506.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-03_Cut_the_Crap__An_Economical_Communication_Pipeline_for_LLM-based_Multi-Agent_Systems.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_Cut_the_Crap__An_Economical_Communication_Pipeline_for_LLM-based_Multi-Agent_Systems.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "ff61aef2fef3a235bfaa123158a990c4f5f27d1a", "publication_date": "2024-01-14", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "authors": "Weizhou Shen, Chenliang Li, Hongzhan Chen, Ming Yan, Xiaojun Quan, Hehong Chen, Ji Zhang, Fei Huang", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 55, "influential_citation_count": 1, "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization. While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task. This modular framework facilitates individual updates and the potential use of smaller LLMs for building each capability. To effectively train this framework, we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task. Second, the fine-tuned LLM is used to instantiate the planner, caller, and summarizer respectively, which are continually fine-tuned on respective sub-tasks. Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.", "pdf_url": "https://arxiv.org/pdf/2401.07324.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-01-14_Small_LLMs_Are_Weak_Tool_Learners__A_Multi-LLM_Agent.pdf", "markdown_path": "data/semantic/markdown_files/2024-01-14_Small_LLMs_Are_Weak_Tool_Learners__A_Multi-LLM_Agent.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "34c6cf6dcd23cd448a11165dbde28671e995ce8d", "publication_date": "2024-01-29", "title": "Beyond Direct Diagnosis: LLM-based Multi-Specialist Agent Consultation for Automatic Diagnosis", "authors": "Hao Wang, Sendong Zhao, Zewen Qiang, Nuwa Xi, Bing Qin, Ting Liu", "venue": "arXiv.org", "citation_count": 15, "influential_citation_count": 0, "abstract": "Automatic diagnosis is a significant application of AI in healthcare, where diagnoses are generated based on the symptom description of patients. Previous works have approached this task directly by modeling the relationship between the normalized symptoms and all possible diseases. However, in the clinical diagnostic process, patients are initially consulted by a general practitioner and, if necessary, referred to specialists in specific domains for a more comprehensive evaluation. The final diagnosis often emerges from a collaborative consultation among medical specialist groups. Recently, large language models have shown impressive capabilities in natural language understanding. In this study, we adopt tuning-free LLM-based agents as medical practitioners and propose the Agent-derived Multi-Specialist Consultation (AMSC) framework to model the diagnosis process in the real world by adaptively fusing probability distributions of agents over potential diseases. Experimental results demonstrate the superiority of our approach compared with baselines. Notably, our approach requires significantly less parameter updating and training time, enhancing efficiency and practical utility. Furthermore, we delve into a novel perspective on the role of implicit symptoms within the context of automatic diagnosis.", "pdf_url": "https://arxiv.org/pdf/2401.16107.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-01-29_Beyond_Direct_Diagnosis__LLM-based_Multi-Specialist_Agent_Consultation_for_Automatic_Diagnosis.pdf", "markdown_path": "data/semantic/markdown_files/2024-01-29_Beyond_Direct_Diagnosis__LLM-based_Multi-Specialist_Agent_Consultation_for_Automatic_Diagnosis.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "ead6121fbc787d508dc6a6d7106f72bf0d647d03", "publication_date": "2023-06-05", "title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents", "authors": "Yashar Talebirad, Amirhossein Nadiri", "venue": "arXiv.org", "citation_count": 222, "influential_citation_count": 7, "abstract": "In this paper, we present a novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems. Our framework introduces a collaborative environment where multiple intelligent agent components, each with distinctive attributes and roles, work together to handle complex tasks more efficiently and effectively. We demonstrate the practicality and versatility of our framework through case studies in artificial general intelligence (AGI), specifically focusing on the Auto-GPT and BabyAGI models. We also examine the\"Gorilla\"model, which integrates external APIs into the LLM. Our framework addresses limitations and challenges such as looping issues, security risks, scalability, system evaluation, and ethical considerations. By modeling various domains such as courtroom simulations and software development scenarios, we showcase the potential applications and benefits of our proposed multi-agent system. Our framework provides an avenue for advancing the capabilities and performance of LLMs through collaboration and knowledge exchange among intelligent agents.", "pdf_url": "https://arxiv.org/pdf/2306.03314.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-06-05_Multi-Agent_Collaboration__Harnessing_the_Power_of_Intelligent_LLM_Agents.pdf", "markdown_path": "data/semantic/markdown_files/2023-06-05_Multi-Agent_Collaboration__Harnessing_the_Power_of_Intelligent_LLM_Agents.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "dc10d108823630343484c5eecbb5c3011751282e", "publication_date": "2024-06-27", "title": "LayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design", "authors": "Bingyang Liu, Haoyi Zhang, Xiaohan Gao, Zichen Kong, Xiyuan Tang, Yibo Lin, Runsheng Wang, Ru Huang", "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems", "citation_count": 13, "influential_citation_count": 0, "abstract": "Analog layout design heavily involves interactive processes between humans and design tools. Electronic Design Automation (EDA) tools for this task are usually designed to use scripting commands or visualized buttons for manipulation, especially for interactive automation functionalities, which have a steep learning curve and cumbersome user experience, making a notable barrier to designers' adoption. Aiming to address such a usability issue, this paper introduces LayoutCopilot, a pioneering multi-agent collaborative framework powered by Large Language Models (LLMs) for interactive analog layout design. LayoutCopilot simplifies human-tool interaction by converting natural language instructions into executable script commands, and it interprets high-level design intents into actionable suggestions, significantly streamlining the design process. Experimental results demonstrate the flexibility, efficiency, and accessibility of LayoutCopilot in handling real-world analog designs.", "pdf_url": "https://arxiv.org/pdf/2406.18873.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-06-27_LayoutCopilot__An_LLM-powered_Multi-agent_Collaborative_Framework_for_Interactive_Analog_Layout_Desi.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-27_LayoutCopilot__An_LLM-powered_Multi-agent_Collaborative_Framework_for_Interactive_Analog_Layout_Desi.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "fb66fb26ad3a0e26ed6b56c42a8c02e1737c811a", "publication_date": "2024-09-30", "title": "TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation", "authors": "Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou", "venue": "arXiv.org", "citation_count": 12, "influential_citation_count": 1, "abstract": "Code translation converts code from one programming language to another while maintaining its original functionality, which is crucial for software migration, system refactoring, and cross-platform development. Traditional rule-based methods rely on manually-written rules, which can be time-consuming and often result in less readable code. To overcome this, learning-based methods have been developed, leveraging parallel data to train models for automated code translation. More recently, the advance of Large Language Models (LLMs) further boosts learning-based code translation. Although promising, LLM-translated program still suffers from diverse quality issues (e.g., syntax errors and semantic errors). In particular, it can be challenging for LLMs to self-debug these errors when simply provided with the corresponding error messages. In this work, we propose a novel LLM-based multi-agent system TRANSAGENT, which enhances LLM-based code translation by fixing the syntax errors and semantic errors with the synergy between four LLM-based agents, including Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error Fixer. The main insight of TRANSAGENT is to first localize the error code block in the target program based on the execution alignment between the target and source program, which can narrow down the fixing space and thus lower down the fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark from recent programming tasks to mitigate the potential data leakage issue. On our benchmark, TRANSAGENT outperforms the latest LLM-based code translation technique UniTrans in both translation effectiveness and efficiency; additionally, our evaluation on different LLMs show the generalization of TRANSAGENT and our ablation study shows the contribution of each agent.", "pdf_url": "https://arxiv.org/pdf/2409.19894.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-09-30_TRANSAGENT__An_LLM-Based_Multi-Agent_System_for_Code_Translation.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-30_TRANSAGENT__An_LLM-Based_Multi-Agent_System_for_Code_Translation.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "e321349644c97f0c0d0147c09690e2485d2d61c4", "publication_date": "2024-11-24", "title": "DrugAgent: Automating AI-aided Drug Discovery Programming through LLM Multi-Agent Collaboration", "authors": "Sizhe Liu, Yizhou Lu, Siyu Chen, Xiyang Hu, Jieyu Zhao, Tianfan Fu, Yue Zhao", "venue": "arXiv.org", "citation_count": 12, "influential_citation_count": 0, "abstract": "Recent progress in Large Language Models (LLMs) has drawn attention to their potential for accelerating drug discovery. However, a central problem remains: translating theoretical ideas into robust implementations in the highly specialized context of pharmaceutical research. This limitation prevents practitioners from making full use of the latest AI developments in drug discovery. To address this challenge, we introduce DrugAgent, a multi-agent framework that automates machine learning (ML) programming for drug discovery tasks. DrugAgent employs an LLM Planner that formulates high-level ideas and an LLM Instructor that identifies and integrates domain knowledge when implementing those ideas. We present case studies on three representative drug discovery tasks. Our results show that DrugAgent consistently outperforms leading baselines, including a relative improvement of 4.92% in ROC-AUC compared to ReAct for drug-target interaction (DTI). DrugAgent is publicly available at https://anonymous.4open.science/r/drugagent-5C42/.", "pdf_url": "https://arxiv.org/pdf/2411.15692.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-11-24_DrugAgent__Automating_AI-aided_Drug_Discovery_Programming_through_LLM_Multi-Agent_Collaboration.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-24_DrugAgent__Automating_AI-aided_Drug_Discovery_Programming_through_LLM_Multi-Agent_Collaboration.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "a4d33353dfdc546d499726c87456bf5dfc0e7bf2", "publication_date": "2024-03-28", "title": "Enhancing Anomaly Detection in Financial Markets with an LLM-based Multi-Agent Framework", "authors": "Taejin Park", "venue": "", "citation_count": 12, "influential_citation_count": 0, "abstract": "This paper introduces a Large Language Model (LLM)-based multi-agent framework designed to enhance anomaly detection within financial market data, tackling the longstanding challenge of manually verifying system-generated anomaly alerts. The framework harnesses a collaborative network of AI agents, each specialised in distinct functions including data conversion, expert analysis via web research, institutional knowledge utilization or cross-checking and report consolidation and management roles. By coordinating these agents towards a common objective, the framework provides a comprehensive and automated approach for validating and interpreting financial data anomalies. I analyse the S&P 500 index to demonstrate the framework's proficiency in enhancing the efficiency, accuracy and reduction of human intervention in financial market monitoring. The integration of AI's autonomous functionalities with established analytical methods not only underscores the framework's effectiveness in anomaly detection but also signals its broader applicability in supporting financial market monitoring.", "pdf_url": "https://arxiv.org/pdf/2403.19735.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-28_Enhancing_Anomaly_Detection_in_Financial_Markets_with_an_LLM-based_Multi-Agent_Framework.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-28_Enhancing_Anomaly_Detection_in_Financial_Markets_with_an_LLM-based_Multi-Agent_Framework.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "755853c6b30f5a186131e23a63c68a3f2737068e", "publication_date": "2023-09-18", "title": "SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models", "authors": "S. S. Kannan, Vishnunandan L. N. Venkatesh, Byung-Cheol Min", "venue": "IEEE/RJS International Conference on Intelligent RObots and Systems", "citation_count": 112, "influential_citation_count": 6, "abstract": "In this work, we introduce SMART-LLM, an innovative framework designed for embodied multi-robot task planning. SMART-LLM: Smart Multi-Agent Robot Task Planning using Large Language Models (LLMs), harnesses the power of LLMs to convert high-level task instructions provided as input into a multi-robot task plan. It accomplishes this by executing a series of stages, including task decomposition, coalition formation, and task allocation, all guided by programmatic LLM prompts within the few-shot prompting paradigm. We create a benchmark dataset designed for validating the multi-robot task planning problem, encompassing four distinct categories of high-level instructions that vary in task complexity. Our evaluation experiments span both simulation and real-world scenarios, demonstrating that the proposed model can achieve promising results for generating multi-robot task plans. The experimental videos, code, and datasets from the work can be found at https://sites.google.com/view/smart-llm/.", "pdf_url": "https://arxiv.org/pdf/2309.10062.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-09-18_SMART-LLM__Smart_Multi-Agent_Robot_Task_Planning_using_Large_Language_Models.pdf", "markdown_path": "data/semantic/markdown_files/2023-09-18_SMART-LLM__Smart_Multi-Agent_Robot_Task_Planning_using_Large_Language_Models.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "273b72d9998e06a7ceb1bf9405a0d274cd088800", "publication_date": "2024-04-18", "title": "AgentCoord: Visually Exploring Coordination Strategy for LLM-based Multi-Agent Collaboration", "authors": "Bo Pan, Jiaying Lu, Ke Wang, Li Zheng, Zhen Wen, Yingchaojie Feng, Minfeng Zhu, Wei Chen", "venue": "arXiv.org", "citation_count": 11, "influential_citation_count": 1, "abstract": "The potential of automatic task-solving through Large Language Model (LLM)-based multi-agent collaboration has recently garnered widespread attention from both the research community and industry. While utilizing natural language to coordinate multiple agents presents a promising avenue for democratizing agent technology for general users, designing coordination strategies remains challenging with existing coordination frameworks. This difficulty stems from the inherent ambiguity of natural language for specifying the collaboration process and the significant cognitive effort required to extract crucial information (e.g. agent relationship, task dependency, result correspondence) from a vast amount of text-form content during exploration. In this work, we present a visual exploration framework to facilitate the design of coordination strategies in multi-agent collaboration. We first establish a structured representation for LLM-based multi-agent coordination strategy to regularize the ambiguity of natural language. Based on this structure, we devise a three-stage generation method that leverages LLMs to convert a user's general goal into an executable initial coordination strategy. Users can further intervene at any stage of the generation process, utilizing LLMs and a set of interactions to explore alternative strategies. Whenever a satisfactory strategy is identified, users can commence the collaboration and examine the visually enhanced execution result. We develop AgentCoord, a prototype interactive system, and conduct a formal user study to demonstrate the feasibility and effectiveness of our approach.", "pdf_url": "https://arxiv.org/pdf/2404.11943.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-18_AgentCoord__Visually_Exploring_Coordination_Strategy_for_LLM-based_Multi-Agent_Collaboration.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-18_AgentCoord__Visually_Exploring_Coordination_Strategy_for_LLM-based_Multi-Agent_Collaboration.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "066686edd54bf49d763a83510746425f6aaa4ae7", "publication_date": "2024-02-21", "title": "LLM Based Multi-Agent Generation of Semi-structured Documents from Semantic Templates in the Public Administration Domain", "authors": "Emanuele Musumeci, Michele Brienza, Vincenzo Suriani, Daniele Nardi, D. Bloisi", "venue": "Interacci\u00f3n", "citation_count": 11, "influential_citation_count": 0, "abstract": "In the last years' digitalization process, the creation and management of documents in various domains, particularly in Public Administration (PA), have become increasingly complex and diverse. This complexity arises from the need to handle a wide range of document types, often characterized by semi-structured forms. Semi-structured documents present a fixed set of data without a fixed format. As a consequence, a template-based solution cannot be used, as understanding a document requires the extraction of the data structure. The recent introduction of Large Language Models (LLMs) has enabled the creation of customized text output satisfying user requests. In this work, we propose a novel approach that combines the LLMs with prompt engineering and multi-agent systems for generating new documents compliant with a desired structure. The main contribution of this work concerns replacing the commonly used manual prompting with a task description generated by semantic retrieval from an LLM. The potential of this approach is demonstrated through a series of experiments and case studies, showcasing its effectiveness in real-world PA scenarios.", "pdf_url": "https://arxiv.org/pdf/2402.14871.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-02-21_LLM_Based_Multi-Agent_Generation_of_Semi-structured_Documents_from_Semantic_Templates_in_the_Public_.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-21_LLM_Based_Multi-Agent_Generation_of_Semi-structured_Documents_from_Semantic_Templates_in_the_Public_.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "027d9a3371c13ea567bca75e675db295022a300b", "publication_date": "2024-04-07", "title": "LLM-Based Multi-Agent Systems for Software Engineering: Literature Review, Vision, and the Road Ahead", "authors": "Junda He, Christoph Treude, David Lo", "venue": "ACM Transactions on Software Engineering and Methodology", "citation_count": 12, "influential_citation_count": 0, "abstract": "Integrating Large Language Models (LLMs) into autonomous agents marks a significant shift in the research landscape by offering cognitive abilities that are competitive with human planning and reasoning. This article explores the transformative potential of integrating Large Language Models into Multi-Agent (LMA) systems for addressing complex challenges in software engineering (SE). By leveraging the collaborative and specialized abilities of multiple agents, LMA systems enable autonomous problem-solving, improve robustness, and provide scalable solutions for managing the complexity of real-world software projects. In this article, we conduct a systematic review of recent primary studies to map the current landscape of LMA applications across various stages of the software development lifecycle (SDLC). To illustrate current capabilities and limitations, we perform two case studies to demonstrate the effectiveness of state-of-the-art LMA frameworks. Additionally, we identify critical research gaps and propose a comprehensive research agenda focused on enhancing individual agent capabilities and optimizing agent synergy. Our work outlines a forward-looking vision for developing fully autonomous, scalable, and trustworthy LMA systems, laying the foundation for the evolution of Software Engineering 2.0.", "pdf_url": "https://arxiv.org/pdf/2404.04834.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-07_LLM-Based_Multi-Agent_Systems_for_Software_Engineering__Literature_Review__Vision__and_the_Road_Ahea.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-07_LLM-Based_Multi-Agent_Systems_for_Software_Engineering__Literature_Review__Vision__and_the_Road_Ahea.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "6b07e1a6b4779e28ae7243fbd12313792617b6f3", "publication_date": "2024-07-31", "title": "MetaOpenFOAM: an LLM-based multi-agent framework for CFD", "authors": "Yuxuan Chen, Xu Zhu, Hua Zhou, Zhuyin Ren", "venue": "arXiv.org", "citation_count": 11, "influential_citation_count": 1, "abstract": "Remarkable progress has been made in automated problem solving through societies of agents based on large language models (LLMs). Computational fluid dynamics (CFD), as a complex problem, presents unique challenges in automated simulations that require sophisticated solutions. MetaOpenFOAM, as a novel multi-agent collaborations framework, aims to complete CFD simulation tasks with only natural language as input. These simulation tasks include mesh pre-processing, simulation and so on. MetaOpenFOAM harnesses the power of MetaGPT's assembly line paradigm, which assigns diverse roles to various agents, efficiently breaking down complex CFD tasks into manageable subtasks. Langchain further complements MetaOpenFOAM by integrating Retrieval-Augmented Generation (RAG) technology, which enhances the framework's ability by integrating a searchable database of OpenFOAM tutorials for LLMs. Tests on a benchmark for natural language-based CFD solver, consisting of eight CFD simulation tasks, have shown that MetaOpenFOAM achieved a high pass rate per test (85%), with each test case costing only $0.22 on average. The eight CFD simulation tasks encompass a range of multidimensional flow problems, covering compressible and incompressible flows with different physical processes. This demonstrates the capability to automate CFD simulations using only natural language input, iteratively correcting errors to achieve the desired simulations. An ablation study was conducted to verify the necessity of each component in the multi-agent system and the RAG technology. A sensitivity study on the randomness of LLM showed that LLM with low randomness can obtain more stable and accurate results. Additionally, MetaOpenFOAM owns the ability to identify and modify key parameters in user requirements, and excels in correcting bugs when failure match occur,which demonstrates the generalization of MetaOpenFOAM.", "pdf_url": "https://arxiv.org/pdf/2407.21320.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-07-31_MetaOpenFOAM__an_LLM-based_multi-agent_framework_for_CFD.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-31_MetaOpenFOAM__an_LLM-based_multi-agent_framework_for_CFD.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "a8a9d66263651e70f98e3fd411aff9abc2be1ec3", "publication_date": "2024-08-07", "title": "From Data to Story: Towards Automatic Animated Data Video Creation with LLM-Based Multi-Agent Systems", "authors": "Leixian Shen, Haotian Li, Yun Wang, Huamin Qu", "venue": "2024 IEEE VIS Workshop on Data Storytelling in an Era of Generative AI (GEN4DS)", "citation_count": 9, "influential_citation_count": 1, "abstract": "Creating data stories from raw data is challenging due to humans' limited attention spans and the need for specialized skills. Recent advancements in large language models (LLMs) offer great oppor-tunities to develop systems with autonomous agents to streamline the data storytelling workflow. Though multi-agent systems have benefits such as fully realizing LLM potentials with decomposed tasks for individual agents, designing such systems also faces challenges in task decomposition, performance optimization for sub-tasks, and workflow design. To better understand these issues, we develop Data Director, an LLM-based multi-agent system designed to automate the creation of animated data videos, a representative genre of data stories. Data Director interprets raw data, breaks down tasks, designs agent roles to make informed decisions automatically, and seamlessly integrates diverse components of data videos. A case study demonstrates Data Director's effectiveness in generating data videos. Throughout development, we have derived lessons learned from addressing challenges, guiding further advancements in autonomous agents for data storytelling. We also shed light on future directions for global optimization, human-in-the-loop design, and the application of advanced multimodal LLMs.", "pdf_url": "https://arxiv.org/pdf/2408.03876.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-08-07_From_Data_to_Story__Towards_Automatic_Animated_Data_Video_Creation_with_LLM-Based_Multi-Agent_System.pdf", "markdown_path": "data/semantic/markdown_files/2024-08-07_From_Data_to_Story__Towards_Automatic_Animated_Data_Video_Creation_with_LLM-Based_Multi-Agent_System.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "ba9437c571310ef5dd84820daea87122a395b83b", "publication_date": "2024-08-07", "title": "Optimization modeling and verification from problem specifications using a multi-agent multi-stage LLM framework", "authors": "Mahdi Mostajabdaveh, Timothy T. L. Yu, Rindranirina Ramamonjison, G. Carenini, Zirui Zhou, Yong Zhang", "venue": "INFOR. Information systems and operational research", "citation_count": 9, "influential_citation_count": 0, "abstract": "Abstract This paper explores the use of Large Language Models (LLMs) in modeling real-world optimization problems. We concretely define the task of translating natural language descriptions into optimization models (NL2OPT) and provide criteria for classifying optimization problems for the NL2OPT task. Our novel multi-agent modeling framework leverages relations identifier agents and a multi-agent verification mechanism, eliminating the need for solver execution. Additionally, we introduce a straightforward and practical evaluation framework, offering a more effective assessment method compared to traditional execution-based evaluations. We have created a unique dataset tailored for optimization modeling, featuring Problem Specifications as a structured representation of optimization problems. Through comprehensive experiments, our study compares our modeling framework with existing LLM reasoning strategies, highlighting their relative effectiveness in optimization modeling tasks. We also perform ablation studies to explore the effect of different components of our modeling framework. Experimental results demonstrate that our multi-agent framework outperforms many common LLM prompting strategies.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "c5836fa8127fe158991486fd8f949c5c02cf0ed0", "publication_date": "2024-09-16", "title": "AutoSafeCoder: A Multi-Agent Framework for Securing LLM Code Generation through Static Analysis and Fuzz Testing", "authors": "Ana Nunez, Nafis Tanveer Islam, S. Jha, Peyman Najafirad", "venue": "arXiv.org", "citation_count": 9, "influential_citation_count": 0, "abstract": "Recent advancements in automatic code generation using large language models (LLMs) have brought us closer to fully automated secure software development. However, existing approaches often rely on a single agent for code generation, which struggles to produce secure, vulnerability-free code. Traditional program synthesis with LLMs has primarily focused on functional correctness, often neglecting critical dynamic security implications that happen during runtime. To address these challenges, we propose AutoSafeCoder, a multi-agent framework that leverages LLM-driven agents for code generation, vulnerability analysis, and security enhancement through continuous collaboration. The framework consists of three agents: a Coding Agent responsible for code generation, a Static Analyzer Agent identifying vulnerabilities, and a Fuzzing Agent performing dynamic testing using a mutation-based fuzzing approach to detect runtime errors. Our contribution focuses on ensuring the safety of multi-agent code generation by integrating dynamic and static testing in an iterative process during code generation by LLM that improves security. Experiments using the SecurityEval dataset demonstrate a 13% reduction in code vulnerabilities compared to baseline LLMs, with no compromise in functionality.", "pdf_url": "https://arxiv.org/pdf/2409.10737.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-09-16_AutoSafeCoder__A_Multi-Agent_Framework_for_Securing_LLM_Code_Generation_through_Static_Analysis_and_.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-16_AutoSafeCoder__A_Multi-Agent_Framework_for_Securing_LLM_Code_Generation_through_Static_Analysis_and_.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "c47867e212534ca3da34e2220d78d803b5cdcf1c", "publication_date": "2024-04-26", "title": "PLAYER*: Enhancing LLM-based Multi-Agent Communication and Interaction in Murder Mystery Games", "authors": "Qinglin Zhu, Runcong Zhao, Jinhua Du, Lin Gui, Yulan He", "venue": "arXiv.org", "citation_count": 8, "influential_citation_count": 1, "abstract": "We introduce WellPlay, a reasoning dataset for multi-agent conversational inference in Murder Mystery Games (MMGs). WellPlay comprises 1,482 inferential questions across 12 games, spanning objectives, reasoning, and relationship understanding, and establishes a systematic benchmark for evaluating agent reasoning abilities in complex social settings. Building on this foundation, we present PLAYER*, a novel framework for Large Language Model (LLM)-based agents in MMGs. MMGs pose unique challenges, including undefined state spaces, absent intermediate rewards, and the need for strategic reasoning through natural language. PLAYER* addresses these challenges with a sensor-based state representation and an information-driven strategy that optimises questioning and suspect pruning. Experiments show that PLAYER* outperforms existing methods in reasoning accuracy, efficiency, and agent-human interaction, advancing reasoning agents for complex social scenarios.", "pdf_url": "https://arxiv.org/pdf/2404.17662.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-26_PLAYER___Enhancing_LLM-based_Multi-Agent_Communication_and_Interaction_in_Murder_Mystery_Games.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-26_PLAYER___Enhancing_LLM-based_Multi-Agent_Communication_and_Interaction_in_Murder_Mystery_Games.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "2779980959833699b78c8f5779bf35a4e87299bd", "publication_date": "2024-09-23", "title": "AmpAgent: An LLM-based Multi-Agent System for Multi-stage Amplifier Schematic Design from Literature for Process and Performance Porting", "authors": "Chengjie Liu, Weiyu Chen, Anlan Peng, Yuan Du, Li Du, Jun Yang", "venue": "arXiv.org", "citation_count": 9, "influential_citation_count": 0, "abstract": "Multi-stage amplifiers are widely applied in analog circuits. However, their large number of components, complex transfer functions, and intricate pole-zero distributions necessitate extensive manpower for derivation and param sizing to ensure their stability. In order to achieve efficient derivation of the transfer function and simplify the difficulty of circuit design, we propose AmpAgent: a multi-agent system based on large language models (LLMs) for efficiently designing such complex amplifiers from literature with process and performance porting. AmpAgent is composed of three agents: Literature Analysis Agent, Mathematics Reasoning Agent and Device Sizing Agent. They are separately responsible for retrieving key information (e.g. formulas and transfer functions) from the literature, decompose the whole circuit's design problem by deriving the key formulas, and address the decomposed problem iteratively. AmpAgent was employed in the schematic design of seven types of multi-stage amplifiers with different compensation techniques. In terms of design efficiency, AmpAgent has reduced the number of iterations by 1.32$ \\sim $4${\\times}$ and execution time by 1.19$ \\sim $2.99${\\times}$ compared to conventional optimization algorithms, with a success rate increased by 1.03$ \\sim $6.79${\\times}$. In terms of circuit performance, it has improved by 1.63$ \\sim $27.25${\\times}$ compared to the original literature. The findings suggest that LLMs could play a crucial role in the field of complex analog circuit schematic design, as well as process and performance porting.", "pdf_url": "https://arxiv.org/pdf/2409.14739.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-09-23_AmpAgent__An_LLM-based_Multi-Agent_System_for_Multi-stage_Amplifier_Schematic_Design_from_Literature.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-23_AmpAgent__An_LLM-based_Multi-Agent_System_for_Multi-stage_Amplifier_Schematic_Design_from_Literature.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "1fd19dc0180b83c3e91f9fe3b4bb47e93a553660", "publication_date": "2024", "title": "LLM experiments with simulation: Large Language Model Multi-Agent System for Process Simulation Parametrization in Digital Twins", "authors": "Yuchen Xia, Daniel Dittler, N. Jazdi, Haonan Chen, M. Weyrich", "venue": "arXiv.org", "citation_count": 6, "influential_citation_count": 0, "abstract": "\u2014 This paper presents a novel design of a multi-agent system framework that applies a large language model (LLM) to automate the parametrization of process simulations in digital twins. We propose a multi-agent framework that includes four types of agents: observation, reasoning, decision and summarization. By enabling dynamic interaction between LLM agents and simulation model, the developed system can automatically explore the parametrization of the simulation and use heuristic reasoning to determine a set of parameters to control the simulation to achieve an objective. The proposed approach enhances the simulation model by infusing it with heuristics from LLM and enables autonomous search for feasible parametrization to solve a user task. Furthermore, the system has the potential to increase user-friendliness and reduce the cognitive load on human users by assisting in complex decision-making processes. The effectiveness and functionality of the system are demonstrated through a case study, and the visualized demos are available at a GitHub Repository: https://github.com/YuchenXia/LLMDrivenSimulation", "pdf_url": "https://arxiv.org/abs/2405.18092/pdf/2405.18092", "pdf_filepath": "data/semantic/pdf_files/2024_LLM_experiments_with_simulation__Large_Language_Model_Multi-Agent_System_for_Process_Simulation_Para.pdf", "markdown_path": "data/semantic/markdown_files/2024_LLM_experiments_with_simulation__Large_Language_Model_Multi-Agent_System_for_Process_Simulation_Para.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "9c36ef621a9576c123194ffb8aa7c136f22f1c39", "publication_date": "2024-05-05", "title": "Language Evolution for Evading Social Media Regulation via LLM-Based Multi-Agent Simulation", "authors": "Jinyu Cai, Jialong Li, Mingyue Zhang, Munan Li, Chen-Shu Wang, Kenji Tei", "venue": "IEEE Congress on Evolutionary Computation", "citation_count": 6, "influential_citation_count": 0, "abstract": "Social media platforms such as Twitter, Reddit, and Sina Weibo playa crucial role in global communication but often encounter strict regulations in geopolitically sensitive regions. This situation has prompted users to ingeniously modify their way of communicating, frequently resorting to coded language in these regulated social media environments. This shift in communication is not merely a strategy to counteract regulation, but a vivid manifestation of language evolution, demonstrating how language naturally evolves under societal and technological pressures. Studying the evolution of language in regulated social media contexts is of significant importance for ensuring freedom of speech, optimizing content moderation, and advancing linguistic research. This paper proposes a multi-agent simulation frame-work using Large Language Models (LLMs) to explore the evolution of user language in regulated social media environments. The framework employs LLM-driven agents: supervisory agent who enforce dialogue supervision and participant agents who evolve their language strategies while engaging in conversation, simulating the evolution of communication styles under strict regulations aimed at evading social media regulation. The study evaluates the framework's effectiveness through a range of scenarios from abstract scenarios to real-world situations. Key findings indicate that LLMs are capable of simulating nuanced language dynamics and interactions in constrained settings, showing improvement in both evading supervision and information accuracy as evolution progresses. Furthermore, it was found that LLM agents adopt different strategies for different scenarios. The reproduction kit can be accessed at https://github.com/BlueLinkXlGA-MAS.", "pdf_url": "https://arxiv.org/pdf/2405.02858.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-05-05_Language_Evolution_for_Evading_Social_Media_Regulation_via_LLM-Based_Multi-Agent_Simulation.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-05_Language_Evolution_for_Evading_Social_Media_Regulation_via_LLM-Based_Multi-Agent_Simulation.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "e35391872b0170d8f845b9aff3440efbefd0bb02", "publication_date": "2024-07-05", "title": "BlockAgents: Towards Byzantine-Robust LLM-Based Multi-Agent Coordination via Blockchain", "authors": "Bei Chen, Gaolei Li, Xi Lin, Zheng Wang, Jianhua Li", "venue": "ACM Turing Celebration Conference", "citation_count": 6, "influential_citation_count": 0, "abstract": "Recent advancements in multi-agent systems based on large language models (LLM) have shown potential for problem-solving and planning tasks. However, most existing LLM-based multi-agent approaches show vulnerability against byzantine attacks. First, agents instantiated on diverse LLMs may inherit biases present in the LLMs and thus exhibit deception behavior. Second, as the number of agents grows, collusive behavior among multiple malicious agents poses a potential threat. In this paper, we propose BlockAgents, an innovative framework that integrates blockchain into LLM-based cooperative multi-agent systems to mitigate byzantine behaviors. BlockAgents completes multi-agent collaboration through a unified workflow including role assignment, proposal statement, evaluation, and decision-making. To help the agent who contributes the most to the group thinking process acquire accounting rights, we propose a proof-of-thought (PoT) consensus mechanism combined with stake-based miner designation and multi-round debate-style voting. To effectively distinguish valid and abnormal answers, we design a multi-metric prompt-based evaluation method for each evaluator to score each proposal by carefully and comprehensively considering multiple dimensions. Experiments on three datasets show that BlockAgents reduces the interference of poisoning attacks on accuracy to less than 3% and reduces the success rate of backdoor attacks to less than 5%, demonstrating the resistance ability against Byzantine attacks.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "2d591bd9f42bbbd259510d871bdd6786b1283b2d", "publication_date": "2024-09-05", "title": "LLM-based multi-agent poetry generation in non-cooperative environments", "authors": "Ran Zhang, Steffen Eger", "venue": "arXiv.org", "citation_count": 6, "influential_citation_count": 0, "abstract": "Despite substantial progress of large language models (LLMs) for automatic poetry generation, the generated poetry lacks diversity while the training process differs greatly from human learning. Under the rationale that the learning process of the poetry generation systems should be more human-like and their output more diverse and novel, we introduce a framework based on social learning where we emphasize non-cooperative interactions besides cooperative interactions to encourage diversity. Our experiments are the first attempt at LLM-based multi-agent systems in non-cooperative environments for poetry generation employing both TRAINING-BASED agents (GPT-2) and PROMPTING-BASED agents (GPT-3 and GPT-4). Our evaluation based on 96k generated poems shows that our framework benefits the poetry generation process for TRAINING-BASED agents resulting in 1) a 3.0-3.7 percentage point (pp) increase in diversity and a 5.6-11.3 pp increase in novelty according to distinct and novel n-grams. The generated poetry from TRAINING-BASED agents also exhibits group divergence in terms of lexicons, styles and semantics. PROMPTING-BASED agents in our framework also benefit from non-cooperative environments and a more diverse ensemble of models with non-homogeneous agents has the potential to further enhance diversity, with an increase of 7.0-17.5 pp according to our experiments. However, PROMPTING-BASED agents show a decrease in lexical diversity over time and do not exhibit the group-based divergence intended in the social network. Our paper argues for a paradigm shift in creative tasks such as automatic poetry generation to include social learning processes (via LLM-based agent modeling) similar to human interaction.", "pdf_url": "https://arxiv.org/pdf/2409.03659.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-09-05_LLM-based_multi-agent_poetry_generation_in_non-cooperative_environments.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-05_LLM-based_multi-agent_poetry_generation_in_non-cooperative_environments.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "04847af01a0ba0beadb98d36a3059b7cac701f1a", "publication_date": "2024-02-22", "title": "Triad: A Framework Leveraging a Multi-Role LLM-based Agent to Solve Knowledge Base Question Answering", "authors": "Chang Zong, Yuchen Yan, Weiming Lu, Eliot Huang, Jian Shao, Y. Zhuang", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 12, "influential_citation_count": 1, "abstract": "Recent progress with LLM-based agents has shown promising results across various tasks. However, their use in answering questions from knowledge bases remains largely unexplored. Implementing a KBQA system using traditional methods is challenging due to the shortage of task-specific training data and the complexity of creating task-focused model structures. In this paper, we present Triad, a unified framework that utilizes an LLM-based agent with multiple roles for KBQA tasks. The agent is assigned three roles to tackle different KBQA subtasks: agent as a generalist for mastering various subtasks, as a decision maker for the selection of candidates, and as an advisor for answering questions with knowledge. Our KBQA framework is executed in four phases, involving the collaboration of the agent\u2019s multiple roles. We evaluated the performance of our framework using three benchmark datasets, and the results show that our framework outperforms state-of-the-art systems on the LC-QuAD and YAGO-QA benchmarks, yielding F1 scores of 11.8% and 20.7%, respectively.", "pdf_url": "https://arxiv.org/pdf/2402.14320.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-02-22_Triad__A_Framework_Leveraging_a_Multi-Role_LLM-based_Agent_to_Solve_Knowledge_Base_Question_Answerin.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-22_Triad__A_Framework_Leveraging_a_Multi-Role_LLM-based_Agent_to_Solve_Knowledge_Base_Question_Answerin.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "305a54897c5dcc39ca9d4b266990b13c5d0fc97a", "publication_date": "2024-11-27", "title": "Exploration of LLM Multi-Agent Application Implementation Based on LangGraph+CrewAI", "authors": "Zhihua Duan, Jialin Wang", "venue": "arXiv.org", "citation_count": 8, "influential_citation_count": 1, "abstract": "With the rapid development of large model technology, the application of agent technology in various fields is becoming increasingly widespread, profoundly changing people's work and lifestyles. In complex and dynamic systems, multi-agents achieve complex tasks that are difficult for a single agent to complete through division of labor and collaboration among agents. This paper discusses the integrated application of LangGraph and CrewAI. LangGraph improves the efficiency of information transmission through graph architecture, while CrewAI enhances team collaboration capabilities and system performance through intelligent task allocation and resource management. The main research contents of this paper are: (1) designing the architecture of agents based on LangGraph for precise control; (2) enhancing the capabilities of agents based on CrewAI to complete a variety of tasks. This study aims to delve into the application of LangGraph and CrewAI in multi-agent systems, providing new perspectives for the future development of agent technology, and promoting technological progress and application innovation in the field of large model intelligent agents.", "pdf_url": "https://arxiv.org/pdf/2411.18241.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-11-27_Exploration_of_LLM_Multi-Agent_Application_Implementation_Based_on_LangGraph_CrewAI.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-27_Exploration_of_LLM_Multi-Agent_Application_Implementation_Based_on_LangGraph_CrewAI.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "1cf7ac84dd6babdd2cf18faa298f7b05a04b57fa", "publication_date": "2024-11-11", "title": "A Multi-Agent Approach for REST API Testing with Semantic Graphs and LLM-Driven Inputs", "authors": "Myeongsoo Kim, Tyler Stennett, Saurabh Sinha, Alessandro Orso", "venue": "arXiv.org", "citation_count": 6, "influential_citation_count": 0, "abstract": "As modern web services increasingly rely on REST APIs, their thorough testing has become crucial. Furthermore, the advent of REST API documentation languages, such as the OpenAPI Specification, has led to the emergence of many black-box REST API testing tools. However, these tools often focus on individual test elements in isolation (e.g., APIs, parameters, values), resulting in lower coverage and less effectiveness in fault detection. To address these limitations, we present AutoRestTest, the first black-box tool to adopt a dependency-embedded multi-agent approach for REST API testing that integrates multi-agent reinforcement learning (MARL) with a semantic property dependency graph (SPDG) and Large Language Models (LLMs). Our approach treats REST API testing as a separable problem, where four agents -- API, dependency, parameter, and value agents -- collaborate to optimize API exploration. LLMs handle domain-specific value generation, the SPDG model simplifies the search space for dependencies using a similarity score between API operations, and MARL dynamically optimizes the agents' behavior. Our evaluation of AutoRestTest on 12 real-world REST services shows that it outperforms the four leading black-box REST API testing tools, including those assisted by RESTGPT (which generates realistic test inputs using LLMs), in terms of code coverage, operation coverage, and fault detection. Notably, AutoRestTest is the only tool able to trigger an internal server error in the Spotify service. Our ablation study illustrates that each component of AutoRestTest -- the SPDG, the LLM, and the agent-learning mechanism -- contributes to its overall effectiveness.", "pdf_url": "https://arxiv.org/pdf/2411.07098.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-11-11_A_Multi-Agent_Approach_for_REST_API_Testing_with_Semantic_Graphs_and_LLM-Driven_Inputs.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-11_A_Multi-Agent_Approach_for_REST_API_Testing_with_Semantic_Graphs_and_LLM-Driven_Inputs.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "c474f9b87013301b66cc921a2f7a3918d506d684", "publication_date": "2024-08-02", "title": "On the Resilience of LLM-Based Multi-Agent Collaboration with Faulty Agents", "authors": "Jen-Tse Huang, Jiaxu Zhou, Tailin Jin, Xuhui Zhou, Zixi Chen, Wenxuan Wang, Youliang Yuan, Maarten Sap, Michael R. Lyu", "venue": "", "citation_count": 6, "influential_citation_count": 0, "abstract": "Large language model-based multi-agent systems have shown great abilities across various tasks due to the collaboration of expert agents, each focusing on a specific domain. However, the impact of clumsy or even malicious agents--those who frequently make errors in their tasks--on the overall performance of the system remains underexplored. This paper investigates: (1) What is the resilience of various system structures (e.g., A$\\rightarrow$B$\\rightarrow$C, A$\\leftrightarrow$B$\\leftrightarrow$C) under faulty agents, on different downstream tasks? (2) How can we increase system resilience to defend against these agents? To simulate faulty agents, we propose two approaches--AutoTransform and AutoInject--which introduce mistakes into the agents' responses. Experiments on four downstream tasks using six systems show that the\"hierarchical\"structure, i.e., A$\\rightarrow$(B$\\leftrightarrow$C), exhibits superior resilience with the lowest performance drop of 5.5%, compared to 10.5% and 23.7% of other two structures. To further improve resilience, we introduce (1) Challenger, that introduces a mechanism for each agent to challenge others' outputs, and (2) Inspector, an additional agent to review and correct messages, recovering up to 96.4% errors made by faulty agents. Our code and data are available at https://github.com/CUHK-ARISE/MAS-Resilience.", "pdf_url": "https://arxiv.org/pdf/2408.00989.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-08-02_On_the_Resilience_of_LLM-Based_Multi-Agent_Collaboration_with_Faulty_Agents.pdf", "markdown_path": "data/semantic/markdown_files/2024-08-02_On_the_Resilience_of_LLM-Based_Multi-Agent_Collaboration_with_Faulty_Agents.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "f3bcb9395d8b912361cc534f00e837c832000150", "publication_date": "2023", "title": "LLM-Deliberation: Evaluating LLMs with Interactive Multi-Agent Negotiation Games", "authors": "Sahar Abdelnabi, Amr Gomaa, S. Sivaprasad, Lea Sch\u00f6nherr, Mario Fritz", "venue": "arXiv.org", "citation_count": 43, "influential_citation_count": 1, "abstract": "There is a growing interest in using Large Language Models (LLMs) as agents to tackle real-world tasks that may require assessing complex situations. Yet, we have a limited understanding of LLMs\u2019 reasoning and decision-making capabilities, partly stemming from a lack of dedicated evaluation benchmarks. As negotiating and compromising are key aspects of our everyday communication and collaboration, we propose using scorable negotiation games as a new evaluation framework for LLMs. We create a testbed of diverse text-based, multi-agent, multi-issue, semantically rich negotiation games, with easily tunable difficulty. To solve the challenge, agents need to have strong arithmetic, inference, exploration, and planning capabilities, while seamlessly integrating them. Via a systematic zero-shot Chain-of-Thought prompting (CoT), we show that agents can negotiate and consistently reach successful deals. We quantify the performance with multiple metrics and observe a large gap between GPT-4 and earlier models. Importantly, we test the generalization to new games and setups. Finally, we show that these games can help evaluate other critical aspects, such as the interaction dynamics between agents in the presence of greedy and adversarial players.", "pdf_url": "https://arxiv.org/abs/2309.17234/pdf/2309.17234", "pdf_filepath": "data/semantic/pdf_files/2023_LLM-Deliberation__Evaluating_LLMs_with_Interactive_Multi-Agent_Negotiation_Games.pdf", "markdown_path": "data/semantic/markdown_files/2023_LLM-Deliberation__Evaluating_LLMs_with_Interactive_Multi-Agent_Negotiation_Games.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "aaaa79c5c01e6cd26123fec6cdefd8bb6875ef40", "publication_date": "2024-12-14", "title": "TrendSim: Simulating Trending Topics in Social Media Under Poisoning Attacks with LLM-based Multi-agent System", "authors": "Zeyu Zhang, Jianxun Lian, Chen Ma, Yaning Qu, Ye Luo, Lei Wang, Rui Li, Xu Chen, Yankai Lin, Le Wu, Xing Xie, Ji-Rong Wen", "venue": "North American Chapter of the Association for Computational Linguistics", "citation_count": 4, "influential_citation_count": 2, "abstract": "Trending topics have become a significant part of modern social media, attracting users to participate in discussions of breaking events. However, they also bring in a new channel for poisoning attacks, resulting in negative impacts on society. Therefore, it is urgent to study this critical problem and develop effective strategies for defense. In this paper, we propose TrendSim, an LLM-based multi-agent system to simulate trending topics in social media under poisoning attacks. Specifically, we create a simulation environment for trending topics that incorporates a time-aware interaction mechanism, centralized message dissemination, and an interactive system. Moreover, we develop LLM-based human-like agents to simulate users in social media, and propose prototype-based attackers to replicate poisoning attacks. Besides, we evaluate TrendSim from multiple aspects to validate its effectiveness. Based on TrendSim, we conduct simulation experiments to study four critical problems about poisoning attacks on trending topics for social benefit.", "pdf_url": "https://arxiv.org/pdf/2412.12196.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-14_TrendSim__Simulating_Trending_Topics_in_Social_Media_Under_Poisoning_Attacks_with_LLM-based_Multi-ag.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-14_TrendSim__Simulating_Trending_Topics_in_Social_Media_Under_Poisoning_Attacks_with_LLM-based_Multi-ag.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "0ce98d9600e4dc450747689222685b5fb5f16c81", "publication_date": "2024-10-16", "title": "MedAide: Towards an Omni Medical Aide via Specialized LLM-based Multi-Agent Collaboration", "authors": "Jinjie Wei, Dingkang Yang, Yanshu Li, Qingyao Xu, Zhaoyu Chen, Mingcheng Li, Yue Jiang, Xiaolu Hou, Lihua Zhang", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Large Language Model (LLM)-driven interactive systems currently show potential promise in healthcare domains. Despite their remarkable capabilities, LLMs typically lack personalized recommendations and diagnosis analysis in sophisticated medical applications, causing hallucinations and performance bottlenecks. To address these challenges, this paper proposes MedAide, an LLM-based omni medical multi-agent collaboration framework for specialized healthcare services. Specifically, MedAide first performs query rewriting through retrieval-augmented generation to accomplish accurate medical intent understanding. Immediately, we devise a contextual encoder to obtain intent prototype embeddings, which are used to recognize fine-grained intents by similarity matching. According to the intent relevance, the activated agents collaborate effectively to provide integrated decision analysis. Extensive experiments are conducted on four medical benchmarks with composite intents. Experimental results from automated metrics and expert doctor evaluations show that MedAide outperforms current LLMs and improves their medical proficiency and strategic reasoning.", "pdf_url": "https://arxiv.org/pdf/2410.12532.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-16_MedAide__Towards_an_Omni_Medical_Aide_via_Specialized_LLM-based_Multi-Agent_Collaboration.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-16_MedAide__Towards_an_Omni_Medical_Aide_via_Specialized_LLM-based_Multi-Agent_Collaboration.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "94e04d0e1ad8d9a6b82e8068df71df9036123d19", "publication_date": "2024-10-03", "title": "Choices are More Important than Efforts: LLM Enables Efficient Multi-Agent Exploration", "authors": "Yun Qu, Boyuan Wang, Yuhang Jiang, Jianzhun Shao, Yixiu Mao, Cheems Wang, Chang Liu, Xiangyang Ji", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "With expansive state-action spaces, efficient multi-agent exploration remains a longstanding challenge in reinforcement learning. Although pursuing novelty, diversity, or uncertainty attracts increasing attention, redundant efforts brought by exploration without proper guidance choices poses a practical issue for the community. This paper introduces a systematic approach, termed LEMAE, choosing to channel informative task-relevant guidance from a knowledgeable Large Language Model (LLM) for Efficient Multi-Agent Exploration. Specifically, we ground linguistic knowledge from LLM into symbolic key states, that are critical for task fulfillment, in a discriminative manner at low LLM inference costs. To unleash the power of key states, we design Subspace-based Hindsight Intrinsic Reward (SHIR) to guide agents toward key states by increasing reward density. Additionally, we build the Key State Memory Tree (KSMT) to track transitions between key states in a specific task for organized exploration. Benefiting from diminishing redundant explorations, LEMAE outperforms existing SOTA approaches on the challenging benchmarks (e.g., SMAC and MPE) by a large margin, achieving a 10x acceleration in certain scenarios.", "pdf_url": "https://arxiv.org/pdf/2410.02511.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-03_Choices_are_More_Important_than_Efforts__LLM_Enables_Efficient_Multi-Agent_Exploration.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_Choices_are_More_Important_than_Efforts__LLM_Enables_Efficient_Multi-Agent_Exploration.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "f8a65e3740502306847ae916fdeb0d8d1813f00b", "publication_date": "2024-05-28", "title": "LLM experiments with simulation: Large Language Model Multi-Agent System for Simulation Model Parametrization in Digital Twins", "authors": "Yuchen Xia, Daniel Dittler, N. Jazdi, Haonan Chen, M. Weyrich", "venue": "IEEE International Conference on Emerging Technologies and Factory Automation", "citation_count": 4, "influential_citation_count": 0, "abstract": "This paper presents a novel design of a multi-agent system framework that applies large language models (LLMs) to automate the parametrization of simulation models in digital twins. This framework features specialized LLM agents tasked with observing, reasoning, decision-making, and summarizing, enabling them to dynamically interact with digital twin simulations to explore parametrization possibilities and determine feasible parameter settings to achieve an obj ective. The proposed approach enhances the usability of simulation model by infusing it with knowledge heuristics from LLM and enables autonomous search for feasible parametrization to solve a user task. Furthermore, the system has the potential to increase user-friendliness and reduce the cognitive load on human users by assisting in complex decision-making processes. The effectiveness and functionality of the system are demonstrated through a case study, and the visualized demos and codes are available at a GitHub Repository: https://github.comlYuchenXia/LLMDrivenSimulation", "pdf_url": "https://arxiv.org/pdf/2405.18092.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-05-28_LLM_experiments_with_simulation__Large_Language_Model_Multi-Agent_System_for_Simulation_Model_Parame.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-28_LLM_experiments_with_simulation__Large_Language_Model_Multi-Agent_System_for_Simulation_Model_Parame.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "a3683fa4943f1bea24f769584e30c062d15305e2", "publication_date": "2024-10-08", "title": "A Hybrid Multi-Agent Conversational Recommender System with LLM and Search Engine in E-commerce", "authors": "Guangtao Nie, Rong Zhi, Xiaofan Yan, Yufan Du, Xiangyang Zhang, Jianwei Chen, Mi Zhou, Hongshen Chen, Tianhao Li, Ziguang Cheng, Sulong Xu, Jinghe Hu", "venue": "ACM Conference on Recommender Systems", "citation_count": 5, "influential_citation_count": 0, "abstract": "Multi-agent collaboration is the latest trending method to build conversational recommender systems (CRS), especially with the widespread use of Large Language Models (LLMs) recently. Typically, these systems employ several LLM agents, each serving distinct roles to meet user needs. In an industrial setting, it\u2019s essential for a CRS to exhibit low first token latency (i.e., the time taken from a user\u2019s input until the system outputs its first response token.) and high scalability\u2014for instance, minimizing the number of LLM inferences per user request\u2014to enhance user experience and boost platform profit. For example, JD.com\u2019s baseline CRS features two LLM agents and a search API but suffers from high first token latency and requires two LLM inferences per request (LIPR), hindering its performance. To address these issues, we introduce a Hybrid Multi-Agent Collaborative Recommender System (Hybrid-MACRS). It includes a central agent powered by a fine-tuned proprietary LLM and a search agent combining a related search module with a search engine. This hybrid system notably reduces first token latency by about 70% and cuts the LIPR from 2 to 1. We conducted thorough online A/B testing to confirm this approach\u2019s efficiency.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "7d44d096ea5ce822a40ee7b5519fb12b65eeba4e", "publication_date": "2024-10-08", "title": "Coevolving with the Other You: Fine-Tuning LLM with Sequential Cooperative Multi-Agent Reinforcement Learning", "authors": "Hao Ma, Tianyi Hu, Zhiqiang Pu, Boyin Liu, Xiaolin Ai, Yanyan Liang, Min Chen", "venue": "Neural Information Processing Systems", "citation_count": 5, "influential_citation_count": 0, "abstract": "Reinforcement learning (RL) has emerged as a pivotal technique for fine-tuning large language models (LLMs) on specific tasks. However, prevailing RL fine-tuning methods predominantly rely on PPO and its variants. Though these algorithms are effective in general RL settings, they often exhibit suboptimal performance and vulnerability to distribution collapse when applied to the fine-tuning of LLMs. In this paper, we propose CORY, extending the RL fine-tuning of LLMs to a sequential cooperative multi-agent reinforcement learning framework, to leverage the inherent coevolution and emergent capabilities of multi-agent systems. In CORY, the LLM to be fine-tuned is initially duplicated into two autonomous agents: a pioneer and an observer. The pioneer generates responses based on queries, while the observer generates responses using both the queries and the pioneer's responses. The two agents are trained together. During training, the agents exchange roles periodically, fostering cooperation and coevolution between them. Experiments evaluate CORY's performance by fine-tuning GPT-2 and Llama-2 under subjective and objective reward functions on the IMDB Review and GSM8K datasets, respectively. Results show that CORY outperforms PPO in terms of policy optimality, resistance to distribution collapse, and training robustness, thereby underscoring its potential as a superior methodology for refining LLMs in real-world applications.", "pdf_url": "https://arxiv.org/pdf/2410.06101.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-08_Coevolving_with_the_Other_You__Fine-Tuning_LLM_with_Sequential_Cooperative_Multi-Agent_Reinforcement.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-08_Coevolving_with_the_Other_You__Fine-Tuning_LLM_with_Sequential_Cooperative_Multi-Agent_Reinforcement.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "2fc8a207405ac233cde98424c36dd19c8731ce5e", "publication_date": "2024-10-10", "title": "Optima: Optimizing Effectiveness and Efficiency for LLM-Based Multi-Agent System", "authors": "Weize Chen, Jiarui Yuan, Cheng Qian, Cheng Yang, Zhiyuan Liu, Maosong Sun", "venue": "arXiv.org", "citation_count": 5, "influential_citation_count": 0, "abstract": "Large Language Model (LLM) based multi-agent systems (MAS) show remarkable potential in collaborative problem-solving, yet they still face critical challenges: low communication efficiency, poor scalability, and a lack of effective parameter-updating optimization methods. We present Optima, a novel framework that addresses these issues by significantly enhancing both communication efficiency and task effectiveness in LLM-based MAS through LLM training. Optima employs an iterative generate, rank, select, and train paradigm with a reward function balancing task performance, token efficiency, and communication readability. We explore various RL algorithms, including Supervised Fine-Tuning, Direct Preference Optimization, and their hybrid approaches, providing insights into their effectiveness-efficiency trade-offs. We integrate Monte Carlo Tree Search-inspired techniques for DPO data generation, treating conversation turns as tree nodes to explore diverse interaction paths. Evaluated on common multi-agent tasks, including information-asymmetric question answering and complex reasoning, Optima shows consistent and substantial improvements over single-agent baselines and vanilla MAS based on Llama 3 8B, achieving up to 2.8x performance gain with less than 10\\% tokens on tasks requiring heavy information exchange. Moreover, Optima's efficiency gains open new possibilities for leveraging inference-compute more effectively, leading to improved inference-time scaling laws. By addressing fundamental challenges in LLM-based MAS, Optima shows the potential towards scalable, efficient, and effective MAS (https://chenweize1998.github.io/optima-project-page).", "pdf_url": "https://arxiv.org/pdf/2410.08115.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-10_Optima__Optimizing_Effectiveness_and_Efficiency_for_LLM-Based_Multi-Agent_System.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-10_Optima__Optimizing_Effectiveness_and_Efficiency_for_LLM-Based_Multi-Agent_System.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "d3172458e2ac692892ff090ddb216f05787fc4d4", "publication_date": "2024-12-15", "title": "CoopetitiveV: Leveraging LLM-powered Coopetitive Multi-Agent Prompting for High-quality Verilog Generation", "authors": "Zhendong Mi, Renming Zheng, Haowen Zhong, Yue Sun, Seth Kneeland, Sayan K. Moitra, Ken Kutzer, Zhaozhuo Xu Shaoyi Huang", "venue": "", "citation_count": 5, "influential_citation_count": 0, "abstract": "Recent advances in agentic LLMs have demonstrated great capabilities in Verilog code generation. However, existing approaches either use LLM-assisted single-agent prompting or cooperation-only multi-agent learning, which will lead to: (i) Degeneration issue for single-agent learning: characterized by diminished error detection and correction capabilities; (ii) Error propagation in cooperation-only multi-agent learning: erroneous information from the former agent will be propagated to the latter through prompts, which can make the latter agents generate buggy code. In this paper, we propose an LLM-based coopetitive multi-agent prompting framework, in which the agents cannot collaborate with each other to form the generation pipeline, but also create a healthy competitive mechanism to improve the generating quality. Our experimental results show that the coopetitive multi-agent framework can effectively mitigate the degeneration risk and reduce the error propagation while improving code error correction capabilities, resulting in higher quality Verilog code generation. The effectiveness of our approach is validated through extensive experiments. On VerilogEval Machine and Human dataset, CoopetitiveV+GPT-4 achieves 99.2% and 99.1% pass@10 scores, respectively. While on RTLLM, CoopetitiveV+GPT-4 obtains 100% syntax and 99.9% functionality pass@5 scores.", "pdf_url": "https://arxiv.org/pdf/2412.11014.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-15_CoopetitiveV__Leveraging_LLM-powered_Coopetitive_Multi-Agent_Prompting_for_High-quality_Verilog_Gene.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-15_CoopetitiveV__Leveraging_LLM-powered_Coopetitive_Multi-Agent_Prompting_for_High-quality_Verilog_Gene.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "1a536b4f5bafbf6f46d474bdc971fc83c5e93544", "publication_date": "2024-10-25", "title": "Can We Trust AI Agents? A Case Study of an LLM-Based Multi-Agent System for Ethical AI", "authors": "Jose Siqueira de Cerqueira, M. Agbese, Rebekah A. Rousi, Nannan Xi, Juho Hamari, Pekka Abrahamsson", "venue": "", "citation_count": 4, "influential_citation_count": 0, "abstract": "AI-based systems, including Large Language Models (LLM), impact millions by supporting diverse tasks but face issues like misinformation, bias, and misuse. AI ethics is crucial as new technologies and concerns emerge, but objective, practical guidance remains debated. This study examines the use of LLMs for AI ethics in practice, assessing how LLM trustworthiness-enhancing techniques affect software development in this context. Using the Design Science Research (DSR) method, we identify techniques for LLM trustworthiness: multi-agents, distinct roles, structured communication, and multiple rounds of debate. We design a multi-agent prototype LLM-MAS, where agents engage in structured discussions on real-world AI ethics issues from the AI Incident Database. We evaluate the prototype across three case scenarios using thematic analysis, hierarchical clustering, comparative (baseline) studies, and running source code. The system generates approximately 2,000 lines of code per case, compared to only 80 lines in baseline trials. Discussions reveal terms like bias detection, transparency, accountability, user consent, GDPR compliance, fairness evaluation, and EU AI Act compliance, showing this prototype ability to generate extensive source code and documentation addressing often overlooked AI ethics issues. However, practical challenges in source code integration and dependency management may limit its use by practitioners.", "pdf_url": "https://arxiv.org/pdf/2411.08881.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-25_Can_We_Trust_AI_Agents__A_Case_Study_of_an_LLM-Based_Multi-Agent_System_for_Ethical_AI.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-25_Can_We_Trust_AI_Agents__A_Case_Study_of_an_LLM-Based_Multi-Agent_System_for_Ethical_AI.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "2dd49a7f82d0559f78a7363542e59c03e332e46a", "publication_date": "2024-10-26", "title": "LLM-Consensus: Multi-Agent Debate for Visual Misinformation Detection", "authors": "Kumud Lakara, Georgia Channing, Juil Sock, Christian Rupprecht, Philip Torr, John P. Collomosse, Christian Schr\u00f6der de Witt", "venue": "", "citation_count": 3, "influential_citation_count": 0, "abstract": "One of the most challenging forms of misinformation involves the out-of-context (OOC) use of images paired with misleading text, creating false narratives. Existing AI-driven detection systems lack explainability and require expensive finetuning. We address these issues with LLM-Consensus, a multi-agent debate system for OOC misinformation detection. LLM-Consensus introduces a novel multi-agent debate framework where multimodal agents collaborate to assess contextual consistency and request external information to enhance cross-context reasoning and decision-making. Our framework enables explainable detection with state-of-the-art accuracy even without domain-specific fine-tuning. Extensive ablation studies confirm that external retrieval significantly improves detection accuracy, and user studies demonstrate that LLM-Consensus boosts performance for both experts and non-experts. These results position LLM-Consensus as a powerful tool for autonomous and citizen intelligence applications.", "pdf_url": "https://arxiv.org/pdf/2410.20140.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-26_LLM-Consensus__Multi-Agent_Debate_for_Visual_Misinformation_Detection.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-26_LLM-Consensus__Multi-Agent_Debate_for_Visual_Misinformation_Detection.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "28c8b3bf4578692c82bed92cb1ebd35056818d24", "publication_date": "2024-05-29", "title": "SSFF: Investigating LLM Predictive Capabilities for Startup Success through a Multi-Agent Framework with Enhanced Explainability and Performance", "authors": "Xisen Wang, Yigit Ihlamur, Fuat Alican", "venue": "", "citation_count": 3, "influential_citation_count": 0, "abstract": "LLM based agents have recently demonstrated strong potential in automating complex tasks, yet accurately predicting startup success remains an open challenge with few benchmarks and tailored frameworks. To address these limitations, we propose the Startup Success Forecasting Framework, an autonomous system that emulates the reasoning of venture capital analysts through a multi agent collaboration model. Our framework integrates traditional machine learning methods such as random forests and neural networks within a retrieval augmented generation framework composed of three interconnected modules: a prediction block, an analysis block, and an external knowledge block. We evaluate our framework and identify three main findings. First, by leveraging founder segmentation, startups led by L5 founders are 3.79 times more likely to succeed than those led by L1 founders. Second, baseline large language models consistently overpredict startup success and struggle under realistic class imbalances largely due to overreliance on founder claims. Third, our framework significantly enhances prediction accuracy, yielding a 108.3 percent relative improvement over GPT 4o mini and a 30.8 percent relative improvement over GPT 4o. These results demonstrate the value of a multi agent approach combined with discriminative machine learning in mitigating the limitations of standard large language model based prediction methods.", "pdf_url": "https://arxiv.org/pdf/2405.19456.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-05-29_SSFF__Investigating_LLM_Predictive_Capabilities_for_Startup_Success_through_a_Multi-Agent_Framework_.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-29_SSFF__Investigating_LLM_Predictive_Capabilities_for_Startup_Success_through_a_Multi-Agent_Framework_.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "c063152553b92e3f857532e3061f86b395ecfdec", "publication_date": "2024-12-31", "title": "Task Offloading with LLM-Enhanced Multi-Agent Reinforcement Learning in UAV-Assisted Edge Computing", "authors": "Feifan Zhu, Fei Huang, Yantao Yu, Guojin Liu, Tiancong Huang", "venue": "Italian National Conference on Sensors", "citation_count": 3, "influential_citation_count": 0, "abstract": "Unmanned aerial vehicles (UAVs) furnished with computational servers enable user equipment (UE) to offload complex computational tasks, thereby addressing the limitations of edge computing in remote or resource-constrained environments. The application of value decomposition algorithms for UAV trajectory planning has drawn considerable research attention. However, existing value decomposition algorithms commonly encounter obstacles in effectively associating local observations with the global state of UAV clusters, which hinders their task-solving capabilities and gives rise to reduced task completion rates and prolonged convergence times. To address these challenges, this paper introduces an innovative multi-agent deep learning framework that conceptualizes multi-UAV trajectory optimization as a decentralized partially observable Markov decision process (Dec-POMDP). This framework integrates the QTRAN algorithm with a large language model (LLM) for efficient region decomposition and employs graph convolutional networks (GCNs) combined with self-attention mechanisms to adeptly manage inter-subregion relationships. The simulation results demonstrate that the proposed method significantly outperforms existing deep reinforcement learning methods, with improvements in convergence speed and task completion rate exceeding 10%. Overall, this framework significantly advances UAV trajectory optimization and enhances the performance of multi-agent systems within UAV-assisted edge computing environments.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "753f304ab54491030acc5a041be878a85851eef3", "publication_date": "2024-08-12", "title": "Audit-LLM: Multi-Agent Collaboration for Log-based Insider Threat Detection", "authors": "Chengyu Song, Linru Ma, Jianming Zheng, Jinzhi Liao, Hongyu Kuang, Lin Yang", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Log-based insider threat detection (ITD) detects malicious user activities by auditing log entries. Recently, large language models (LLMs) with strong common sense knowledge have emerged in the domain of ITD. Nevertheless, diverse activity types and overlong log files pose a significant challenge for LLMs in directly discerning malicious ones within myriads of normal activities. Furthermore, the faithfulness hallucination issue from LLMs aggravates its application difficulty in ITD, as the generated conclusion may not align with user commands and activity context. In response to these challenges, we introduce Audit-LLM, a multi-agent log-based insider threat detection framework comprising three collaborative agents: (i) the Decomposer agent, breaking down the complex ITD task into manageable sub-tasks using Chain-of-Thought (COT) reasoning;(ii) the Tool Builder agent, creating reusable tools for sub-tasks to overcome context length limitations in LLMs; and (iii) the Executor agent, generating the final detection conclusion by invoking constructed tools. To enhance conclusion accuracy, we propose a pair-wise Evidence-based Multi-agent Debate (EMAD) mechanism, where two independent Executors iteratively refine their conclusions through reasoning exchange to reach a consensus. Comprehensive experiments conducted on three publicly available ITD datasets-CERT r4.2, CERT r5.2, and PicoDomain-demonstrate the superiority of our method over existing baselines and show that the proposed EMAD significantly improves the faithfulness of explanations generated by LLMs.", "pdf_url": "https://arxiv.org/pdf/2408.08902.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-08-12_Audit-LLM__Multi-Agent_Collaboration_for_Log-based_Insider_Threat_Detection.pdf", "markdown_path": "data/semantic/markdown_files/2024-08-12_Audit-LLM__Multi-Agent_Collaboration_for_Log-based_Insider_Threat_Detection.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "69ba84363777acefbdfda225204430b232560c72", "publication_date": "2024-09-17", "title": "Improving LLM Reasoning with Multi-Agent Tree-of-Thought Validator Agent", "authors": "Fatemeh Haji, Mazal Bethany, Maryam Tabar, J. Chiang, Anthony Rios, Peyman Najafirad", "venue": "arXiv.org", "citation_count": 5, "influential_citation_count": 0, "abstract": "Multi-agent strategies have emerged as a promising approach to enhance the reasoning abilities of Large Language Models (LLMs) by assigning specialized roles in the problem-solving process. Concurrently, Tree of Thoughts (ToT) methods have shown potential in improving reasoning for complex question-answering tasks by exploring diverse reasoning paths. A critical limitation in multi-agent reasoning is the 'Reasoner' agent's shallow exploration of reasoning paths. While ToT strategies could help mitigate this problem, they may generate flawed reasoning branches, which could harm the trustworthiness of the final answer. To leverage the strengths of both multi-agent reasoning and ToT strategies, we introduce a novel approach combining ToT-based Reasoner agents with a Thought Validator agent. Multiple Reasoner agents operate in parallel, employing ToT to explore diverse reasoning paths. The Thought Validator then scrutinizes these paths, considering a Reasoner's conclusion only if its reasoning is valid. This method enables a more robust voting strategy by discarding faulty reasoning paths, enhancing the system's ability to tackle tasks requiring systematic and trustworthy reasoning. Our method demonstrates superior performance compared to existing techniques when evaluated on the GSM8K dataset, outperforming the standard ToT strategy by an average 5.6% across four LLMs. The code and related content can be found in: https://github.com/SecureAIAutonomyLab/MA-ToT", "pdf_url": "https://arxiv.org/pdf/2409.11527.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-09-17_Improving_LLM_Reasoning_with_Multi-Agent_Tree-of-Thought_Validator_Agent.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-17_Improving_LLM_Reasoning_with_Multi-Agent_Tree-of-Thought_Validator_Agent.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "66b4426196981d30875f574bae6c4dbc8b67e476", "publication_date": "2024-12-15", "title": "EduMAS: A Novel LLM-Powered Multi-Agent Framework for Educational Support", "authors": "Qiaomu Li, Ying Xie, S. Chakravarty, Dabae Lee", "venue": "BigData Congress [Services Society]", "citation_count": 4, "influential_citation_count": 0, "abstract": "In general, educational support with Large Language Models (LLMs) faces challenges in knowledge organization, expertise integration, and contextual adaptation. So, we present EduMAS, a novel multi-agent framework that coordinates specialized agents with graph-based knowledge navigation. Our framework introduces three key innovations: (1) Specialized Agents that provide expertise in different learning aspects to solve decomposed subtasks professionally; (2) Graph Navigator for graph-based knowledge extraction and selection to improve the quality of responses; (3) The Emotional Awareness mechanism for better contextual adaptation. Through comprehensive experiments on college-level physics education and evaluated by six state-of-the-art LLMs, EduMAS demonstrates significant improvements over the baseline model in complex concept integration, cross-disciplinary understanding, and theory-to-application translation. Ablation studies further validate the contribution of each framework component, Specialized Agents and Graph Navigator play important roles in performance improvement. Our work provides strong support for LLM-powered multi-agent system in AI-assisted education.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "39dcc14ec83876663fca65dd8ac5496ba4d73e12", "publication_date": "2024-12-16", "title": "Harnessing Language for Coordination: A Framework and Benchmark for LLM-Driven Multi-Agent Control", "authors": "Timoth\u00e9e Anne, Noah Syrkis, Meriem Elhosni, Florian Turati, Franck Legendre, Alain Jaquier, Sebastian Risi", "venue": "IEEE Transactions on Games", "citation_count": 2, "influential_citation_count": 1, "abstract": "Large Language Models (LLMs) have demonstrated remarkable performance across various tasks. Their potential to facilitate human coordination with many agents is a promising but largely under-explored area. Such capabilities would be helpful in disaster response, urban planning, and real-time strategy scenarios. In this work, we introduce (1) a real-time strategy game benchmark designed to evaluate these abilities and (2) a novel framework we term HIVE. HIVE empowers a single human to coordinate swarms of up to 2,000 agents through a natural language dialog with an LLM. We present promising results on this multi-agent benchmark, with our hybrid approach solving tasks such as coordinating agent movements, exploiting unit weaknesses, leveraging human annotations, and understanding terrain and strategic points. Our findings also highlight critical limitations of current models, including difficulties in processing spatial visual information and challenges in formulating long-term strategic plans. This work sheds light on the potential and limitations of LLMs in human-swarm coordination, paving the way for future research in this area. The HIVE project page, hive.syrkis.com, includes videos of the system in action.", "pdf_url": "https://arxiv.org/pdf/2412.11761.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-16_Harnessing_Language_for_Coordination__A_Framework_and_Benchmark_for_LLM-Driven_Multi-Agent_Control.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-16_Harnessing_Language_for_Coordination__A_Framework_and_Benchmark_for_LLM-Driven_Multi-Agent_Control.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "f08e6657e93226e67c6cf19a1d76cb46e1535ede", "publication_date": "2024-10-05", "title": "YOLO-MARL: You Only LLM Once for Multi-agent Reinforcement Learning", "authors": "Zhuang Yuan, Yi Shen, Zhili Zhang, Yuxiao Chen, Fei Miao", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Advancements in deep multi-agent reinforcement learning (MARL) have positioned it as a promising approach for decision-making in cooperative games. However, it still remains challenging for MARL agents to learn cooperative strategies for some game environments. Recently, large language models (LLMs) have demonstrated emergent reasoning capabilities, making them promising candidates for enhancing coordination among the agents. However, due to the model size of LLMs, it can be expensive to frequently infer LLMs for actions that agents can take. In this work, we propose You Only LLM Once for MARL (YOLO-MARL), a novel framework that leverages the high-level task planning capabilities of LLMs to improve the policy learning process of multi-agents in cooperative games. Notably, for each game environment, YOLO-MARL only requires one time interaction with LLMs in the proposed strategy generation, state interpretation and planning function generation modules, before the MARL policy training process. This avoids the ongoing costs and computational time associated with frequent LLMs API calls during training. Moreover, the trained decentralized normal-sized neural network-based policies operate independently of the LLM. We evaluate our method across three different environments and demonstrate that YOLO-MARL outperforms traditional MARL algorithms.", "pdf_url": "https://arxiv.org/pdf/2410.03997.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-05_YOLO-MARL__You_Only_LLM_Once_for_Multi-agent_Reinforcement_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-05_YOLO-MARL__You_Only_LLM_Once_for_Multi-agent_Reinforcement_Learning.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "9220f3e319d735241c7ae6be3389e49f65a9770b", "publication_date": "2024-11-21", "title": "LLM-based Multi-Agent Systems: Techniques and Business Perspectives", "authors": "Yingxuan Yang, Qiuying Peng, Jun Wang, Weinan Zhang", "venue": "", "citation_count": 2, "influential_citation_count": 0, "abstract": "In the era of (multi-modal) large language models, most operational processes can be reformulated and reproduced using LLM agents. The LLM agents can perceive, control, and get feedback from the environment so as to accomplish the given tasks in an autonomous manner. Besides the environment-interaction property, the LLM agents can call various external tools to ease the task completion process. The tools can be regarded as a predefined operational process with private or real-time knowledge that does not exist in the parameters of LLMs. As a natural trend of development, the tools for calling are becoming autonomous agents, thus the full intelligent system turns out to be a LLM-based Multi-Agent System (LaMAS). Compared to the previous single-LLM-agent system, LaMAS has the advantages of i) dynamic task decomposition and organic specialization, ii) higher flexibility for system changing, iii) proprietary data preserving for each participating entity, and iv) feasibility of monetization for each entity. This paper discusses the technical and business landscapes of LaMAS. To support the ecosystem of LaMAS, we provide a preliminary version of such LaMAS protocol considering technical requirements, data privacy, and business incentives. As such, LaMAS would be a practical solution to achieve artificial collective intelligence in the near future.", "pdf_url": "https://arxiv.org/pdf/2411.14033.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-11-21_LLM-based_Multi-Agent_Systems__Techniques_and_Business_Perspectives.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-21_LLM-based_Multi-Agent_Systems__Techniques_and_Business_Perspectives.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "84f93f0cb97daf7ee15b64cd5d1a355e13b7e4d6", "publication_date": "2024-12-23", "title": "A Survey on LLM-based Multi-Agent System: Recent Advances and New Frontiers in Application", "authors": "Shuaihang Chen, Yuanxing Liu, Wei Han, Weinan Zhang, Ting Liu", "venue": "", "citation_count": 2, "influential_citation_count": 0, "abstract": "LLM-based Multi-Agent Systems ( LLM-MAS ) have become a research hotspot since the rise of large language models (LLMs). However, with the continuous influx of new related works, the existing reviews struggle to capture them comprehensively. This paper presents a comprehensive survey of these studies. We first discuss the definition of LLM-MAS, a framework encompassing much of previous work. We provide an overview of the various applications of LLM-MAS in (i) solving complex tasks, (ii) simulating specific scenarios, and (iii) evaluating generative agents. Building on previous studies, we also highlight several challenges and propose future directions for research in this field.", "pdf_url": "https://arxiv.org/pdf/2412.17481.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-23_A_Survey_on_LLM-based_Multi-Agent_System__Recent_Advances_and_New_Frontiers_in_Application.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-23_A_Survey_on_LLM-based_Multi-Agent_System__Recent_Advances_and_New_Frontiers_in_Application.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "c3dfa3b6d02f4bf90168acfc40f5edc7e335cde8", "publication_date": "2024-10-02", "title": "Zodiac: A Cardiologist-Level LLM Framework for Multi-Agent Diagnostics", "authors": "Yuan Zhou, Peng Zhang, Mengya Song, Alice Zheng, Yiwen Lu, Zhiheng Liu, Yong Chen, Zhaohan Xi", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "Large language models (LLMs) have demonstrated remarkable progress in healthcare. However, a significant gap remains regarding LLMs' professionalism in domain-specific clinical practices, limiting their application in real-world diagnostics. In this work, we introduce ZODIAC, an LLM-powered framework with cardiologist-level professionalism designed to engage LLMs in cardiological diagnostics. ZODIAC assists cardiologists by extracting clinically relevant characteristics from patient data, detecting significant arrhythmias, and generating preliminary reports for the review and refinement by cardiologists. To achieve cardiologist-level professionalism, ZODIAC is built on a multi-agent collaboration framework, enabling the processing of patient data across multiple modalities. Each LLM agent is fine-tuned using real-world patient data adjudicated by cardiologists, reinforcing the model's professionalism. ZODIAC undergoes rigorous clinical validation with independent cardiologists, evaluated across eight metrics that measure clinical effectiveness and address security concerns. Results show that ZODIAC outperforms industry-leading models, including OpenAI's GPT-4o, Meta's Llama-3.1-405B, and Google's Gemini-pro, as well as medical-specialist LLMs like Microsoft's BioGPT. ZODIAC demonstrates the transformative potential of specialized LLMs in healthcare by delivering domain-specific solutions that meet the stringent demands of medical practice. Notably, ZODIAC has been successfully integrated into electrocardiography (ECG) devices, exemplifying the growing trend of embedding LLMs into Software-as-Medical-Device (SaMD).", "pdf_url": "https://arxiv.org/pdf/2410.02026.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-02_Zodiac__A_Cardiologist-Level_LLM_Framework_for_Multi-Agent_Diagnostics.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-02_Zodiac__A_Cardiologist-Level_LLM_Framework_for_Multi-Agent_Diagnostics.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "0732eecfb26c93a839ecbe9314a247d6a89f1fd0", "publication_date": "2024-10-17", "title": "Rapid and Automated Alloy Design with Graph Neural Network-Powered LLM-Driven Multi-Agent Systems", "authors": "Alireza Ghafarollahi, Markus J. Buehler", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "A multi-agent AI model is used to automate the discovery of new metallic alloys, integrating multimodal data and external knowledge including insights from physics via atomistic simulations. Our multi-agent system features three key components: (a) a suite of LLMs responsible for tasks such as reasoning and planning, (b) a group of AI agents with distinct roles and expertise that dynamically collaborate, and (c) a newly developed graph neural network (GNN) model for rapid retrieval of key physical properties. A set of LLM-driven AI agents collaborate to automate the exploration of the vast design space of MPEAs, guided by predictions from the GNN. We focus on the NbMoTa family of body-centered cubic (bcc) alloys, modeled using an ML-based interatomic potential, and target two key properties: the Peierls barrier and solute/screw dislocation interaction energy. Our GNN model accurately predicts these atomic-scale properties, providing a faster alternative to costly brute-force calculations and reducing the computational burden on multi-agent systems for physics retrieval. This AI system revolutionizes materials discovery by reducing reliance on human expertise and overcoming the limitations of direct all-atom simulations. By synergizing the predictive power of GNNs with the dynamic collaboration of LLM-based agents, the system autonomously navigates vast alloy design spaces, identifying trends in atomic-scale material properties and predicting macro-scale mechanical strength, as demonstrated by several computational experiments. This approach accelerates the discovery of advanced alloys and holds promise for broader applications in other complex systems, marking a significant step forward in automated materials design.", "pdf_url": "https://arxiv.org/pdf/2410.13768.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-17_Rapid_and_Automated_Alloy_Design_with_Graph_Neural_Network-Powered_LLM-Driven_Multi-Agent_Systems.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-17_Rapid_and_Automated_Alloy_Design_with_Graph_Neural_Network-Powered_LLM-Driven_Multi-Agent_Systems.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "ca01cb09c81af738b8108615115e7bfe96f44ec9", "publication_date": "2024-10-19", "title": "An Electoral Approach to Diversify LLM-based Multi-Agent Collective Decision-Making", "authors": "Xiutian Zhao, Ke Wang, Wei Peng", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 2, "influential_citation_count": 0, "abstract": "Modern large language models (LLMs) have exhibited cooperative synergy on complex task-solving, and collective decision-making (CDM) is a pivotal component in LLM-based multi-agent collaboration frameworks. Our survey on 52 recent such systems uncovers a severe lack of diversity, with a heavy reliance on dictatorial and plurality voting for CDM. Through the lens of social choice theory, we scrutinize widely-adopted CDM methods and identify their limitations. To enrich current landscape of LLM-based CDM, we present GEDI, an electoral CDM module that incorporates various ordinal preferential voting mechanisms. Our empirical case study across three benchmarks shows that the integration of certain CDM methods can markedly improve the reasoning capabilities and robustness of some leading LLMs, all without requiring intricate system designs. Additionally, we find that some CDM mechanisms generate positive synergies even with as few as three agents. The voting-based methods also demonstrate robustness against single points of failure, as well as diversity in terms of hit-rate@k and subject-wise impacts.", "pdf_url": "https://arxiv.org/pdf/2410.15168.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-19_An_Electoral_Approach_to_Diversify_LLM-based_Multi-Agent_Collective_Decision-Making.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-19_An_Electoral_Approach_to_Diversify_LLM-based_Multi-Agent_Collective_Decision-Making.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "ca2cd41370f85d065407959b7ed3616f8746dd39", "publication_date": "2024-09-10", "title": "Research on the role of LLM in multi-agent systems: A survey", "authors": "Jianxiang Ma", "venue": "Applied and Computational Engineering", "citation_count": 1, "influential_citation_count": 0, "abstract": "In recent years, the rapid development of large language model (LLM) has demonstrated superior performance in language understanding, text generation, planning, reasoning, and knowledge integration. This has led to the emergence of intelligent agents based on LLM. By leveraging the capabilities of LLM, these agents can effectively make decisions based on given objectives and possess certain learning and adaptation abilities. However, single-agent systems are generally suited to solving relatively simple problems and are limited in handling complex tasks that require coordination. For instance, in fields such as power grid management or traffic control systems, relying solely on a single agent is often insufficient for effective decision-making. In this context, adopting multi-agent systems proves to be more effective: through collaboration among multiple agents, each undertaking specific tasks, complex problems can be efficiently managed through interaction and coordination. This survey will analyze the role of LLM in multi-agent collaboration, discuss and analyze the current research challenges and key issues, and explore potential directions for future development.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "e35426fd81c78b044258cf419be6b7e5093b71c0", "publication_date": "2023-12-15", "title": "ReST meets ReAct: Self-Improvement for Multi-Step Reasoning LLM Agent", "authors": "Renat Aksitov, Sobhan Miryoosefi, Zong-xiao Li, Daliang Li, Sheila Babayan, Kavya Kopparapu, Zachary Fisher, Ruiqi Guo, Sushant Prakash, Pranesh Srinivasan, M. Zaheer, Felix X. Yu, Sanjiv Kumar", "venue": "arXiv.org", "citation_count": 48, "influential_citation_count": 6, "abstract": "Answering complex natural language questions often necessitates multi-step reasoning and integrating external information. Several systems have combined knowledge retrieval with a large language model (LLM) to answer such questions. These systems, however, suffer from various failure cases, and we cannot directly train them end-to-end to fix such failures, as interaction with external knowledge is non-differentiable. To address these deficiencies, we define a ReAct-style LLM agent with the ability to reason and act upon external knowledge. We further refine the agent through a ReST-like method that iteratively trains on previous trajectories, employing growing-batch reinforcement learning with AI feedback for continuous self-improvement and self-distillation. Starting from a prompted large model and after just two iterations of the algorithm, we can produce a fine-tuned small model that achieves comparable performance on challenging compositional question-answering benchmarks with two orders of magnitude fewer parameters.", "pdf_url": "https://arxiv.org/pdf/2312.10003.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-15_ReST_meets_ReAct__Self-Improvement_for_Multi-Step_Reasoning_LLM_Agent.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-15_ReST_meets_ReAct__Self-Improvement_for_Multi-Step_Reasoning_LLM_Agent.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "6d828a7aace632477c5d89c1d4e2182645030b85", "publication_date": "2023-10-05", "title": "Balancing Autonomy and Alignment: A Multi-Dimensional Taxonomy for Autonomous LLM-powered Multi-Agent Architectures", "authors": "Thorsten H\u00e4ndler", "venue": "arXiv.org", "citation_count": 23, "influential_citation_count": 1, "abstract": "Large language models (LLMs) have revolutionized the field of artificial intelligence, endowing it with sophisticated language understanding and generation capabilities. However, when faced with more complex and interconnected tasks that demand a profound and iterative thought process, LLMs reveal their inherent limitations. Autonomous LLM-powered multi-agent systems represent a strategic response to these challenges. Such systems strive for autonomously tackling user-prompted goals by decomposing them into manageable tasks and orchestrating their execution and result synthesis through a collective of specialized intelligent agents. Equipped with LLM-powered reasoning capabilities, these agents harness the cognitive synergy of collaborating with their peers, enhanced by leveraging contextual resources such as tools and datasets. While these architectures hold promising potential in amplifying AI capabilities, striking the right balance between different levels of autonomy and alignment remains the crucial challenge for their effective operation. This paper proposes a comprehensive multi-dimensional taxonomy, engineered to analyze how autonomous LLM-powered multi-agent systems balance the dynamic interplay between autonomy and alignment across various aspects inherent to architectural viewpoints such as goal-driven task management, agent composition, multi-agent collaboration, and context interaction. It also includes a domain-ontology model specifying fundamental architectural concepts. Our taxonomy aims to empower researchers, engineers, and AI practitioners to systematically analyze the architectural dynamics and balancing strategies employed by these increasingly prevalent AI systems. The exploratory taxonomic classification of selected representative LLM-powered multi-agent systems illustrates its practical utility and reveals potential for future research and development.", "pdf_url": "https://arxiv.org/pdf/2310.03659.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-10-05_Balancing_Autonomy_and_Alignment__A_Multi-Dimensional_Taxonomy_for_Autonomous_LLM-powered_Multi-Agen.pdf", "markdown_path": "data/semantic/markdown_files/2023-10-05_Balancing_Autonomy_and_Alignment__A_Multi-Dimensional_Taxonomy_for_Autonomous_LLM-powered_Multi-Agen.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "611088d69b8d1e829e9f0d9d0f63c460c2b76674", "publication_date": "2024-04-03", "title": "Learn to Disguise: Avoid Refusal Responses in LLM's Defense via a Multi-agent Attacker-Disguiser Game", "authors": "Qianqiao Xu, Zhiliang Tian, Hongyan Wu, Zhen Huang, Yiping Song, Feng Liu, Dongsheng Li", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "With the enhanced performance of large models on natural language processing tasks, potential moral and ethical issues of large models arise. There exist malicious attackers who induce large models to jailbreak and generate information containing illegal, privacy-invasive information through techniques such as prompt engineering. As a result, large models counter malicious attackers' attacks using techniques such as safety alignment. However, the strong defense mechanism of the large model through rejection replies is easily identified by attackers and used to strengthen attackers' capabilities. In this paper, we propose a multi-agent attacker-disguiser game approach to achieve a weak defense mechanism that allows the large model to both safely reply to the attacker and hide the defense intent. First, we construct a multi-agent framework to simulate attack and defense scenarios, playing different roles to be responsible for attack, disguise, safety evaluation, and disguise evaluation tasks. After that, we design attack and disguise game algorithms to optimize the game strategies of the attacker and the disguiser and use the curriculum learning process to strengthen the capabilities of the agents. The experiments verify that the method in this paper is more effective in strengthening the model's ability to disguise the defense intent compared with other methods. Moreover, our approach can adapt any black-box large model to assist the model in defense and does not suffer from model version iterations.", "pdf_url": "https://arxiv.org/pdf/2404.02532.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-03_Learn_to_Disguise__Avoid_Refusal_Responses_in_LLM_s_Defense_via_a_Multi-agent_Attacker-Disguiser_Gam.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-03_Learn_to_Disguise__Avoid_Refusal_Responses_in_LLM_s_Defense_via_a_Multi-agent_Attacker-Disguiser_Gam.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "b9ebbedc3284a0c4638ce23103672c29c1b164e0", "publication_date": "2024-08-19", "title": "GoNoGo: An Efficient LLM-based Multi-Agent System for Streamlining Automotive Software Release Decision-Making", "authors": "Arsham Gholamzadeh Khoee, Yinan Yu, R. Feldt, Andris Freimanis, Patrick Andersson, Dhasarathy Parthasarathy", "venue": "International Conference on Testing Software and Systems", "citation_count": 2, "influential_citation_count": 0, "abstract": "Traditional methods for making software deployment decisions in the automotive industry typically rely on manual analysis of tabular software test data. These methods often lead to higher costs and delays in the software release cycle due to their labor-intensive nature. Large Language Models (LLMs) present a promising solution to these challenges. However, their application generally demands multiple rounds of human-driven prompt engineering, which limits their practical deployment, particularly for industrial end-users who need reliable and efficient results. In this paper, we propose GoNoGo, an LLM agent system designed to streamline automotive software deployment while meeting both functional requirements and practical industrial constraints. Unlike previous systems, GoNoGo is specifically tailored to address domain-specific and risk-sensitive systems. We evaluate GoNoGo's performance across different task difficulties using zero-shot and few-shot examples taken from industrial practice. Our results show that GoNoGo achieves a 100% success rate for tasks up to Level 2 difficulty with 3-shot examples, and maintains high performance even for more complex tasks. We find that GoNoGo effectively automates decision-making for simpler tasks, significantly reducing the need for manual intervention. In summary, GoNoGo represents an efficient and user-friendly LLM-based solution currently employed in our industrial partner's company to assist with software release decision-making, supporting more informed and timely decisions in the release process for risk-sensitive vehicle systems.", "pdf_url": "https://arxiv.org/pdf/2408.09785.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-08-19_GoNoGo__An_Efficient_LLM-based_Multi-Agent_System_for_Streamlining_Automotive_Software_Release_Decis.pdf", "markdown_path": "data/semantic/markdown_files/2024-08-19_GoNoGo__An_Efficient_LLM-based_Multi-Agent_System_for_Streamlining_Automotive_Software_Release_Decis.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "425f1edd88fe3539c40ddd93c3e07c95de67ba00", "publication_date": "2023-11-28", "title": "Embodied Multi-Modal Agent trained by an LLM from a Parallel TextWorld", "authors": "Yijun Yang, Tianyi Zhou, Kanxue Li, Dapeng Tao, Lusong Li, Li Shen, Xiaodong He, Jing Jiang, Yuhui Shi", "venue": "Computer Vision and Pattern Recognition", "citation_count": 39, "influential_citation_count": 3, "abstract": "While large language models (LLMs) excel in a simulated world of texts, they struggle to interact with the more realistic world without perceptions of other modalities such as visual or audio signals. Although vision-language models (VLMs) integrate LLM modules (1) aligned with static image features, and (2) may possess prior knowledge of world dynamics (as demonstrated in the text world), they have not been trained in an embodied visual world and thus cannot align with its dynamics. On the other hand, training an embodied agent in a noisy visual world without expert guidance is often chal-lenging and inefficient. In this paper, we train a VLM agent living in a visual world using an LLM agent excelling in a parallel text world. Specifically, we distill LLM's reflection outcomes (improved actions by analyzing mistakes) in a text world's tasks to finetune the VLM on the same tasks of the visual world, resulting in an Embodied Multi-Modal Agent (EMMA) quickly adapting to the visual world dy-namics. Such cross-modality imitation learning between the two parallel worlds is achieved by a novel DAgger-DPO algorithm, enabling EMMA to generalize to a broad scope of new tasks without any further guidance from the LLM expert. Extensive evaluations on the ALFWorld benchmark's diverse tasks highlight EMMA's superior performance to SOTA VLM-based agents, e.g., 20%-70% improvement in the success rate.", "pdf_url": "https://arxiv.org/pdf/2311.16714.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-11-28_Embodied_Multi-Modal_Agent_trained_by_an_LLM_from_a_Parallel_TextWorld.pdf", "markdown_path": "data/semantic/markdown_files/2023-11-28_Embodied_Multi-Modal_Agent_trained_by_an_LLM_from_a_Parallel_TextWorld.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "1a8d722eb907e71dc7f507ae1ca7c569b37f03b3", "publication_date": "2024", "title": "MuLan: Multimodal-LLM Agent for Progressive Multi-Object Diffusion", "authors": "Sen Li, Ruochen Wang, Cho-Jui Hsieh, Minhao Cheng, Tianyi Zhou", "venue": "arXiv.org", "citation_count": 6, "influential_citation_count": 0, "abstract": "Existing text-to-image models still struggle to generate images of multiple objects, especially in handling their spatial positions, relative sizes, overlapping, and attribute bindings. In this paper, we develop a training-free Mu ltimodal-L LM a ge n t (MuLan) to address these challenges by progressive multi-object generation with planning and feedback control, like a human painter. MuLan harnesses a large language model (LLM) to decompose a prompt to a sequence of sub-tasks, each generating only one object conditioned on previously generated objects by stable diffusion. Unlike existing LLM-grounded methods, MuLan only produces a high-level plan at the beginning while the exact size and location of each object are determined by an LLM and attention guidance upon each sub-task. Moreover, MuLan adopts a vision-language model (VLM) to provide feedback to the image generated in each sub-task and control the diffusion model to re-generate the image if it violates the original prompt. Hence, each model in every step of MuLan only needs to address an easy sub-task it is specialized for. We collect 200 prompts containing multi-objects with spatial relationships and attribute bindings from different benchmarks to evaluate MuLan. The results demonstrate the superiority of MuLan in generating multiple objects over baselines. The code is available on https:github.com/ measure-infinity/mulan-code .", "pdf_url": "https://arxiv.org/abs/2402.12741/pdf/2402.12741", "pdf_filepath": "data/semantic/pdf_files/2024_MuLan__Multimodal-LLM_Agent_for_Progressive_Multi-Object_Diffusion.pdf", "markdown_path": "data/semantic/markdown_files/2024_MuLan__Multimodal-LLM_Agent_for_Progressive_Multi-Object_Diffusion.md"}
{"query_date": "2025-06-12", "query_keyword": "Multi-Agent LLM", "paper_id": "2165b570f4971fb6a4028df04582b3905b82a015", "publication_date": "2024", "title": "The Multi-agent System based on LLM for Online Discussions", "authors": "Yihan Dong", "venue": "Adaptive Agents and Multi-Agent Systems", "citation_count": 5, "influential_citation_count": 0, "abstract": "The considerable improvement on the Internet and the corresponding applications leads to the result of online discussions becoming far more popular and significant than any other method for people to communicate with each other and reach a consensus. Meanwhile, the incredible improvement in Large Language Models (LLM) has promoted the performance of LLM-based agents in text understanding and content generation capabilities. The research objective of the PhD thesis is to build democratic discussion environments, with three main issues existing right now: 1) Large-scale discussions tend to be complicated, 2) Rumours and misinformation bring negative effects to the discussions, and 3) Direct democratic discussions are complex and time-consuming. This extended abstract introduces the efforts that have been made to address those issues, with the introduction of the potential directions in the future.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-13", "query_keyword": "open-set", "paper_id": "c3e5a20b844c042d2174263d2fd5b30d8cc8f0b0", "publication_date": "2023-03-09", "title": "Grounding DINO: Marrying DINO with Grounded Pre-Training for Open-Set Object Detection", "authors": "Shilong Liu, Zhaoyang Zeng, Tianhe Ren, Feng Li, Hao Zhang, Jie Yang, Chun-yue Li, Jianwei Yang, Hang Su, Jun-Juan Zhu, Lei Zhang", "venue": "European Conference on Computer Vision", "citation_count": 1960, "influential_citation_count": 294, "abstract": "In this paper, we present an open-set object detector, called Grounding DINO, by marrying Transformer-based detector DINO with grounded pre-training, which can detect arbitrary objects with human inputs such as category names or referring expressions. The key solution of open-set object detection is introducing language to a closed-set detector for open-set concept generalization. To effectively fuse language and vision modalities, we conceptually divide a closed-set detector into three phases and propose a tight fusion solution, which includes a feature enhancer, a language-guided query selection, and a cross-modality decoder for cross-modality fusion. While previous works mainly evaluate open-set object detection on novel categories, we propose to also perform evaluations on referring expression comprehension for objects specified with attributes. Grounding DINO performs remarkably well on all three settings, including benchmarks on COCO, LVIS, ODinW, and RefCOCO/+/g. Grounding DINO achieves a $52.5$ AP on the COCO detection zero-shot transfer benchmark, i.e., without any training data from COCO. It sets a new record on the ODinW zero-shot benchmark with a mean $26.1$ AP. Code will be available at \\url{https://github.com/IDEA-Research/GroundingDINO}.", "pdf_url": "https://arxiv.org/pdf/2303.05499.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-03-09_Grounding_DINO__Marrying_DINO_with_Grounded_Pre-Training_for_Open-Set_Object_Detection.pdf", "markdown_path": "data/semantic/markdown_files/2023-03-09_Grounding_DINO__Marrying_DINO_with_Grounded_Pre-Training_for_Open-Set_Object_Detection.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "9994d82142288e8c4d92e9b7846144150c920beb", "publication_date": "2024", "title": "An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Models are Task-specific Classifiers", "authors": "Hui Huang, Yingqi Qu, Hongli Zhou, Jing Liu, Muyun Yang, Tiejun Zhao", "venue": "arXiv.org", "citation_count": 54, "influential_citation_count": 2, "abstract": "Recently, there has been a growing trend of utilizing Large Language Model (LLM) to evaluate the quality of other LLMs. Many studies have employed proprietary close-source models, especially GPT4, as the evaluator. Alterna-tively, other works have fine-tuned judge models based on open-source LLMs as the evaluator. In this study, we conduct an empirical study of different judge models on their evaluation capability. Our findings indicate that although the fine-tuned judge models achieve high accuracy on in-domain test sets, even surpassing GPT4, they are inherently task-specific classifiers, and their generalizability and fairness severely underperform GPT4.", "pdf_url": "https://arxiv.org/abs/2403.02839/pdf/2403.02839", "pdf_filepath": "data/semantic/pdf_files/2024_An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation__Fine-tuned_Judge_Models_are_Task-specific_C.pdf", "markdown_path": "data/semantic/markdown_files/2024_An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation__Fine-tuned_Judge_Models_are_Task-specific_C.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "3ef7c18208e6f4c96f6441eef865c26b434c14fb", "publication_date": "2024-04-14", "title": "Unveiling LLM Evaluation Focused on Metrics: Challenges and Solutions", "authors": "Taojun Hu, Xiao-Hua Zhou", "venue": "arXiv.org", "citation_count": 16, "influential_citation_count": 1, "abstract": "Natural Language Processing (NLP) is witnessing a remarkable breakthrough driven by the success of Large Language Models (LLMs). LLMs have gained significant attention across academia and industry for their versatile applications in text generation, question answering, and text summarization. As the landscape of NLP evolves with an increasing number of domain-specific LLMs employing diverse techniques and trained on various corpus, evaluating performance of these models becomes paramount. To quantify the performance, it's crucial to have a comprehensive grasp of existing metrics. Among the evaluation, metrics which quantifying the performance of LLMs play a pivotal role. This paper offers a comprehensive exploration of LLM evaluation from a metrics perspective, providing insights into the selection and interpretation of metrics currently in use. Our main goal is to elucidate their mathematical formulations and statistical interpretations. We shed light on the application of these metrics using recent Biomedical LLMs. Additionally, we offer a succinct comparison of these metrics, aiding researchers in selecting appropriate metrics for diverse tasks. The overarching goal is to furnish researchers with a pragmatic guide for effective LLM evaluation and metric selection, thereby advancing the understanding and application of these large language models.", "pdf_url": "https://arxiv.org/pdf/2404.09135.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-14_Unveiling_LLM_Evaluation_Focused_on_Metrics__Challenges_and_Solutions.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-14_Unveiling_LLM_Evaluation_Focused_on_Metrics__Challenges_and_Solutions.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "f1bbe52d857a5b3abc3fc9d9469c407a4add8d2c", "publication_date": "2024-03-05", "title": "An Empirical Study of LLM-as-a-Judge for LLM Evaluation: Fine-tuned Judge Model is not a General Substitute for GPT-4", "authors": "Hui Huang, Yingqi Qu, Hongli Zhou, Jing Liu, Muyun Yang, Bing Xu, Tiejun Zhao", "venue": "", "citation_count": 22, "influential_citation_count": 1, "abstract": "Recently, there has been a growing trend of utilizing Large Language Model (LLM) to evaluate the quality of other LLMs. Many studies have fine-tuned judge models based on open-source LLMs for evaluation. While the fine-tuned judge models are claimed to achieve comparable evaluation capability with GPT-4, in this work, we conduct an empirical study of LLM-as-a-Judge. Our findings indicate that although the fine-tuned judge models achieve high performance on in-domain test sets, even surpassing GPT-4, they underperform GPT-4 across several dimensions, including generalizability, fairness and adaptability. We also reveal that the fine-tuned judge model inherently operates as a task-specific classifier, consequently imposing the limitations.", "pdf_url": "https://arxiv.org/pdf/2403.02839.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-05_An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation__Fine-tuned_Judge_Model_is_not_a_General_Sub.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-05_An_Empirical_Study_of_LLM-as-a-Judge_for_LLM_Evaluation__Fine-tuned_Judge_Model_is_not_a_General_Sub.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "f187697a28fdc8d6d44dc3c1ea3a65ed85449c42", "publication_date": "2024-04-25", "title": "Examining the robustness of LLM evaluation to the distributional assumptions of benchmarks", "authors": "Melissa Ailem, Katerina Marazopoulou, Charlotte Siska, James Bono", "venue": "Annual Meeting of the Association for Computational Linguistics", "citation_count": 22, "influential_citation_count": 1, "abstract": "Benchmarks have emerged as the central approach for evaluating Large Language Models (LLMs). The research community often relies on a model's average performance across the test prompts of a benchmark to evaluate the model's performance. This is consistent with the assumption that the test prompts within a benchmark represent a random sample from a real-world distribution of interest. We note that this is generally not the case; instead, we hold that the distribution of interest varies according to the specific use case. We find that (1) the correlation in model performance across test prompts is non-random, (2) accounting for correlations across test prompts can change model rankings on major benchmarks, (3) explanatory factors for these correlations include semantic similarity and common LLM failure points.", "pdf_url": "https://arxiv.org/pdf/2404.16966.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-25_Examining_the_robustness_of_LLM_evaluation_to_the_distributional_assumptions_of_benchmarks.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-25_Examining_the_robustness_of_LLM_evaluation_to_the_distributional_assumptions_of_benchmarks.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "82068d5f0126575e6b41dc4aa0653dd85939c91d", "publication_date": "2024-10-04", "title": "TICKing All the Boxes: Generated Checklists Improve LLM Evaluation and Generation", "authors": "Jonathan Cook, Tim Rockt\u00e4schel, Jakob N. Foerster, Dennis Aumiller, Alex Wang", "venue": "arXiv.org", "citation_count": 13, "influential_citation_count": 0, "abstract": "Given the widespread adoption and usage of Large Language Models (LLMs), it is crucial to have flexible and interpretable evaluations of their instruction-following ability. Preference judgments between model outputs have become the de facto evaluation standard, despite distilling complex, multi-faceted preferences into a single ranking. Furthermore, as human annotation is slow and costly, LLMs are increasingly used to make these judgments, at the expense of reliability and interpretability. In this work, we propose TICK (Targeted Instruct-evaluation with ChecKlists), a fully automated, interpretable evaluation protocol that structures evaluations with LLM-generated, instruction-specific checklists. We first show that, given an instruction, LLMs can reliably produce high-quality, tailored evaluation checklists that decompose the instruction into a series of YES/NO questions. Each question asks whether a candidate response meets a specific requirement of the instruction. We demonstrate that using TICK leads to a significant increase (46.4% $\\to$ 52.2%) in the frequency of exact agreements between LLM judgements and human preferences, as compared to having an LLM directly score an output. We then show that STICK (Self-TICK) can be used to improve generation quality across multiple benchmarks via self-refinement and Best-of-N selection. STICK self-refinement on LiveBench reasoning tasks leads to an absolute gain of $+$7.8%, whilst Best-of-N selection with STICK attains $+$6.3% absolute improvement on the real-world instruction dataset, WildBench. In light of this, structured, multi-faceted self-improvement is shown to be a promising way to further advance LLM capabilities. Finally, by providing LLM-generated checklists to human evaluators tasked with directly scoring LLM responses to WildBench instructions, we notably increase inter-annotator agreement (0.194 $\\to$ 0.256).", "pdf_url": "https://arxiv.org/pdf/2410.03608.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-04_TICKing_All_the_Boxes__Generated_Checklists_Improve_LLM_Evaluation_and_Generation.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-04_TICKing_All_the_Boxes__Generated_Checklists_Improve_LLM_Evaluation_and_Generation.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "4906654ecb2d42cfee13f46bebe2ec02bb6442b1", "publication_date": "2024-06-03", "title": "A Survey of Useful LLM Evaluation", "authors": "Ji-Lun Peng, Sijia Cheng, Egil Diau, Yung-Yu Shih, Po-Heng Chen, Yen-Ting Lin, Yun-Nung Chen", "venue": "arXiv.org", "citation_count": 14, "influential_citation_count": 2, "abstract": "LLMs have gotten attention across various research domains due to their exceptional performance on a wide range of complex tasks. Therefore, refined methods to evaluate the capabilities of LLMs are needed to determine the tasks and responsibility they should undertake. Our study mainly discussed how LLMs, as useful tools, should be effectively assessed. We proposed the two-stage framework: from ``core ability'' to ``agent'', clearly explaining how LLMs can be applied based on their specific capabilities, along with the evaluation methods in each stage. Core ability refers to the capabilities that LLMs need in order to generate high-quality natural language texts. After confirming LLMs possess core ability, they can solve real-world and complex tasks as agent. In the\"core ability\"stage, we discussed the reasoning ability, societal impact, and domain knowledge of LLMs. In the ``agent'' stage, we demonstrated embodied action, planning, and tool learning of LLMs agent applications. Finally, we examined the challenges currently confronting the evaluation methods for LLMs, as well as the directions for future development.", "pdf_url": "https://arxiv.org/pdf/2406.00936.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-06-03_A_Survey_of_Useful_LLM_Evaluation.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-03_A_Survey_of_Useful_LLM_Evaluation.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "8dce168f723158b771b526401113064c36fc875e", "publication_date": "2023-12-31", "title": "State of What Art? A Call for Multi-Prompt LLM Evaluation", "authors": "Moran Mizrahi, Guy Kaplan, Daniel Malkin, Rotem Dror, Dafna Shahaf, Gabriel Stanovsky", "venue": "Transactions of the Association for Computational Linguistics", "citation_count": 139, "influential_citation_count": 11, "abstract": "Abstract Recent advances in LLMs have led to an abundance of evaluation benchmarks, which typically rely on a single instruction template per task. We create a large-scale collection of instruction paraphrases and comprehensively analyze the brittleness introduced by single-prompt evaluations across 6.5M instances, involving 20 different LLMs and 39 tasks from 3 benchmarks. We find that different instruction templates lead to very different performance, both absolute and relative. Instead, we propose a set of diverse metrics on multiple instruction paraphrases, specifically tailored for different use cases (e.g., LLM vs. downstream development), ensuring a more reliable and meaningful assessment of LLM capabilities. We show that our metrics provide new insights into the strengths and limitations of current LLMs.", "pdf_url": "https://arxiv.org/pdf/2401.00595.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-12-31_State_of_What_Art__A_Call_for_Multi-Prompt_LLM_Evaluation.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-31_State_of_What_Art__A_Call_for_Multi-Prompt_LLM_Evaluation.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "0bbef27ae2d4df771b19330a2f4c59070b45cd6d", "publication_date": "2024-10-11", "title": "Towards Multilingual LLM Evaluation for European Languages", "authors": "Klaudia Thellmann, Bernhard Stadler, Michael Fromm, Jasper Schulze Buschhoff, Alex Jude, Fabio Barth, Johannes Leveling, Nicolas Flores-Herr, Joachim K\u00f6hler, Ren\u00e9 J\u00e4kel, Mehdi Ali", "venue": "arXiv.org", "citation_count": 9, "influential_citation_count": 0, "abstract": "The rise of Large Language Models (LLMs) has revolutionized natural language processing across numerous languages and tasks. However, evaluating LLM performance in a consistent and meaningful way across multiple European languages remains challenging, especially due to the scarcity of language-parallel multilingual benchmarks. We introduce a multilingual evaluation approach tailored for European languages. We employ translated versions of five widely-used benchmarks to assess the capabilities of 40 LLMs across 21 European languages. Our contributions include examining the effectiveness of translated benchmarks, assessing the impact of different translation services, and offering a multilingual evaluation framework for LLMs that includes newly created datasets: EU20-MMLU, EU20-HellaSwag, EU20-ARC, EU20-TruthfulQA, and EU20-GSM8K. The benchmarks and results are made publicly available to encourage further research in multilingual LLM evaluation.", "pdf_url": "https://arxiv.org/pdf/2410.08928.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-10-11_Towards_Multilingual_LLM_Evaluation_for_European_Languages.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-11_Towards_Multilingual_LLM_Evaluation_for_European_Languages.md"}
{"query_date": "2025-06-13", "query_keyword": "LLM evaluation", "paper_id": "18b3b96ffb28c785452081aa367cbc02a1cf7567", "publication_date": "2024-01-09", "title": "MERA: A Comprehensive LLM Evaluation in Russian", "authors": "Alena Fenogenova, Artem Chervyakov, Nikita Martynov, Anastasia Kozlova, M. Tikhonova, Albina Akhmetgareeva, Anton A. Emelyanov, Denis Shevelev, Pavel Lebedev, Leonid S. Sinev, Ulyana Isaeva, Katerina Kolomeytseva, Daniil Moskovskiy, Elizaveta Goncharova, Nikita Savushkin, Polina Mikhailova, Denis Dimitrov, Alexander Panchenko, Sergey Markov", "venue": "Annual Meeting of the Association for Computational Linguistics", "citation_count": 12, "influential_citation_count": 1, "abstract": "Over the past few years, one of the most notable advancements in AI research has been in foundation models (FMs), headlined by the rise of language models (LMs). As the models' size increases, LMs demonstrate enhancements in measurable aspects and the development of new qualitative features. However, despite researchers' attention and the rapid growth in LM application, the capabilities, limitations, and associated risks still need to be better understood. To address these issues, we introduce an open Multimodal Evaluation of Russian-language Architectures (MERA), a new instruction benchmark for evaluating foundation models oriented towards the Russian language. The benchmark encompasses 21 evaluation tasks for generative models in 11 skill domains and is designed as a black-box test to ensure the exclusion of data leakage. The paper introduces a methodology to evaluate FMs and LMs in zero- and few-shot fixed instruction settings that can be extended to other modalities. We propose an evaluation methodology, an open-source code base for the MERA assessment, and a leaderboard with a submission system. We evaluate open LMs as baselines and find that they are still far behind the human level. We publicly release MERA to guide forthcoming research, anticipate groundbreaking model features, standardize the evaluation procedure, and address potential societal drawbacks.", "pdf_url": "https://arxiv.org/pdf/2401.04531.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-01-09_MERA__A_Comprehensive_LLM_Evaluation_in_Russian.pdf", "markdown_path": "data/semantic/markdown_files/2024-01-09_MERA__A_Comprehensive_LLM_Evaluation_in_Russian.md"}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "8279e3f5e6bb900b7fd3d001416203aea1f49673", "publication_date": "2024-11-18", "title": "Text-Guided Unknown Pseudo-Labeling for Open-World Object Detection", "authors": "Xuefei Wang, Dong Xu", "venue": "Electronics", "citation_count": 0, "influential_citation_count": 0, "abstract": "Open-world object detection (OWOD) focuses on training models with partially known class labels, enabling the detection of objects from known classes while concurrently identifying objects from unknown classes. Current models often perform suboptimally in generating pseudo-labels for unknown objects based on objectness scores due to inherent biases towards known classes. To address this issue, we propose a cross-modal learning model named Text-Guided Unknown Pseudo-Labeling for Open-world Object Detection(TGOOD) building on the Featurized Query R-CNN (FQR-CNN) framework. Specifically, we introduce a module called Similarity-Random-Similarity (SRS) to guide the model in detecting unknown objects during training. Additionally, we replace the one-to-one label assignment strategy in FQR-CNN with a one-to-many (OTM) label assignment strategy to provide more supervisory information during training. Moreover, we propose the ROI features Refinement Module (RRM) to enhance the discriminability of all objects. Experimental evaluations on the PASCAL VOC, MS-COCO, and COCO-O benchmarks demonstrate TGOOD\u2019s superior open-world detection capability.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "f06c4e1be96489c58bbf441ab5e04b5566b47276", "publication_date": "2024", "title": "Open-world barely-supervised learning via augmented pseudo labels", "authors": "Zhongnian Li, Yanyan Ding, Meng Wei, Xinzheng Xu", "venue": "Electronic Research Archive", "citation_count": 1, "influential_citation_count": 0, "abstract": "Open-world semi-supervised learning (OWSSL) has received significant attention since it addresses the issue of unlabeled data containing classes not present in the labeled data. Unfortunately, existing OWSSL methods still rely on a large amount of labeled data from seen classes, overlooking the reality that a substantial amount of labels is difficult to obtain in real scenarios. In this paper, we explored a new setting called open-world barely-supervised learning (OWBSL), where only a single label was provided for each seen class, greatly reducing labeling costs. To tackle the OWBSL task, we proposed a novel framework that leveraged augmented pseudo-labels generated for the unlabeled data. Specifically, we first generated initial pseudo-labels for the unlabeled data using visual-language models. Subsequently, to ensure that the pseudo-labels remained reliable while being updated during model training, we enhanced them using predictions from weak data augmentation. This way, we obtained the augmented pseudo-labels. Additionally, to fully exploit the information from unlabeled data, we incorporated consistency regularization based on strong and weak augmentations into our framework. Our experimental results on multiple benchmark datasets demonstrated the effectiveness of our method.", "pdf_url": null, "pdf_filepath": "", "markdown_path": ""}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "eb9fbefd5d71ab2d6522a8f51e9189ad082621f1", "publication_date": "2024-06-03", "title": "Advancing Weakly-Supervised Audio-Visual Video Parsing via Segment-wise Pseudo Labeling", "authors": "Jinxing Zhou, Dan Guo, Yiran Zhong, Meng Wang", "venue": "International Journal of Computer Vision", "citation_count": 19, "influential_citation_count": 0, "abstract": "The Audio-Visual Video Parsing task aims to identify and temporally localize the events that occur in either or both the audio and visual streams of audible videos. It often performs in a weakly-supervised manner, where only video event labels are provided, \\ie, the modalities and the timestamps of the labels are unknown. Due to the lack of densely annotated labels, recent work attempts to leverage pseudo labels to enrich the supervision. A commonly used strategy is to generate pseudo labels by categorizing the known video event labels for each modality. However, the labels are still confined to the video level, and the temporal boundaries of events remain unlabeled. In this paper, we propose a new pseudo label generation strategy that can explicitly assign labels to each video segment by utilizing prior knowledge learned from the open world. Specifically, we exploit the large-scale pretrained models, namely CLIP and CLAP, to estimate the events in each video segment and generate segment-level visual and audio pseudo labels, respectively. We then propose a new loss function to exploit these pseudo labels by taking into account their category-richness and segment-richness. A label denoising strategy is also adopted to further improve the visual pseudo labels by flipping them whenever abnormally large forward losses occur. We perform extensive experiments on the LLP dataset and demonstrate the effectiveness of each proposed design and we achieve state-of-the-art video parsing performance on all types of event parsing, \\ie, audio event, visual event, and audio-visual event. We also examine the proposed pseudo label generation strategy on a relevant weakly-supervised audio-visual event localization task and the experimental results again verify the benefits and generalization of our method.", "pdf_url": "https://arxiv.org/pdf/2406.00919.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-06-03_Advancing_Weakly-Supervised_Audio-Visual_Video_Parsing_via_Segment-wise_Pseudo_Labeling.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-03_Advancing_Weakly-Supervised_Audio-Visual_Video_Parsing_via_Segment-wise_Pseudo_Labeling.md"}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "6b347356468f5e8b6da338e59931701454e7216b", "publication_date": "2024-03-12", "title": "Open-Vocabulary Scene Text Recognition via Pseudo-Image Labeling and Margin Loss", "authors": "Xuhua Ren, Hengcan Shi, Jin Li", "venue": "arXiv.org", "citation_count": 0, "influential_citation_count": 0, "abstract": "Scene text recognition is an important and challenging task in computer vision. However, most prior works focus on recognizing pre-defined words, while there are various out-of-vocabulary (OOV) words in real-world applications. In this paper, we propose a novel open-vocabulary text recognition framework, Pseudo-OCR, to recognize OOV words. The key challenge in this task is the lack of OOV training data. To solve this problem, we first propose a pseudo label generation module that leverages character detection and image inpainting to produce substantial pseudo OOV training data from real-world images. Unlike previous synthetic data, our pseudo OOV data contains real characters and backgrounds to simulate real-world applications. Secondly, to reduce noises in pseudo data, we present a semantic checking mechanism to filter semantically meaningful data. Thirdly, we introduce a quality-aware margin loss to boost the training with pseudo data. Our loss includes a margin-based part to enhance the classification ability, and a quality-aware part to penalize low-quality samples in both real and pseudo data. Extensive experiments demonstrate that our approach outperforms the state-of-the-art on eight datasets and achieves the first rank in the ICDAR2022 challenge.", "pdf_url": "https://arxiv.org/pdf/2403.07518.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-12_Open-Vocabulary_Scene_Text_Recognition_via_Pseudo-Image_Labeling_and_Margin_Loss.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-12_Open-Vocabulary_Scene_Text_Recognition_via_Pseudo-Image_Labeling_and_Margin_Loss.md"}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "1439e2fda31ccde024d7e871a3ddbee8953f6807", "publication_date": "2024-04-01", "title": "PDF: A Probability-Driven Framework for Open World 3D Point Cloud Semantic Segmentation", "authors": "Jinfeng Xu, Siyuan Yang, Xianzhi Li, Yuan Tang, Yixue Hao, Long Hu, Min Chen", "venue": "Computer Vision and Pattern Recognition", "citation_count": 3, "influential_citation_count": 0, "abstract": "Existing point cloud semantic segmentation networks cannot identify unknown classes and update their knowledge, due to a closed-set and static perspective of the real world, which would induce the intelligent agent to make bad decisions. To address this problem, we propose a Probability-Driven Framework (PDF)11Code available at: https://github.com/JinfengX/PointCloudPDF. for open world semantic segmentation that includes (i) a lightweight U-decoder branch to identify unknown classes by estimating the uncertainties, (ii) a flexible pseudo-labeling scheme to supply geometry features along with probability distribution features of unknown classes by generating pseudo labels, and (iii) an incremental knowledge distillation strategy to incorporate novel classes into the existing knowledge base gradually. Our framework enables the model to behave like human beings, which could recognize unknown objects and incrementally learn them with the corresponding knowledge. Experimental results on the S3DIS and ScanNetv2 datasets demonstrate that the proposed PDF outperforms other methods by a large margin in both important tasks of open world semantic segmentation.", "pdf_url": "https://arxiv.org/pdf/2404.00979.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-04-01_PDF__A_Probability-Driven_Framework_for_Open_World_3D_Point_Cloud_Semantic_Segmentation.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-01_PDF__A_Probability-Driven_Framework_for_Open_World_3D_Point_Cloud_Semantic_Segmentation.md"}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "7a4e507c90c1c38ba5549ea9d9c0243cc850ea08", "publication_date": "2024-03-29", "title": "Beyond the Known: Novel Class Discovery for Open-world Graph Learning", "authors": "Yucheng Jin, Yun Xiong, Juncheng Fang, Xixi Wu, Dongxiao He, Xing Jia, Bingchen Zhao, Philip S. Yu", "venue": "International Conference on Database Systems for Advanced Applications", "citation_count": 1, "influential_citation_count": 0, "abstract": "Node classification on graphs is of great importance in many applications. Due to the limited labeling capability and evolution in real-world open scenarios, novel classes can emerge on unlabeled testing nodes. However, little attention has been paid to novel class discovery on graphs. Discovering novel classes is challenging as novel and known class nodes are correlated by edges, which makes their representations indistinguishable when applying message passing GNNs. Furthermore, the novel classes lack labeling information to guide the learning process. In this paper, we propose a novel method Open-world gRAph neuraL network (ORAL) to tackle these challenges. ORAL first detects correlations between classes through semi-supervised prototypical learning. Inter-class correlations are subsequently eliminated by the prototypical attention network, leading to distinctive representations for different classes. Furthermore, to fully explore multi-scale graph features for alleviating label deficiencies, ORAL generates pseudo-labels by aligning and ensembling label estimations from multiple stacked prototypical attention networks. Extensive experiments on several benchmark datasets show the effectiveness of our proposed method.", "pdf_url": "https://arxiv.org/pdf/2403.19907.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-03-29_Beyond_the_Known__Novel_Class_Discovery_for_Open-world_Graph_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-29_Beyond_the_Known__Novel_Class_Discovery_for_Open-world_Graph_Learning.md"}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "d33e9727a5a6343b04fbdacb1dff6fce0870ec54", "publication_date": "2024-12-21", "title": "Uncertainty Quantification in Continual Open-World Learning", "authors": "Amanda Rios, I. Ndiour, Parual Datta, Jaroslaw Sydir, Omesh Tickoo, Nilesh A. Ahuja", "venue": "arXiv.org", "citation_count": 0, "influential_citation_count": 0, "abstract": "AI deployed in the real-world should be capable of autonomously adapting to novelties encountered after deployment. Yet, in the field of continual learning, the reliance on novelty and labeling oracles is commonplace albeit unrealistic. This paper addresses a challenging and under-explored problem: a deployed AI agent that continuously encounters unlabeled data - which may include both unseen samples of known classes and samples from novel (unknown) classes - and must adapt to it continuously. To tackle this challenge, we propose our method COUQ\"Continual Open-world Uncertainty Quantification\", an iterative uncertainty estimation algorithm tailored for learning in generalized continual open-world multi-class settings. We rigorously apply and evaluate COUQ on key sub-tasks in the Continual Open-World: continual novelty detection, uncertainty guided active learning, and uncertainty guided pseudo-labeling for semi-supervised CL. We demonstrate the effectiveness of our method across multiple datasets, ablations, backbones and performance superior to state-of-the-art.", "pdf_url": "https://arxiv.org/pdf/2412.16409.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-12-21_Uncertainty_Quantification_in_Continual_Open-World_Learning.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-21_Uncertainty_Quantification_in_Continual_Open-World_Learning.md"}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "758e8513f04172a541570ecd05ead8a934795f5d", "publication_date": "2024-06-14", "title": "POWN: Prototypical Open-World Node Classification", "authors": "Marcel Hoffmann, Lukas Galke, A. Scherp", "venue": "CoLLAs", "citation_count": 0, "influential_citation_count": 0, "abstract": "We consider the problem of \\textit{true} open-world semi-supervised node classification, in which nodes in a graph either belong to known or new classes, with the latter not present during training. Existing methods detect and reject new classes but fail to distinguish between different new classes. We adapt existing methods and show they do not solve the problem sufficiently. We introduce a novel end-to-end approach for classification into known classes and new classes based on class prototypes, which we call Prototypical Open-World Learning for Node Classification (POWN). Our method combines graph semi-supervised learning, self-supervised learning, and pseudo-labeling to learn prototype representations of new classes in a zero-shot way. In contrast to existing solutions from the vision domain, POWN does not require data augmentation techniques for node classification. Experiments on benchmark datasets demonstrate the effectiveness of POWN, where it outperforms baselines by up to $20\\%$ accuracy on the small and up to $30\\%$ on the large datasets. Source code is available at https://github.com/Bobowner/POWN.", "pdf_url": "https://arxiv.org/pdf/2406.09926.pdf", "pdf_filepath": "data/semantic/pdf_files/2024-06-14_POWN__Prototypical_Open-World_Node_Classification.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-14_POWN__Prototypical_Open-World_Node_Classification.md"}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "fedd4914d6283a3e4f629eac56e32857268cec46", "publication_date": "2023-08-31", "title": "Unsupervised Recognition of Unknown Objects for Open-World Object Detection", "authors": "Ru Fang, Guansong Pang, Lei Zhou, Xiaolong Bai, Jingyi Zheng", "venue": "arXiv.org", "citation_count": 6, "influential_citation_count": 2, "abstract": "Open-World Object Detection (OWOD) extends object detection problem to a realistic and dynamic scenario, where a detection model is required to be capable of detecting both known and unknown objects and incrementally learning newly introduced knowledge. Current OWOD models, such as ORE and OW-DETR, focus on pseudo-labeling regions with high objectness scores as unknowns, whose performance relies heavily on the supervision of known objects. While they can detect the unknowns that exhibit similar features to the known objects, they suffer from a severe label bias problem that they tend to detect all regions (including unknown object regions) that are dissimilar to the known objects as part of the background. To eliminate the label bias, this paper proposes a novel approach that learns an unsupervised discriminative model to recognize true unknown objects from raw pseudo labels generated by unsupervised region proposal methods. The resulting model can be further refined by a classification-free self-training method which iteratively extends pseudo unknown objects to the unlabeled regions. Experimental results show that our method 1) significantly outperforms the prior SOTA in detecting unknown objects while maintaining competitive performance of detecting known object classes on the MS COCO dataset, and 2) achieves better generalization ability on the LVIS and Objects365 datasets.", "pdf_url": "https://arxiv.org/pdf/2308.16527.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-08-31_Unsupervised_Recognition_of_Unknown_Objects_for_Open-World_Object_Detection.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-31_Unsupervised_Recognition_of_Unknown_Objects_for_Open-World_Object_Detection.md"}
{"query_date": "2025-06-13", "query_keyword": "open-world Pseudo-Labeling", "paper_id": "b60fcdb171b448bb9ac1bb6acc7c9aa2df6002e2", "publication_date": "2023-09-25", "title": "3D Indoor Instance Segmentation in an Open-World", "authors": "Mohamed El Amine Boudjoghra, Salwa K. Al Khatib, Jean Lahoud, Hisham Cholakkal, R. Anwer, Salman A. Khan, F. Khan", "venue": "Neural Information Processing Systems", "citation_count": 6, "influential_citation_count": 0, "abstract": "Existing 3D instance segmentation methods typically assume that all semantic classes to be segmented would be available during training and only seen categories are segmented at inference. We argue that such a closed-world assumption is restrictive and explore for the first time 3D indoor instance segmentation in an open-world setting, where the model is allowed to distinguish a set of known classes as well as identify an unknown object as unknown and then later incrementally learning the semantic category of the unknown when the corresponding category labels are available. To this end, we introduce an open-world 3D indoor instance segmentation method, where an auto-labeling scheme is employed to produce pseudo-labels during training and induce separation to separate known and unknown category labels. We further improve the pseudo-labels quality at inference by adjusting the unknown class probability based on the objectness score distribution. We also introduce carefully curated open-world splits leveraging realistic scenarios based on inherent object distribution, region-based indoor scene exploration and randomness aspect of open-world classes. Extensive experiments reveal the efficacy of the proposed contributions leading to promising open-world 3D instance segmentation performance.", "pdf_url": "https://arxiv.org/pdf/2309.14338.pdf", "pdf_filepath": "data/semantic/pdf_files/2023-09-25_3D_Indoor_Instance_Segmentation_in_an_Open-World.pdf", "markdown_path": "data/semantic/markdown_files/2023-09-25_3D_Indoor_Instance_Segmentation_in_an_Open-World.md"}
