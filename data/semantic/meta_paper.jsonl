{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "8ba57771dd6345821a0cbe83c4c7eb50f66b7b65", "publication_date": "2024-03-02", "title": "AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks", "authors": "Yifan Zeng, Yiran Wu, Xiao Zhang, Huazheng Wang, Qingyun Wu", "venue": "arXiv.org", "citation_count": 71, "influential_citation_count": 4, "abstract": "Despite extensive pre-training in moral alignment to prevent generating harmful information, large language models (LLMs) remain vulnerable to jailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense framework that filters harmful responses from LLMs. With the response-filtering mechanism, our framework is robust against different jailbreak attack prompts, and can be used to defend different victim models. AutoDefense assigns different roles to LLM agents and employs them to complete the defense task collaboratively. The division in tasks enhances the overall instruction-following of LLMs and enables the integration of other defense components as tools. With AutoDefense, small open-source LMs can serve as agents and defend larger models against jailbreak attacks. Our experiments show that AutoDefense can effectively defense against different jailbreak attacks, while maintaining the performance at normal user request. For example, we reduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using LLaMA-2-13b with a 3-agent system. Our code and data are publicly available at https://github.com/XHMY/AutoDefense.", "pdf_url": "https://arxiv.org/pdf/2403.04783.pdf", "pdf_filename": "2024-03-02_AutoDefense__Multi-Agent_LLM_Defense_against_Jailb.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-02_AutoDefense__Multi-Agent_LLM_Defense_against_Jailb.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "6e212b711e334ae4df26bbd57dc8eab925f98474", "publication_date": "2024-12-02", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "authors": "S. Motwani, Chandler Smith, Rocktim Jyoti Das, Markian Rybchuk, Philip Torr, Ivan Laptev, Fabio Pizzati, Ronald Clark, Christian Schr\u00f6der de Witt", "venue": "arXiv.org", "citation_count": 13, "influential_citation_count": 1, "abstract": "Large Language Models (LLMs) often produce answers with a single chain-of-thought, which restricts their ability to explore reasoning paths or self-correct flawed outputs in complex tasks. In this paper, we introduce MALT (Multi-Agent LLM Training), a novel post-training strategy that divides the reasoning process into generation, verification, and refinement steps using a sequential pipeline of heterogeneous agents. During data generation, each agent is repeatedly sampled to form a multi-agent search tree, where final outputs are graded against ground-truth data. We then apply value iteration to propagate reward signals back to each role-conditioned model, automatically producing multi-agent post-training data without human or teacher-model supervision. Our off-policy approach allows each agent to specialize by learning from correct and incorrect trajectories, ultimately improving the end-to-end reasoning chain. On MATH, GSM8K, and CSQA, MALT surpasses the same baseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40% respectively, making it an important advance towards multi-agent cooperative training.", "pdf_url": "https://arxiv.org/pdf/2412.01928.pdf", "pdf_filename": "2024-12-02_MALT__Improving_Reasoning_with_Multi-Agent_LLM_Tra.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-02_MALT__Improving_Reasoning_with_Multi-Agent_LLM_Tra.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "efde8940a0b924e93d35184c4a1e8f9670b94fe7", "publication_date": "2024-10-03", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "authors": "Patara Trirat, Wonyong Jeong, Sung Ju Hwang", "venue": "arXiv.org", "citation_count": 15, "influential_citation_count": 0, "abstract": "Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposes AutoML-Agent, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment. AutoML-Agent takes user's task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed results and guide the code generation LLM in implementing successful solutions. Extensive experiments on seven downstream tasks using fourteen datasets show that AutoML-Agent achieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.", "pdf_url": "https://arxiv.org/pdf/2410.02958.pdf", "pdf_filename": "2024-10-03_AutoML-Agent__A_Multi-Agent_LLM_Framework_for_Full.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_AutoML-Agent__A_Multi-Agent_LLM_Framework_for_Full.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "b92ec2ef54e4df2d08cbc66e4dda3e37b6362dbd", "publication_date": "2024-10-03", "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions", "authors": "Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-655, Chris Bamford, Devendra Singh, Diego Chaplot, laume Lample, L\u00e9lio Lucile Saulnier, Renard Lavaud, M. Lachaux, Pierre Stock, Teven Le Scao, Jerry Kang, Mark W. Bennett, Devon Carbado, Pam Casey, P. Liang, Chiyu Wu, Louis-philippe Morency, Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, S. Welleck, Amir Yazdan Bakhsh, ing Bao, Mo Bavarian, J. Belgum, Ir-wan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Made-laine Boyd, Anna-Luisa Brakman, Greg Brock-724 man, Tim Brooks, M. Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Su-Hong Chen, Ruby Chen, Jason Chen, Mark Chen, Benjamin Chess, Chester Cho, Hyung Casey Chu, Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Tarun Goel, Gabriel Gogineni, Rapha Goh, Jonathan Gontijo-738 Lopes, Morgan Gordon, Scott Grafstein, Ryan Gray, Joshua Greene, Shixiang Shane Gross, Yufei Gu, Chris Guo, Jesse Hallacy, Jeff Han, Harris Yuchen, Mike He, Johannes Heaton, C. Heidecke, Alan Hesse, W. Hickey, Peter Hickey, Hoeschele Brandon, Kenny Houghton, Shengli Hsu, Xin Hu, Joost Hu, Shantanu Huizinga, Shawn Jain, Jain Joanne, Angela Jang, Roger Jiang, Haozhun Jiang, Denny Jin, Shino Jin, Billie Jomoto, Hee-woo Jonn, Tomer Jun, \u0141ukasz Kaftan, Ali Kaiser, Ingmar Ka-748 mali, Kanitscheider, Nitish Shirish, Keskar Tabarak, Logan Khan, J. Kilpatrick, Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirch-751 ner, J. Kiros, Matthew Knight, Daniel Kokotajlo, \u0141ukasz Kondraciuk, Andrew Kondrich, Aris Kon-753 stantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Chak Daniel Levy, Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Ma-teusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, A. Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, S. McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, An-drey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel P. Mossing, Tong Mu, Mira Murati, O. Murk, David M\u00e9ly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Ouyang Long, Cullen O'Keefe, J. Pachocki, A. Paino, Joe Palermo, Ashley Pantuliano, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-779 der, Mario D. Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qim-ing Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Tianhao Shengjia Zhao, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Sandhini Agarwal, Alex Gray, Jacob Hilton, Fraser Kelton, Luke Miller, Amanda Askell, P. Welinder, Paul F. Christiano, Joon Sung Park, Joseph O\u2019Brien, Carrie J. Cai, Ringel Morris, Percy Liang, Michael S. Bern-814, Alec Radford, Karthik Narasimhan, Tim Salimans, Rachel Rudinger, Jason Naradowsky, Brian Leonard, Nisan Stiennon, Ryan Ziegler, Chelsea Lowe, Alec Voss, Radford, Dario Amodei, Christiano. 2020. Learn-842, Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jie Zhao, Diba Mirza, Kai-Wei Belding, Chang William, Yang Wang, Yixin Wan, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, Nanyun Peng, \u201ckelly", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 11, "influential_citation_count": 0, "abstract": "As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain insights into various societal aspects, it is essential to mitigate these biases. To that end, our study investigates the presence of implicit gender biases in multi-agent LLM interactions and proposes two strategies to mitigate these biases. We begin by creating a dataset of scenarios where implicit gender biases might arise, and subsequently develop a metric to assess the presence of biases. Our empirical analysis reveals that LLMs generate outputs characterized by strong implicit bias associations (>= 50\\% of the time). Furthermore, these biases tend to escalate following multi-agent interactions. To mitigate them, we propose two strategies: self-reflection with in-context examples (ICE); and supervised fine-tuning. Our research demonstrates that both methods effectively mitigate implicit biases, with the ensemble of fine-tuning and self-reflection proving to be the most successful.", "pdf_url": "https://arxiv.org/pdf/2410.02584.pdf", "pdf_filename": "2024-10-03_Towards_Implicit_Bias_Detection_and_Mitigation_in_.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_Towards_Implicit_Bias_Detection_and_Mitigation_in_.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "2c797fb1f140f254d4bcdbfadcb34e246dca6564", "publication_date": "2024", "title": "Conformity, Confabulation, and Impersonation: Persona Inconstancy in Multi-Agent LLM Collaboration", "authors": "Razan Baltaji, Babak Hemmatian, L. Varshney", "venue": "C3NLP", "citation_count": 8, "influential_citation_count": 1, "abstract": "This study explores the sources of instability in maintaining cultural personas and opinions within multi-agent LLM systems. Drawing on simulations of inter-cultural collaboration and debate, we analyze agents\u2019 pre- and post-discussion private responses alongside chat transcripts to assess the stability of cultural personas and the impact of opinion diversity on group outcomes. Our findings suggest that multi-agent discussions can encourage collective decisions that reflect diverse perspectives, yet this benefit is tempered by the agents\u2019 susceptibility to conformity due to perceived peer pressure and challenges in maintaining consistent personas and opinions. Counterintuitively, instructions that encourage debate in support of one\u2019s opinions increase the rate of instability. Without addressing the factors we identify, the full potential of multi-agent frameworks for producing more culturally diverse AI outputs will remain untapped.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "c83b6a023a5c5ec71b44920a41b41fc007266c44", "publication_date": "2025-03-17", "title": "Why Do Multi-Agent LLM Systems Fail?", "authors": "Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, K. Ramchandran, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica", "venue": "arXiv.org", "citation_count": 28, "influential_citation_count": 4, "abstract": "Despite growing enthusiasm for Multi-Agent LLM Systems (MAS), their performance gains on popular benchmarks often remain minimal compared with single-agent frameworks. This gap highlights the need to systematically analyze the challenges hindering MAS effectiveness. We present MAST (Multi-Agent System Failure Taxonomy), the first empirically grounded taxonomy designed to understand MAS failures. We analyze seven popular MAS frameworks across over 200 tasks, involving six expert human annotators. Through this process, we identify 14 unique failure modes, organized into 3 overarching categories, (i) specification issues, (ii) inter-agent misalignment, and (iii) task verification. MAST emerges iteratively from rigorous inter-annotator agreement studies, achieving a Cohen's Kappa score of 0.88. To support scalable evaluation, we develop a validated LLM-as-a-Judge pipeline integrated with MAST. We leverage two case studies to demonstrate MAST's practical utility in analyzing failures and guiding MAS development. Our findings reveal that identified failures require more complex solutions, highlighting a clear roadmap for future research. We open source our comprehensive dataset and LLM annotator to facilitate further development of MAS.", "pdf_url": "https://arxiv.org/pdf/2503.13657.pdf", "pdf_filename": "2025-03-17_Why_Do_Multi-Agent_LLM_Systems_Fail_.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-17_Why_Do_Multi-Agent_LLM_Systems_Fail_.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "d0aab1a022d8ebe3afc83f3c21a52e50e5759494", "publication_date": "2024-12-22", "title": "KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis", "authors": "Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio", "venue": "arXiv.org", "citation_count": 9, "influential_citation_count": 0, "abstract": "Integrating Large Language Models (LLMs) in healthcare diagnosis demands systematic frameworks that can handle complex medical scenarios while maintaining specialized expertise. We present KG4Diagnosis, a novel hierarchical multi-agent framework that combines LLMs with automated knowledge graph construction, encompassing 362 common diseases across medical specialties. Our framework mirrors real-world medical systems through a two-tier architecture: a general practitioner (GP) agent for initial assessment and triage, coordinating with specialized agents for in-depth diagnosis in specific domains. The core innovation lies in our end-to-end knowledge graph generation methodology, incorporating: (1) semantic-driven entity and relation extraction optimized for medical terminology, (2) multi-dimensional decision relationship reconstruction from unstructured medical texts, and (3) human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an extensible foundation for specialized medical diagnosis systems, with capabilities to incorporate new diseases and medical knowledge. The framework's modular design enables seamless integration of domain-specific enhancements, making it valuable for developing targeted medical diagnosis systems. We provide architectural guidelines and protocols to facilitate adoption across medical contexts.", "pdf_url": "https://arxiv.org/pdf/2412.16833.pdf", "pdf_filename": "2024-12-22_KG4Diagnosis__A_Hierarchical_Multi-Agent_LLM_Frame.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-22_KG4Diagnosis__A_Hierarchical_Multi-Agent_LLM_Frame.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "1343c620c0625c95e32d9735ece30ff0a702a879", "publication_date": "2024-12-29", "title": "Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning", "authors": "Hang Ni, Yuzhi Wang, Hao Liu", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.", "pdf_url": "https://arxiv.org/pdf/2412.20505.pdf", "pdf_filename": "2024-12-29_Planning__Living_and_Judging__A_Multi-agent_LLM-ba.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-29_Planning__Living_and_Judging__A_Multi-agent_LLM-ba.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "6b9e4b6803b8eb8bbe3b72c14fce90a853311503", "publication_date": "2024", "title": "Synthetic Arabic Medical Dialogues Using Advanced Multi-Agent LLM Techniques", "authors": "Mariam Almutairi, Lulwah Alkulaib, M. Aktas, Sara A. Alsalamah, Chang-Tien Lu", "venue": "ARABICNLP", "citation_count": 3, "influential_citation_count": 0, "abstract": "The increasing use of artificial intelligence in healthcare requires robust datasets for training and validation, particularly in the domain of medical conversations. However, the creation and accessibility of such datasets in Arabic face significant challenges, especially due to the sensitivity and privacy concerns that are associated with medical conversations. These conversations are rarely recorded or preserved, making the availability of comprehensive Arabic medical dialogue datasets scarce. This limitation slows down not only the development of effective natural language processing models but also restricts the opportunity for open comparison of algorithms and their outcomes. Recent advancements in large language models (LLMs) like ChatGPT, GPT-4, Gemini-pro, and Claude-3 show promising capabilities in generating synthetic data. To address this gap, we introduce a novel Multi-Agent LLM approach capable of generating synthetic Arabic medical dialogues from patient notes, regardless of the original language. This development presents a significant step towards overcoming the barriers in dataset availability, enhancing the potential for broader research and application in AI-driven medical dialogue systems.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "6130bafdaa0e4c22ffc7844ba2bd4e5cf8ba5451", "publication_date": "2024-11-22", "title": "Regulator-Manufacturer AI Agents Modeling: Mathematical Feedback-Driven Multi-Agent LLM Framework", "authors": "Yu Han, Zekun Guo", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "The increasing complexity of regulatory updates from global authorities presents significant challenges for medical device manufacturers, necessitating agile strategies to sustain compliance and maintain market access. Concurrently, regulatory bodies must effectively monitor manufacturers' responses and develop strategic surveillance plans. This study employs a multi-agent modeling approach, enhanced with Large Language Models (LLMs), to simulate regulatory dynamics and examine the adaptive behaviors of key actors, including regulatory bodies, manufacturers, and competitors. These agents operate within a simulated environment governed by regulatory flow theory, capturing the impacts of regulatory changes on compliance decisions, market adaptation, and innovation strategies. Our findings illuminate the influence of regulatory shifts on industry behaviour and identify strategic opportunities for improving regulatory practices, optimizing compliance, and fostering innovation. By leveraging the integration of multi-agent systems and LLMs, this research provides a novel perspective and offers actionable insights for stakeholders navigating the evolving regulatory landscape of the medical device industry.", "pdf_url": "https://arxiv.org/pdf/2411.15356.pdf", "pdf_filename": "2024-11-22_Regulator-Manufacturer_AI_Agents_Modeling__Mathema.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-22_Regulator-Manufacturer_AI_Agents_Modeling__Mathema.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "8e39c6435cd4b030c32065a72ef4d97358323852", "publication_date": "2024-07-30", "title": "Forensic Analysis of Artifacts from Microsoft's Multi-Agent LLM Platform AutoGen", "authors": "Clinton Walker, Taha Gharaibeh, Ruba Alsmadi, C. Hall, Ibrahim M. Baggili", "venue": "ARES", "citation_count": 2, "influential_citation_count": 0, "abstract": "Innovations in technology bring new challenges that need to be addressed, especially in the field of technical artifact discovery and analysis that enables digital forensic practitioners. Digital forensic analysis of these innovations is a constant challenge for digital investigators. In the rapidly evolving landscape of Artificial Intelligence (AI), keeping up with the digital forensic analysis of each new tool is a difficult task. New, advanced Large Language Model (LLM)s can produce human-like artifacts because of their complex textual processing capabilities. One of the newest innovations is a multi-agent Large Language Model (LLM) framework by Microsoft called AutoGen. AutoGen enables the creation of a team of specialist Large Language Model (LLM)-backed agents where the agents \"chat\" with each other to plan, iterate, and determine when a given task is complete. Typically one of the agents represents the human user while the other agents work autonomously after the human gives each agent a responsibility on the team. Thus, from a digital forensics perspective, it is necessary to determine which artifacts are created by the human user and which artifacts are created by the autonomous agents. Analysis in this work indicates that the current implementation of AutoGen has little in artifacts for attribution outside of particular memory artifacts, yet has strong indicators of usage in disk and network artifacts. Our research provides the initial account on the digital artifacts of the Large Language Model (LLM) technology AutoGen and first artifact examination for a Large Language Model (LLM) framework.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "03702ca194d23145b9b9b2ed2f31145e08366436", "publication_date": "2024-10-30", "title": "ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration", "authors": "Andrew Estornell, Jean-Fran\u00e7ois Ton, Yuanshun Yao, Yang Liu", "venue": "International Conference on Learning Representations", "citation_count": 2, "influential_citation_count": 0, "abstract": "Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models. While these paradigms show promise in improving model efficacy, most works in this area treat collaboration as an emergent behavior, rather than a learned behavior. In doing so, current multi-agent frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. To address this limitation, we propose ACC-Collab, an Actor-Critic based learning framework to produce a two-agent team (an actor-agent and a critic-agent) specialized in collaboration. We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.", "pdf_url": "https://arxiv.org/pdf/2411.00053.pdf", "pdf_filename": "2024-10-30_ACC-Collab__An_Actor-Critic_Approach_to_Multi-Agen.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-30_ACC-Collab__An_Actor-Critic_Approach_to_Multi-Agen.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "0fcf26cf17ecc9e2cc2aea069c6f8a3eccd375a4", "publication_date": "2025-03-31", "title": "Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks", "authors": "Rana Muhammad Shahroz Khan, Zhen Tan, Sukwon Yun, Charles Flemming, Tianlong Chen", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 1, "abstract": "Most discussions about Large Language Model (LLM) safety have focused on single-agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and decentralized reasoning. In this work, we innovatively focus on attacking pragmatic systems that have constrains such as limited token bandwidth, latency between message delivery, and defense mechanisms. We design a $\\textit{permutation-invariant adversarial attack}$ that optimizes prompt distribution across latency and bandwidth-constraint network topologies to bypass distributed safety mechanisms within the system. Formulating the attack path as a problem of $\\textit{maximum-flow minimum-cost}$, coupled with the novel $\\textit{Permutation-Invariant Evasion Loss (PIEL)}$, we leverage graph-based optimization to maximize attack success rate while minimizing detection risk. Evaluating across models including $\\texttt{Llama}$, $\\texttt{Mistral}$, $\\texttt{Gemma}$, $\\texttt{DeepSeek}$ and other variants on various datasets like $\\texttt{JailBreakBench}$ and $\\texttt{AdversarialBench}$, our method outperforms conventional attacks by up to $7\\times$, exposing critical vulnerabilities in multi-agent systems. Moreover, we demonstrate that existing defenses, including variants of $\\texttt{Llama-Guard}$ and $\\texttt{PromptGuard}$, fail to prohibit our attack, emphasizing the urgent need for multi-agent specific safety mechanisms.", "pdf_url": "https://arxiv.org/pdf/2504.00218.pdf", "pdf_filename": "2025-03-31_Agents_Under_Siege__Breaking_Pragmatic_Multi-Agent.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-31_Agents_Under_Siege__Breaking_Pragmatic_Multi-Agent.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "a9c0d81fcf801fa689e04438289e09098659c1dd", "publication_date": "2025-04-24", "title": "A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation", "authors": "Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, J. Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. R. Alexander, Robert B. Ross, Yan Feng, L. Levy, Weijie J. Su, C. J. Taylor", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.", "pdf_url": "https://arxiv.org/pdf/2504.17200.pdf", "pdf_filename": "2025-04-24_A_RAG-Based_Multi-Agent_LLM_System_for_Natural_Haz.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-24_A_RAG-Based_Multi-Agent_LLM_System_for_Natural_Haz.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "5bd02af3887d41a79aba5c5ac614bf7d980d0519", "publication_date": "2024-11-05", "title": "SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction", "authors": "Shlomo Neuberger, Niv Eckhaus, Uri Berger, Amir Taubenfeld, Gabriel Stanovsky, Ariel Goldstein", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Many human interactions, such as political debates, are carried out in group settings, where there are arbitrarily many participants, each with different views and agendas. To explore such complex social settings, we present SAUCE: a customizable Python platform, allowing researchers to plug-and-play various LLMs participating in discussions on any topic chosen by the user. Our platform takes care of instantiating the models, scheduling their responses, managing the discussion history, and producing a comprehensive output log, all customizable through configuration files, requiring little to no coding skills. A novel feature of SAUCE is our asynchronous communication feature, where models decide when to speak in addition to what to say, thus modeling an important facet of human communication. We show SAUCE's attractiveness in two initial experiments, and invite the community to use it in simulating various group simulations.", "pdf_url": "https://arxiv.org/pdf/2411.03397.pdf", "pdf_filename": "2024-11-05_SAUCE__Synchronous_and_Asynchronous_User-Customiza.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-05_SAUCE__Synchronous_and_Asynchronous_User-Customiza.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "646aa75e6394652f265da46ee5c07cc804210f8c", "publication_date": "2023-12-24", "title": "Agent4Ranking: Semantic Robust Ranking via Personalized Query Rewriting Using Multi-agent LLM", "authors": "Xiaopeng Li, Lixin Su, Pengyue Jia, Xiangyu Zhao, Suqi Cheng, Junfeng Wang, Dawei Yin", "venue": "arXiv.org", "citation_count": 15, "influential_citation_count": 0, "abstract": "Search engines are crucial as they provide an efficient and easy way to access vast amounts of information on the internet for diverse information needs. User queries, even with a specific need, can differ significantly. Prior research has explored the resilience of ranking models against typical query variations like paraphrasing, misspellings, and order changes. Yet, these works overlook how diverse demographics uniquely formulate identical queries. For instance, older individuals tend to construct queries more naturally and in varied order compared to other groups. This demographic diversity necessitates enhancing the adaptability of ranking models to diverse query formulations. To this end, in this paper, we propose a framework that integrates a novel rewriting pipeline that rewrites queries from various demographic perspectives and a novel framework to enhance ranking robustness. To be specific, we use Chain of Thought (CoT) technology to utilize Large Language Models (LLMs) as agents to emulate various demographic profiles, then use them for efficient query rewriting, and we innovate a robust Multi-gate Mixture of Experts (MMoE) architecture coupled with a hybrid loss function, collectively strengthening the ranking models' robustness. Our extensive experimentation on both public and industrial datasets assesses the efficacy of our query rewriting approach and the enhanced accuracy and robustness of the ranking model. The findings highlight the sophistication and effectiveness of our proposed model.", "pdf_url": "https://arxiv.org/pdf/2312.15450.pdf", "pdf_filename": "2023-12-24_Agent4Ranking__Semantic_Robust_Ranking_via_Persona.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-24_Agent4Ranking__Semantic_Robust_Ranking_via_Persona.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "356b85ae926b2a8b4cd794e10fe8f37891ebf8d7", "publication_date": "2025-03-15", "title": "SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning", "authors": "Edward Y. Chang, Longling Geng", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Recent LLM-based agent frameworks have demonstrated impressive capabilities in task delegation and workflow orchestration, but face significant challenges in maintaining context awareness and ensuring planning consistency. This paper presents SagaLLM, a structured multi-agent framework that addresses four fundamental limitations in current LLM approaches: inadequate self-validation, context narrowing, lacking transaction properties, and insufficient inter-agent coordination. By implementing specialized context management agents and validation protocols, SagaLLM preserves critical constraints and state information throughout complex planning processes, enabling robust and consistent decision-making even during disruptions. We evaluate our approach using selected problems from the REALM benchmark, focusing on sequential and reactive planning scenarios that challenge both context retention and adaptive reasoning. Our experiments with state-of-the-art LLMs, Claude 3.7, DeepSeek R1, GPT-4o, and GPT-o1, demonstrate that while these models exhibit impressive reasoning capabilities, they struggle with maintaining global constraint awareness during complex planning tasks, particularly when adapting to unexpected changes. In contrast, the distributed cognitive architecture of SagaLLM shows significant improvements in planning consistency, constraint enforcement, and adaptation to disruptions in various scenarios.", "pdf_url": "https://arxiv.org/pdf/2503.11951.pdf", "pdf_filename": "2025-03-15_SagaLLM__Context_Management__Validation__and_Trans.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-15_SagaLLM__Context_Management__Validation__and_Trans.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "50bc4f98893dde3039a0d1b11145963c165c2f94", "publication_date": "2025-02-03", "title": "PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback", "authors": "Kanika Goswami, Puneet Mathur, Ryan A. Rossi, Franck Dernoncourt", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Scientific data visualization is pivotal for transforming raw data into comprehensible visual representations, enabling pattern recognition, forecasting, and the presentation of data-driven insights. However, novice users often face difficulties due to the complexity of selecting appropriate tools and mastering visualization techniques. Large Language Models (LLMs) have recently demonstrated potential in assisting code generation, though they struggle with accuracy and require iterative debugging. In this paper, we propose PlotGen, a novel multi-agent framework aimed at automating the creation of precise scientific visualizations. PlotGen orchestrates multiple LLM-based agents, including a Query Planning Agent that breaks down complex user requests into executable steps, a Code Generation Agent that converts pseudocode into executable Python code, and three retrieval feedback agents - a Numeric Feedback Agent, a Lexical Feedback Agent, and a Visual Feedback Agent - that leverage multimodal LLMs to iteratively refine the data accuracy, textual labels, and visual correctness of generated plots via self-reflection. Extensive experiments show that PlotGen outperforms strong baselines, achieving a 4-6 percent improvement on the MatPlotBench dataset, leading to enhanced user trust in LLM-generated visualizations and improved novice productivity due to a reduction in debugging time needed for plot errors.", "pdf_url": "https://arxiv.org/pdf/2502.00988.pdf", "pdf_filename": "2025-02-03_PlotGen__Multi-Agent_LLM-based_Scientific_Data_Vis.pdf", "markdown_path": "data/semantic/markdown_files/2025-02-03_PlotGen__Multi-Agent_LLM-based_Scientific_Data_Vis.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "f7a636f9fba4e3e2107569a68580ed1acbb5f639", "publication_date": "2025-04-02", "title": "Self-Resource Allocation in Multi-Agent LLM Systems", "authors": "Alfonso Amayuelas, Jingbo Yang, Saaket Agashe, Ashwin Nagarajan, Antonis Antoniades, Xin Eric Wang, W. Wang", "venue": "arXiv.org", "citation_count": 5, "influential_citation_count": 0, "abstract": "With the development of LLMs as agents, there is a growing interest in connecting multiple agents into multi-agent systems to solve tasks concurrently, focusing on their role in task assignment and coordination. This paper explores how LLMs can effectively allocate computational tasks among multiple agents, considering factors such as cost, efficiency, and performance. In this work, we address key questions, including the effectiveness of LLMs as orchestrators and planners, comparing their effectiveness in task assignment and coordination. Our experiments demonstrate that LLMs can achieve high validity and accuracy in resource allocation tasks. We find that the planner method outperforms the orchestrator method in handling concurrent actions, resulting in improved efficiency and better utilization of agents. Additionally, we show that providing explicit information about worker capabilities enhances the allocation strategies of planners, particularly when dealing with suboptimal workers.", "pdf_url": "https://arxiv.org/pdf/2504.02051.pdf", "pdf_filename": "2025-04-02_Self-Resource_Allocation_in_Multi-Agent_LLM_System.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-02_Self-Resource_Allocation_in_Multi-Agent_LLM_System.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "82f5b9da7ca932129f849f3fe7319e747855af37", "publication_date": "2025-03-18", "title": "MANTRA: Enhancing Automated Method-Level Refactoring with Contextual RAG and Multi-Agent LLM Collaboration", "authors": "Yisen Xu, Feng Lin, Jinqiu Yang, Tse-Hsun Chen, Nikolaos Tsantalis", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 1, "abstract": "Maintaining and scaling software systems relies heavily on effective code refactoring, yet this process remains labor-intensive, requiring developers to carefully analyze existing codebases and prevent the introduction of new defects. Although recent advancements have leveraged Large Language Models (LLMs) to automate refactoring tasks, current solutions are constrained in scope and lack mechanisms to guarantee code compilability and successful test execution. In this work, we introduce MANTRA, a comprehensive LLM agent-based framework that automates method-level refactoring. MANTRA integrates Context-Aware Retrieval-Augmented Generation, coordinated Multi-Agent Collaboration, and Verbal Reinforcement Learning to emulate human decision-making during refactoring while preserving code correctness and readability. Our empirical study, conducted on 703 instances of\"pure refactorings\"(i.e., code changes exclusively involving structural improvements), drawn from 10 representative Java projects, covers the six most prevalent refactoring operations. Experimental results demonstrate that MANTRA substantially surpasses a baseline LLM model (RawGPT ), achieving an 82.8% success rate (582/703) in producing code that compiles and passes all tests, compared to just 8.7% (61/703) with RawGPT. Moreover, in comparison to IntelliJ's LLM-powered refactoring tool (EM-Assist), MANTRA exhibits a 50% improvement in generating Extract Method transformations. A usability study involving 37 professional developers further shows that refactorings performed by MANTRA are perceived to be as readable and reusable as human-written code, and in certain cases, even more favorable. These results highlight the practical advantages of MANTRA and emphasize the growing potential of LLM-based systems in advancing the automation of software refactoring tasks.", "pdf_url": "https://arxiv.org/pdf/2503.14340.pdf", "pdf_filename": "2025-03-18_MANTRA__Enhancing_Automated_Method-Level_Refactori.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-18_MANTRA__Enhancing_Automated_Method-Level_Refactori.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "b4e979f4407cd3dd7fee0b8a87eab6b571f38514", "publication_date": "2025-04-01", "title": "When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)", "authors": "Mahak Agarwal, Divyam Khanna", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "In many real-world scenarios, a single Large Language Model (LLM) may encounter contradictory claims-some accurate, others forcefully incorrect-and must judge which is true. We investigate this risk in a single-turn, multi-agent debate framework: one LLM-based agent provides a factual answer from TruthfulQA, another vigorously defends a falsehood, and the same LLM architecture serves as judge. We introduce the Confidence-Weighted Persuasion Override Rate (CW-POR), which captures not only how often the judge is deceived but also how strongly it believes the incorrect choice. Our experiments on five open-source LLMs (3B-14B parameters), where we systematically vary agent verbosity (30-300 words), reveal that even smaller models can craft persuasive arguments that override truthful answers-often with high confidence. These findings underscore the importance of robust calibration and adversarial testing to prevent LLMs from confidently endorsing misinformation.", "pdf_url": "https://arxiv.org/pdf/2504.00374.pdf", "pdf_filename": "2025-04-01_When_Persuasion_Overrides_Truth_in_Multi-Agent_LLM.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-01_When_Persuasion_Overrides_Truth_in_Multi-Agent_LLM.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "7cac6fd998b511d0e58d6463e8212a0c3d3c28cd", "publication_date": "2025-04-09", "title": "Modeling Response Consistency in Multi-Agent LLM Systems: A Comparative Analysis of Shared and Separate Context Approaches", "authors": "Tooraj Helmi", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Large Language Models (LLMs) are increasingly utilized in multi-agent systems (MAS) to enhance collaborative problem-solving and interactive reasoning. Recent advancements have enabled LLMs to function as autonomous agents capable of understanding complex interactions across multiple topics. However, deploying LLMs in MAS introduces challenges related to context management, response consistency, and scalability, especially when agents must operate under memory limitations and handle noisy inputs. While prior research has explored optimizing context sharing and response latency in LLM-driven MAS, these efforts often focus on either fully centralized or decentralized configurations, each with distinct trade-offs. In this paper, we develop a probabilistic framework to analyze the impact of shared versus separate context configurations on response consistency and response times in LLM-based MAS. We introduce the Response Consistency Index (RCI) as a metric to evaluate the effects of context limitations, noise, and inter-agent dependencies on system performance. Our approach differs from existing research by focusing on the interplay between memory constraints and noise management, providing insights into optimizing scalability and response times in environments with interdependent topics. Through this analysis, we offer a comprehensive understanding of how different configurations impact the efficiency of LLM-driven multi-agent systems, thereby guiding the design of more robust architectures.", "pdf_url": "https://arxiv.org/pdf/2504.07303.pdf", "pdf_filename": "2025-04-09_Modeling_Response_Consistency_in_Multi-Agent_LLM_S.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-09_Modeling_Response_Consistency_in_Multi-Agent_LLM_S.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "b0ce81b9f302f4ce37648d6ef2a25dc80f88806b", "publication_date": "2024-12-01", "title": "Generating AI Literacy MCQs: A Multi-Agent LLM Approach", "authors": "Jiayi Wang, Ruiwei Xiao, Ying-Jui Tseng", "venue": "Technical Symposium on Computer Science Education", "citation_count": 0, "influential_citation_count": 0, "abstract": "Artificial intelligence (AI) is transforming society, making it crucial to prepare the next generation through AI literacy in K-12 education. However, scalable and reliable AI literacy materials and assessment resources are lacking. To address this gap, our study presents a novel approach to generating multiple-choice questions (MCQs) for AI literacy assessments. Our method utilizes large language models (LLMs) to automatically generate scalable, high-quality assessment questions. These questions align with user-provided learning objectives, grade levels, and Bloom's Taxonomy levels. We introduce an iterative workflow incorporating LLM-powered critique agents to ensure the generated questions meet pedagogical standards. In the preliminary evaluation, experts expressed strong interest in using the LLM-generated MCQs, indicating that this system could enrich existing AI literacy materials and provide a valuable addition to the toolkit of K-12 educators.", "pdf_url": "https://arxiv.org/pdf/2412.00970.pdf", "pdf_filename": "2024-12-01_Generating_AI_Literacy_MCQs__A_Multi-Agent_LLM_App.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-01_Generating_AI_Literacy_MCQs__A_Multi-Agent_LLM_App.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c", "publication_date": "2023", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework", "authors": "Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang", "venue": "arXiv.org", "citation_count": 640, "influential_citation_count": 51, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "e89ee3f84f1f07229a7ba211bad3465d2c80a325", "publication_date": "2024-02-28", "title": "Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?", "authors": "Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, Yangqiu Song", "venue": "Annual Meeting of the Association for Computational Linguistics", "citation_count": 73, "influential_citation_count": 2, "abstract": "Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, we reevaluate this claim through systematic experiments, where we propose a novel group discussion framework to enrich the set of discussion mechanisms. Interestingly, our results show that a single-agent LLM with strong prompts can achieve almost the same performance as the best existing discussion approach on a wide range of reasoning tasks and backbone LLMs. We observe that the multi-agent discussion performs better than a single agent only when there is no demonstration in the prompt. Further study reveals the common interaction mechanisms of LLMs during the discussion.", "pdf_url": "https://arxiv.org/pdf/2402.18272.pdf", "pdf_filename": "2024-02-28_Rethinking_the_Bounds_of_LLM_Reasoning__Are_Multi-.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-28_Rethinking_the_Bounds_of_LLM_Reasoning__Are_Multi-.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "fc8ce12d6186ddaa797e2b36d5e8eb7921425308", "publication_date": "2024-10-08", "title": "A survey on LLM-based multi-agent systems: workflow, infrastructure, and challenges", "authors": "Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu, Yi Yang", "venue": "Vicinagearth", "citation_count": 50, "influential_citation_count": 3, "abstract": "The pursuit of more intelligent and credible autonomous systems, akin to human society, has been a long-standing endeavor for humans. Leveraging the exceptional reasoning and planning capabilities of large language models (LLMs), LLM-based agents have been proposed and have achieved remarkable success across a wide array of tasks. Notably, LLM-based multi-agent systems (MAS) are considered a promising pathway towards realizing general artificial intelligence that is equivalent to or surpasses human-level intelligence. In this paper, we present a comprehensive survey of these studies, offering a systematic review of LLM-based MAS. Adhering to the workflow of LLM-based multi-agent systems, we synthesize a general structure encompassing five key components: profile, perception, self-action, mutual interaction, and evolution. This unified framework encapsulates much of the previous work in the field. Furthermore, we illuminate the extensive applications of LLM-based MAS in two principal areas: problem-solving and world simulation. Finally, we discuss in detail several contemporary challenges and provide insights into potential future directions in this domain.", "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44336-024-00009-2.pdf", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "006c4c7470566327e5b02b94936d0be0033fc9f5", "publication_date": "2024-03-26", "title": "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution", "authors": "Wei Tao, Yucheng Zhou, Wenqiang Zhang, Yu-Xi Cheng", "venue": "Neural Information Processing Systems", "citation_count": 41, "influential_citation_count": 3, "abstract": "In software development, resolving the emergent issues within GitHub repositories is a complex challenge that involves not only the incorporation of new code but also the maintenance of existing code. Large Language Models (LLMs) have shown promise in code generation but face difficulties in resolving Github issues, particularly at the repository level. To overcome this challenge, we empirically study the reason why LLMs fail to resolve GitHub issues and analyze the major factors. Motivated by the empirical findings, we propose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution, MAGIS, consisting of four agents customized for software evolution: Manager, Repository Custodian, Developer, and Quality Assurance Engineer agents. This framework leverages the collaboration of various agents in the planning and coding process to unlock the potential of LLMs to resolve GitHub issues. In experiments, we employ the SWE-bench benchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub issues, significantly outperforming the baselines. Specifically, MAGIS achieves an eight-fold increase in resolved ratio over the direct application of GPT-4, the advanced LLM.", "pdf_url": "https://arxiv.org/pdf/2403.17927.pdf", "pdf_filename": "2024-03-26_MAGIS__LLM-Based_Multi-Agent_Framework_for_GitHub_.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-26_MAGIS__LLM-Based_Multi-Agent_Framework_for_GitHub_.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "ab6f63877fdb55ce0b05964476e6fb303fc376af", "publication_date": "2024-04-26", "title": "A Unified Debugging Approach via LLM-Based Multi-Agent Synergy", "authors": "Cheryl Lee, Chun Xia, Jen-Tse Huang, Zhouruixing Zhu, Lingming Zhang, Michael R. Lyu", "venue": "", "citation_count": 35, "influential_citation_count": 4, "abstract": "Software debugging is a time-consuming endeavor involving a series of steps, such as fault localization and patch generation, each requiring thorough analysis and a deep understanding of the underlying logic. While large language models (LLMs) demonstrate promising potential in coding tasks, their performance in debugging remains limited. Current LLM-based methods often focus on isolated steps and struggle with complex bugs. In this paper, we propose the first end-to-end framework, FixAgent, for unified debugging through multi-agent synergy. It mimics the entire cognitive processes of developers, with each agent specialized as a particular component of this process rather than mirroring the actions of an independent expert as in previous multi-agent systems. Agents are coordinated through a three-level design, following a cognitive model of debugging, allowing adaptive handling of bugs with varying complexities. Experiments on extensive benchmarks demonstrate that FixAgent significantly outperforms state-of-the-art repair methods, fixing 1.25$\\times$ to 2.56$\\times$ bugs on the repo-level benchmark, Defects4J. This performance is achieved without requiring ground-truth root-cause code statements, unlike the baselines. Our source code is available on https://github.com/AcceptePapier/UniDebugger.", "pdf_url": "https://arxiv.org/pdf/2404.17153.pdf", "pdf_filename": "2024-04-26_A_Unified_Debugging_Approach_via_LLM-Based_Multi-A.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-26_A_Unified_Debugging_Approach_via_LLM-Based_Multi-A.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "c5cb68ac59f98fafc7cb96b86fca27e662e0cba8", "publication_date": "2024-04-02", "title": "Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization", "authors": "Yoichi Ishibashi, Yoshimasa Nishimura", "venue": "arXiv.org", "citation_count": 38, "influential_citation_count": 3, "abstract": "Recent advancements in automatic code generation using large language model (LLM) agent have brought us closer to the future of automated software development. However, existing single-agent approaches face limitations in generating and improving large-scale, complex codebases due to constraints in context length. To tackle this challenge, we propose Self-Organized multi-Agent framework (SoA), a novel multi-agent framework that enables the scalable and efficient generation and optimization of large-scale code. In SoA, self-organized agents operate independently to generate and modify code components while seamlessly collaborating to construct the overall codebase. A key feature of our framework is the automatic multiplication of agents based on problem complexity, allowing for dynamic scalability. This enables the overall code volume to be increased indefinitely according to the number of agents, while the amount of code managed by each agent remains constant. We evaluate SoA on the HumanEval benchmark and demonstrate that, compared to a single-agent system, each agent in SoA handles significantly less code, yet the overall generated code is substantially greater. Moreover, SoA surpasses the powerful single-agent baseline by 5% in terms of Pass@1 accuracy.", "pdf_url": "https://arxiv.org/pdf/2404.02183.pdf", "pdf_filename": "2024-04-02_Self-Organized_Agents__A_LLM_Multi-Agent_Framework.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-02_Self-Organized_Agents__A_LLM_Multi-Agent_Framework.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "6d1ef839db3d637977392f4a7046c26bfea37d46", "publication_date": "2024-02-05", "title": "LLM Multi-Agent Systems: Challenges and Open Problems", "authors": "Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu, Chaoyang He", "venue": "arXiv.org", "citation_count": 42, "influential_citation_count": 3, "abstract": "This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.", "pdf_url": "https://arxiv.org/pdf/2402.03578.pdf", "pdf_filename": "2024-02-05_LLM_Multi-Agent_Systems__Challenges_and_Open_Probl.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-05_LLM_Multi-Agent_Systems__Challenges_and_Open_Probl.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "165921d2aa4f1d110d25d488ea8b205d134b16e6", "publication_date": "2024-10-09", "title": "Prompt Infection: LLM-to-LLM Prompt Injection within Multi-Agent Systems", "authors": "Donghyun Lee, Mo Tiwari", "venue": "arXiv.org", "citation_count": 20, "influential_citation_count": 3, "abstract": "As Large Language Models (LLMs) grow increasingly powerful, multi-agent systems are becoming more prevalent in modern AI applications. Most safety research, however, has focused on vulnerabilities in single-agent LLMs. These include prompt injection attacks, where malicious prompts embedded in external content trick the LLM into executing unintended or harmful actions, compromising the victim's application. In this paper, we reveal a more dangerous vector: LLM-to-LLM prompt injection within multi-agent systems. We introduce Prompt Infection, a novel attack where malicious prompts self-replicate across interconnected agents, behaving much like a computer virus. This attack poses severe threats, including data theft, scams, misinformation, and system-wide disruption, all while propagating silently through the system. Our extensive experiments demonstrate that multi-agent systems are highly susceptible, even when agents do not publicly share all communications. To address this, we propose LLM Tagging, a defense mechanism that, when combined with existing safeguards, significantly mitigates infection spread. This work underscores the urgent need for advanced security measures as multi-agent LLM systems become more widely adopted.", "pdf_url": "https://arxiv.org/pdf/2410.07283.pdf", "pdf_filename": "2024-10-09_Prompt_Infection__LLM-to-LLM_Prompt_Injection_with.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-09_Prompt_Infection__LLM-to-LLM_Prompt_Injection_with.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "8bf02bb6762641924feb5bade378ef57024cc534", "publication_date": "None", "title": "Reliable Decision-Making for Multi-Agent LLM Systems", "authors": "Xian Yeow, Shunichi Lee, Lasitha Akatsuka, Vidyaratne Aman, Ahmed Kumar, Chetan Farahat, Gupta", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "ec58a564fdda29e6a9a0a7bab5eeb4c290f716d7", "publication_date": "2023-08-14", "title": "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate", "authors": "Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shan Zhang, Jie Fu, Zhiyuan Liu", "venue": "arXiv.org", "citation_count": 485, "influential_citation_count": 31, "abstract": "Text evaluation has historically posed significant challenges, often demanding substantial labor and time cost. With the emergence of large language models (LLMs), researchers have explored LLMs' potential as alternatives for human evaluation. While these single-agent-based approaches show promise, experimental results suggest that further advancements are needed to bridge the gap between their current effectiveness and human-level evaluation quality. Recognizing that best practices of human evaluation processes often involve multiple human annotators collaborating in the evaluation, we resort to a multi-agent debate framework, moving beyond single-agent prompting strategies. The multi-agent-based approach enables a group of LLMs to synergize with an array of intelligent counterparts, harnessing their distinct capabilities and expertise to enhance efficiency and effectiveness in handling intricate tasks. In this paper, we construct a multi-agent referee team called ChatEval to autonomously discuss and evaluate the quality of generated responses from different models on open-ended questions and traditional natural language generation (NLG) tasks. Our analysis shows that ChatEval transcends mere textual scoring, offering a human-mimicking evaluation process for reliable assessments. Our code is available at https://github.com/chanchimin/ChatEval.", "pdf_url": "https://arxiv.org/pdf/2308.07201", "pdf_filename": "2023-08-14_ChatEval__Towards_Better_LLM-based_Evaluators_thro.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-14_ChatEval__Towards_Better_LLM-based_Evaluators_thro.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "174fab182b3968879884a5af2ef2344ef2623516", "publication_date": "None", "title": "MASON - A Multi-Agent LLM Framework for No-Code Development", "authors": "Muhammed Roshan, Kayvan Palayamkot, Karim", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "e1b62c7ee4e22ab63e3b0c9968563e6675833e36", "publication_date": "2024-05-23", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "authors": "Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Xuelong Li, Zhen Wang", "venue": "arXiv.org", "citation_count": 31, "influential_citation_count": 1, "abstract": "Grounding the reasoning ability of large language models (LLMs) for embodied tasks is challenging due to the complexity of the physical world. Especially, LLM planning for multi-agent collaboration requires communication of agents or credit assignment as the feedback to re-adjust the proposed plans and achieve effective coordination. However, existing methods that overly rely on physical verification or self-reflection suffer from excessive and inefficient querying of LLMs. In this paper, we propose a novel framework for multi-agent collaboration that introduces Reinforced Advantage feedback (ReAd) for efficient self-refinement of plans. Specifically, we perform critic regression to learn a sequential advantage function from LLM-planned data, and then treat the LLM planner as an optimizer to generate actions that maximize the advantage function. It endows the LLM with the foresight to discern whether the action contributes to accomplishing the final task. We provide theoretical analysis by extending advantage-weighted regression in reinforcement learning to multi-agent systems. Experiments on Overcooked-AI and a difficult variant of RoCoBench show that ReAd surpasses baselines in success rate, and also significantly decreases the interaction steps of agents and query rounds of LLMs, demonstrating its high efficiency for grounding LLMs. More results are given at https://read-llm.github.io/.", "pdf_url": "https://arxiv.org/pdf/2405.14314.pdf", "pdf_filename": "2024-05-23_Towards_Efficient_LLM_Grounding_for_Embodied_Multi.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-23_Towards_Efficient_LLM_Grounding_for_Embodied_Multi.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "dd38755291d108ab86c68d1aac7485921bb8e647", "publication_date": "2024-05-17", "title": "LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions", "authors": "Chuanneng Sun, Songjun Huang, D. Pompili", "venue": "arXiv.org", "citation_count": 32, "influential_citation_count": 0, "abstract": "In recent years, Large Language Models (LLMs) have shown great abilities in various tasks, including question answering, arithmetic problem solving, and poem writing, among others. Although research on LLM-as-an-agent has shown that LLM can be applied to Reinforcement Learning (RL) and achieve decent results, the extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as many aspects, such as coordination and communication between agents, are not considered in the RL frameworks of a single agent. To inspire more research on LLM-based MARL, in this letter, we survey the existing LLM-based single-agent and multi-agent RL frameworks and provide potential research directions for future research. In particular, we focus on the cooperative tasks of multiple agents with a common goal and communication among them. We also consider human-in/on-the-loop scenarios enabled by the language component in the framework.", "pdf_url": "https://arxiv.org/pdf/2405.11106.pdf", "pdf_filename": "2024-05-17_LLM-based_Multi-Agent_Reinforcement_Learning__Curr.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-17_LLM-based_Multi-Agent_Reinforcement_Learning__Curr.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "b93ac10de176c4a7aaa2cc652b90bb25636532cd", "publication_date": "2024-02-18", "title": "Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation", "authors": "Siyuan Wang, Zhuohan Long, Zhihao Fan, Zhongyu Wei, Xuanjing Huang", "venue": "International Conference on Computational Linguistics", "citation_count": 32, "influential_citation_count": 2, "abstract": "This paper presents a benchmark self-evolving framework to dynamically evaluate rapidly advancing Large Language Models (LLMs), aiming for a more accurate assessment of their capabilities and limitations. We utilize a multi-agent system to manipulate the context or question of original instances, reframing new evolving instances with high confidence that dynamically extend existing benchmarks. Towards a more scalable, robust and fine-grained evaluation, we implement six reframing operations to construct evolving instances testing LLMs against diverse queries, data noise and probing their problem-solving sub-abilities. With this framework, we extend benchmark datasets of four tasks. Experimental results show a general performance decline in most LLMs against their original results. This decline under our scalable and robust evaluations, alongside our fine-grained evaluation, more accurately reflect models' capabilities. Besides, our framework widens performance discrepancies both between different models and within the same model across various tasks, facilitating more informed model selection for specific tasks (Code and data are available at https://github.com/NanshineLoong/Self-Evolving-Benchmark).", "pdf_url": "https://arxiv.org/pdf/2402.11443.pdf", "pdf_filename": "2024-02-18_Benchmark_Self-Evolving__A_Multi-Agent_Framework_f.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-18_Benchmark_Self-Evolving__A_Multi-Agent_Framework_f.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "0b41a6899c29a04e1217e6cc80a3d915ea18e2d8", "publication_date": "2024-07-09", "title": "FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making", "authors": "Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W. Suchow, Rong Liu, Zhenyu Cui, Denghui Zhang, K. Subbalakshmi, Guojun Xiong, Yueru He, Jimin Huang, Dong Li, Qianqian Xie", "venue": "Neural Information Processing Systems", "citation_count": 24, "influential_citation_count": 1, "abstract": "Large language models (LLMs) have demonstrated notable potential in conducting complex tasks and are increasingly utilized in various financial applications. However, high-quality sequential financial investment decision-making remains challenging. These tasks require multiple interactions with a volatile environment for every decision, demanding sufficient intelligence to maximize returns and manage risks. Although LLMs have been used to develop agent systems that surpass human teams and yield impressive investment returns, opportunities to enhance multi-sourced information synthesis and optimize decision-making outcomes through timely experience refinement remain unexplored. Here, we introduce the FinCon, an LLM-based multi-agent framework with CONceptual verbal reinforcement tailored for diverse FINancial tasks. Inspired by effective real-world investment firm organizational structures, FinCon utilizes a manager-analyst communication hierarchy. This structure allows for synchronized cross-functional agent collaboration towards unified goals through natural language interactions and equips each agent with greater memory capacity than humans. Additionally, a risk-control component in FinCon enhances decision quality by episodically initiating a self-critiquing mechanism to update systematic investment beliefs. The conceptualized beliefs serve as verbal reinforcement for the future agent's behavior and can be selectively propagated to the appropriate node that requires knowledge updates. This feature significantly improves performance while reducing unnecessary peer-to-peer communication costs. Moreover, FinCon demonstrates strong generalization capabilities in various financial tasks, including single stock trading and portfolio management.", "pdf_url": "https://arxiv.org/pdf/2407.06567.pdf", "pdf_filename": "2024-07-09_FinCon__A_Synthesized_LLM_Multi-Agent_System_with_.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-09_FinCon__A_Synthesized_LLM_Multi-Agent_System_with_.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "3d814347e382fc3fcc071876744f139d2c101be7", "publication_date": "2024-07-10", "title": "Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities", "authors": "Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu", "venue": "arXiv.org", "citation_count": 25, "influential_citation_count": 2, "abstract": "The rapid adoption of large language models (LLMs) in multi-agent systems has highlighted their impressive capabilities in various applications, such as collaborative problem-solving and autonomous negotiation. However, the security implications of these LLM-based multi-agent systems have not been thoroughly investigated, particularly concerning the spread of manipulated knowledge. In this paper, we investigate this critical issue by constructing a detailed threat model and a comprehensive simulation environment that mirrors real-world multi-agent deployments in a trusted platform. Subsequently, we propose a novel two-stage attack method involving Persuasiveness Injection and Manipulated Knowledge Injection to systematically explore the potential for manipulated knowledge (i.e., counterfactual and toxic knowledge) spread without explicit prompt manipulation. Our method leverages the inherent vulnerabilities of LLMs in handling world knowledge, which can be exploited by attackers to unconsciously spread fabricated information. Through extensive experiments, we demonstrate that our attack method can successfully induce LLM-based agents to spread both counterfactual and toxic knowledge without degrading their foundational capabilities during agent communication. Furthermore, we show that these manipulations can persist through popular retrieval-augmented generation frameworks, where several benign agents store and retrieve manipulated chat histories for future interactions. This persistence indicates that even after the interaction has ended, the benign agents may continue to be influenced by manipulated knowledge. Our findings reveal significant security risks in LLM-based multi-agent systems, emphasizing the imperative need for robust defenses against manipulated knowledge spread, such as introducing ``guardian'' agents and advanced fact-checking tools.", "pdf_url": "https://arxiv.org/pdf/2407.07791.pdf", "pdf_filename": "2024-07-10_Flooding_Spread_of_Manipulated_Knowledge_in_LLM-Ba.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-10_Flooding_Spread_of_Manipulated_Knowledge_in_LLM-Ba.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "dd565137ec79da38bf2d01319bba195c66733212", "publication_date": "2024-07-13", "title": "CellAgent: An LLM-driven Multi-Agent Framework for Automated Single-cell Data Analysis", "authors": "Yihang Xiao, Jinyi Liu, Yan Zheng, Xiaohan Xie, Jianye Hao, Mingzhi Li, Ruitao Wang, Fei Ni, Yuxiao Li, Jintian Luo, Shaoqing Jiao, Jiajie Peng", "venue": "arXiv.org", "citation_count": 20, "influential_citation_count": 1, "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is crucial for biological research, as it enables the precise characterization of cellular heterogeneity. However, manual manipulation of various tools to achieve desired outcomes can be labor-intensive for researchers. To address this, we introduce CellAgent (http://cell.agent4science.cn/), an LLM-driven multi-agent framework, specifically designed for the automatic processing and execution of scRNA-seq data analysis tasks, providing high-quality results with no human intervention. Firstly, to adapt general LLMs to the biological field, CellAgent constructs LLM-driven biological expert roles - planner, executor, and evaluator - each with specific responsibilities. Then, CellAgent introduces a hierarchical decision-making mechanism to coordinate these biological experts, effectively driving the planning and step-by-step execution of complex data analysis tasks. Furthermore, we propose a self-iterative optimization mechanism, enabling CellAgent to autonomously evaluate and optimize solutions, thereby guaranteeing output quality. We evaluate CellAgent on a comprehensive benchmark dataset encompassing dozens of tissues and hundreds of distinct cell types. Evaluation results consistently show that CellAgent effectively identifies the most suitable tools and hyperparameters for single-cell analysis tasks, achieving optimal performance. This automated framework dramatically reduces the workload for science data analyses, bringing us into the\"Agent for Science\"era.", "pdf_url": "https://arxiv.org/pdf/2407.09811.pdf", "pdf_filename": "2024-07-13_CellAgent__An_LLM-driven_Multi-Agent_Framework_for.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-13_CellAgent__An_LLM-driven_Multi-Agent_Framework_for.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "d4656bba3a424a25fcd9e1fbf3966f080ace9c2f", "publication_date": "2024-01-02", "title": "LLM Harmony: Multi-Agent Communication for Problem Solving", "authors": "Sumedh Rasal", "venue": "arXiv.org", "citation_count": 23, "influential_citation_count": 0, "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving. Traditional techniques like chain-of-thought prompting necessitate explicit human guidance. This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs' autonomous problem-solving capabilities. The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios. Extensive experimentation demonstrates the framework's superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.", "pdf_url": "https://arxiv.org/pdf/2401.01312.pdf", "pdf_filename": "2024-01-02_LLM_Harmony__Multi-Agent_Communication_for_Problem.pdf", "markdown_path": "data/semantic/markdown_files/2024-01-02_LLM_Harmony__Multi-Agent_Communication_for_Problem.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "aebfeb42bbd155c1541a67fddf0a6e2bc5d6ae34", "publication_date": "2024-10-03", "title": "Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems", "authors": "Guibin Zhang, Yanwei Yue, Zhixun Li, Sukwon Yun, Guancheng Wan, Kun Wang, Dawei Cheng, Jeffrey Xu Yu, Tianlong Chen", "venue": "arXiv.org", "citation_count": 17, "influential_citation_count": 0, "abstract": "Recent advancements in large language model (LLM)-powered agents have shown that collective intelligence can significantly outperform individual capabilities, largely attributed to the meticulously designed inter-agent communication topologies. Though impressive in performance, existing multi-agent pipelines inherently introduce substantial token overhead, as well as increased economic costs, which pose challenges for their large-scale deployments. In response to this challenge, we propose an economical, simple, and robust multi-agent communication framework, termed $\\texttt{AgentPrune}$, which can seamlessly integrate into mainstream multi-agent systems and prunes redundant or even malicious communication messages. Technically, $\\texttt{AgentPrune}$ is the first to identify and formally define the \\textit{communication redundancy} issue present in current LLM-based multi-agent pipelines, and efficiently performs one-shot pruning on the spatial-temporal message-passing graph, yielding a token-economic and high-performing communication topology. Extensive experiments across six benchmarks demonstrate that $\\texttt{AgentPrune}$ \\textbf{(I)} achieves comparable results as state-of-the-art topologies at merely $\\$5.6$ cost compared to their $\\$43.7$, \\textbf{(II)} integrates seamlessly into existing multi-agent frameworks with $28.1\\%\\sim72.8\\%\\downarrow$ token reduction, and \\textbf{(III)} successfully defend against two types of agent-based adversarial attacks with $3.5\\%\\sim10.8\\%\\uparrow$ performance boost.", "pdf_url": "https://arxiv.org/pdf/2410.02506.pdf", "pdf_filename": "2024-10-03_Cut_the_Crap__An_Economical_Communication_Pipeline.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_Cut_the_Crap__An_Economical_Communication_Pipeline.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "d0a074d5da6dc44177b7a9533f700b0d8fda23be", "publication_date": "2024", "title": "LLM-Based Multi-Agent Systems for Software Engineering: Vision and the Road Ahead", "authors": "Junda He, Christoph Treude, David Lo", "venue": "arXiv.org", "citation_count": 16, "influential_citation_count": 0, "abstract": "Integrating Large Language Models(LLMs) intoautonomousagents marks a signi\ufb01cant shift in the research landscape by o\ufb00ering cognitive abilities competitive to human planning and reasoning. This paper envisions the evolution of LLM-based Multi-Agent (LMA) systems in addressing complex and multi-faceted software engineering challenges. LMA systems introduce numerous bene\ufb01ts, including enhanced robustness throughcollaborativecross-examination, autonomous problem-solving, and scalable solutions to complex software projects. By examining the role of LMA systems in future software engineering practices, this vision paper highlights the potential applications and emerging challenges. We further point to speci\ufb01c opportunities for research and conclude with a research agenda with a set of research questions to guide future research directions", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "9ea0757c750ab1222a7442d3485a74d1c526b04c", "publication_date": "2023-08-16", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation", "authors": "Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, A. Awadallah, Ryen W. White, Doug Burger, Chi Wang", "venue": "", "citation_count": 342, "influential_citation_count": 27, "abstract": "AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.", "pdf_url": "https://arxiv.org/pdf/2308.08155.pdf", "pdf_filename": "2023-08-16_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Mu.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-16_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Mu.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "ff61aef2fef3a235bfaa123158a990c4f5f27d1a", "publication_date": "2024-01-14", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "authors": "Weizhou Shen, Chenliang Li, Hongzhan Chen, Ming Yan, Xiaojun Quan, Hehong Chen, Ji Zhang, Fei Huang", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 55, "influential_citation_count": 1, "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization. While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task. This modular framework facilitates individual updates and the potential use of smaller LLMs for building each capability. To effectively train this framework, we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task. Second, the fine-tuned LLM is used to instantiate the planner, caller, and summarizer respectively, which are continually fine-tuned on respective sub-tasks. Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.", "pdf_url": "https://arxiv.org/pdf/2401.07324.pdf", "pdf_filename": "2024-01-14_Small_LLMs_Are_Weak_Tool_Learners__A_Multi-LLM_Age.pdf", "markdown_path": "data/semantic/markdown_files/2024-01-14_Small_LLMs_Are_Weak_Tool_Learners__A_Multi-LLM_Age.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "ead6121fbc787d508dc6a6d7106f72bf0d647d03", "publication_date": "2023-06-05", "title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents", "authors": "Yashar Talebirad, Amirhossein Nadiri", "venue": "arXiv.org", "citation_count": 220, "influential_citation_count": 7, "abstract": "In this paper, we present a novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems. Our framework introduces a collaborative environment where multiple intelligent agent components, each with distinctive attributes and roles, work together to handle complex tasks more efficiently and effectively. We demonstrate the practicality and versatility of our framework through case studies in artificial general intelligence (AGI), specifically focusing on the Auto-GPT and BabyAGI models. We also examine the\"Gorilla\"model, which integrates external APIs into the LLM. Our framework addresses limitations and challenges such as looping issues, security risks, scalability, system evaluation, and ethical considerations. By modeling various domains such as courtroom simulations and software development scenarios, we showcase the potential applications and benefits of our proposed multi-agent system. Our framework provides an avenue for advancing the capabilities and performance of LLMs through collaboration and knowledge exchange among intelligent agents.", "pdf_url": "http://arxiv.org/pdf/2306.03314", "pdf_filename": "2023-06-05_Multi-Agent_Collaboration__Harnessing_the_Power_of.pdf", "markdown_path": "data/semantic/markdown_files/2023-06-05_Multi-Agent_Collaboration__Harnessing_the_Power_of.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "dc10d108823630343484c5eecbb5c3011751282e", "publication_date": "2024-06-27", "title": "LayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design", "authors": "Bingyang Liu, Haoyi Zhang, Xiaohan Gao, Zichen Kong, Xiyuan Tang, Yibo Lin, Runsheng Wang, Ru Huang", "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems", "citation_count": 13, "influential_citation_count": 0, "abstract": "Analog layout design heavily involves interactive processes between humans and design tools. Electronic Design Automation (EDA) tools for this task are usually designed to use scripting commands or visualized buttons for manipulation, especially for interactive automation functionalities, which have a steep learning curve and cumbersome user experience, making a notable barrier to designers' adoption. Aiming to address such a usability issue, this paper introduces LayoutCopilot, a pioneering multi-agent collaborative framework powered by Large Language Models (LLMs) for interactive analog layout design. LayoutCopilot simplifies human-tool interaction by converting natural language instructions into executable script commands, and it interprets high-level design intents into actionable suggestions, significantly streamlining the design process. Experimental results demonstrate the flexibility, efficiency, and accessibility of LayoutCopilot in handling real-world analog designs.", "pdf_url": "https://arxiv.org/pdf/2406.18873.pdf", "pdf_filename": "2024-06-27_LayoutCopilot__An_LLM-powered_Multi-agent_Collabor.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-27_LayoutCopilot__An_LLM-powered_Multi-agent_Collabor.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "fb66fb26ad3a0e26ed6b56c42a8c02e1737c811a", "publication_date": "2024-09-30", "title": "TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation", "authors": "Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou", "venue": "arXiv.org", "citation_count": 12, "influential_citation_count": 1, "abstract": "Code translation converts code from one programming language to another while maintaining its original functionality, which is crucial for software migration, system refactoring, and cross-platform development. Traditional rule-based methods rely on manually-written rules, which can be time-consuming and often result in less readable code. To overcome this, learning-based methods have been developed, leveraging parallel data to train models for automated code translation. More recently, the advance of Large Language Models (LLMs) further boosts learning-based code translation. Although promising, LLM-translated program still suffers from diverse quality issues (e.g., syntax errors and semantic errors). In particular, it can be challenging for LLMs to self-debug these errors when simply provided with the corresponding error messages. In this work, we propose a novel LLM-based multi-agent system TRANSAGENT, which enhances LLM-based code translation by fixing the syntax errors and semantic errors with the synergy between four LLM-based agents, including Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error Fixer. The main insight of TRANSAGENT is to first localize the error code block in the target program based on the execution alignment between the target and source program, which can narrow down the fixing space and thus lower down the fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark from recent programming tasks to mitigate the potential data leakage issue. On our benchmark, TRANSAGENT outperforms the latest LLM-based code translation technique UniTrans in both translation effectiveness and efficiency; additionally, our evaluation on different LLMs show the generalization of TRANSAGENT and our ablation study shows the contribution of each agent.", "pdf_url": "https://arxiv.org/pdf/2409.19894.pdf", "pdf_filename": "2024-09-30_TRANSAGENT__An_LLM-Based_Multi-Agent_System_for_Co.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-30_TRANSAGENT__An_LLM-Based_Multi-Agent_System_for_Co.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "a4d33353dfdc546d499726c87456bf5dfc0e7bf2", "publication_date": "2024-03-28", "title": "Enhancing Anomaly Detection in Financial Markets with an LLM-based Multi-Agent Framework", "authors": "Taejin Park", "venue": "", "citation_count": 12, "influential_citation_count": 0, "abstract": "This paper introduces a Large Language Model (LLM)-based multi-agent framework designed to enhance anomaly detection within financial market data, tackling the longstanding challenge of manually verifying system-generated anomaly alerts. The framework harnesses a collaborative network of AI agents, each specialised in distinct functions including data conversion, expert analysis via web research, institutional knowledge utilization or cross-checking and report consolidation and management roles. By coordinating these agents towards a common objective, the framework provides a comprehensive and automated approach for validating and interpreting financial data anomalies. I analyse the S&P 500 index to demonstrate the framework's proficiency in enhancing the efficiency, accuracy and reduction of human intervention in financial market monitoring. The integration of AI's autonomous functionalities with established analytical methods not only underscores the framework's effectiveness in anomaly detection but also signals its broader applicability in supporting financial market monitoring.", "pdf_url": "https://arxiv.org/pdf/2403.19735.pdf", "pdf_filename": "2024-03-28_Enhancing_Anomaly_Detection_in_Financial_Markets_w.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-28_Enhancing_Anomaly_Detection_in_Financial_Markets_w.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "e321349644c97f0c0d0147c09690e2485d2d61c4", "publication_date": "2024-11-24", "title": "DrugAgent: Automating AI-aided Drug Discovery Programming through LLM Multi-Agent Collaboration", "authors": "Sizhe Liu, Yizhou Lu, Siyu Chen, Xiyang Hu, Jieyu Zhao, Tianfan Fu, Yue Zhao", "venue": "arXiv.org", "citation_count": 12, "influential_citation_count": 0, "abstract": "Recent progress in Large Language Models (LLMs) has drawn attention to their potential for accelerating drug discovery. However, a central problem remains: translating theoretical ideas into robust implementations in the highly specialized context of pharmaceutical research. This limitation prevents practitioners from making full use of the latest AI developments in drug discovery. To address this challenge, we introduce DrugAgent, a multi-agent framework that automates machine learning (ML) programming for drug discovery tasks. DrugAgent employs an LLM Planner that formulates high-level ideas and an LLM Instructor that identifies and integrates domain knowledge when implementing those ideas. We present case studies on three representative drug discovery tasks. Our results show that DrugAgent consistently outperforms leading baselines, including a relative improvement of 4.92% in ROC-AUC compared to ReAct for drug-target interaction (DTI). DrugAgent is publicly available at https://anonymous.4open.science/r/drugagent-5C42/.", "pdf_url": "https://arxiv.org/pdf/2411.15692.pdf", "pdf_filename": "2024-11-24_DrugAgent__Automating_AI-aided_Drug_Discovery_Prog.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-24_DrugAgent__Automating_AI-aided_Drug_Discovery_Prog.md"}
