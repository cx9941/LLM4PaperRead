{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "8ba57771dd6345821a0cbe83c4c7eb50f66b7b65", "publication_date": "2024-03-02", "title": "AutoDefense: Multi-Agent LLM Defense against Jailbreak Attacks", "authors": "Yifan Zeng, Yiran Wu, Xiao Zhang, Huazheng Wang, Qingyun Wu", "venue": "arXiv.org", "citation_count": 71, "influential_citation_count": 4, "abstract": "Despite extensive pre-training in moral alignment to prevent generating harmful information, large language models (LLMs) remain vulnerable to jailbreak attacks. In this paper, we propose AutoDefense, a multi-agent defense framework that filters harmful responses from LLMs. With the response-filtering mechanism, our framework is robust against different jailbreak attack prompts, and can be used to defend different victim models. AutoDefense assigns different roles to LLM agents and employs them to complete the defense task collaboratively. The division in tasks enhances the overall instruction-following of LLMs and enables the integration of other defense components as tools. With AutoDefense, small open-source LMs can serve as agents and defend larger models against jailbreak attacks. Our experiments show that AutoDefense can effectively defense against different jailbreak attacks, while maintaining the performance at normal user request. For example, we reduce the attack success rate on GPT-3.5 from 55.74% to 7.95% using LLaMA-2-13b with a 3-agent system. Our code and data are publicly available at https://github.com/XHMY/AutoDefense.", "pdf_url": "https://arxiv.org/pdf/2403.04783.pdf", "pdf_filename": "2024-03-02_AutoDefense__Multi-Agent_LLM_Defense_against_Jailb.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-02_AutoDefense__Multi-Agent_LLM_Defense_against_Jailb.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "6e212b711e334ae4df26bbd57dc8eab925f98474", "publication_date": "2024-12-02", "title": "MALT: Improving Reasoning with Multi-Agent LLM Training", "authors": "S. Motwani, Chandler Smith, Rocktim Jyoti Das, Markian Rybchuk, Philip Torr, Ivan Laptev, Fabio Pizzati, Ronald Clark, Christian Schr\u00f6der de Witt", "venue": "arXiv.org", "citation_count": 13, "influential_citation_count": 1, "abstract": "Large Language Models (LLMs) often produce answers with a single chain-of-thought, which restricts their ability to explore reasoning paths or self-correct flawed outputs in complex tasks. In this paper, we introduce MALT (Multi-Agent LLM Training), a novel post-training strategy that divides the reasoning process into generation, verification, and refinement steps using a sequential pipeline of heterogeneous agents. During data generation, each agent is repeatedly sampled to form a multi-agent search tree, where final outputs are graded against ground-truth data. We then apply value iteration to propagate reward signals back to each role-conditioned model, automatically producing multi-agent post-training data without human or teacher-model supervision. Our off-policy approach allows each agent to specialize by learning from correct and incorrect trajectories, ultimately improving the end-to-end reasoning chain. On MATH, GSM8K, and CSQA, MALT surpasses the same baseline LLM with a relative improvement of 15.66%, 7.42%, and 9.40% respectively, making it an important advance towards multi-agent cooperative training.", "pdf_url": "https://arxiv.org/pdf/2412.01928.pdf", "pdf_filename": "2024-12-02_MALT__Improving_Reasoning_with_Multi-Agent_LLM_Tra.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-02_MALT__Improving_Reasoning_with_Multi-Agent_LLM_Tra.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "efde8940a0b924e93d35184c4a1e8f9670b94fe7", "publication_date": "2024-10-03", "title": "AutoML-Agent: A Multi-Agent LLM Framework for Full-Pipeline AutoML", "authors": "Patara Trirat, Wonyong Jeong, Sung Ju Hwang", "venue": "arXiv.org", "citation_count": 15, "influential_citation_count": 0, "abstract": "Automated machine learning (AutoML) accelerates AI development by automating tasks in the development pipeline, such as optimal model search and hyperparameter tuning. Existing AutoML systems often require technical expertise to set up complex tools, which is in general time-consuming and requires a large amount of human effort. Therefore, recent works have started exploiting large language models (LLM) to lessen such burden and increase the usability of AutoML frameworks via a natural language interface, allowing non-expert users to build their data-driven solutions. These methods, however, are usually designed only for a particular process in the AI development pipeline and do not efficiently use the inherent capacity of the LLMs. This paper proposes AutoML-Agent, a novel multi-agent framework tailored for full-pipeline AutoML, i.e., from data retrieval to model deployment. AutoML-Agent takes user's task descriptions, facilitates collaboration between specialized LLM agents, and delivers deployment-ready models. Unlike existing work, instead of devising a single plan, we introduce a retrieval-augmented planning strategy to enhance exploration to search for more optimal plans. We also decompose each plan into sub-tasks (e.g., data preprocessing and neural network design) each of which is solved by a specialized agent we build via prompting executing in parallel, making the search process more efficient. Moreover, we propose a multi-stage verification to verify executed results and guide the code generation LLM in implementing successful solutions. Extensive experiments on seven downstream tasks using fourteen datasets show that AutoML-Agent achieves a higher success rate in automating the full AutoML process, yielding systems with good performance throughout the diverse domains.", "pdf_url": "https://arxiv.org/pdf/2410.02958.pdf", "pdf_filename": "2024-10-03_AutoML-Agent__A_Multi-Agent_LLM_Framework_for_Full.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_AutoML-Agent__A_Multi-Agent_LLM_Framework_for_Full.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "b92ec2ef54e4df2d08cbc66e4dda3e37b6362dbd", "publication_date": "2024-10-03", "title": "Towards Implicit Bias Detection and Mitigation in Multi-Agent LLM Interactions", "authors": "Ziwei Ji, Tiezheng Yu, Yan Xu, Nayeon Lee, Albert Q. Jiang, Alexandre Sablayrolles, Arthur Men-655, Chris Bamford, Devendra Singh, Diego Chaplot, laume Lample, L\u00e9lio Lucile Saulnier, Renard Lavaud, M. Lachaux, Pierre Stock, Teven Le Scao, Jerry Kang, Mark W. Bennett, Devon Carbado, Pam Casey, P. Liang, Chiyu Wu, Louis-philippe Morency, Aman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri Alon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, Shashank Gupta, Bodhisattwa Prasad Majumder, Katherine Hermann, S. Welleck, Amir Yazdan Bakhsh, ing Bao, Mo Bavarian, J. Belgum, Ir-wan Bello, Jake Berdine, Gabriel Bernadett-Shapiro, Christopher Berner, Lenny Bogdonoff, Oleg Boiko, Made-laine Boyd, Anna-Luisa Brakman, Greg Brock-724 man, Tim Brooks, M. Brundage, Kevin Button, Trevor Cai, Rosie Campbell, Andrew Cann, Brittany Carey, Chelsea Carlson, Rory Carmichael, Brooke Chan, Che Chang, Fotis Chantzis, Derek Chen, Su-Hong Chen, Ruby Chen, Jason Chen, Mark Chen, Benjamin Chess, Chester Cho, Hyung Casey Chu, Won Chung, Dave Cummings, Jeremiah Currier, Yunxing Dai, Tarun Goel, Gabriel Gogineni, Rapha Goh, Jonathan Gontijo-738 Lopes, Morgan Gordon, Scott Grafstein, Ryan Gray, Joshua Greene, Shixiang Shane Gross, Yufei Gu, Chris Guo, Jesse Hallacy, Jeff Han, Harris Yuchen, Mike He, Johannes Heaton, C. Heidecke, Alan Hesse, W. Hickey, Peter Hickey, Hoeschele Brandon, Kenny Houghton, Shengli Hsu, Xin Hu, Joost Hu, Shantanu Huizinga, Shawn Jain, Jain Joanne, Angela Jang, Roger Jiang, Haozhun Jiang, Denny Jin, Shino Jin, Billie Jomoto, Hee-woo Jonn, Tomer Jun, \u0141ukasz Kaftan, Ali Kaiser, Ingmar Ka-748 mali, Kanitscheider, Nitish Shirish, Keskar Tabarak, Logan Khan, J. Kilpatrick, Kim, Christina Kim, Yongjik Kim, Jan Hendrik Kirch-751 ner, J. Kiros, Matthew Knight, Daniel Kokotajlo, \u0141ukasz Kondraciuk, Andrew Kondrich, Aris Kon-753 stantinidis, Kyle Kosic, Gretchen Krueger, Vishal Kuo, Michael Lampe, Ikai Lan, Teddy Lee, Jan Leike, Jade Leung, Chak Daniel Levy, Ming Li, Rachel Lim, Molly Lin, Stephanie Lin, Ma-teusz Litwin, Theresa Lopez, Ryan Lowe, Patricia Lue, A. Makanju, Kim Malfacini, Sam Manning, Todor Markov, Yaniv Markovski, Bianca Martin, Katie Mayer, Andrew Mayne, Bob McGrew, S. McKinney, Christine McLeavey, Paul McMillan, Jake McNeil, David Medina, Aalok Mehta, Jacob Menick, Luke Metz, An-drey Mishchenko, Pamela Mishkin, Vinnie Monaco, Evan Morikawa, Daniel P. Mossing, Tong Mu, Mira Murati, O. Murk, David M\u00e9ly, Ashvin Nair, Reiichiro Nakano, Rajeev Nayak, Arvind Neelakantan, Richard Ngo, Hyeonwoo Noh, Ouyang Long, Cullen O'Keefe, J. Pachocki, A. Paino, Joe Palermo, Ashley Pantuliano, Carl Ross, Bob Rotsted, Henri Roussez, Nick Ry-779 der, Mario D. Saltarelli, Ted Sanders, Shibani Santurkar, Girish Sastry, Heather Schmidt, David Schnurr, John Schulman, Daniel Selsam, Kyla Sheppard, Toki Sherbakov, Jessica Shieh, Sarah Shoker, Pranav Shyam, Szymon Sidor, Eric Sigler, Maddie Simens, Jordan Sitkin, Katarina Slama, Ian Sohl, Benjamin Sokolowsky, Yang Song, Natalie Staudacher, Clemens Winter, Samuel Wolrich, Hannah Wong, Lauren Workman, Sherwin Wu, Jeff Wu, Michael Wu, Kai Xiao, Tao Xu, Sarah Yoo, Kevin Yu, Qim-ing Yuan, Wojciech Zaremba, Rowan Zellers, Chong Zhang, Marvin Zhang, Tianhao Shengjia Zhao, Xu Jiang, Diogo Almeida, Carroll L. Wainwright, Sandhini Agarwal, Alex Gray, Jacob Hilton, Fraser Kelton, Luke Miller, Amanda Askell, P. Welinder, Paul F. Christiano, Joon Sung Park, Joseph O\u2019Brien, Carrie J. Cai, Ringel Morris, Percy Liang, Michael S. Bern-814, Alec Radford, Karthik Narasimhan, Tim Salimans, Rachel Rudinger, Jason Naradowsky, Brian Leonard, Nisan Stiennon, Ryan Ziegler, Chelsea Lowe, Alec Voss, Radford, Dario Amodei, Christiano. 2020. Learn-842, Tony Sun, Andrew Gaut, Shirlyn Tang, Yuxin Huang, Mai ElSherief, Jie Zhao, Diba Mirza, Kai-Wei Belding, Chang William, Yang Wang, Yixin Wan, George Pu, Jiao Sun, Aparna Garimella, Kai-Wei Chang, Nanyun Peng, \u201ckelly", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 11, "influential_citation_count": 0, "abstract": "As Large Language Models (LLMs) continue to evolve, they are increasingly being employed in numerous studies to simulate societies and execute diverse social tasks. However, LLMs are susceptible to societal biases due to their exposure to human-generated data. Given that LLMs are being used to gain insights into various societal aspects, it is essential to mitigate these biases. To that end, our study investigates the presence of implicit gender biases in multi-agent LLM interactions and proposes two strategies to mitigate these biases. We begin by creating a dataset of scenarios where implicit gender biases might arise, and subsequently develop a metric to assess the presence of biases. Our empirical analysis reveals that LLMs generate outputs characterized by strong implicit bias associations (>= 50\\% of the time). Furthermore, these biases tend to escalate following multi-agent interactions. To mitigate them, we propose two strategies: self-reflection with in-context examples (ICE); and supervised fine-tuning. Our research demonstrates that both methods effectively mitigate implicit biases, with the ensemble of fine-tuning and self-reflection proving to be the most successful.", "pdf_url": "https://arxiv.org/pdf/2410.02584.pdf", "pdf_filename": "2024-10-03_Towards_Implicit_Bias_Detection_and_Mitigation_in_.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_Towards_Implicit_Bias_Detection_and_Mitigation_in_.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "2c797fb1f140f254d4bcdbfadcb34e246dca6564", "publication_date": "2024", "title": "Conformity, Confabulation, and Impersonation: Persona Inconstancy in Multi-Agent LLM Collaboration", "authors": "Razan Baltaji, Babak Hemmatian, L. Varshney", "venue": "C3NLP", "citation_count": 8, "influential_citation_count": 1, "abstract": "This study explores the sources of instability in maintaining cultural personas and opinions within multi-agent LLM systems. Drawing on simulations of inter-cultural collaboration and debate, we analyze agents\u2019 pre- and post-discussion private responses alongside chat transcripts to assess the stability of cultural personas and the impact of opinion diversity on group outcomes. Our findings suggest that multi-agent discussions can encourage collective decisions that reflect diverse perspectives, yet this benefit is tempered by the agents\u2019 susceptibility to conformity due to perceived peer pressure and challenges in maintaining consistent personas and opinions. Counterintuitively, instructions that encourage debate in support of one\u2019s opinions increase the rate of instability. Without addressing the factors we identify, the full potential of multi-agent frameworks for producing more culturally diverse AI outputs will remain untapped.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "c83b6a023a5c5ec71b44920a41b41fc007266c44", "publication_date": "2025-03-17", "title": "Why Do Multi-Agent LLM Systems Fail?", "authors": "Mert Cemri, Melissa Z. Pan, Shuyi Yang, Lakshya A. Agrawal, Bhavya Chopra, Rishabh Tiwari, Kurt Keutzer, Aditya Parameswaran, Dan Klein, K. Ramchandran, Matei Zaharia, Joseph E. Gonzalez, Ion Stoica", "venue": "arXiv.org", "citation_count": 28, "influential_citation_count": 4, "abstract": "Despite growing enthusiasm for Multi-Agent LLM Systems (MAS), their performance gains on popular benchmarks often remain minimal compared with single-agent frameworks. This gap highlights the need to systematically analyze the challenges hindering MAS effectiveness. We present MAST (Multi-Agent System Failure Taxonomy), the first empirically grounded taxonomy designed to understand MAS failures. We analyze seven popular MAS frameworks across over 200 tasks, involving six expert human annotators. Through this process, we identify 14 unique failure modes, organized into 3 overarching categories, (i) specification issues, (ii) inter-agent misalignment, and (iii) task verification. MAST emerges iteratively from rigorous inter-annotator agreement studies, achieving a Cohen's Kappa score of 0.88. To support scalable evaluation, we develop a validated LLM-as-a-Judge pipeline integrated with MAST. We leverage two case studies to demonstrate MAST's practical utility in analyzing failures and guiding MAS development. Our findings reveal that identified failures require more complex solutions, highlighting a clear roadmap for future research. We open source our comprehensive dataset and LLM annotator to facilitate further development of MAS.", "pdf_url": "https://arxiv.org/pdf/2503.13657.pdf", "pdf_filename": "2025-03-17_Why_Do_Multi-Agent_LLM_Systems_Fail_.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-17_Why_Do_Multi-Agent_LLM_Systems_Fail_.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "d0aab1a022d8ebe3afc83f3c21a52e50e5759494", "publication_date": "2024-12-22", "title": "KG4Diagnosis: A Hierarchical Multi-Agent LLM Framework with Knowledge Graph Enhancement for Medical Diagnosis", "authors": "Kaiwen Zuo, Yirui Jiang, Fan Mo, Pietro Lio", "venue": "arXiv.org", "citation_count": 9, "influential_citation_count": 0, "abstract": "Integrating Large Language Models (LLMs) in healthcare diagnosis demands systematic frameworks that can handle complex medical scenarios while maintaining specialized expertise. We present KG4Diagnosis, a novel hierarchical multi-agent framework that combines LLMs with automated knowledge graph construction, encompassing 362 common diseases across medical specialties. Our framework mirrors real-world medical systems through a two-tier architecture: a general practitioner (GP) agent for initial assessment and triage, coordinating with specialized agents for in-depth diagnosis in specific domains. The core innovation lies in our end-to-end knowledge graph generation methodology, incorporating: (1) semantic-driven entity and relation extraction optimized for medical terminology, (2) multi-dimensional decision relationship reconstruction from unstructured medical texts, and (3) human-guided reasoning for knowledge expansion. KG4Diagnosis serves as an extensible foundation for specialized medical diagnosis systems, with capabilities to incorporate new diseases and medical knowledge. The framework's modular design enables seamless integration of domain-specific enhancements, making it valuable for developing targeted medical diagnosis systems. We provide architectural guidelines and protocols to facilitate adoption across medical contexts.", "pdf_url": "https://arxiv.org/pdf/2412.16833.pdf", "pdf_filename": "2024-12-22_KG4Diagnosis__A_Hierarchical_Multi-Agent_LLM_Frame.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-22_KG4Diagnosis__A_Hierarchical_Multi-Agent_LLM_Frame.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "1343c620c0625c95e32d9735ece30ff0a702a879", "publication_date": "2024-12-29", "title": "Planning, Living and Judging: A Multi-agent LLM-based Framework for Cyclical Urban Planning", "authors": "Hang Ni, Yuzhi Wang, Hao Liu", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Urban regeneration presents significant challenges within the context of urbanization, requiring adaptive approaches to tackle evolving needs. Leveraging advancements in large language models (LLMs), we propose Cyclical Urban Planning (CUP), a new paradigm that continuously generates, evaluates, and refines urban plans in a closed-loop. Specifically, our multi-agent LLM-based framework consists of three key components: (1) Planning, where LLM agents generate and refine urban plans based on contextual data; (2) Living, where agents simulate the behaviors and interactions of residents, modeling life in the urban environment; and (3) Judging, which involves evaluating plan effectiveness and providing iterative feedback for improvement. The cyclical process enables a dynamic and responsive planning approach. Experiments on the real-world dataset demonstrate the effectiveness of our framework as a continuous and adaptive planning process.", "pdf_url": "https://arxiv.org/pdf/2412.20505.pdf", "pdf_filename": "2024-12-29_Planning__Living_and_Judging__A_Multi-agent_LLM-ba.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-29_Planning__Living_and_Judging__A_Multi-agent_LLM-ba.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "6b9e4b6803b8eb8bbe3b72c14fce90a853311503", "publication_date": "2024", "title": "Synthetic Arabic Medical Dialogues Using Advanced Multi-Agent LLM Techniques", "authors": "Mariam Almutairi, Lulwah Alkulaib, M. Aktas, Sara A. Alsalamah, Chang-Tien Lu", "venue": "ARABICNLP", "citation_count": 3, "influential_citation_count": 0, "abstract": "The increasing use of artificial intelligence in healthcare requires robust datasets for training and validation, particularly in the domain of medical conversations. However, the creation and accessibility of such datasets in Arabic face significant challenges, especially due to the sensitivity and privacy concerns that are associated with medical conversations. These conversations are rarely recorded or preserved, making the availability of comprehensive Arabic medical dialogue datasets scarce. This limitation slows down not only the development of effective natural language processing models but also restricts the opportunity for open comparison of algorithms and their outcomes. Recent advancements in large language models (LLMs) like ChatGPT, GPT-4, Gemini-pro, and Claude-3 show promising capabilities in generating synthetic data. To address this gap, we introduce a novel Multi-Agent LLM approach capable of generating synthetic Arabic medical dialogues from patient notes, regardless of the original language. This development presents a significant step towards overcoming the barriers in dataset availability, enhancing the potential for broader research and application in AI-driven medical dialogue systems.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "6130bafdaa0e4c22ffc7844ba2bd4e5cf8ba5451", "publication_date": "2024-11-22", "title": "Regulator-Manufacturer AI Agents Modeling: Mathematical Feedback-Driven Multi-Agent LLM Framework", "authors": "Yu Han, Zekun Guo", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "The increasing complexity of regulatory updates from global authorities presents significant challenges for medical device manufacturers, necessitating agile strategies to sustain compliance and maintain market access. Concurrently, regulatory bodies must effectively monitor manufacturers' responses and develop strategic surveillance plans. This study employs a multi-agent modeling approach, enhanced with Large Language Models (LLMs), to simulate regulatory dynamics and examine the adaptive behaviors of key actors, including regulatory bodies, manufacturers, and competitors. These agents operate within a simulated environment governed by regulatory flow theory, capturing the impacts of regulatory changes on compliance decisions, market adaptation, and innovation strategies. Our findings illuminate the influence of regulatory shifts on industry behaviour and identify strategic opportunities for improving regulatory practices, optimizing compliance, and fostering innovation. By leveraging the integration of multi-agent systems and LLMs, this research provides a novel perspective and offers actionable insights for stakeholders navigating the evolving regulatory landscape of the medical device industry.", "pdf_url": "https://arxiv.org/pdf/2411.15356.pdf", "pdf_filename": "2024-11-22_Regulator-Manufacturer_AI_Agents_Modeling__Mathema.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-22_Regulator-Manufacturer_AI_Agents_Modeling__Mathema.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "8e39c6435cd4b030c32065a72ef4d97358323852", "publication_date": "2024-07-30", "title": "Forensic Analysis of Artifacts from Microsoft's Multi-Agent LLM Platform AutoGen", "authors": "Clinton Walker, Taha Gharaibeh, Ruba Alsmadi, C. Hall, Ibrahim M. Baggili", "venue": "ARES", "citation_count": 2, "influential_citation_count": 0, "abstract": "Innovations in technology bring new challenges that need to be addressed, especially in the field of technical artifact discovery and analysis that enables digital forensic practitioners. Digital forensic analysis of these innovations is a constant challenge for digital investigators. In the rapidly evolving landscape of Artificial Intelligence (AI), keeping up with the digital forensic analysis of each new tool is a difficult task. New, advanced Large Language Model (LLM)s can produce human-like artifacts because of their complex textual processing capabilities. One of the newest innovations is a multi-agent Large Language Model (LLM) framework by Microsoft called AutoGen. AutoGen enables the creation of a team of specialist Large Language Model (LLM)-backed agents where the agents \"chat\" with each other to plan, iterate, and determine when a given task is complete. Typically one of the agents represents the human user while the other agents work autonomously after the human gives each agent a responsibility on the team. Thus, from a digital forensics perspective, it is necessary to determine which artifacts are created by the human user and which artifacts are created by the autonomous agents. Analysis in this work indicates that the current implementation of AutoGen has little in artifacts for attribution outside of particular memory artifacts, yet has strong indicators of usage in disk and network artifacts. Our research provides the initial account on the digital artifacts of the Large Language Model (LLM) technology AutoGen and first artifact examination for a Large Language Model (LLM) framework.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "03702ca194d23145b9b9b2ed2f31145e08366436", "publication_date": "2024-10-30", "title": "ACC-Collab: An Actor-Critic Approach to Multi-Agent LLM Collaboration", "authors": "Andrew Estornell, Jean-Fran\u00e7ois Ton, Yuanshun Yao, Yang Liu", "venue": "International Conference on Learning Representations", "citation_count": 2, "influential_citation_count": 0, "abstract": "Large language models (LLMs) have demonstrated a remarkable ability to serve as general-purpose tools for various language-based tasks. Recent works have demonstrated that the efficacy of such models can be improved through iterative dialog between multiple models. While these paradigms show promise in improving model efficacy, most works in this area treat collaboration as an emergent behavior, rather than a learned behavior. In doing so, current multi-agent frameworks rely on collaborative behaviors to have been sufficiently trained into off-the-shelf models. To address this limitation, we propose ACC-Collab, an Actor-Critic based learning framework to produce a two-agent team (an actor-agent and a critic-agent) specialized in collaboration. We demonstrate that ACC-Collab outperforms SotA multi-agent techniques on a wide array of benchmarks.", "pdf_url": "https://arxiv.org/pdf/2411.00053.pdf", "pdf_filename": "2024-10-30_ACC-Collab__An_Actor-Critic_Approach_to_Multi-Agen.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-30_ACC-Collab__An_Actor-Critic_Approach_to_Multi-Agen.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "0fcf26cf17ecc9e2cc2aea069c6f8a3eccd375a4", "publication_date": "2025-03-31", "title": "Agents Under Siege: Breaking Pragmatic Multi-Agent LLM Systems with Optimized Prompt Attacks", "authors": "Rana Muhammad Shahroz Khan, Zhen Tan, Sukwon Yun, Charles Flemming, Tianlong Chen", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 1, "abstract": "Most discussions about Large Language Model (LLM) safety have focused on single-agent settings but multi-agent LLM systems now create novel adversarial risks because their behavior depends on communication between agents and decentralized reasoning. In this work, we innovatively focus on attacking pragmatic systems that have constrains such as limited token bandwidth, latency between message delivery, and defense mechanisms. We design a $\\textit{permutation-invariant adversarial attack}$ that optimizes prompt distribution across latency and bandwidth-constraint network topologies to bypass distributed safety mechanisms within the system. Formulating the attack path as a problem of $\\textit{maximum-flow minimum-cost}$, coupled with the novel $\\textit{Permutation-Invariant Evasion Loss (PIEL)}$, we leverage graph-based optimization to maximize attack success rate while minimizing detection risk. Evaluating across models including $\\texttt{Llama}$, $\\texttt{Mistral}$, $\\texttt{Gemma}$, $\\texttt{DeepSeek}$ and other variants on various datasets like $\\texttt{JailBreakBench}$ and $\\texttt{AdversarialBench}$, our method outperforms conventional attacks by up to $7\\times$, exposing critical vulnerabilities in multi-agent systems. Moreover, we demonstrate that existing defenses, including variants of $\\texttt{Llama-Guard}$ and $\\texttt{PromptGuard}$, fail to prohibit our attack, emphasizing the urgent need for multi-agent specific safety mechanisms.", "pdf_url": "https://arxiv.org/pdf/2504.00218.pdf", "pdf_filename": "2025-03-31_Agents_Under_Siege__Breaking_Pragmatic_Multi-Agent.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-31_Agents_Under_Siege__Breaking_Pragmatic_Multi-Agent.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "a9c0d81fcf801fa689e04438289e09098659c1dd", "publication_date": "2025-04-24", "title": "A RAG-Based Multi-Agent LLM System for Natural Hazard Resilience and Adaptation", "authors": "Yangxinyu Xie, Bowen Jiang, Tanwi Mallick, J. Bergerson, John K. Hutchison, Duane R. Verner, Jordan Branham, M. R. Alexander, Robert B. Ross, Yan Feng, L. Levy, Weijie J. Su, C. J. Taylor", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "Large language models (LLMs) are a transformational capability at the frontier of artificial intelligence and machine learning that can support decision-makers in addressing pressing societal challenges such as extreme natural hazard events. As generalized models, LLMs often struggle to provide context-specific information, particularly in areas requiring specialized knowledge. In this work we propose a retrieval-augmented generation (RAG)-based multi-agent LLM system to support analysis and decision-making in the context of natural hazards and extreme weather events. As a proof of concept, we present WildfireGPT, a specialized system focused on wildfire hazards. The architecture employs a user-centered, multi-agent design to deliver tailored risk insights across diverse stakeholder groups. By integrating natural hazard and extreme weather projection data, observational datasets, and scientific literature through an RAG framework, the system ensures both the accuracy and contextual relevance of the information it provides. Evaluation across ten expert-led case studies demonstrates that WildfireGPT significantly outperforms existing LLM-based solutions for decision support.", "pdf_url": "https://arxiv.org/pdf/2504.17200.pdf", "pdf_filename": "2025-04-24_A_RAG-Based_Multi-Agent_LLM_System_for_Natural_Haz.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-24_A_RAG-Based_Multi-Agent_LLM_System_for_Natural_Haz.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "5bd02af3887d41a79aba5c5ac614bf7d980d0519", "publication_date": "2024-11-05", "title": "SAUCE: Synchronous and Asynchronous User-Customizable Environment for Multi-Agent LLM Interaction", "authors": "Shlomo Neuberger, Niv Eckhaus, Uri Berger, Amir Taubenfeld, Gabriel Stanovsky, Ariel Goldstein", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "Many human interactions, such as political debates, are carried out in group settings, where there are arbitrarily many participants, each with different views and agendas. To explore such complex social settings, we present SAUCE: a customizable Python platform, allowing researchers to plug-and-play various LLMs participating in discussions on any topic chosen by the user. Our platform takes care of instantiating the models, scheduling their responses, managing the discussion history, and producing a comprehensive output log, all customizable through configuration files, requiring little to no coding skills. A novel feature of SAUCE is our asynchronous communication feature, where models decide when to speak in addition to what to say, thus modeling an important facet of human communication. We show SAUCE's attractiveness in two initial experiments, and invite the community to use it in simulating various group simulations.", "pdf_url": "https://arxiv.org/pdf/2411.03397.pdf", "pdf_filename": "2024-11-05_SAUCE__Synchronous_and_Asynchronous_User-Customiza.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-05_SAUCE__Synchronous_and_Asynchronous_User-Customiza.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "646aa75e6394652f265da46ee5c07cc804210f8c", "publication_date": "2023-12-24", "title": "Agent4Ranking: Semantic Robust Ranking via Personalized Query Rewriting Using Multi-agent LLM", "authors": "Xiaopeng Li, Lixin Su, Pengyue Jia, Xiangyu Zhao, Suqi Cheng, Junfeng Wang, Dawei Yin", "venue": "arXiv.org", "citation_count": 15, "influential_citation_count": 0, "abstract": "Search engines are crucial as they provide an efficient and easy way to access vast amounts of information on the internet for diverse information needs. User queries, even with a specific need, can differ significantly. Prior research has explored the resilience of ranking models against typical query variations like paraphrasing, misspellings, and order changes. Yet, these works overlook how diverse demographics uniquely formulate identical queries. For instance, older individuals tend to construct queries more naturally and in varied order compared to other groups. This demographic diversity necessitates enhancing the adaptability of ranking models to diverse query formulations. To this end, in this paper, we propose a framework that integrates a novel rewriting pipeline that rewrites queries from various demographic perspectives and a novel framework to enhance ranking robustness. To be specific, we use Chain of Thought (CoT) technology to utilize Large Language Models (LLMs) as agents to emulate various demographic profiles, then use them for efficient query rewriting, and we innovate a robust Multi-gate Mixture of Experts (MMoE) architecture coupled with a hybrid loss function, collectively strengthening the ranking models' robustness. Our extensive experimentation on both public and industrial datasets assesses the efficacy of our query rewriting approach and the enhanced accuracy and robustness of the ranking model. The findings highlight the sophistication and effectiveness of our proposed model.", "pdf_url": "https://arxiv.org/pdf/2312.15450.pdf", "pdf_filename": "2023-12-24_Agent4Ranking__Semantic_Robust_Ranking_via_Persona.pdf", "markdown_path": "data/semantic/markdown_files/2023-12-24_Agent4Ranking__Semantic_Robust_Ranking_via_Persona.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "356b85ae926b2a8b4cd794e10fe8f37891ebf8d7", "publication_date": "2025-03-15", "title": "SagaLLM: Context Management, Validation, and Transaction Guarantees for Multi-Agent LLM Planning", "authors": "Edward Y. Chang, Longling Geng", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Recent LLM-based agent frameworks have demonstrated impressive capabilities in task delegation and workflow orchestration, but face significant challenges in maintaining context awareness and ensuring planning consistency. This paper presents SagaLLM, a structured multi-agent framework that addresses four fundamental limitations in current LLM approaches: inadequate self-validation, context narrowing, lacking transaction properties, and insufficient inter-agent coordination. By implementing specialized context management agents and validation protocols, SagaLLM preserves critical constraints and state information throughout complex planning processes, enabling robust and consistent decision-making even during disruptions. We evaluate our approach using selected problems from the REALM benchmark, focusing on sequential and reactive planning scenarios that challenge both context retention and adaptive reasoning. Our experiments with state-of-the-art LLMs, Claude 3.7, DeepSeek R1, GPT-4o, and GPT-o1, demonstrate that while these models exhibit impressive reasoning capabilities, they struggle with maintaining global constraint awareness during complex planning tasks, particularly when adapting to unexpected changes. In contrast, the distributed cognitive architecture of SagaLLM shows significant improvements in planning consistency, constraint enforcement, and adaptation to disruptions in various scenarios.", "pdf_url": "https://arxiv.org/pdf/2503.11951.pdf", "pdf_filename": "2025-03-15_SagaLLM__Context_Management__Validation__and_Trans.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-15_SagaLLM__Context_Management__Validation__and_Trans.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "50bc4f98893dde3039a0d1b11145963c165c2f94", "publication_date": "2025-02-03", "title": "PlotGen: Multi-Agent LLM-based Scientific Data Visualization via Multimodal Feedback", "authors": "Kanika Goswami, Puneet Mathur, Ryan A. Rossi, Franck Dernoncourt", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Scientific data visualization is pivotal for transforming raw data into comprehensible visual representations, enabling pattern recognition, forecasting, and the presentation of data-driven insights. However, novice users often face difficulties due to the complexity of selecting appropriate tools and mastering visualization techniques. Large Language Models (LLMs) have recently demonstrated potential in assisting code generation, though they struggle with accuracy and require iterative debugging. In this paper, we propose PlotGen, a novel multi-agent framework aimed at automating the creation of precise scientific visualizations. PlotGen orchestrates multiple LLM-based agents, including a Query Planning Agent that breaks down complex user requests into executable steps, a Code Generation Agent that converts pseudocode into executable Python code, and three retrieval feedback agents - a Numeric Feedback Agent, a Lexical Feedback Agent, and a Visual Feedback Agent - that leverage multimodal LLMs to iteratively refine the data accuracy, textual labels, and visual correctness of generated plots via self-reflection. Extensive experiments show that PlotGen outperforms strong baselines, achieving a 4-6 percent improvement on the MatPlotBench dataset, leading to enhanced user trust in LLM-generated visualizations and improved novice productivity due to a reduction in debugging time needed for plot errors.", "pdf_url": "https://arxiv.org/pdf/2502.00988.pdf", "pdf_filename": "2025-02-03_PlotGen__Multi-Agent_LLM-based_Scientific_Data_Vis.pdf", "markdown_path": "data/semantic/markdown_files/2025-02-03_PlotGen__Multi-Agent_LLM-based_Scientific_Data_Vis.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "f7a636f9fba4e3e2107569a68580ed1acbb5f639", "publication_date": "2025-04-02", "title": "Self-Resource Allocation in Multi-Agent LLM Systems", "authors": "Alfonso Amayuelas, Jingbo Yang, Saaket Agashe, Ashwin Nagarajan, Antonis Antoniades, Xin Eric Wang, W. Wang", "venue": "arXiv.org", "citation_count": 5, "influential_citation_count": 0, "abstract": "With the development of LLMs as agents, there is a growing interest in connecting multiple agents into multi-agent systems to solve tasks concurrently, focusing on their role in task assignment and coordination. This paper explores how LLMs can effectively allocate computational tasks among multiple agents, considering factors such as cost, efficiency, and performance. In this work, we address key questions, including the effectiveness of LLMs as orchestrators and planners, comparing their effectiveness in task assignment and coordination. Our experiments demonstrate that LLMs can achieve high validity and accuracy in resource allocation tasks. We find that the planner method outperforms the orchestrator method in handling concurrent actions, resulting in improved efficiency and better utilization of agents. Additionally, we show that providing explicit information about worker capabilities enhances the allocation strategies of planners, particularly when dealing with suboptimal workers.", "pdf_url": "https://arxiv.org/pdf/2504.02051.pdf", "pdf_filename": "2025-04-02_Self-Resource_Allocation_in_Multi-Agent_LLM_System.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-02_Self-Resource_Allocation_in_Multi-Agent_LLM_System.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "82f5b9da7ca932129f849f3fe7319e747855af37", "publication_date": "2025-03-18", "title": "MANTRA: Enhancing Automated Method-Level Refactoring with Contextual RAG and Multi-Agent LLM Collaboration", "authors": "Yisen Xu, Feng Lin, Jinqiu Yang, Tse-Hsun Chen, Nikolaos Tsantalis", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 1, "abstract": "Maintaining and scaling software systems relies heavily on effective code refactoring, yet this process remains labor-intensive, requiring developers to carefully analyze existing codebases and prevent the introduction of new defects. Although recent advancements have leveraged Large Language Models (LLMs) to automate refactoring tasks, current solutions are constrained in scope and lack mechanisms to guarantee code compilability and successful test execution. In this work, we introduce MANTRA, a comprehensive LLM agent-based framework that automates method-level refactoring. MANTRA integrates Context-Aware Retrieval-Augmented Generation, coordinated Multi-Agent Collaboration, and Verbal Reinforcement Learning to emulate human decision-making during refactoring while preserving code correctness and readability. Our empirical study, conducted on 703 instances of\"pure refactorings\"(i.e., code changes exclusively involving structural improvements), drawn from 10 representative Java projects, covers the six most prevalent refactoring operations. Experimental results demonstrate that MANTRA substantially surpasses a baseline LLM model (RawGPT ), achieving an 82.8% success rate (582/703) in producing code that compiles and passes all tests, compared to just 8.7% (61/703) with RawGPT. Moreover, in comparison to IntelliJ's LLM-powered refactoring tool (EM-Assist), MANTRA exhibits a 50% improvement in generating Extract Method transformations. A usability study involving 37 professional developers further shows that refactorings performed by MANTRA are perceived to be as readable and reusable as human-written code, and in certain cases, even more favorable. These results highlight the practical advantages of MANTRA and emphasize the growing potential of LLM-based systems in advancing the automation of software refactoring tasks.", "pdf_url": "https://arxiv.org/pdf/2503.14340.pdf", "pdf_filename": "2025-03-18_MANTRA__Enhancing_Automated_Method-Level_Refactori.pdf", "markdown_path": "data/semantic/markdown_files/2025-03-18_MANTRA__Enhancing_Automated_Method-Level_Refactori.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "b4e979f4407cd3dd7fee0b8a87eab6b571f38514", "publication_date": "2025-04-01", "title": "When Persuasion Overrides Truth in Multi-Agent LLM Debates: Introducing a Confidence-Weighted Persuasion Override Rate (CW-POR)", "authors": "Mahak Agarwal, Divyam Khanna", "venue": "arXiv.org", "citation_count": 2, "influential_citation_count": 0, "abstract": "In many real-world scenarios, a single Large Language Model (LLM) may encounter contradictory claims-some accurate, others forcefully incorrect-and must judge which is true. We investigate this risk in a single-turn, multi-agent debate framework: one LLM-based agent provides a factual answer from TruthfulQA, another vigorously defends a falsehood, and the same LLM architecture serves as judge. We introduce the Confidence-Weighted Persuasion Override Rate (CW-POR), which captures not only how often the judge is deceived but also how strongly it believes the incorrect choice. Our experiments on five open-source LLMs (3B-14B parameters), where we systematically vary agent verbosity (30-300 words), reveal that even smaller models can craft persuasive arguments that override truthful answers-often with high confidence. These findings underscore the importance of robust calibration and adversarial testing to prevent LLMs from confidently endorsing misinformation.", "pdf_url": "https://arxiv.org/pdf/2504.00374.pdf", "pdf_filename": "2025-04-01_When_Persuasion_Overrides_Truth_in_Multi-Agent_LLM.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-01_When_Persuasion_Overrides_Truth_in_Multi-Agent_LLM.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "7cac6fd998b511d0e58d6463e8212a0c3d3c28cd", "publication_date": "2025-04-09", "title": "Modeling Response Consistency in Multi-Agent LLM Systems: A Comparative Analysis of Shared and Separate Context Approaches", "authors": "Tooraj Helmi", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Large Language Models (LLMs) are increasingly utilized in multi-agent systems (MAS) to enhance collaborative problem-solving and interactive reasoning. Recent advancements have enabled LLMs to function as autonomous agents capable of understanding complex interactions across multiple topics. However, deploying LLMs in MAS introduces challenges related to context management, response consistency, and scalability, especially when agents must operate under memory limitations and handle noisy inputs. While prior research has explored optimizing context sharing and response latency in LLM-driven MAS, these efforts often focus on either fully centralized or decentralized configurations, each with distinct trade-offs. In this paper, we develop a probabilistic framework to analyze the impact of shared versus separate context configurations on response consistency and response times in LLM-based MAS. We introduce the Response Consistency Index (RCI) as a metric to evaluate the effects of context limitations, noise, and inter-agent dependencies on system performance. Our approach differs from existing research by focusing on the interplay between memory constraints and noise management, providing insights into optimizing scalability and response times in environments with interdependent topics. Through this analysis, we offer a comprehensive understanding of how different configurations impact the efficiency of LLM-driven multi-agent systems, thereby guiding the design of more robust architectures.", "pdf_url": "https://arxiv.org/pdf/2504.07303.pdf", "pdf_filename": "2025-04-09_Modeling_Response_Consistency_in_Multi-Agent_LLM_S.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-09_Modeling_Response_Consistency_in_Multi-Agent_LLM_S.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "b0ce81b9f302f4ce37648d6ef2a25dc80f88806b", "publication_date": "2024-12-01", "title": "Generating AI Literacy MCQs: A Multi-Agent LLM Approach", "authors": "Jiayi Wang, Ruiwei Xiao, Ying-Jui Tseng", "venue": "Technical Symposium on Computer Science Education", "citation_count": 0, "influential_citation_count": 0, "abstract": "Artificial intelligence (AI) is transforming society, making it crucial to prepare the next generation through AI literacy in K-12 education. However, scalable and reliable AI literacy materials and assessment resources are lacking. To address this gap, our study presents a novel approach to generating multiple-choice questions (MCQs) for AI literacy assessments. Our method utilizes large language models (LLMs) to automatically generate scalable, high-quality assessment questions. These questions align with user-provided learning objectives, grade levels, and Bloom's Taxonomy levels. We introduce an iterative workflow incorporating LLM-powered critique agents to ensure the generated questions meet pedagogical standards. In the preliminary evaluation, experts expressed strong interest in using the LLM-generated MCQs, indicating that this system could enrich existing AI literacy materials and provide a valuable addition to the toolkit of K-12 educators.", "pdf_url": "https://arxiv.org/pdf/2412.00970.pdf", "pdf_filename": "2024-12-01_Generating_AI_Literacy_MCQs__A_Multi-Agent_LLM_App.pdf", "markdown_path": "data/semantic/markdown_files/2024-12-01_Generating_AI_Literacy_MCQs__A_Multi-Agent_LLM_App.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "1a4c6856292b8c64d19a812a77f0aa6fd47cb96c", "publication_date": "2023", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation Framework", "authors": "Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Shaokun Zhang, Erkang Zhu, Beibin Li, Li Jiang, Xiaoyun Zhang, Chi Wang", "venue": "arXiv.org", "citation_count": 640, "influential_citation_count": 51, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "e89ee3f84f1f07229a7ba211bad3465d2c80a325", "publication_date": "2024-02-28", "title": "Rethinking the Bounds of LLM Reasoning: Are Multi-Agent Discussions the Key?", "authors": "Qineng Wang, Zihao Wang, Ying Su, Hanghang Tong, Yangqiu Song", "venue": "Annual Meeting of the Association for Computational Linguistics", "citation_count": 73, "influential_citation_count": 2, "abstract": "Recent progress in LLMs discussion suggests that multi-agent discussion improves the reasoning abilities of LLMs. In this work, we reevaluate this claim through systematic experiments, where we propose a novel group discussion framework to enrich the set of discussion mechanisms. Interestingly, our results show that a single-agent LLM with strong prompts can achieve almost the same performance as the best existing discussion approach on a wide range of reasoning tasks and backbone LLMs. We observe that the multi-agent discussion performs better than a single agent only when there is no demonstration in the prompt. Further study reveals the common interaction mechanisms of LLMs during the discussion.", "pdf_url": "https://arxiv.org/pdf/2402.18272.pdf", "pdf_filename": "2024-02-28_Rethinking_the_Bounds_of_LLM_Reasoning__Are_Multi-.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-28_Rethinking_the_Bounds_of_LLM_Reasoning__Are_Multi-.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "fc8ce12d6186ddaa797e2b36d5e8eb7921425308", "publication_date": "2024-10-08", "title": "A survey on LLM-based multi-agent systems: workflow, infrastructure, and challenges", "authors": "Xinyi Li, Sai Wang, Siqi Zeng, Yu Wu, Yi Yang", "venue": "Vicinagearth", "citation_count": 50, "influential_citation_count": 3, "abstract": "The pursuit of more intelligent and credible autonomous systems, akin to human society, has been a long-standing endeavor for humans. Leveraging the exceptional reasoning and planning capabilities of large language models (LLMs), LLM-based agents have been proposed and have achieved remarkable success across a wide array of tasks. Notably, LLM-based multi-agent systems (MAS) are considered a promising pathway towards realizing general artificial intelligence that is equivalent to or surpasses human-level intelligence. In this paper, we present a comprehensive survey of these studies, offering a systematic review of LLM-based MAS. Adhering to the workflow of LLM-based multi-agent systems, we synthesize a general structure encompassing five key components: profile, perception, self-action, mutual interaction, and evolution. This unified framework encapsulates much of the previous work in the field. Furthermore, we illuminate the extensive applications of LLM-based MAS in two principal areas: problem-solving and world simulation. Finally, we discuss in detail several contemporary challenges and provide insights into potential future directions in this domain.", "pdf_url": "https://link.springer.com/content/pdf/10.1007/s44336-024-00009-2.pdf", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "006c4c7470566327e5b02b94936d0be0033fc9f5", "publication_date": "2024-03-26", "title": "MAGIS: LLM-Based Multi-Agent Framework for GitHub Issue Resolution", "authors": "Wei Tao, Yucheng Zhou, Wenqiang Zhang, Yu-Xi Cheng", "venue": "Neural Information Processing Systems", "citation_count": 41, "influential_citation_count": 3, "abstract": "In software development, resolving the emergent issues within GitHub repositories is a complex challenge that involves not only the incorporation of new code but also the maintenance of existing code. Large Language Models (LLMs) have shown promise in code generation but face difficulties in resolving Github issues, particularly at the repository level. To overcome this challenge, we empirically study the reason why LLMs fail to resolve GitHub issues and analyze the major factors. Motivated by the empirical findings, we propose a novel LLM-based Multi-Agent framework for GitHub Issue reSolution, MAGIS, consisting of four agents customized for software evolution: Manager, Repository Custodian, Developer, and Quality Assurance Engineer agents. This framework leverages the collaboration of various agents in the planning and coding process to unlock the potential of LLMs to resolve GitHub issues. In experiments, we employ the SWE-bench benchmark to compare MAGIS with popular LLMs, including GPT-3.5, GPT-4, and Claude-2. MAGIS can resolve 13.94% GitHub issues, significantly outperforming the baselines. Specifically, MAGIS achieves an eight-fold increase in resolved ratio over the direct application of GPT-4, the advanced LLM.", "pdf_url": "https://arxiv.org/pdf/2403.17927.pdf", "pdf_filename": "2024-03-26_MAGIS__LLM-Based_Multi-Agent_Framework_for_GitHub_.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-26_MAGIS__LLM-Based_Multi-Agent_Framework_for_GitHub_.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "ab6f63877fdb55ce0b05964476e6fb303fc376af", "publication_date": "2024-04-26", "title": "A Unified Debugging Approach via LLM-Based Multi-Agent Synergy", "authors": "Cheryl Lee, Chun Xia, Jen-Tse Huang, Zhouruixing Zhu, Lingming Zhang, Michael R. Lyu", "venue": "", "citation_count": 35, "influential_citation_count": 4, "abstract": "Software debugging is a time-consuming endeavor involving a series of steps, such as fault localization and patch generation, each requiring thorough analysis and a deep understanding of the underlying logic. While large language models (LLMs) demonstrate promising potential in coding tasks, their performance in debugging remains limited. Current LLM-based methods often focus on isolated steps and struggle with complex bugs. In this paper, we propose the first end-to-end framework, FixAgent, for unified debugging through multi-agent synergy. It mimics the entire cognitive processes of developers, with each agent specialized as a particular component of this process rather than mirroring the actions of an independent expert as in previous multi-agent systems. Agents are coordinated through a three-level design, following a cognitive model of debugging, allowing adaptive handling of bugs with varying complexities. Experiments on extensive benchmarks demonstrate that FixAgent significantly outperforms state-of-the-art repair methods, fixing 1.25$\\times$ to 2.56$\\times$ bugs on the repo-level benchmark, Defects4J. This performance is achieved without requiring ground-truth root-cause code statements, unlike the baselines. Our source code is available on https://github.com/AcceptePapier/UniDebugger.", "pdf_url": "https://arxiv.org/pdf/2404.17153.pdf", "pdf_filename": "2024-04-26_A_Unified_Debugging_Approach_via_LLM-Based_Multi-A.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-26_A_Unified_Debugging_Approach_via_LLM-Based_Multi-A.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "c5cb68ac59f98fafc7cb96b86fca27e662e0cba8", "publication_date": "2024-04-02", "title": "Self-Organized Agents: A LLM Multi-Agent Framework toward Ultra Large-Scale Code Generation and Optimization", "authors": "Yoichi Ishibashi, Yoshimasa Nishimura", "venue": "arXiv.org", "citation_count": 38, "influential_citation_count": 3, "abstract": "Recent advancements in automatic code generation using large language model (LLM) agent have brought us closer to the future of automated software development. However, existing single-agent approaches face limitations in generating and improving large-scale, complex codebases due to constraints in context length. To tackle this challenge, we propose Self-Organized multi-Agent framework (SoA), a novel multi-agent framework that enables the scalable and efficient generation and optimization of large-scale code. In SoA, self-organized agents operate independently to generate and modify code components while seamlessly collaborating to construct the overall codebase. A key feature of our framework is the automatic multiplication of agents based on problem complexity, allowing for dynamic scalability. This enables the overall code volume to be increased indefinitely according to the number of agents, while the amount of code managed by each agent remains constant. We evaluate SoA on the HumanEval benchmark and demonstrate that, compared to a single-agent system, each agent in SoA handles significantly less code, yet the overall generated code is substantially greater. Moreover, SoA surpasses the powerful single-agent baseline by 5% in terms of Pass@1 accuracy.", "pdf_url": "https://arxiv.org/pdf/2404.02183.pdf", "pdf_filename": "2024-04-02_Self-Organized_Agents__A_LLM_Multi-Agent_Framework.pdf", "markdown_path": "data/semantic/markdown_files/2024-04-02_Self-Organized_Agents__A_LLM_Multi-Agent_Framework.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "6d1ef839db3d637977392f4a7046c26bfea37d46", "publication_date": "2024-02-05", "title": "LLM Multi-Agent Systems: Challenges and Open Problems", "authors": "Shanshan Han, Qifan Zhang, Yuhang Yao, Weizhao Jin, Zhaozhuo Xu, Chaoyang He", "venue": "arXiv.org", "citation_count": 42, "influential_citation_count": 3, "abstract": "This paper explores multi-agent systems and identify challenges that remain inadequately addressed. By leveraging the diverse capabilities and roles of individual agents, multi-agent systems can tackle complex tasks through agent collaboration. We discuss optimizing task allocation, fostering robust reasoning through iterative debates, managing complex and layered context information, and enhancing memory management to support the intricate interactions within multi-agent systems. We also explore potential applications of multi-agent systems in blockchain systems to shed light on their future development and application in real-world distributed systems.", "pdf_url": "https://arxiv.org/pdf/2402.03578.pdf", "pdf_filename": "2024-02-05_LLM_Multi-Agent_Systems__Challenges_and_Open_Probl.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-05_LLM_Multi-Agent_Systems__Challenges_and_Open_Probl.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "165921d2aa4f1d110d25d488ea8b205d134b16e6", "publication_date": "2024-10-09", "title": "Prompt Infection: LLM-to-LLM Prompt Injection within Multi-Agent Systems", "authors": "Donghyun Lee, Mo Tiwari", "venue": "arXiv.org", "citation_count": 20, "influential_citation_count": 3, "abstract": "As Large Language Models (LLMs) grow increasingly powerful, multi-agent systems are becoming more prevalent in modern AI applications. Most safety research, however, has focused on vulnerabilities in single-agent LLMs. These include prompt injection attacks, where malicious prompts embedded in external content trick the LLM into executing unintended or harmful actions, compromising the victim's application. In this paper, we reveal a more dangerous vector: LLM-to-LLM prompt injection within multi-agent systems. We introduce Prompt Infection, a novel attack where malicious prompts self-replicate across interconnected agents, behaving much like a computer virus. This attack poses severe threats, including data theft, scams, misinformation, and system-wide disruption, all while propagating silently through the system. Our extensive experiments demonstrate that multi-agent systems are highly susceptible, even when agents do not publicly share all communications. To address this, we propose LLM Tagging, a defense mechanism that, when combined with existing safeguards, significantly mitigates infection spread. This work underscores the urgent need for advanced security measures as multi-agent LLM systems become more widely adopted.", "pdf_url": "https://arxiv.org/pdf/2410.07283.pdf", "pdf_filename": "2024-10-09_Prompt_Infection__LLM-to-LLM_Prompt_Injection_with.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-09_Prompt_Infection__LLM-to-LLM_Prompt_Injection_with.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "8bf02bb6762641924feb5bade378ef57024cc534", "publication_date": "None", "title": "Reliable Decision-Making for Multi-Agent LLM Systems", "authors": "Xian Yeow, Shunichi Lee, Lasitha Akatsuka, Vidyaratne Aman, Ahmed Kumar, Chetan Farahat, Gupta", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "ec58a564fdda29e6a9a0a7bab5eeb4c290f716d7", "publication_date": "2023-08-14", "title": "ChatEval: Towards Better LLM-based Evaluators through Multi-Agent Debate", "authors": "Chi-Min Chan, Weize Chen, Yusheng Su, Jianxuan Yu, Wei Xue, Shan Zhang, Jie Fu, Zhiyuan Liu", "venue": "arXiv.org", "citation_count": 485, "influential_citation_count": 31, "abstract": "Text evaluation has historically posed significant challenges, often demanding substantial labor and time cost. With the emergence of large language models (LLMs), researchers have explored LLMs' potential as alternatives for human evaluation. While these single-agent-based approaches show promise, experimental results suggest that further advancements are needed to bridge the gap between their current effectiveness and human-level evaluation quality. Recognizing that best practices of human evaluation processes often involve multiple human annotators collaborating in the evaluation, we resort to a multi-agent debate framework, moving beyond single-agent prompting strategies. The multi-agent-based approach enables a group of LLMs to synergize with an array of intelligent counterparts, harnessing their distinct capabilities and expertise to enhance efficiency and effectiveness in handling intricate tasks. In this paper, we construct a multi-agent referee team called ChatEval to autonomously discuss and evaluate the quality of generated responses from different models on open-ended questions and traditional natural language generation (NLG) tasks. Our analysis shows that ChatEval transcends mere textual scoring, offering a human-mimicking evaluation process for reliable assessments. Our code is available at https://github.com/chanchimin/ChatEval.", "pdf_url": "https://arxiv.org/pdf/2308.07201", "pdf_filename": "2023-08-14_ChatEval__Towards_Better_LLM-based_Evaluators_thro.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-14_ChatEval__Towards_Better_LLM-based_Evaluators_thro.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "174fab182b3968879884a5af2ef2344ef2623516", "publication_date": "None", "title": "MASON - A Multi-Agent LLM Framework for No-Code Development", "authors": "Muhammed Roshan, Kayvan Palayamkot, Karim", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "e1b62c7ee4e22ab63e3b0c9968563e6675833e36", "publication_date": "2024-05-23", "title": "Towards Efficient LLM Grounding for Embodied Multi-Agent Collaboration", "authors": "Yang Zhang, Shixin Yang, Chenjia Bai, Fei Wu, Xiu Li, Xuelong Li, Zhen Wang", "venue": "arXiv.org", "citation_count": 31, "influential_citation_count": 1, "abstract": "Grounding the reasoning ability of large language models (LLMs) for embodied tasks is challenging due to the complexity of the physical world. Especially, LLM planning for multi-agent collaboration requires communication of agents or credit assignment as the feedback to re-adjust the proposed plans and achieve effective coordination. However, existing methods that overly rely on physical verification or self-reflection suffer from excessive and inefficient querying of LLMs. In this paper, we propose a novel framework for multi-agent collaboration that introduces Reinforced Advantage feedback (ReAd) for efficient self-refinement of plans. Specifically, we perform critic regression to learn a sequential advantage function from LLM-planned data, and then treat the LLM planner as an optimizer to generate actions that maximize the advantage function. It endows the LLM with the foresight to discern whether the action contributes to accomplishing the final task. We provide theoretical analysis by extending advantage-weighted regression in reinforcement learning to multi-agent systems. Experiments on Overcooked-AI and a difficult variant of RoCoBench show that ReAd surpasses baselines in success rate, and also significantly decreases the interaction steps of agents and query rounds of LLMs, demonstrating its high efficiency for grounding LLMs. More results are given at https://read-llm.github.io/.", "pdf_url": "https://arxiv.org/pdf/2405.14314.pdf", "pdf_filename": "2024-05-23_Towards_Efficient_LLM_Grounding_for_Embodied_Multi.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-23_Towards_Efficient_LLM_Grounding_for_Embodied_Multi.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "dd38755291d108ab86c68d1aac7485921bb8e647", "publication_date": "2024-05-17", "title": "LLM-based Multi-Agent Reinforcement Learning: Current and Future Directions", "authors": "Chuanneng Sun, Songjun Huang, D. Pompili", "venue": "arXiv.org", "citation_count": 32, "influential_citation_count": 0, "abstract": "In recent years, Large Language Models (LLMs) have shown great abilities in various tasks, including question answering, arithmetic problem solving, and poem writing, among others. Although research on LLM-as-an-agent has shown that LLM can be applied to Reinforcement Learning (RL) and achieve decent results, the extension of LLM-based RL to Multi-Agent System (MAS) is not trivial, as many aspects, such as coordination and communication between agents, are not considered in the RL frameworks of a single agent. To inspire more research on LLM-based MARL, in this letter, we survey the existing LLM-based single-agent and multi-agent RL frameworks and provide potential research directions for future research. In particular, we focus on the cooperative tasks of multiple agents with a common goal and communication among them. We also consider human-in/on-the-loop scenarios enabled by the language component in the framework.", "pdf_url": "https://arxiv.org/pdf/2405.11106.pdf", "pdf_filename": "2024-05-17_LLM-based_Multi-Agent_Reinforcement_Learning__Curr.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-17_LLM-based_Multi-Agent_Reinforcement_Learning__Curr.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "b93ac10de176c4a7aaa2cc652b90bb25636532cd", "publication_date": "2024-02-18", "title": "Benchmark Self-Evolving: A Multi-Agent Framework for Dynamic LLM Evaluation", "authors": "Siyuan Wang, Zhuohan Long, Zhihao Fan, Zhongyu Wei, Xuanjing Huang", "venue": "International Conference on Computational Linguistics", "citation_count": 32, "influential_citation_count": 2, "abstract": "This paper presents a benchmark self-evolving framework to dynamically evaluate rapidly advancing Large Language Models (LLMs), aiming for a more accurate assessment of their capabilities and limitations. We utilize a multi-agent system to manipulate the context or question of original instances, reframing new evolving instances with high confidence that dynamically extend existing benchmarks. Towards a more scalable, robust and fine-grained evaluation, we implement six reframing operations to construct evolving instances testing LLMs against diverse queries, data noise and probing their problem-solving sub-abilities. With this framework, we extend benchmark datasets of four tasks. Experimental results show a general performance decline in most LLMs against their original results. This decline under our scalable and robust evaluations, alongside our fine-grained evaluation, more accurately reflect models' capabilities. Besides, our framework widens performance discrepancies both between different models and within the same model across various tasks, facilitating more informed model selection for specific tasks (Code and data are available at https://github.com/NanshineLoong/Self-Evolving-Benchmark).", "pdf_url": "https://arxiv.org/pdf/2402.11443.pdf", "pdf_filename": "2024-02-18_Benchmark_Self-Evolving__A_Multi-Agent_Framework_f.pdf", "markdown_path": "data/semantic/markdown_files/2024-02-18_Benchmark_Self-Evolving__A_Multi-Agent_Framework_f.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "0b41a6899c29a04e1217e6cc80a3d915ea18e2d8", "publication_date": "2024-07-09", "title": "FinCon: A Synthesized LLM Multi-Agent System with Conceptual Verbal Reinforcement for Enhanced Financial Decision Making", "authors": "Yangyang Yu, Zhiyuan Yao, Haohang Li, Zhiyang Deng, Yupeng Cao, Zhi Chen, Jordan W. Suchow, Rong Liu, Zhenyu Cui, Denghui Zhang, K. Subbalakshmi, Guojun Xiong, Yueru He, Jimin Huang, Dong Li, Qianqian Xie", "venue": "Neural Information Processing Systems", "citation_count": 24, "influential_citation_count": 1, "abstract": "Large language models (LLMs) have demonstrated notable potential in conducting complex tasks and are increasingly utilized in various financial applications. However, high-quality sequential financial investment decision-making remains challenging. These tasks require multiple interactions with a volatile environment for every decision, demanding sufficient intelligence to maximize returns and manage risks. Although LLMs have been used to develop agent systems that surpass human teams and yield impressive investment returns, opportunities to enhance multi-sourced information synthesis and optimize decision-making outcomes through timely experience refinement remain unexplored. Here, we introduce the FinCon, an LLM-based multi-agent framework with CONceptual verbal reinforcement tailored for diverse FINancial tasks. Inspired by effective real-world investment firm organizational structures, FinCon utilizes a manager-analyst communication hierarchy. This structure allows for synchronized cross-functional agent collaboration towards unified goals through natural language interactions and equips each agent with greater memory capacity than humans. Additionally, a risk-control component in FinCon enhances decision quality by episodically initiating a self-critiquing mechanism to update systematic investment beliefs. The conceptualized beliefs serve as verbal reinforcement for the future agent's behavior and can be selectively propagated to the appropriate node that requires knowledge updates. This feature significantly improves performance while reducing unnecessary peer-to-peer communication costs. Moreover, FinCon demonstrates strong generalization capabilities in various financial tasks, including single stock trading and portfolio management.", "pdf_url": "https://arxiv.org/pdf/2407.06567.pdf", "pdf_filename": "2024-07-09_FinCon__A_Synthesized_LLM_Multi-Agent_System_with_.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-09_FinCon__A_Synthesized_LLM_Multi-Agent_System_with_.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "3d814347e382fc3fcc071876744f139d2c101be7", "publication_date": "2024-07-10", "title": "Flooding Spread of Manipulated Knowledge in LLM-Based Multi-Agent Communities", "authors": "Tianjie Ju, Yiting Wang, Xinbei Ma, Pengzhou Cheng, Haodong Zhao, Yulong Wang, Lifeng Liu, Jian Xie, Zhuosheng Zhang, Gongshen Liu", "venue": "arXiv.org", "citation_count": 25, "influential_citation_count": 2, "abstract": "The rapid adoption of large language models (LLMs) in multi-agent systems has highlighted their impressive capabilities in various applications, such as collaborative problem-solving and autonomous negotiation. However, the security implications of these LLM-based multi-agent systems have not been thoroughly investigated, particularly concerning the spread of manipulated knowledge. In this paper, we investigate this critical issue by constructing a detailed threat model and a comprehensive simulation environment that mirrors real-world multi-agent deployments in a trusted platform. Subsequently, we propose a novel two-stage attack method involving Persuasiveness Injection and Manipulated Knowledge Injection to systematically explore the potential for manipulated knowledge (i.e., counterfactual and toxic knowledge) spread without explicit prompt manipulation. Our method leverages the inherent vulnerabilities of LLMs in handling world knowledge, which can be exploited by attackers to unconsciously spread fabricated information. Through extensive experiments, we demonstrate that our attack method can successfully induce LLM-based agents to spread both counterfactual and toxic knowledge without degrading their foundational capabilities during agent communication. Furthermore, we show that these manipulations can persist through popular retrieval-augmented generation frameworks, where several benign agents store and retrieve manipulated chat histories for future interactions. This persistence indicates that even after the interaction has ended, the benign agents may continue to be influenced by manipulated knowledge. Our findings reveal significant security risks in LLM-based multi-agent systems, emphasizing the imperative need for robust defenses against manipulated knowledge spread, such as introducing ``guardian'' agents and advanced fact-checking tools.", "pdf_url": "https://arxiv.org/pdf/2407.07791.pdf", "pdf_filename": "2024-07-10_Flooding_Spread_of_Manipulated_Knowledge_in_LLM-Ba.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-10_Flooding_Spread_of_Manipulated_Knowledge_in_LLM-Ba.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "dd565137ec79da38bf2d01319bba195c66733212", "publication_date": "2024-07-13", "title": "CellAgent: An LLM-driven Multi-Agent Framework for Automated Single-cell Data Analysis", "authors": "Yihang Xiao, Jinyi Liu, Yan Zheng, Xiaohan Xie, Jianye Hao, Mingzhi Li, Ruitao Wang, Fei Ni, Yuxiao Li, Jintian Luo, Shaoqing Jiao, Jiajie Peng", "venue": "arXiv.org", "citation_count": 20, "influential_citation_count": 1, "abstract": "Single-cell RNA sequencing (scRNA-seq) data analysis is crucial for biological research, as it enables the precise characterization of cellular heterogeneity. However, manual manipulation of various tools to achieve desired outcomes can be labor-intensive for researchers. To address this, we introduce CellAgent (http://cell.agent4science.cn/), an LLM-driven multi-agent framework, specifically designed for the automatic processing and execution of scRNA-seq data analysis tasks, providing high-quality results with no human intervention. Firstly, to adapt general LLMs to the biological field, CellAgent constructs LLM-driven biological expert roles - planner, executor, and evaluator - each with specific responsibilities. Then, CellAgent introduces a hierarchical decision-making mechanism to coordinate these biological experts, effectively driving the planning and step-by-step execution of complex data analysis tasks. Furthermore, we propose a self-iterative optimization mechanism, enabling CellAgent to autonomously evaluate and optimize solutions, thereby guaranteeing output quality. We evaluate CellAgent on a comprehensive benchmark dataset encompassing dozens of tissues and hundreds of distinct cell types. Evaluation results consistently show that CellAgent effectively identifies the most suitable tools and hyperparameters for single-cell analysis tasks, achieving optimal performance. This automated framework dramatically reduces the workload for science data analyses, bringing us into the\"Agent for Science\"era.", "pdf_url": "https://arxiv.org/pdf/2407.09811.pdf", "pdf_filename": "2024-07-13_CellAgent__An_LLM-driven_Multi-Agent_Framework_for.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-13_CellAgent__An_LLM-driven_Multi-Agent_Framework_for.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "d4656bba3a424a25fcd9e1fbf3966f080ace9c2f", "publication_date": "2024-01-02", "title": "LLM Harmony: Multi-Agent Communication for Problem Solving", "authors": "Sumedh Rasal", "venue": "arXiv.org", "citation_count": 23, "influential_citation_count": 0, "abstract": "Large Language Models (LLMs) have revolutionized Natural Language Processing but exhibit limitations, particularly in autonomously addressing novel challenges such as reasoning and problem-solving. Traditional techniques like chain-of-thought prompting necessitate explicit human guidance. This paper introduces a novel multi-agent communication framework, inspired by the CAMEL model, to enhance LLMs' autonomous problem-solving capabilities. The framework employs multiple LLM agents, each with a distinct persona, engaged in role-playing communication, offering a nuanced and adaptable approach to diverse problem scenarios. Extensive experimentation demonstrates the framework's superior performance and adaptability, providing valuable insights into the collaborative potential of multiple agents in overcoming the limitations of individual models.", "pdf_url": "https://arxiv.org/pdf/2401.01312.pdf", "pdf_filename": "2024-01-02_LLM_Harmony__Multi-Agent_Communication_for_Problem.pdf", "markdown_path": "data/semantic/markdown_files/2024-01-02_LLM_Harmony__Multi-Agent_Communication_for_Problem.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "aebfeb42bbd155c1541a67fddf0a6e2bc5d6ae34", "publication_date": "2024-10-03", "title": "Cut the Crap: An Economical Communication Pipeline for LLM-based Multi-Agent Systems", "authors": "Guibin Zhang, Yanwei Yue, Zhixun Li, Sukwon Yun, Guancheng Wan, Kun Wang, Dawei Cheng, Jeffrey Xu Yu, Tianlong Chen", "venue": "arXiv.org", "citation_count": 17, "influential_citation_count": 0, "abstract": "Recent advancements in large language model (LLM)-powered agents have shown that collective intelligence can significantly outperform individual capabilities, largely attributed to the meticulously designed inter-agent communication topologies. Though impressive in performance, existing multi-agent pipelines inherently introduce substantial token overhead, as well as increased economic costs, which pose challenges for their large-scale deployments. In response to this challenge, we propose an economical, simple, and robust multi-agent communication framework, termed $\\texttt{AgentPrune}$, which can seamlessly integrate into mainstream multi-agent systems and prunes redundant or even malicious communication messages. Technically, $\\texttt{AgentPrune}$ is the first to identify and formally define the \\textit{communication redundancy} issue present in current LLM-based multi-agent pipelines, and efficiently performs one-shot pruning on the spatial-temporal message-passing graph, yielding a token-economic and high-performing communication topology. Extensive experiments across six benchmarks demonstrate that $\\texttt{AgentPrune}$ \\textbf{(I)} achieves comparable results as state-of-the-art topologies at merely $\\$5.6$ cost compared to their $\\$43.7$, \\textbf{(II)} integrates seamlessly into existing multi-agent frameworks with $28.1\\%\\sim72.8\\%\\downarrow$ token reduction, and \\textbf{(III)} successfully defend against two types of agent-based adversarial attacks with $3.5\\%\\sim10.8\\%\\uparrow$ performance boost.", "pdf_url": "https://arxiv.org/pdf/2410.02506.pdf", "pdf_filename": "2024-10-03_Cut_the_Crap__An_Economical_Communication_Pipeline.pdf", "markdown_path": "data/semantic/markdown_files/2024-10-03_Cut_the_Crap__An_Economical_Communication_Pipeline.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "d0a074d5da6dc44177b7a9533f700b0d8fda23be", "publication_date": "2024", "title": "LLM-Based Multi-Agent Systems for Software Engineering: Vision and the Road Ahead", "authors": "Junda He, Christoph Treude, David Lo", "venue": "arXiv.org", "citation_count": 16, "influential_citation_count": 0, "abstract": "Integrating Large Language Models(LLMs) intoautonomousagents marks a signi\ufb01cant shift in the research landscape by o\ufb00ering cognitive abilities competitive to human planning and reasoning. This paper envisions the evolution of LLM-based Multi-Agent (LMA) systems in addressing complex and multi-faceted software engineering challenges. LMA systems introduce numerous bene\ufb01ts, including enhanced robustness throughcollaborativecross-examination, autonomous problem-solving, and scalable solutions to complex software projects. By examining the role of LMA systems in future software engineering practices, this vision paper highlights the potential applications and emerging challenges. We further point to speci\ufb01c opportunities for research and conclude with a research agenda with a set of research questions to guide future research directions", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "9ea0757c750ab1222a7442d3485a74d1c526b04c", "publication_date": "2023-08-16", "title": "AutoGen: Enabling Next-Gen LLM Applications via Multi-Agent Conversation", "authors": "Qingyun Wu, Gagan Bansal, Jieyu Zhang, Yiran Wu, Beibin Li, Erkang Zhu, Li Jiang, Xiaoyun Zhang, Shaokun Zhang, Jiale Liu, A. Awadallah, Ryen W. White, Doug Burger, Chi Wang", "venue": "", "citation_count": 342, "influential_citation_count": 27, "abstract": "AutoGen is an open-source framework that allows developers to build LLM applications via multiple agents that can converse with each other to accomplish tasks. AutoGen agents are customizable, conversable, and can operate in various modes that employ combinations of LLMs, human inputs, and tools. Using AutoGen, developers can also flexibly define agent interaction behaviors. Both natural language and computer code can be used to program flexible conversation patterns for different applications. AutoGen serves as a generic infrastructure to build diverse applications of various complexities and LLM capacities. Empirical studies demonstrate the effectiveness of the framework in many example applications, with domains ranging from mathematics, coding, question answering, operations research, online decision-making, entertainment, etc.", "pdf_url": "https://arxiv.org/pdf/2308.08155.pdf", "pdf_filename": "2023-08-16_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Mu.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-16_AutoGen__Enabling_Next-Gen_LLM_Applications_via_Mu.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "ff61aef2fef3a235bfaa123158a990c4f5f27d1a", "publication_date": "2024-01-14", "title": "Small LLMs Are Weak Tool Learners: A Multi-LLM Agent", "authors": "Weizhou Shen, Chenliang Li, Hongzhan Chen, Ming Yan, Xiaojun Quan, Hehong Chen, Ji Zhang, Fei Huang", "venue": "Conference on Empirical Methods in Natural Language Processing", "citation_count": 55, "influential_citation_count": 1, "abstract": "Large Language Model (LLM) agents significantly extend the capabilities of standalone LLMs, empowering them to interact with external tools (e.g., APIs, functions) and complete various tasks in a self-directed fashion. The challenge of tool use demands that LLMs not only understand user queries and generate answers accurately but also excel in task planning, tool invocation, and result summarization. While traditional works focus on training a single LLM with all these capabilities, performance limitations become apparent, particularly with smaller models. To overcome these challenges, we propose a novel approach that decomposes the aforementioned capabilities into a planner, caller, and summarizer. Each component is implemented by a single LLM that focuses on a specific capability and collaborates with others to accomplish the task. This modular framework facilitates individual updates and the potential use of smaller LLMs for building each capability. To effectively train this framework, we introduce a two-stage training paradigm. First, we fine-tune a backbone LLM on the entire dataset without discriminating sub-tasks, providing the model with a comprehensive understanding of the task. Second, the fine-tuned LLM is used to instantiate the planner, caller, and summarizer respectively, which are continually fine-tuned on respective sub-tasks. Evaluation across various tool-use benchmarks illustrates that our proposed multi-LLM framework surpasses the traditional single-LLM approach, highlighting its efficacy and advantages in tool learning.", "pdf_url": "https://arxiv.org/pdf/2401.07324.pdf", "pdf_filename": "2024-01-14_Small_LLMs_Are_Weak_Tool_Learners__A_Multi-LLM_Age.pdf", "markdown_path": "data/semantic/markdown_files/2024-01-14_Small_LLMs_Are_Weak_Tool_Learners__A_Multi-LLM_Age.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "ead6121fbc787d508dc6a6d7106f72bf0d647d03", "publication_date": "2023-06-05", "title": "Multi-Agent Collaboration: Harnessing the Power of Intelligent LLM Agents", "authors": "Yashar Talebirad, Amirhossein Nadiri", "venue": "arXiv.org", "citation_count": 220, "influential_citation_count": 7, "abstract": "In this paper, we present a novel framework for enhancing the capabilities of large language models (LLMs) by leveraging the power of multi-agent systems. Our framework introduces a collaborative environment where multiple intelligent agent components, each with distinctive attributes and roles, work together to handle complex tasks more efficiently and effectively. We demonstrate the practicality and versatility of our framework through case studies in artificial general intelligence (AGI), specifically focusing on the Auto-GPT and BabyAGI models. We also examine the\"Gorilla\"model, which integrates external APIs into the LLM. Our framework addresses limitations and challenges such as looping issues, security risks, scalability, system evaluation, and ethical considerations. By modeling various domains such as courtroom simulations and software development scenarios, we showcase the potential applications and benefits of our proposed multi-agent system. Our framework provides an avenue for advancing the capabilities and performance of LLMs through collaboration and knowledge exchange among intelligent agents.", "pdf_url": "http://arxiv.org/pdf/2306.03314", "pdf_filename": "2023-06-05_Multi-Agent_Collaboration__Harnessing_the_Power_of.pdf", "markdown_path": "data/semantic/markdown_files/2023-06-05_Multi-Agent_Collaboration__Harnessing_the_Power_of.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "dc10d108823630343484c5eecbb5c3011751282e", "publication_date": "2024-06-27", "title": "LayoutCopilot: An LLM-powered Multi-agent Collaborative Framework for Interactive Analog Layout Design", "authors": "Bingyang Liu, Haoyi Zhang, Xiaohan Gao, Zichen Kong, Xiyuan Tang, Yibo Lin, Runsheng Wang, Ru Huang", "venue": "IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems", "citation_count": 13, "influential_citation_count": 0, "abstract": "Analog layout design heavily involves interactive processes between humans and design tools. Electronic Design Automation (EDA) tools for this task are usually designed to use scripting commands or visualized buttons for manipulation, especially for interactive automation functionalities, which have a steep learning curve and cumbersome user experience, making a notable barrier to designers' adoption. Aiming to address such a usability issue, this paper introduces LayoutCopilot, a pioneering multi-agent collaborative framework powered by Large Language Models (LLMs) for interactive analog layout design. LayoutCopilot simplifies human-tool interaction by converting natural language instructions into executable script commands, and it interprets high-level design intents into actionable suggestions, significantly streamlining the design process. Experimental results demonstrate the flexibility, efficiency, and accessibility of LayoutCopilot in handling real-world analog designs.", "pdf_url": "https://arxiv.org/pdf/2406.18873.pdf", "pdf_filename": "2024-06-27_LayoutCopilot__An_LLM-powered_Multi-agent_Collabor.pdf", "markdown_path": "data/semantic/markdown_files/2024-06-27_LayoutCopilot__An_LLM-powered_Multi-agent_Collabor.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "fb66fb26ad3a0e26ed6b56c42a8c02e1737c811a", "publication_date": "2024-09-30", "title": "TRANSAGENT: An LLM-Based Multi-Agent System for Code Translation", "authors": "Zhiqiang Yuan, Weitong Chen, Hanlin Wang, Kai Yu, Xin Peng, Yiling Lou", "venue": "arXiv.org", "citation_count": 12, "influential_citation_count": 1, "abstract": "Code translation converts code from one programming language to another while maintaining its original functionality, which is crucial for software migration, system refactoring, and cross-platform development. Traditional rule-based methods rely on manually-written rules, which can be time-consuming and often result in less readable code. To overcome this, learning-based methods have been developed, leveraging parallel data to train models for automated code translation. More recently, the advance of Large Language Models (LLMs) further boosts learning-based code translation. Although promising, LLM-translated program still suffers from diverse quality issues (e.g., syntax errors and semantic errors). In particular, it can be challenging for LLMs to self-debug these errors when simply provided with the corresponding error messages. In this work, we propose a novel LLM-based multi-agent system TRANSAGENT, which enhances LLM-based code translation by fixing the syntax errors and semantic errors with the synergy between four LLM-based agents, including Initial Code Translator, Syntax Error Fixer, Code Aligner, and Semantic Error Fixer. The main insight of TRANSAGENT is to first localize the error code block in the target program based on the execution alignment between the target and source program, which can narrow down the fixing space and thus lower down the fixing difficulties. To evaluate TRANSAGENT, we first construct a new benchmark from recent programming tasks to mitigate the potential data leakage issue. On our benchmark, TRANSAGENT outperforms the latest LLM-based code translation technique UniTrans in both translation effectiveness and efficiency; additionally, our evaluation on different LLMs show the generalization of TRANSAGENT and our ablation study shows the contribution of each agent.", "pdf_url": "https://arxiv.org/pdf/2409.19894.pdf", "pdf_filename": "2024-09-30_TRANSAGENT__An_LLM-Based_Multi-Agent_System_for_Co.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-30_TRANSAGENT__An_LLM-Based_Multi-Agent_System_for_Co.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "a4d33353dfdc546d499726c87456bf5dfc0e7bf2", "publication_date": "2024-03-28", "title": "Enhancing Anomaly Detection in Financial Markets with an LLM-based Multi-Agent Framework", "authors": "Taejin Park", "venue": "", "citation_count": 12, "influential_citation_count": 0, "abstract": "This paper introduces a Large Language Model (LLM)-based multi-agent framework designed to enhance anomaly detection within financial market data, tackling the longstanding challenge of manually verifying system-generated anomaly alerts. The framework harnesses a collaborative network of AI agents, each specialised in distinct functions including data conversion, expert analysis via web research, institutional knowledge utilization or cross-checking and report consolidation and management roles. By coordinating these agents towards a common objective, the framework provides a comprehensive and automated approach for validating and interpreting financial data anomalies. I analyse the S&P 500 index to demonstrate the framework's proficiency in enhancing the efficiency, accuracy and reduction of human intervention in financial market monitoring. The integration of AI's autonomous functionalities with established analytical methods not only underscores the framework's effectiveness in anomaly detection but also signals its broader applicability in supporting financial market monitoring.", "pdf_url": "https://arxiv.org/pdf/2403.19735.pdf", "pdf_filename": "2024-03-28_Enhancing_Anomaly_Detection_in_Financial_Markets_w.pdf", "markdown_path": "data/semantic/markdown_files/2024-03-28_Enhancing_Anomaly_Detection_in_Financial_Markets_w.md"}
{"query_date": "2025-06-10", "query_keyword": "Multi-Agent LLM", "paper_id": "e321349644c97f0c0d0147c09690e2485d2d61c4", "publication_date": "2024-11-24", "title": "DrugAgent: Automating AI-aided Drug Discovery Programming through LLM Multi-Agent Collaboration", "authors": "Sizhe Liu, Yizhou Lu, Siyu Chen, Xiyang Hu, Jieyu Zhao, Tianfan Fu, Yue Zhao", "venue": "arXiv.org", "citation_count": 12, "influential_citation_count": 0, "abstract": "Recent progress in Large Language Models (LLMs) has drawn attention to their potential for accelerating drug discovery. However, a central problem remains: translating theoretical ideas into robust implementations in the highly specialized context of pharmaceutical research. This limitation prevents practitioners from making full use of the latest AI developments in drug discovery. To address this challenge, we introduce DrugAgent, a multi-agent framework that automates machine learning (ML) programming for drug discovery tasks. DrugAgent employs an LLM Planner that formulates high-level ideas and an LLM Instructor that identifies and integrates domain knowledge when implementing those ideas. We present case studies on three representative drug discovery tasks. Our results show that DrugAgent consistently outperforms leading baselines, including a relative improvement of 4.92% in ROC-AUC compared to ReAct for drug-target interaction (DTI). DrugAgent is publicly available at https://anonymous.4open.science/r/drugagent-5C42/.", "pdf_url": "https://arxiv.org/pdf/2411.15692.pdf", "pdf_filename": "2024-11-24_DrugAgent__Automating_AI-aided_Drug_Discovery_Prog.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-24_DrugAgent__Automating_AI-aided_Drug_Discovery_Prog.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "1d32fbfba0d85489f924bed5c6a41fdc28d08914", "publication_date": "2020-07-22", "title": "Multi-Task Curriculum Framework for Open-Set Semi-Supervised Learning", "authors": "Qing Yu, Daiki Ikami, Go Irie, K. Aizawa", "venue": "European Conference on Computer Vision", "citation_count": 130, "influential_citation_count": 31, "abstract": "Semi-supervised learning (SSL) has been proposed to leverage unlabeled data for training powerful models when only limited labeled data is available. While existing SSL methods assume that samples in the labeled and unlabeled data share the classes of their samples, we address a more complex novel scenario named open-set SSL, where out-of-distribution (OOD) samples are contained in unlabeled data. Instead of training an OOD detector and SSL separately, we propose a multi-task curriculum learning framework. First, to detect the OOD samples in unlabeled data, we estimate the probability of the sample belonging to OOD. We use a joint optimization framework, which updates the network parameters and the OOD score alternately. Simultaneously, to achieve high performance on the classification of in-distribution (ID) data, we select ID samples in unlabeled data having small OOD scores, and use these data with labeled data for training the deep neural networks to classify ID samples in a semi-supervised manner. We conduct several experiments, and our method achieves state-of-the-art results by successfully eliminating the effect of OOD samples.", "pdf_url": "https://arxiv.org/pdf/2007.11330.pdf", "pdf_filename": "2020-07-22_Multi-Task_Curriculum_Framework_for_Open-Set_Semi-.pdf", "markdown_path": "data/semantic/markdown_files/2020-07-22_Multi-Task_Curriculum_Framework_for_Open-Set_Semi-.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "85de3579e2142fafecb04b88452ee1c53d4faf3f", "publication_date": "2021-08-12", "title": "Trash to Treasure: Harvesting OOD Data with Cross-Modal Matching for Open-Set Semi-Supervised Learning", "authors": "Junkai Huang, Chaowei Fang, Weikai Chen, Z. Chai, Xiaolin Wei, Pengxu Wei, Liang Lin, Guanbin Li", "venue": "IEEE International Conference on Computer Vision", "citation_count": 64, "influential_citation_count": 16, "abstract": "Open-set semi-supervised learning (open-set SSL) investigates a challenging but practical scenario where out-of-distribution (OOD) samples are contained in the unlabeled data. While the mainstream technique seeks to completely filter out the OOD samples for semi-supervised learning (SSL), we propose a novel training mechanism that could effectively exploit the presence of OOD data for enhanced feature learning while avoiding its adverse impact on the SSL. We achieve this goal by first introducing a warm-up training that leverages all the unlabeled data, including both the in-distribution (ID) and OOD samples. Specifically, we perform a pretext task that enforces our feature extractor to obtain a high-level semantic understanding of the training images, leading to more discriminative features that can benefit the downstream tasks. Since the OOD samples are inevitably detrimental to SSL, we propose a novel cross-modal matching strategy to detect OOD samples. Instead of directly applying binary classification [39], we train the network to predict whether the data sample is matched to an assigned one-hot class label. The appeal of the proposed cross-modal matching over binary classification is the ability to generate a compatible feature space that aligns with the core classification task. Extensive experiments show that our approach substantially lifts the performance on open-set SSL and outperforms the state-of-the-art by a large margin.", "pdf_url": "http://arxiv.org/pdf/2108.05617", "pdf_filename": "2021-08-12_Trash_to_Treasure__Harvesting_OOD_Data_with_Cross-.pdf", "markdown_path": "data/semantic/markdown_files/2021-08-12_Trash_to_Treasure__Harvesting_OOD_Data_with_Cross-.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "a968cea0f72242662bcf8b1d24f3491135907ead", "publication_date": "2023-08-25", "title": "IOMatch: Simplifying Open-Set Semi-Supervised Learning with Joint Inliers and Outliers Utilization", "authors": "Zekun Li, Lei Qi, Yinghuan Shi, Yang Gao", "venue": "IEEE International Conference on Computer Vision", "citation_count": 31, "influential_citation_count": 6, "abstract": "Semi-supervised learning (SSL) aims to leverage massive unlabeled data when labels are expensive to obtain. Unfortunately, in many real-world applications, the collected unlabeled data will inevitably contain unseen-class outliers not belonging to any of the labeled classes. To deal with the challenging open-set SSL task, the mainstream methods tend to first detect outliers and then filter them out. However, we observe a surprising fact that such approach could result in more severe performance degradation when labels are extremely scarce, as the unreliable outlier detector may wrongly exclude a considerable portion of valuable inliers. To tackle with this issue, we introduce a novel open-set SSL framework, IOMatch, which can jointly utilize inliers and outliers, even when it is difficult to distinguish exactly between them. Specifically, we propose to employ a multi-binary classifier in combination with the standard closed-set classifier for producing unified open-set classification targets, which regard all outliers as a single new class. By adopting these targets as open-set pseudo-labels, we optimize an open-set classifier with all unlabeled samples including both inliers and outliers. Extensive experiments have shown that IOMatch significantly outperforms the baseline methods across different benchmark datasets and different settings despite its remarkable simplicity. Our code and models are available at https://github.com/nukezil/IOMatch.", "pdf_url": "https://arxiv.org/pdf/2308.13168.pdf", "pdf_filename": "2023-08-25_IOMatch__Simplifying_Open-Set_Semi-Supervised_Lear.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-25_IOMatch__Simplifying_Open-Set_Semi-Supervised_Lear.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ce7396b78c3ac52160dce71380e8fff2fee480c1", "publication_date": "2024-07-16", "title": "ProSub: Probabilistic Open-Set Semi-Supervised Learning with Subspace-Based Out-of-Distribution Detection", "authors": "Erik Wallin, Lennart Svensson, Fredrik Kahl, Lars Hammarstrand", "venue": "European Conference on Computer Vision", "citation_count": 2, "influential_citation_count": 0, "abstract": "In open-set semi-supervised learning (OSSL), we consider unlabeled datasets that may contain unknown classes. Existing OSSL methods often use the softmax confidence for classifying data as in-distribution (ID) or out-of-distribution (OOD). Additionally, many works for OSSL rely on ad-hoc thresholds for ID/OOD classification, without considering the statistics of the problem. We propose a new score for ID/OOD classification based on angles in feature space between data and an ID subspace. Moreover, we propose an approach to estimate the conditional distributions of scores given ID or OOD data, enabling probabilistic predictions of data being ID or OOD. These components are put together in a framework for OSSL, termed \\emph{ProSub}, that is experimentally shown to reach SOTA performance on several benchmark problems. Our code is available at https://github.com/walline/prosub.", "pdf_url": "https://arxiv.org/pdf/2407.11735.pdf", "pdf_filename": "2024-07-16_ProSub__Probabilistic_Open-Set_Semi-Supervised_Lea.pdf", "markdown_path": "data/semantic/markdown_files/2024-07-16_ProSub__Probabilistic_Open-Set_Semi-Supervised_Lea.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "3beb4d0a73f7fc905b64f4db802fb08645d12003", "publication_date": "2024-09-26", "title": "SCOMatch: Alleviating Overtrusting in Open-set Semi-supervised Learning", "authors": "Zerun Wang, Liuyu Xiang, Lang Huang, Jiafeng Mao, Ling Xiao, Toshihiko Yamasaki", "venue": "European Conference on Computer Vision", "citation_count": 2, "influential_citation_count": 0, "abstract": "Open-set semi-supervised learning (OSSL) leverages practical open-set unlabeled data, comprising both in-distribution (ID) samples from seen classes and out-of-distribution (OOD) samples from unseen classes, for semi-supervised learning (SSL). Prior OSSL methods initially learned the decision boundary between ID and OOD with labeled ID data, subsequently employing self-training to refine this boundary. These methods, however, suffer from the tendency to overtrust the labeled ID data: the scarcity of labeled data caused the distribution bias between the labeled samples and the entire ID data, which misleads the decision boundary to overfit. The subsequent self-training process, based on the overfitted result, fails to rectify this problem. In this paper, we address the overtrusting issue by treating OOD samples as an additional class, forming a new SSL process. Specifically, we propose SCOMatch, a novel OSSL method that 1) selects reliable OOD samples as new labeled data with an OOD memory queue and a corresponding update strategy and 2) integrates the new SSL process into the original task through our Simultaneous Close-set and Open-set self-training. SCOMatch refines the decision boundary of ID and OOD classes across the entire dataset, thereby leading to improved results. Extensive experimental results show that SCOMatch significantly outperforms the state-of-the-art methods on various benchmarks. The effectiveness is further verified through ablation studies and visualization.", "pdf_url": "https://arxiv.org/pdf/2409.17512.pdf", "pdf_filename": "2024-09-26_SCOMatch__Alleviating_Overtrusting_in_Open-set_Sem.pdf", "markdown_path": "data/semantic/markdown_files/2024-09-26_SCOMatch__Alleviating_Overtrusting_in_Open-set_Sem.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "efb9cb7a0576a36c16297fe0992ddcb91e520ce9", "publication_date": "2023-01-24", "title": "Improving Open-Set Semi-Supervised Learning with Self-Supervision", "authors": "Erik Wallin, Lennart Svensson, Fredrik Kahl, Lars Hammarstrand", "venue": "IEEE Workshop/Winter Conference on Applications of Computer Vision", "citation_count": 9, "influential_citation_count": 1, "abstract": "Open-set semi-supervised learning (OSSL) embodies a practical scenario within semi-supervised learning, wherein the unlabeled training set encompasses classes absent from the labeled set. Many existing OSSL methods assume that these out-of-distribution data are harmful and put effort into excluding data belonging to unknown classes from the training objective. In contrast, we propose an OSSL framework that facilitates learning from all unlabeled data through self-supervision. Additionally, we utilize an energy-based score to accurately recognize data belonging to the known classes, making our method well-suited for handling uncurated data in deployment. We show through extensive experimental evaluations that our method yields state-of-the-art results on many of the evaluated benchmark problems in terms of closed-set accuracy and open-set recognition when compared with existing methods for OSSL. Our code is available at https://github.com/walline/ssl-tf2-sefoss.", "pdf_url": "https://arxiv.org/pdf/2301.10127", "pdf_filename": "2023-01-24_Improving_Open-Set_Semi-Supervised_Learning_with_S.pdf", "markdown_path": "data/semantic/markdown_files/2023-01-24_Improving_Open-Set_Semi-Supervised_Learning_with_S.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "0f8f693be24517e8b055d24cc3dcc970119826cf", "publication_date": "2024", "title": "Mutual Filter Teaching for Open-Set Semi-Supervised Learning", "authors": "Xiaokun Li, Rumeng Yi, Y. Huang", "venue": "IEEE transactions on multimedia", "citation_count": 1, "influential_citation_count": 0, "abstract": "Open-set semi-supervised learning (OSSL) provides a practical solution by filtering out-of-distribution (OOD) samples from unlabeled data to guarantee the reliance on large unlabeled data in semi-supervised setting. However, existing OSSL methods mainly focus on identifying in-distribution (ID) samples and discarding OOD samples, while ignoring to make full use of samples that could not be exactly identified as ID or OOD samples. Those samples are more likely to be hard samples, which should be carefully explored to boost the performance in OSSL task. Hence, in this paper, we propose a novel framework, named Mutual Filter Teaching (MFT), where two networks are trained simultaneously to divide the unlabeled data into three parts: ID samples, OOD samples and hard samples. The samples are regarded as ID or OOD samples only if two networks give consistent decisions according to Mahalanobis distance between the unlabeled samples and their closest class prototypes. For those samples with inconsistent decisions, we treat them as hard samples and design an efficient mutual teaching scheme where the samples detected by only one network as positive samples are fed to its peer network for training. Furthermore, we propose to employ the prediction variance of two networks to dynamically rectify the learning from hard samples. Experiments on multiple benchmark datasets demonstrate that our approach achieves the state-of-the-art performance.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "1c952a381a5175f9dd936435b8f1a2bd706c8ffb", "publication_date": "2024-08-01", "title": "Partial Optimal Transport Based Out-of-Distribution Detection for Open-Set Semi-Supervised Learning", "authors": "Yilong Ren, Chuanwen Feng, Xike Xie, S. K. Zhou", "venue": "International Joint Conference on Artificial Intelligence", "citation_count": 1, "influential_citation_count": 0, "abstract": "Semi-supervised learning (SSL) is a machine learning paradigm that utilizes both labeled and unlabeled data to enhance the performance of learning tasks. However, SSL methods operate under the assumption that the label spaces of labeled and unlabeled data are identical, which may not hold in open-world applications. In such scenarios, the unlabeled data may contain novel categories that were not presented in the labeled training data, essentially outliers. This specific challenge is referred to as the Open-set Semi-supervised Learning (OSSL) problem. In OSSL, a pivotal concern is the detection of out-of-distribution (OOD) samples within unlabeled data. Existing methods often struggle to provide effective OOD detection strategies, especially when dealing with datasets comprising a large number of training categories. In response to this challenge, we model the OOD detection problem in OSSL as a partial optimal transport (POT) problem. With POT theory, we devise a mass score function to measure the likelihood of a sample being an outlier, which enables a binary classifier for OOD detection. Further, we put forward an OOD loss, enabling the seamless integration of the binary classifier and off-the-shelf SSL methods under OSSL settings, all within an end-to-end training framework. We extensively evaluate our proposal under various datasets and OSSL configurations, consistently demonstrating the superior performance of our proposal. Codes are available at https://github.com/ryl0427/Code_for_POT_OSSL.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "7c146bf72b942a721fce8acd66f3e33ef0284d04", "publication_date": "2023-10-01", "title": "SSB: Simple but Strong Baseline for Boosting Performance of Open-Set Semi-Supervised Learning", "authors": "Yue Fan, Anna Kukleva, Dengxin Dai, B. Schiele", "venue": "IEEE International Conference on Computer Vision", "citation_count": 9, "influential_citation_count": 2, "abstract": "Semi-supervised learning (SSL) methods effectively leverage unlabeled data to improve model generalization. However, SSL models often underperform in open-set scenarios, where unlabeled data contain outliers from novel categories that do not appear in the labeled set. In this paper, we study the challenging and realistic open-set SSL setting, where the goal is to both correctly classify inliers and to detect outliers. Intuitively, the inlier classifier should be trained on inlier data only. However, we find that inlier classification performance can be largely improved by incorporating high-confidence pseudo-labeled data, regardless of whether they are inliers or outliers. Also, we propose to utilize non-linear transformations to separate the features used for inlier classification and outlier detection in the multi-task learning framework, preventing adverse effects between them. Additionally, we introduce pseudo-negative mining, which further boosts outlier detection performance. The three ingredients lead to what we call Simple but Strong Baseline (SSB) for open-set SSL. In experiments, SSB greatly improves both inlier classification and outlier detection performance, outperforming existing methods by a large margin. Our code will be released at https://github.com/YUE-FAN/SSB.", "pdf_url": "https://arxiv.org/pdf/2311.10572.pdf", "pdf_filename": "2023-10-01_SSB__Simple_but_Strong_Baseline_for_Boosting_Perfo.pdf", "markdown_path": "data/semantic/markdown_files/2023-10-01_SSB__Simple_but_Strong_Baseline_for_Boosting_Perfo.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "64dc93a71c087a1983c5410e4e27bec5e6ee3042", "publication_date": "2024", "title": "Data Augmentation with Diffusion for Open-Set Semi-Supervised Learning", "authors": "Seonghyun Ban, Heesan Kong, Kee-Eung Kim", "venue": "Neural Information Processing Systems", "citation_count": 2, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "7b5d2b10d75e4f09223193141bc2d8343c297b25", "publication_date": "2023-03-21", "title": "Adaptive Negative Evidential Deep Learning for Open-set Semi-supervised Learning", "authors": "Yang Yu, Danruo Deng, Fu-Lun Liu, Yueming Jin, Q. Dou, Guangyong Chen, P. Heng", "venue": "AAAI Conference on Artificial Intelligence", "citation_count": 4, "influential_citation_count": 2, "abstract": "Semi-supervised learning (SSL) methods assume that labeled\ndata, unlabeled data and test data are from the same distribution. Open-set semi-supervised learning (Open-set SSL) con-\nsiders a more practical scenario, where unlabeled data and\ntest data contain new categories (outliers) not observed in\nlabeled data (inliers). Most previous works focused on out-\nlier detection via binary classifiers, which suffer from insufficient scalability and inability to distinguish different types\nof uncertainty. In this paper, we propose a novel framework,\nAdaptive Negative Evidential Deep Learning (ANEDL) to\ntackle these limitations. Concretely, we first introduce evidential deep learning (EDL) as an outlier detector to quantify\ndifferent types of uncertainty, and design different uncertainty\nmetrics for self-training and inference. Furthermore, we propose a novel adaptive negative optimization strategy, making\nEDL more tailored to the unlabeled dataset containing both\ninliers and outliers. As demonstrated empirically, our proposed method outperforms existing state-of-the-art methods\nacross four datasets.", "pdf_url": "https://arxiv.org/pdf/2303.12091", "pdf_filename": "2023-03-21_Adaptive_Negative_Evidential_Deep_Learning_for_Ope.pdf", "markdown_path": "data/semantic/markdown_files/2023-03-21_Adaptive_Negative_Evidential_Deep_Learning_for_Ope.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ca6587d6d5c217fb85d116afcdc5180b7b7df7bc", "publication_date": "2021", "title": "On The Consistency Training for Open-Set Semi-Supervised Learning", "authors": "Huixiang Luo, Hao Cheng, Yuting Gao, Ke Li, Mengdan Zhang, Fanxu Meng, Xiao-Wei Guo, Feiyue Huang, Xing Sun", "venue": "arXiv.org", "citation_count": 20, "influential_citation_count": 1, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "283ffe259563101460d291fd6f4cb8d3e34eb2e4", "publication_date": "2024", "title": "Binary Decomposition: A Problem Transformation Perspective for Open-Set Semi-Supervised Learning", "authors": "Jun-Yi Hang, Min-Ling Zhang", "venue": "International Conference on Machine Learning", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "8ad0412e6fe5ec505a04652bdb3606653f4d2253", "publication_date": "2024-07-01", "title": "Knowing the unknowns: Network traffic detection with open-set semi-supervised learning", "authors": "Rui Chen, Lailong Luo, Xiaodong Wang, Bangbang Ren, Deke Guo, Shi Zhu", "venue": "Comput. Networks", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "0a76cee261445bf7b99c88cb4f4fb3fef488a3ba", "publication_date": "2022-09-28", "title": "Prompt-driven efficient Open-set Semi-supervised Learning", "authors": "Haoran Li, Chun-Mei Feng, Tao Zhou, Yong Xu, Xiaojun Chang", "venue": "arXiv.org", "citation_count": 4, "influential_citation_count": 0, "abstract": "Open-set semi-supervised learning (OSSL) has attracted growing interest, which investigates a more practical scenario where out-of-distribution (OOD) samples are only contained in unlabeled data. Existing OSSL methods like OpenMatch learn an OOD detector to identify outliers, which often update all modal parameters (i.e., full fine-tuning) to propagate class information from labeled data to unlabeled ones. Currently, prompt learning has been developed to bridge gaps between pre-training and fine-tuning, which shows higher computational efficiency in several downstream tasks. In this paper, we propose a prompt-driven efficient OSSL framework, called OpenPrompt, which can propagate class information from labeled to unlabeled data with only a small number of trainable parameters. We propose a prompt-driven joint space learning mechanism to detect OOD data by maximizing the distribution gap between ID and OOD samples in unlabeled data, thereby our method enables the outliers to be detected in a new way. The experimental results on three public datasets show that OpenPrompt outperforms state-of-the-art methods with less than 1% of trainable parameters. More importantly, OpenPrompt achieves a 4% improvement in terms of AUROC on outlier detection over a fully supervised model on CIFAR10.", "pdf_url": "http://arxiv.org/pdf/2209.14205", "pdf_filename": "2022-09-28_Prompt-driven_efficient_Open-set_Semi-supervised_L.pdf", "markdown_path": "data/semantic/markdown_files/2022-09-28_Prompt-driven_efficient_Open-set_Semi-supervised_L.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "3903072a7b790851ff9e41a473e200bd93951f87", "publication_date": "2023-10-20", "title": "LaRW: boosting open-set semi-supervised learning with label-guided re-weighting", "authors": "Jihong Ouyang, Dong Mao, Qingyi Meng", "venue": "Multim. Tools Appl.", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "9d61aacf945002347135a660a0e73ad7a76c8279", "publication_date": "2023-08-29", "title": "Prototype Fission: Closing Set for Robust Open-set Semi-supervised Learning", "authors": "Xuwei Tan, Yi-Jie Huang, Yaqian Li", "venue": "arXiv.org", "citation_count": 1, "influential_citation_count": 0, "abstract": "Semi-supervised Learning (SSL) has been proven vulnerable to out-of-distribution (OOD) samples in realistic large-scale unsupervised datasets due to over-confident pseudo-labeling OODs as in-distribution (ID). A key underlying problem is class-wise latent space spreading from closed seen space to open unseen space, and the bias is further magnified in SSL's self-training loops. To close the ID distribution set so that OODs are better rejected for safe SSL, we propose Prototype Fission(PF) to divide class-wise latent spaces into compact sub-spaces by automatic fine-grained latent space mining, driven by coarse-grained labels only. Specifically, we form multiple unique learnable sub-class prototypes for each class, optimized towards both diversity and consistency. The Diversity Modeling term encourages samples to be clustered by one of the multiple sub-class prototypes, while the Consistency Modeling term clusters all samples of the same class to a global prototype. Instead of\"opening set\", i.e., modeling OOD distribution, Prototype Fission\"closes set\"and makes it hard for OOD samples to fit in sub-class latent space. Therefore, PF is compatible with existing methods for further performance gains. Extensive experiments validate the effectiveness of our method in open-set SSL settings in terms of successfully forming sub-classes, discriminating OODs from IDs and improving overall accuracy. Codes will be released.", "pdf_url": "https://arxiv.org/pdf/2308.15575", "pdf_filename": "2023-08-29_Prototype_Fission__Closing_Set_for_Robust_Open-set.pdf", "markdown_path": "data/semantic/markdown_files/2023-08-29_Prototype_Fission__Closing_Set_for_Robust_Open-set.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "630bb51965a99477b09d3961937fde6397f338c3", "publication_date": "2023-06-30", "title": "Exploration and Exploitation of Unlabeled Data for Open-Set Semi-Supervised Learning", "authors": "Ganlong Zhao, Guanbin Li, Yipeng Qin, Jinjin Zhang, Z. Chai, Xiaolin Wei, Liang Lin, Yizhou Yu", "venue": "International Journal of Computer Vision", "citation_count": 1, "influential_citation_count": 0, "abstract": "In this paper, we address a complex but practical scenario in semi-supervised learning (SSL) named open-set SSL, where unlabeled data contain both in-distribution (ID) and out-of-distribution (OOD) samples. Unlike previous methods that only consider ID samples to be useful and aim to filter out OOD ones completely during training, we argue that the exploration and exploitation of both ID and OOD samples can benefit SSL. To support our claim, i) we propose a prototype-based clustering and identification algorithm that explores the inherent similarity and difference among samples at feature level and effectively cluster them around several predefined ID and OOD prototypes, thereby enhancing feature learning and facilitating ID/OOD identification; ii) we propose an importance-based sampling method that exploits the difference in importance of each ID and OOD sample to SSL, thereby reducing the sampling bias and improving the training. Our proposed method achieves state-of-the-art in several challenging benchmarks, and improves upon existing SSL methods even when ID samples are totally absent in unlabeled data.", "pdf_url": "http://arxiv.org/pdf/2306.17699", "pdf_filename": "2023-06-30_Exploration_and_Exploitation_of_Unlabeled_Data_for.pdf", "markdown_path": "data/semantic/markdown_files/2023-06-30_Exploration_and_Exploitation_of_Unlabeled_Data_for.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "39b78531ba54110d3e1cc9a452a5c941a1cc08dc", "publication_date": "2022-05-02", "title": "Open-Set Semi-Supervised Learning for 3D Point Cloud Understanding", "authors": "Xian Shi, Xun Xu, Wanyue Zhang, Xiatian Zhu, Chuan-Sheng Foo, K. Jia", "venue": "International Conference on Pattern Recognition", "citation_count": 5, "influential_citation_count": 0, "abstract": "Semantic understanding of 3D point cloud relies on learning models with massively annotated data, which, in many cases, are expensive or difficult to collect. This has led to an emerging research interest in semi-supervised learning (SSL) for 3D point cloud. It is commonly assumed in SSL that the unlabeled data are drawn from the same distribution as that of the labeled ones; This assumption, however, rarely holds true in realistic environments. Blindly using out-of-distribution (OOD) unlabeled data could harm SSL performance. In this work, we propose to selectively utilize unlabeled data through sample weighting, so that only conducive unlabeled data would be prioritized. To estimate the weights, we adopt a bi-level optimization framework which iteratively optimizes a meta-objective on a held-out validation set and a task-objective on a training set. Faced with the instability of efficient bi-level optimizers, we further propose three regularization techniques to enhance the training stability. Extensive experiments on 3D point cloud classification and segmentation tasks verify the effectiveness of our proposed method. We also demonstrate the feasibility of a more efficient training strategy. Our code is released on Github1.", "pdf_url": "https://arxiv.org/pdf/2205.01006", "pdf_filename": "2022-05-02_Open-Set_Semi-Supervised_Learning_for_3D_Point_Clo.pdf", "markdown_path": "data/semantic/markdown_files/2022-05-02_Open-Set_Semi-Supervised_Learning_for_3D_Point_Clo.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "4b324aafefcafbc49c70ccfcc1323e65ff2238c2", "publication_date": "2021-01-19", "title": "An Empirical Study and Analysis on Open-Set Semi-Supervised Learning", "authors": "Huixiang Luo, Hao Cheng, Fanxu Meng, Yuting Gao, Ke Li, Mengdan Zhang, Xing Sun", "venue": "", "citation_count": 8, "influential_citation_count": 1, "abstract": "Pseudo-labeling (PL) and Data Augmentation-based Consistency Training (DACT) are two approaches widely used in Semi-Supervised Learning (SSL) methods. These methods exhibit great power in many machine learning tasks by utilizing unlabeled data for efficient training. But in a more realistic setting (termed as open-set SSL), where unlabeled dataset contains out-of-distribution (OOD) samples, the traditional SSL methods suffer severe performance degradation. Recent approaches mitigate the negative influence of OOD samples by filtering them out from the unlabeled data. However, it is not clear whether directly removing the OOD samples is the best choice. Furthermore, why PL and DACT could perform differently in open-set SSL remains a mystery. In this paper, we thoroughly analyze various SSL methods (PL and DACT) on open-set SSL and discuss pros and cons of these two approaches separately. Based on our analysis, we propose Style Disturbance to improve traditional SSL methods on open-set SSL and experimentally show our approach can achieve state-of-the-art results on various datasets by utilizing OOD samples properly. We believe our study can bring new insights for SSL research.", "pdf_url": "https://arxiv.org/pdf/2101.08237.pdf", "pdf_filename": "2021-01-19_An_Empirical_Study_and_Analysis_on_Open-Set_Semi-S.pdf", "markdown_path": "data/semantic/markdown_files/2021-01-19_An_Empirical_Study_and_Analysis_on_Open-Set_Semi-S.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ca61ddc0c59af7aded9b53a8762198eded9a012d", "publication_date": "2024-11-15", "title": "OPN: Open-Set Semi-Supervised Learning for Intelligent Fault Diagnosis of Rotating Machinery", "authors": "Zuqiang Su, Xiaolong Zhang, Guoyin Wang, Sheng Lu, Song Feng, Baoping Tang", "venue": "IEEE Sensors Journal", "citation_count": 0, "influential_citation_count": 0, "abstract": "Semi-supervised learning (SSL) is effective in addressing the scarcity of label information in the fault diagnosis of rotating machinery. However, existing SSL methods generally assume that the labeled and unlabeled fault samples share a consistent label space, which is difficult to guarantee in practical applications and limits the applicability of SSL. To address this issue, this study presents a method denoted as open-set semi-supervised learning (O3SL) for intelligent fault diagnosis (IFD). First, an orthogonal projection network (OPN) is proposed to classify fault samples based on feature projection. Moreover, an open-set recognition (OSR) module based on feature projection residual (FPR) is further presented to discover potential unknown fault types in unlabeled fault samples. Finally, a pseudo-label correction updating (PLCU) module is developed to further dynamically generate corrected pseudo-labels and thus to improve the performance of OPN. Extensive experiments on two gearbox fault datasets have validated the effectiveness of the proposed OPN-based O3SL method.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "58cadf791b7512ecb84365a679515e69f4c24694", "publication_date": "2024-06-30", "title": "Open-Set Semi-Supervised Learning by Distribution Alignment", "authors": "Qiao Xiao, Jinjing Zhu, Boqian Wu, Yu Zhang", "venue": "IEEE International Joint Conference on Neural Network", "citation_count": 0, "influential_citation_count": 0, "abstract": "Semi-Supervised Learning (SSL) has been shown to be effective in the closed-set case where the label spaces in labeled and unlabeled data are the same. However, in open-set SSL, its performance is seriously degraded since unlabeled data contains some classes not seen in the labeled data, leading to the distribution mismatch between labeled and unlabeled data. To solve this problem, we propose a Distribution Aligned Openset SSL (DAOSSL) method, which aims to explicitly reduce the empirical distribution mismatch between the labeled and unlabeled data. Specifically, we first introduce a progressive separation mechanism that utilizes a coarse-to-fine pipeline to weigh the unlabeled data. Based on this weighting strategy, we then propose a weighted distribution alignment approach to minimize the distribution discrepancy between the labeled and unlabeled data. These two strategies can be easily integrated into existing deep SSL approaches for open-set SSL tasks. The effectiveness of the proposed DAOSSL method is demonstrated through empirical studies, which show that the method is able to successfully reduce the distribution mismatch between labeled and unlabeled data, resulting in performance improvement in open-set SSL tasks.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "25bfb942b3556ba11c4bb6060ab62e92783e7783", "publication_date": "2022-05-13", "title": "Knowledge Distillation Meets Open-Set Semi-Supervised Learning", "authors": "Jing Yang, Xiatian Zhu, Adrian Bulat, Brais Mart\u00ednez, Georgios Tzimiropoulos", "venue": "International Journal of Computer Vision", "citation_count": 10, "influential_citation_count": 1, "abstract": "Existing knowledge distillation methods mostly focus on distillation of teacher\u2019s prediction and intermediate activation. However, the structured representation, which arguably is one of the most critical ingredients of deep models, is largely overlooked. In this work, we propose a novel semantic representational distillation (SRD) method dedicated for distilling representational knowledge semantically from a pretrained teacher to a target student. The key idea is that we leverage the teacher\u2019s classifier as a semantic critic for evaluating the representations of both teacher and student and distilling the semantic knowledge with high-order structured information over all feature dimensions. This is accomplished by introducing a notion of cross-network logit computed through passing student\u2019s representation into teacher\u2019s classifier. Further, considering the set of seen classes as a basis for the semantic space in a combinatorial perspective, we scale SRD to unseen classes for enabling effective exploitation of largely available, arbitrary unlabeled training data. At the problem level, this establishes an interesting connection between knowledge distillation with open-set semi-supervised learning (SSL). Extensive experiments show that our SRD outperforms significantly previous state-of-the-art knowledge distillation methods on both coarse object classification and fine face recognition tasks, as well as less studied yet practically crucial binary network distillation. Under more realistic open-set SSL settings we introduce, we reveal that knowledge distillation is generally more effective than existing out-of-distribution sample detection, and our proposed SRD is superior over both previous distillation and SSL competitors. The source code is available at https://github.com/jingyang2017/SRD_ossl.", "pdf_url": "https://arxiv.org/pdf/2205.06701", "pdf_filename": "2022-05-13_Knowledge_Distillation_Meets_Open-Set_Semi-Supervi.pdf", "markdown_path": "data/semantic/markdown_files/2022-05-13_Knowledge_Distillation_Meets_Open-Set_Semi-Supervi.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "2d08b2bddeea882d4bab2a338e68303d2271241c", "publication_date": "2025", "title": "Enhancing Respiratory Sound Classification Based on Open-Set Semi-Supervised Learning", "authors": "Won-Yang Cho, Sangjun Lee", "venue": "Computers, Materials &amp; Continua", "citation_count": 0, "influential_citation_count": 0, "abstract": ": The classification of respiratory sounds is crucial in diagnosing and monitoring respiratory diseases. However, auscultation is highly subjective, making it challenging to analyze respiratory sounds accurately. Although deep learning has been increasingly applied to this task, most existing approaches have primarily relied on supervised learning. Since supervised learning requires large amounts of labeled data, recent studies have explored self-supervised and semi-supervised methods to overcome this limitation. However, these approaches have largely assumed a closed-set setting, where the classes present in the unlabeled data are considered identical to those in the labeled data. In contrast, this study explores an open-set semi-supervised learning setting, where the unlabeled data may contain additional, unknown classes. To address this challenge, a distance-based prototype network is employed to classify respiratory sounds in an open-set setting. In the first stage, the prototype network is trained using labeled and unlabeled data to derive prototype representations of known classes. In the second stage, distances between unlabeled data and known class prototypes are computed, and samples exceeding an adaptive threshold are identified as unknown. A new prototype is then calculated for this unknown class. In the final stage, semi-supervised learning is employed to classify labeled and unlabeled data into known and unknown classes. Compared to conventional closed-set semi-supervised learning approaches, the proposed method achieved an average classification accuracy improvement of 2%\u20135%. Additionally, in cases of data scarcity, utilizing unlabeled data further improved classification performance by 6%\u20138%. The findings of this study are expected to significantly enhance respiratory sound classification performance in practical clinical settings.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "54d400ea6b2522582191062a3e508129410d0d81", "publication_date": "2025-04-17", "title": "The Others: Naturally Isolating Out-of-Distribution Samples for Robust Open-Set Semi-Supervised Learning", "authors": "You Rim Choi, Subeom Park, Seojun Heo, Eunchung Noh, Hyung-Sin Kim", "venue": "arXiv.org", "citation_count": 0, "influential_citation_count": 0, "abstract": "Open-Set Semi-Supervised Learning (OSSL) tackles the practical challenge of learning from unlabeled data that may include both in-distribution (ID) and unknown out-of-distribution (OOD) classes. However, existing OSSL methods form suboptimal feature spaces by either excluding OOD samples, interfering with them, or overtrusting their information during training. In this work, we introduce MagMatch, a novel framework that naturally isolates OOD samples through a prototype-based contrastive learning paradigm. Unlike conventional methods, MagMatch does not assign any prototypes to OOD samples; instead, it selectively aligns ID samples with class prototypes using an ID-Selective Magnetic (ISM) module, while allowing OOD samples - the\"others\"- to remain unaligned in the feature space. To support this process, we propose Selective Magnetic Alignment (SMA) loss for unlabeled data, which dynamically adjusts alignment based on sample confidence. Extensive experiments on diverse datasets demonstrate that MagMatch significantly outperforms existing methods in both closed-set classification accuracy and OOD detection AUROC, especially in generalizing to unseen OOD data.", "pdf_url": "https://arxiv.org/pdf/2504.12569.pdf", "pdf_filename": "2025-04-17_The_Others__Naturally_Isolating_Out-of-Distributio.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-17_The_Others__Naturally_Isolating_Out-of-Distributio.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "8fe06c0ce3bc987a03b98460a8e455e61ef9df41", "publication_date": "2025-04-14", "title": "Open-Set Semi-Supervised Learning for Long-Tailed Medical Datasets", "authors": "D. Kareem, Jean Lahoud, M. Fiaz, Amandeep Kumar, Hisham Cholakkal", "venue": "IEEE International Symposium on Biomedical Imaging", "citation_count": 0, "influential_citation_count": 0, "abstract": "Many practical medical imaging scenarios include categories that are under-represented but still crucial. The relevance of image recognition models to real-world applications lies in their ability to generalize to these rare classes as well as unseen classes. Real-world generalization requires taking into account the various complexities that can be encountered in the real-world. First, training data is highly imbalanced, which may lead to model exhibiting bias toward the more frequently represented classes. Moreover, real-world data may contain unseen classes that need to be identified, and model performance is affected by the data scarcity. While medical image recognition has been extensively addressed in the literature, current methods do not take into account all the intricacies in the real-world scenarios. To this end, we propose an open-set learning method for highly imbal-anced medical datasets using a semi-supervised approach. Understanding the adverse impact of long-tail distribution at the inherent model characteristics, we implement a reg-ularization strategy at the feature level complemented by a classifier normalization technique. We conduct extensive experiments on the publicly available datasets, ISIC20 18, ISIC2019, and TissueMNIST with various numbers of labelled samples. Our analysis shows that addressing the impact of long-tail data in classification significantly improves the overall performance of the network in terms of closed-set and open-set accuracies on all datasets. Our code and trained models will be made publicly available at https://github.com/Daniyanaj/OpenLTR.", "pdf_url": "https://arxiv.org/pdf/2505.14846.pdf", "pdf_filename": "2025-04-14_Open-Set_Semi-Supervised_Learning_for_Long-Tailed_.pdf", "markdown_path": "data/semantic/markdown_files/2025-04-14_Open-Set_Semi-Supervised_Learning_for_Long-Tailed_.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "51144ecc84d601c0556b4126a74e48039afd0488", "publication_date": "2024-12-01", "title": "Closed loop networks for open-set semi-supervised learning", "authors": "Jihong Ouyang, Qingyi Meng, Ximing Li, Zhengjie Zhang, C. Li, Wenting Wang", "venue": "Information Sciences", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "7158479d7e2ef251a7c21d22ff87fe85030e3d12", "publication_date": "2024-05-11", "title": "Robust Semi-Supervised Learning by Wisely Leveraging Open-Set Data", "authors": "Yang Yang, Nan Jiang, Yi Xu, De-Chuan Zhan", "venue": "IEEE Transactions on Pattern Analysis and Machine Intelligence", "citation_count": 18, "influential_citation_count": 0, "abstract": "Open-set Semi-supervised Learning (OSSL) holds a realistic setting that unlabeled data may come from classes unseen in the labeled set, i.e., out-of-distribution (OOD) data, which could cause performance degradation in conventional SSL models. To handle this issue, except for the traditional in-distribution (ID) classifier, some existing OSSL approaches employ an extra OOD detection module to avoid the potential negative impact of the OOD data. Nevertheless, these approaches typically employ the entire set of open-set data during their training process, which may contain data unfriendly to the OSSL task that can negatively influence the model performance. This inspires us to develop a robust open-set data selection strategy for OSSL. Through a theoretical understanding from the perspective of learning theory, we propose Wise Open-set Semi-supervised Learning (WiseOpen), a generic OSSL framework that selectively leverages the open-set data for training the model. By applying a gradient-variance-based selection mechanism, WiseOpen exploits a friendly subset instead of the whole open-set dataset to enhance the model's capability of ID classification. Moreover, to reduce the computational expense, we also propose two practical variants of WiseOpen by adopting low-frequency update and loss-based selection respectively. Extensive experiments demonstrate the effectiveness of WiseOpen in comparison with the state-of-the-art.", "pdf_url": "https://arxiv.org/pdf/2405.06979", "pdf_filename": "2024-05-11_Robust_Semi-Supervised_Learning_by_Wisely_Leveragi.pdf", "markdown_path": "data/semantic/markdown_files/2024-05-11_Robust_Semi-Supervised_Learning_by_Wisely_Leveragi.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "d1232747682f81dfed184fc32047808e7073f96f", "publication_date": "2024-12-19", "title": "An Open-Set Semi-Supervised Multi-Task Learning Framework for Context Classification in Biomedical Texts", "authors": "Difei Tang, Thomas Yu Chow Tam, Haomiao Luo, C. Telmer, Natasa Miskov-Zivanov", "venue": "bioRxiv", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "70f0862c41a3abd2ba2b247955fef637e62223a1", "publication_date": "2024-11-20", "title": "Collaborative Feature-Logits Contrastive Learning for Open-Set Semi-Supervised Object Detection", "authors": "Xinhao Zhong, Siyu Jiao, Yao Zhao, Yunchao Wei", "venue": "ACM Multimedia Asia", "citation_count": 0, "influential_citation_count": 0, "abstract": "Current Semi-Supervised Object Detection (SSOD) methods enhance detector performance by leveraging large amounts of unlabeled data, assuming that both labeled and unlabeled data share the same label space. However, in open-set scenarios, the unlabeled dataset contains both in-distribution (ID) classes and out-of-distribution (OOD) classes. Applying semi-supervised detectors in such settings can lead to misclassifying OOD class as ID classes. To alleviate this issue, we propose a simple yet effective method, termed Collaborative Feature-Logits Detector (CFL-Detector). Specifically, we introduce a feature-level clustering method using contrastive loss to clarify vector boundaries in the feature space and highlight class differences. Additionally, by optimizing the logits-level uncertainty classification loss, the model enhances its ability to effectively distinguish between ID and OOD classes. Extensive experiments demonstrate that our method achieves state-of-the-art performance compared to existing methods.", "pdf_url": "http://arxiv.org/pdf/2411.13001", "pdf_filename": "2024-11-20_Collaborative_Feature-Logits_Contrastive_Learning_.pdf", "markdown_path": "data/semantic/markdown_files/2024-11-20_Collaborative_Feature-Logits_Contrastive_Learning_.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "6090e038294df604b6da851e34349da4b77b5cf8", "publication_date": "2020", "title": "I NTRODUCTION TO QUASI - OPEN SET SEMI - SUPERVISED LEARNING FOR BIG DATA ANALYTICS", "authors": "E. Engelbrecht, J. D. Preez", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "ca6101451283bd33473a609ae42a3852bea8df08", "publication_date": "2024-04-19", "title": "Category-aware Filtering for Open-set Semi-Supervised Object Detection", "authors": "Yiqi Zou, Kuo Wang, Dongyu Zhang, Mingzhi Mao, Guanbin Li", "venue": "2024 5th International Conference on Computer Vision, Image and Deep Learning (CVIDL)", "citation_count": 0, "influential_citation_count": 0, "abstract": "Semi-Supervised Object Detection (SSOD) has gained significant interest in recent years. However, the majority of existing methods are based on the close-set assumption. In this paper, we address a challenging but more practical scenario, Open-Set Semi-Supervised Object Detection (OSSOD), where out-of-distribution (OOD) samples are contained in unlabeled data. The previous approach employs an offline detector to eliminate OOD pseudo labels, which is intricate and time-consuming. And the limited availability of labeled data hampers the performance of the OOD detector. In contrast, we propose a simple yet effective approach that facilitates the detector\u2019s performance in open scenarios. Specifically, we employ soft-distribution on all identified instances as our training objective to enhance the model\u2019s feature extraction capability. And we further design a radius-aware matching approach to filter OOD samples according to categories with varying diversity in unlabeled data. Our category-aware design has been proven effective through extensive experiments, surpassing current state-of-the-art work.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "866169f5b40c631dc2c81bbe2378232dff728e0a", "publication_date": "2021-05-28", "title": "OpenMatch: Open-set Consistency Regularization for Semi-supervised Learning with Outliers", "authors": "Kuniaki Saito, Donghyun Kim, Kate Saenko", "venue": "Neural Information Processing Systems", "citation_count": 65, "influential_citation_count": 20, "abstract": "Semi-supervised learning (SSL) is an effective means to leverage unlabeled data to improve a model's performance. Typical SSL methods like FixMatch assume that labeled and unlabeled data share the same label space. However, in practice, unlabeled data can contain categories unseen in the labeled set, i.e., outliers, which can significantly harm the performance of SSL algorithms. To address this problem, we propose a novel Open-set Semi-Supervised Learning (OSSL) approach called OpenMatch. Learning representations of inliers while rejecting outliers is essential for the success of OSSL. To this end, OpenMatch unifies FixMatch with novelty detection based on one-vs-all (OVA) classifiers. The OVA-classifier outputs the confidence score of a sample being an inlier, providing a threshold to detect outliers. Another key contribution is an open-set soft-consistency regularization loss, which enhances the smoothness of the OVA-classifier with respect to input transformations and greatly improves outlier detection. OpenMatch achieves state-of-the-art performance on three datasets, and even outperforms a fully supervised model in detecting outliers unseen in unlabeled data on CIFAR10.", "pdf_url": "https://arxiv.org/pdf/2105.14148.pdf", "pdf_filename": "2021-05-28_OpenMatch__Open-set_Consistency_Regularization_for.pdf", "markdown_path": "data/semantic/markdown_files/2021-05-28_OpenMatch__Open-set_Consistency_Regularization_for.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "a6adafce25ec2a1938f54922b12a2bfc7338280e", "publication_date": "2025-02-01", "title": "Robust contrastive learning based on evidential uncertainty for open-set semi-supervised industrial fault diagnosis.", "authors": "Shuaijie Chen, Chuang Peng, Lei Chen, Kuangrong Hao", "venue": "ISA transactions", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "778b1791b42eb3115b1a0ba8361e354de64ba3e5", "publication_date": "2023-10-01", "title": "Rethinking Safe Semi-supervised Learning: Transferring the Open-set Problem to A Close-set One", "authors": "Qiankun Ma, Jiyao Gao, Bo Zhan, Yunpeng Guo, Jiliu Zhou, Yan Wang", "venue": "IEEE International Conference on Computer Vision", "citation_count": 11, "influential_citation_count": 1, "abstract": "Conventional semi-supervised learning (SSL) lies in the close-set assumption that the labeled and unlabeled sets contain data with the same seen classes, called in-distribution (ID) data. In contrast, safe SSL investigates a more challenging open-set problem where unlabeled set may involve some out-of-distribution (OOD) data with unseen classes, which could harm the performance of SSL. When we are experimenting with the mainstream safe SSL methods, we have a surprising finding that all OOD data show a clear tendency to gather in the feature space. This inspires us to solve the safe SSL problem from a fresh perspective. Specifically, for a classification task with K seen classes, we utilize a prototype network not only to generate K prototypes of all seen classes, but also explicitly model an additional prototype for the OOD data, transferring the K-way classification on the open-set to the (K+1)-way on the close-set. In this way, the typical SSL techniques (e.g., consistency regularization and pseudo labeling) can be applied to tackle the safe SSL problem without additional consideration of OOD data processing like other safe SSL methods do. Particularly, considering the possible low-confidence pseudo labels, we further propose an iterative negative learning (INL) paradigm to enforce the network learning knowledge from complementary labels on wider classes, improving the network\u2019s classification performance. Extensive experiments on four benchmark datasets show that our approach remarkably lifts the performance on safe SSL and outperforms the state-of-the-art methods.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "5866785ca6c9b47af5a55f1e5ecd4f179110da31", "publication_date": "2022-07-01", "title": "End-to-End Open-Set Semi-Supervised Node Classification with Out-of-Distribution Detection", "authors": "Tiancheng Huang, Donglin Wang, Yuan Fang, Zhengyu Chen", "venue": "International Joint Conference on Artificial Intelligence", "citation_count": 11, "influential_citation_count": 0, "abstract": "Out-Of-Distribution (OOD) samples are prevalent in real-world applications. The OOD issue becomes even more severe on graph data, as the effect of OOD nodes can be potentially amplified by propagation through the graph topology. Recent works have considered the OOD detection problem, which is critical for reducing the uncertainty in learning and improving the robustness. However, no prior work considers simultaneously OOD detection and node classification on graphs in an end-to-end manner. In this paper, we study a novel problem of end-to-end open-set semi-supervised node classification (OSSNC) on graphs, which deals with node classification in the presence of OOD nodes. Given the lack of supervision on OOD nodes, we introduce a latent variable to indicate in-distribution or OOD nodes in a variational inference framework, and further propose a novel algorithm named as Learning to Mix Neighbors (LMN) which learns to dampen the influence of OOD nodes through the messaging-passing in typical graph neural networks. Extensive experiments on various datasets show that the proposed method outperforms state-of-the-art baselines in terms of both node classification and OOD detection.", "pdf_url": "https://www.ijcai.org/proceedings/2022/0290.pdf", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "3e25f2446a5346ce605a8054ca9af247f50fc3b1", "publication_date": "2023", "title": "Linking generative semi-supervised learning and generative open-set recognition", "authors": "E. Engelbrecht, J. D. Preez", "venue": "arXiv.org", "citation_count": 3, "influential_citation_count": 0, "abstract": "\u2014This study investigates the relationship between semi-supervised learning (SSL) and open-set recognition (OSR) in the context of generative adversarial networks (GANs). Although no previous study has formally linked SSL and OSR, their respective methods share striking similarities. Speci\ufb01cally, SSL-GANs and OSR-GANs require generator to produce samples in the complementary space. Subsequently, by regularising networks with generated samples, both SSL and OSR classi\ufb01ers generalize the open space. To demonstrate the connection between SSL and OSR, we theoretically and experimentally compare state-of-the-art SSL-GAN methods with state-of-the-art OSR-GAN methods. Our results indicate that the SSL optimised margin-GANs, which have a stronger foundation in literature, set the new standard for the combined SSL-OSR task and achieves new state-of-other art results in certain general OSR experiments. However, the OSR optimised adversarial reciprocal point (ARP)-GANs still slightly out-performed margin-GANs at other OSR experiments. This result indicates unique insights for the combined optimisation task of SSL-OSR.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "39e3d557378ad29d9f2546eb8199b454295daa22", "publication_date": "2023", "title": "DeCAB: Debiased Semi-supervised Learning for Imbalanced Open-Set Data", "authors": "Xiaolin Huang, Mengke Li, Yang Lu, Hanzi Wang", "venue": "Chinese Conference on Pattern Recognition and Computer Vision", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "c39cb060e8649ba017901056ce66bfb2b50796bc", "publication_date": "2021-06-29", "title": "OpenCoS: Contrastive Semi-supervised Learning for Handling Open-set Unlabeled Data", "authors": "Jongjin Park, Sukmin Yun, Jongheon Jeong, Jinwoo Shin", "venue": "ECCV Workshops", "citation_count": 29, "influential_citation_count": 1, "abstract": "Semi-supervised learning (SSL) has been a powerful strategy to incorporate few labels in learning better representations. In this paper, we focus on a practical scenario that one aims to apply SSL when unlabeled data may contain out-of-class samples - those that cannot have one-hot encoded labels from a closed-set of classes in label data, i.e., the unlabeled data is an open-set. Specifically, we introduce OpenCoS, a simple framework for handling this realistic semi-supervised learning scenario based upon a recent framework of self-supervised visual representation learning. We first observe that the out-of-class samples in the open-set unlabeled dataset can be identified effectively via self-supervised contrastive learning. Then, OpenCoS utilizes this information to overcome the failure modes in the existing state-of-the-art semi-supervised methods, by utilizing one-hot pseudo-labels and soft-labels for the identified in- and out-of-class unlabeled data, respectively. Our extensive experimental results show the effectiveness of OpenCoS under the presence of out-of-class samples, fixing up the state-of-the-art semi-supervised methods to be suitable for diverse scenarios involving open-set unlabeled data.", "pdf_url": "https://arxiv.org/pdf/2107.08943.pdf", "pdf_filename": "2021-06-29_OpenCoS__Contrastive_Semi-supervised_Learning_for_.pdf", "markdown_path": "data/semantic/markdown_files/2021-06-29_OpenCoS__Contrastive_Semi-supervised_Learning_for_.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "d8428f5231486e1d6d23e516f566625d79e08018", "publication_date": "2022-10-01", "title": "A Semi-Supervised Learning Method for Hyperspectral-Image Open Set Classification", "authors": "Zhaolin Duan, Hao Chen, Xiaohua Li, Jiliu Zhou, Yuanyuan Wang", "venue": "Photogrammetric Engineering &amp; Remote Sensing", "citation_count": 3, "influential_citation_count": 1, "abstract": "We present a conceptually simple and flexible method for hyperspectral-image open set classification. Unlike previous methods, where the abundant unlabeled data inherent in the data set are ignored completely and unknown classes are inferred using score post-calibration, our approach\n makes the unlabeled data join in and help to train a simple and practical model for open set classification. The model is able to provide an explicit decision score for both unknown classes and each known class. The main idea of the proposed method is augmenting the original training set of\n K known classes using the pseudo-labeled unknown-category samples that are detected elaborately from the unlabeled data using modified OpenMax and semi-supervised iterative learning. Then a (K + 1)-class deep convolutional neural network model is trained based on the augmented training set\n with (K + 1) class samples. The model can not only classify instances of each known class but also refuse instances of unknown class explicitly. We validated the proposed method on four well-known hyperspectral-image data sets, obtaining superior performance over previous methods.", "pdf_url": "https://doi.org/10.14358/pers.21-00067r3", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "d40d4d096b6ddce83c3fb8bfd414f7134b5e148f", "publication_date": "2025", "title": "Semi-Supervised Graph Constraint Dual Classifier Network With Unknown Class Feature Learning for Hyperspectral Image Open-Set Classification", "authors": "Na Li, Xiaopeng Song, Yongxu Liu, Wenxiang Zhu, Chuang Li, Wei-Tao Zhang, Yinghui Quan", "venue": "IEEE Geoscience and Remote Sensing Letters", "citation_count": 0, "influential_citation_count": 0, "abstract": "In view of the practical value of open datasets of hyperspectral images (HSIs), HSI open-set classification (OSC) has attracted more and more attention. Existing HSI OSC methods are usually based on learning labeled samples to identify unknown classes. However, due to the complex high-dimensional characteristics of HSIs and the limited number of labeled samples, the recognition of unknown classes based only on limited labeled samples often has low and unstable accuracy. To address this problem, we propose a semi-supervised graph constraint dual classifier network (SSGCDCN) that can achieve efficient and stable OSC by learning unknown class features and relationships among samples. First, a dual classifier consisting of a multiclassifier and multiple binary classifiers is constructed, which has the ability to discover the unknown class samples by assigning and enabling pseudo-labels to participate in model training to achieve unknown class feature learning. Then, to improve the classification accuracy of both known and unknown classes, a homogeneous graph constraint is imposed on SSGCDCN to learn the relationship information among samples (including labeled and unlabeled samples). This constraint can bring the features of similar samples closer while pushing apart features of dissimilar samples. Experiments evaluated on three datasets demonstrate that the proposed method can obtain superior OSC performance than other state-of-the-art classification methods.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "5e9d90ff6b3b06ef592808a38a32cebadd9abd69", "publication_date": "2022", "title": "Open-Set Fault Diagnosis Method for Industrial Process Based on Semi-supervised Learning", "authors": "Jiaren Liu, Hong Song, Jianguo Wang", "venue": "International Conference on Intelligent Robotics and Applications", "citation_count": 1, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "154bb63c2bdd660d86bdb07518e5bcd1740f85c3", "publication_date": "2022-08-01", "title": "CAPT: Contrastive Pre-Training based Semi-Supervised Open-Set Learning", "authors": "Zhuoyi Wang, Yibo Hu, L. Khan, Kevin W. Hamlen, B. Thuraisingham", "venue": "Conference on Multimedia Information Processing and Retrieval", "citation_count": 1, "influential_citation_count": 1, "abstract": "Deep Semi-Supervised Learning (SSL) has shown very effective performance in recent years, such methods are typically under assumptions of a closed-world setting, where instances in the labeled and unlabeled data share the same class set. However, in real-world applications, samples with novel classes may be contained in the unlabeled data during the model deployment (open-set scenario), i.e. new types of scene images may occur in a self-driving system. In this paper, we advocate a two-stage semi-supervised learning approach CAPT, a framework for handling this realistic sce-nario based on a self-supervised pre-training step. The key idea is to introduce the embedding from pre-training into the SSL open-set classifier, so that the model can recognize the seen classes and cluster the instances from novel categories simultaneously. Our framework first pre-train a semantically meaningful representation of all samples from the labeled and unlabeled dataset. Next, CAPT applies the learned embedding as initialization to build a semisupervised classifier for clustering novel classes. We thoroughly evaluate our framework on large-scale image benchmarks CIFAR10, CIFAR100, obtaining state-of-the-art results.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "4dc007686394c4e32e8a37ec480ae0e692222400", "publication_date": "2020-02-20", "title": "Multi-Task Curriculum Learning for Open-Set Semi-Supervised Recognition", "authors": "Yu Qing, Irie Go, Aizawa Kiyoharu", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "11da6c90c29fbb8ddff6eaeeea40212b6624c226", "publication_date": "2024-08-01", "title": "Open-Domain Semi-Supervised Learning via Glocal Cluster Structure Exploitation", "authors": "Zekun Li, Lei Qi, Yawen Li, Yinghuan Shi, Yang Gao", "venue": "IEEE Transactions on Knowledge and Data Engineering", "citation_count": 1, "influential_citation_count": 0, "abstract": "Semi-supervised learning (SSL) aims to reduce the heavy reliance of current deep models on costly manual annotation by leveraging a large amount of unlabeled data in combination with a much smaller set of labeled data. However, most existing SSL methods assume that all labeled and unlabeled data are drawn from the same feature distribution, which can be impractical in real-world applications. In this study, we take the initial step to systematically investigate the open-domain semi-supervised learning setting, where a feature distribution mismatch exists between labeled and unlabeled data. In pursuit of an effective solution for open-domain SSL, we propose a novel framework called GlocalMatch, which aims to exploit both global and local (i.e., glocal) cluster structure of open-domain unlabeled data. The glocal cluster structure is utilized in two complementary ways. First, GlocalMatch optimizes a Glocal Cluster Compacting (GCC) objective, that encourages feature representations of the same class, whether with in the same domain or across different domains, to become closer to each other. Second, GlocalMatch incorporates a Glocal Semantic Aggregation (GSA) strategy to produce more reliable pseudo-labels by aggregating predictions from neighboring clusters. Extensive experiments demonstrate that GlocalMatch outperforms the state-of-the-art SSL methods significantly, achieving superior performance for both in-domain and out-of-domain generalization.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "23784d956043af0c247d7e985f15be407a3edd68", "publication_date": "2023-11-06", "title": "A Graph-Theoretic Framework for Understanding Open-World Semi-Supervised Learning", "authors": "Yiyou Sun, Zhenmei Shi, Yixuan Li", "venue": "Neural Information Processing Systems", "citation_count": 23, "influential_citation_count": 1, "abstract": "Open-world semi-supervised learning aims at inferring both known and novel classes in unlabeled data, by harnessing prior knowledge from a labeled set with known classes. Despite its importance, there is a lack of theoretical foundations for this problem. This paper bridges the gap by formalizing a graph-theoretic framework tailored for the open-world setting, where the clustering can be theoretically characterized by graph factorization. Our graph-theoretic framework illuminates practical algorithms and provides guarantees. In particular, based on our graph formulation, we apply the algorithm called Spectral Open-world Representation Learning (SORL), and show that minimizing our loss is equivalent to performing spectral decomposition on the graph. Such equivalence allows us to derive a provable error bound on the clustering performance for both known and novel classes, and analyze rigorously when labeled data helps. Empirically, SORL can match or outperform several strong baselines on common benchmark datasets, which is appealing for practical usage while enjoying theoretical guarantees.", "pdf_url": "https://arxiv.org/pdf/2311.03524.pdf", "pdf_filename": "2023-11-06_A_Graph-Theoretic_Framework_for_Understanding_Open.pdf", "markdown_path": "data/semantic/markdown_files/2023-11-06_A_Graph-Theoretic_Framework_for_Understanding_Open.md"}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "7dbb50f47fbd28929dba42af64d83a8ac9680532", "publication_date": "2025-05-28", "title": "SS-OPDet: A Semi-Supervised Open-Set Detection Framework for Dead Pine Wood Detection", "authors": "Xiaojian Lu, Shiguo Huang, Songqing Wu, Feiping Zhang, Mingqing Weng, Jianlong Luo, Xiaolin Li", "venue": "Italian National Conference on Sensors", "citation_count": 0, "influential_citation_count": 0, "abstract": "Pine wilt disease poses a significant threat to pine forests worldwide, necessitating efficient and accurate detection of dead pine wood for effective disease control and forest management. Traditional deep learning methods based on supervised closed-set paradigms often struggle to address unknown interfering objects, causing false positives, missed detection, and increased annotation burdens. To overcome these challenges, we propose SS-OPDet, a semi-supervised open-set detection framework that leverages a small amount of labeled data along with abundant unlabeled data. SS-OPDet integrates a Weighted Multi-scale Feature Fusion module to dynamically integrate global- and local-scale features, thereby significantly improving representational accuracy for dead pine wood. Additionally, a Dynamic Confidence Pseudo-Label Generation strategy categorizes predictions by confidence level, effectively reducing training noise and maximizing the use of reliable unlabeled data. Experimental results from 7733 UAV images demonstrate that SS-OPDet achieves an average precision (APK) of 84.73%, a recall (RK) of 94.48%, an Absolute Open-Set Error (AOSE) of 271 and a Wilderness Impact (WI) of 0.0917%. Cross-region validation further confirms the robustness and generalization capability of the proposed framework. The proposed method offers a cost-effective and accurate solution for timely detection of pine wilt disease, providing substantial benefits to forest monitoring and management.", "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
{"query_date": "2025-06-11", "query_keyword": "Open-set semi Supervised Learning", "paper_id": "9fdd0407a09072ecf3a9fd90af492d3f391b589c", "publication_date": "2019", "title": "Operational classifier development using quasi-open set semi-supervised training and GANs", "authors": "E. Engelbrecht, J. D. Preez", "venue": "", "citation_count": 0, "influential_citation_count": 0, "abstract": null, "pdf_url": "", "pdf_filename": "", "markdown_path": ""}
